{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5fecd0",
   "metadata": {},
   "source": [
    "# Demo of the BGTM on 2-Dimensional Joe-Copula\n",
    "\n",
    "In this demonstration we show how the GTM can be used to learn a probability distribution from synthetic data sampled from a 2 dimensional Joe copula.\n",
    "To sample synthetic copula data we use the [pyvinecopulib](https://github.com/vinecopulib/pyvinecopulib) library.\n",
    "Fore more details on copulas we refer to the Book [Analyzing Dependent Data with Vine Copulas](https://link.springer.com/book/10.1007/978-3-030-13785-4) for an comprehensive introduction to copulas and vine copulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b4550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gtm import *\n",
    "\n",
    "# Sample Copulas Package\n",
    "import pyvinecopulib as pv\n",
    "\n",
    "# Other Stuff\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_helpers import Generic_Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed17c60",
   "metadata": {},
   "source": [
    "### 1. Sample Synthetic Copula Data and Compute Likelihoods\n",
    "\n",
    "We sample data from a Joe Copula and add Gaussian marginals. Feel free to exchange the copula parameter, the rotation or even the copula itsself.\n",
    "The list of copulas can be found with `help(pv.Bicop)`.\n",
    "\n",
    "Notice we use Sklars Theorem to compute the density of the joint copula and Gaussian marginals density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91426a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "copula_pv = pv.Bicop(family=pv.BicopFamily.joe, parameters=np.array([[2.5]]), rotation=90)\n",
    "\n",
    "# Train\n",
    "N_train = 2000\n",
    "simulated_data_uniform_train = copula_pv.simulate(n=N_train)\n",
    "simulated_data_train = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_train)).float()\n",
    "\n",
    "# Validate\n",
    "N_validate = 2000\n",
    "simulated_data_uniform_validate = copula_pv.simulate(n=N_validate)\n",
    "simulated_data_validate = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_validate)).float()\n",
    "\n",
    "# Test\n",
    "N_test = 20000\n",
    "simulated_data_uniform_test = copula_pv.simulate(n=N_test)\n",
    "simulated_data_test = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a347f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143635/3463905256.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/tmp/ipykernel_143635/3463905256.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/tmp/ipykernel_143635/3463905256.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_train = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_validate = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_test = (torch.tensor(loglik_copula) + log_marginals).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ae322",
   "metadata": {},
   "source": [
    "We further estimate the copula on the synthetic data to get an oracle denisity estimator. Hence an estimator that knows the true underlying structure and merely estiamtes the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab3f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_pv_est = pv.Bicop(family=pv.BicopFamily.joe, rotation=90)\n",
    "copula_pv_est.fit(simulated_data_uniform_train)\n",
    "means = simulated_data_train.mean(0)\n",
    "vars = simulated_data_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357cb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_train).sum(1)\n",
    "loglik_true_est_train = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_validate).sum(1)\n",
    "loglik_true_est_validate = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_test).sum(1)\n",
    "loglik_true_est_test = (torch.tensor(loglik_copula) + log_marginals).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cde9d2",
   "metadata": {},
   "source": [
    "The package is implemented to use Dataloaders for training. This is done to accommodate larger datasets trained batch wise as is common in deep learning and bioinformatics applications. Feel free to use the [`Generic_Dataset`](demos/dataset_helpers.py) class to easily adjust it to your data. For full data training, thus whithout batches simply seet the `batch_size` arguement in the `DataLoader` to the data size as we do in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83659cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and DataLoader\n",
    "dataset_train = Generic_Dataset(simulated_data_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=50)\n",
    "\n",
    "dataset_validate = Generic_Dataset(simulated_data_validate)\n",
    "dataloader_validate = DataLoader(dataset_validate, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c111eb",
   "metadata": {},
   "source": [
    "### 2. Define Model\n",
    "\n",
    "We define a simple GTM model with the standard parameters.\n",
    "Notable custamizable parameter are: \n",
    "- The dimensionality of the data `number_variables`\n",
    "- The number of transformation layers `num_trans_layers`, either 0 or 1.\n",
    "- The number of decorrelation layers `num_decorr_layers`, typically 3 or more. \n",
    "- the spline to use for the transformation layer splines `spline_transformation` and the decorrelation layer splines `spline_decorrelation`.  The two types of layers: P-Splines (`bspline`) or bernstein polynomials (`bernstein`).\n",
    "- The degrees of the splines, representing there flexibility, being `degree_decorrelation` for the decorrelation layer splines and `degree_transformations` for the transformation layer. When using `bspline`, then `degree_transformations` can also be given a list with varying degrees for each dimension of the data.\n",
    "- `transformation_spline_range`sets the outer borders for the transformation layer splines, this dependends on the input data and should be set a bit wider then the actual data.\n",
    "- `device` either `cpu`or `cuda`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8347a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-10-27 17:08:24,531] A new study created in RDB with name: no-name-e279e6c9-c21a-4da0-bcd6-c32ce7207890\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:595: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  x=input_a_clone.T, t=knots.T, c=params_a.T, p=order, d=derivativ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<35:27,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5338, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4214942455291748\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<28:08,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5295, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.419033169746399\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5058, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:47,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5304, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.415461540222168\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<24:47,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5311, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.414026141166687\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:05<46:46,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5329, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4126477241516113\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5348, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:09<1:09:47,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5341, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4118887186050415\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5114, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:10<1:06:43,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5349, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4116885662078857\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:13<1:09:50,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5359, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.410987377166748\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5452, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:15<1:05:49,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5405, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4099438190460205\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4754, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:16<57:08,  1.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5382, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4098081588745117\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:16<46:31,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5373, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4106369018554688\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:17<39:40,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5430, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4092146158218384\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4863, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:18<34:29,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.409685492515564\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:18<31:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5394, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.409430980682373\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(7.6567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:19<28:37,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5396, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4094804525375366\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.9202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5349, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:20<27:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.411155343055725\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4759, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:21<43:41,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5311, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4175901412963867\n",
      "Early Stop at iteration 16 with minimal loss tensor(1.4092) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<47:21,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4078, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3702492713928223\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.8337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(13.4728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4113, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3575663566589355\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:17,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3764488697052002\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:05<47:46,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3846849203109741\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:07<47:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3970, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.387393832206726\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:08<47:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3723405599594116\n",
      "current_loss: tensor(1.1885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:10<56:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3736118078231812\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3576) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:08:59,099] Trial 0 finished with value: -2.5464470982551575 and parameters: {'penalty_decorrelation_ridge_first_difference': 9.565537490949405, 'penalty_decorrelation_ridge_second_difference': 1.0129298378628733}. Best is trial 0 with value: -2.5464470982551575.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4056, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3644204139709473\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<50:03,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3696078062057495\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3642982244491577\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4115, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:03:43,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3768928050994873\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:58:14,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3747689723968506\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.8423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9745, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:08:58,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4044, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3862566947937012\n",
      "current_loss: tensor(1.1854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:19<1:48:03,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3799102306365967\n",
      "current_loss: tensor(1.1720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(20.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:41:38,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3785406351089478\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3643) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:09:21,542] Trial 1 finished with value: -2.5286944687366484 and parameters: {'penalty_decorrelation_ridge_first_difference': 17.96873530761529, 'penalty_decorrelation_ridge_second_difference': 6.746854647408776}. Best is trial 1 with value: -2.5286944687366484.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<52:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3803671598434448\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<50:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.375882863998413\n",
      "current_loss: tensor(1.1747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<50:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.4037302732467651\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:21:39,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3760333061218262\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:09:01,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3864364624023438\n",
      "current_loss: tensor(1.1620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:19<2:15:22,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3786343336105347\n",
      "current_loss: tensor(1.1549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:22<2:02:29,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.379348874092102\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3759) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:09:44,718] Trial 2 finished with value: -2.5019510090351105 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.6008407042162909, 'penalty_decorrelation_ridge_second_difference': 1.2032238777610447}. Best is trial 2 with value: -2.5019510090351105.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4142, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:05,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4134, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3635119199752808\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<48:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4176, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3587827682495117\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.9705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4073, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.365264892578125\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4103, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:09:32,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4080, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3661304712295532\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:03:58,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4033, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3723061084747314\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:10:06,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4026, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.371767520904541\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:20<1:54:17,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4057, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3695755004882812\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3588) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:10:06,306] Trial 3 finished with value: -2.5522674560546874 and parameters: {'penalty_decorrelation_ridge_first_difference': 28.250829996228592, 'penalty_decorrelation_ridge_second_difference': 16.417074387166256}. Best is trial 2 with value: -2.5019510090351105.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<52:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3738425970077515\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<50:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3829050064086914\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:24,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3725385665893555\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(515.5336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:25:25,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3662688732147217\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:04:57,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3694554567337036\n",
      "current_loss: tensor(1.1654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:04:48,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3727707862854004\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:56:31,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3782920837402344\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.4544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:22<1:35:54,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3817962408065796\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:24<1:41:07,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3791625499725342\n",
      "Early Stop at iteration 8 with minimal loss tensor(1.3663) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:10:31,651] Trial 4 finished with value: -2.498746359348297 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.1870160067926541, 'penalty_decorrelation_ridge_second_difference': 7.337048917454604}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3650223016738892\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(25.6739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<50:14,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3770865201950073\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<50:13,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3694534301757812\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3927, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:15:27,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3705159425735474\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:00:43,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3723151683807373\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:18<2:02:01,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3773759603500366\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3650) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:10:51,518] Trial 5 finished with value: -2.528251510858536 and parameters: {'penalty_decorrelation_ridge_first_difference': 8.939714123068471, 'penalty_decorrelation_ridge_second_difference': 6.799020340087907}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4126, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.364755392074585\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<50:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4111, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.364564061164856\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3710764646530151\n",
      "current_loss: tensor(1.1949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4066, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:11:54,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3678988218307495\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(92.9580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.9707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:51:54,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3687553405761719\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:02:01,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3652770519256592\n",
      "current_loss: tensor(1.1873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:19<1:45:46,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4057, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3691569566726685\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3646) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:11:11,692] Trial 6 finished with value: -2.5442174792289736 and parameters: {'penalty_decorrelation_ridge_first_difference': 24.395642094202017, 'penalty_decorrelation_ridge_second_difference': 26.200287365373338}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4126, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:50,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4108, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.363290548324585\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4087, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<54:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3646453619003296\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<50:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3655139207839966\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:09<1:28:41,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3647934198379517\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:16<2:23:15,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4071, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3728671073913574\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:19<2:11:38,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3658356666564941\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3633) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:11:33,434] Trial 7 finished with value: -2.545306611061096 and parameters: {'penalty_decorrelation_ridge_first_difference': 24.57232002430748, 'penalty_decorrelation_ridge_second_difference': 25.26838064410493}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4103, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:26,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3638354539871216\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<48:28,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3651882410049438\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4057, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3650113344192505\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:06:10,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.369103193283081\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:59:30,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.367275595664978\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:18<2:01:13,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.369697093963623\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3638) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:11:53,267] Trial 8 finished with value: -2.542709821462631 and parameters: {'penalty_decorrelation_ridge_first_difference': 22.571157095528438, 'penalty_decorrelation_ridge_second_difference': 16.40172069287037}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4175, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:36,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3650730848312378\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<48:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3730063438415527\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:33,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3675520420074463\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3666.0203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:12:33,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3699405193328857\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4085, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:52:08,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3715144395828247\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(9.4641, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:17<1:56:35,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3668164014816284\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3651) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:12:12,149] Trial 9 finished with value: -2.5511120438575743 and parameters: {'penalty_decorrelation_ridge_first_difference': 28.894580794000433, 'penalty_decorrelation_ridge_second_difference': 16.546427220626782}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<48:19,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3706570863723755\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(8.9265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:39,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3651260137557983\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:16,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3890811204910278\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3964, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:06<1:03:32,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3768244981765747\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:53:32,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3720664978027344\n",
      "current_loss: tensor(1.1750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:03:09,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3704500198364258\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:20<1:53:11,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3729965686798096\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3651) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:12:34,567] Trial 10 finished with value: -2.5215911746025084 and parameters: {'penalty_decorrelation_ridge_first_difference': 3.9374171763341126, 'penalty_decorrelation_ridge_second_difference': 18.83174529004336}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(19.6428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3610836267471313\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4039, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3693219423294067\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4030, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3668701648712158\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.7251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4034, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:04:37,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3659732341766357\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4034, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:58:41,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.365005612373352\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4033, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:18<2:03:33,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4021, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3667771816253662\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3611) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:12:55,114] Trial 11 finished with value: -2.548883718252182 and parameters: {'penalty_decorrelation_ridge_first_difference': 17.897610058373353, 'penalty_decorrelation_ridge_second_difference': 28.22366022905861}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<59:53,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4099, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3630660772323608\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<53:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3636581897735596\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<54:11,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4000, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3639332056045532\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:10<1:43:23,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3970, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3687721490859985\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:15<2:02:45,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3690712451934814\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:18<2:04:43,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3671929836273193\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3631) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:13:15,732] Trial 12 finished with value: -2.5457634389400483 and parameters: {'penalty_decorrelation_ridge_first_difference': 16.737591001950577, 'penalty_decorrelation_ridge_second_difference': 15.928701318023503}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4278, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4058, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3597177267074585\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(72.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4035, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.372231125831604\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(7.9912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(20.6208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(81.0582, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:51,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3617397546768188\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(104.0994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(115.1114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:13:52,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3953, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3734725713729858\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<2:00:52,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.366550326347351\n",
      "current_loss: tensor(1.1769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:18<2:00:39,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3681979179382324\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3597) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:13:35,727] Trial 13 finished with value: -2.53701274394989 and parameters: {'penalty_decorrelation_ridge_first_difference': 10.629677055324859, 'penalty_decorrelation_ridge_second_difference': 4.733341338145697}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.0663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<48:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.365847110748291\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:40,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4108, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3649929761886597\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3633962869644165\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:06:13,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3652448654174805\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:54:13,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3656408786773682\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4056, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:03:23,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3646531105041504\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:20<1:54:26,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3654783964157104\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:43:22,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3803770542144775\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3634) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:13:58,770] Trial 14 finished with value: -2.5400994956493377 and parameters: {'penalty_decorrelation_ridge_first_difference': 27.667930830774925, 'penalty_decorrelation_ridge_second_difference': 2.3565637244327933}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(8.0456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3687891960144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:30,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3777927160263062\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:55,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3793078660964966\n",
      "current_loss: tensor(1.1751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:07:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3777316808700562\n",
      "current_loss: tensor(1.1669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.6983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:15<2:20:09,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.7320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3790663480758667\n",
      "current_loss: tensor(1.1685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:19<2:12:47,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3832228183746338\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3688) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:14:20,901] Trial 15 finished with value: -2.5199695229530334 and parameters: {'penalty_decorrelation_ridge_first_difference': 1.0614865931993362, 'penalty_decorrelation_ridge_second_difference': 9.956289501558754}. Best is trial 4 with value: -2.498746359348297.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.1144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<52:33,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3734257221221924\n",
      "current_loss: tensor(1.1741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.8892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<54:30,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.374965786933899\n",
      "current_loss: tensor(1.1826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<52:37,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3712091445922852\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:09<1:37:49,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3872321844100952\n",
      "current_loss: tensor(1.1640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3895, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<1:54:10,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3775274753570557\n",
      "current_loss: tensor(1.1669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(11.6958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:04:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3688007593154907\n",
      "current_loss: tensor(1.1616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.8287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:20<1:42:33,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.379530906677246\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.7990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:21<1:25:13,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3900178670883179\n",
      "current_loss: tensor(1.1538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:23<1:13:56,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3889093399047852\n",
      "current_loss: tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.9718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:24<1:05:57,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.379438877105713\n",
      "current_loss: tensor(1.1556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:26<1:26:22,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3901945352554321\n",
      "Early Stop at iteration 10 with minimal loss tensor(1.3688) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:14:47,860] Trial 16 finished with value: -2.493683874607086 and parameters: {'penalty_decorrelation_ridge_first_difference': 3.420672228709569, 'penalty_decorrelation_ridge_second_difference': 0.6593198023803968}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<48:35,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.373207449913025\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:15,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3618658781051636\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(5.7088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3781765699386597\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:07:27,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3738521337509155\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3953, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:58:29,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3844410181045532\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.0675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:02:17,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3808571100234985\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1889, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:20<1:51:45,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3795623779296875\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3619) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:15:09,235] Trial 17 finished with value: -2.527888172864914 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.094024796473833, 'penalty_decorrelation_ridge_second_difference': 12.024231881154204}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.373785376548767\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<48:11,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3764228820800781\n",
      "current_loss: tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:37,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3668626546859741\n",
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:06<1:00:18,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.370065450668335\n",
      "current_loss: tensor(1.1825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:55:38,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3726816177368164\n",
      "current_loss: tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:04:40,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3795133829116821\n",
      "current_loss: tensor(1.1673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(46.6656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:19<1:48:56,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.377596378326416\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:40:33,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3809878826141357\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3669) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:15:31,409] Trial 18 finished with value: -2.512417286634445 and parameters: {'penalty_decorrelation_ridge_first_difference': 2.373518024446126, 'penalty_decorrelation_ridge_second_difference': 5.347622532253572}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.4162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4068, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.364473581314087\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4043, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.365883231163025\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:25,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.372025489807129\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.6680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:08:29,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3987, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.367671012878418\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4009, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:11:13,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3716323375701904\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.0798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4039, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:19<2:15:52,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3631716966629028\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1889, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:56:18,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3740684986114502\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:22<1:34:37,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3631234169006348\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.6113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:24<1:19:57,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3991, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3750355243682861\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:25<1:09:28,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3664900064468384\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.9362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:27<1:02:48,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3780620098114014\n",
      "current_loss: tensor(1.1798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.6848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:28<57:32,  1.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3744690418243408\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:29<1:22:24,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.380323052406311\n",
      "Early Stop at iteration 12 with minimal loss tensor(1.3631) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:16:02,485] Trial 19 finished with value: -2.519848132133484 and parameters: {'penalty_decorrelation_ridge_first_difference': 19.27453583395001, 'penalty_decorrelation_ridge_second_difference': 0.4292218604558379}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<46:56,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3639808893203735\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4382, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:34,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3598898649215698\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:14,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3634436130523682\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:09:33,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.371291160583496\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<2:01:46,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3658478260040283\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:03:42,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.381279468536377\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:20<1:54:55,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(2.0360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.374109148979187\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3599) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:16:24,396] Trial 20 finished with value: -2.539899241924286 and parameters: {'penalty_decorrelation_ridge_first_difference': 12.104177058744288, 'penalty_decorrelation_ridge_second_difference': 15.671329196363219}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3827725648880005\n",
      "current_loss: tensor(1.1854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<47:58,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3700822591781616\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:27,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3964, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.368417501449585\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:06<1:03:03,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.371212363243103\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4026, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:12<1:51:35,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3661689758300781\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:16<1:59:37,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3790452480316162\n",
      "current_loss: tensor(1.1599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:19<1:49:41,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.388410210609436\n",
      "current_loss: tensor(1.1664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.1065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:21<1:30:11,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3782223463058472\n",
      "current_loss: tensor(1.1595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.1334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:22<1:16:54,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.372969627380371\n",
      "current_loss: tensor(1.1640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.9661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:24<1:29:32,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.384518027305603\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3662) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:16:49,613] Trial 21 finished with value: -2.4974878311157225 and parameters: {'penalty_decorrelation_ridge_first_difference': 1.6883550311196522, 'penalty_decorrelation_ridge_second_difference': 2.2126313915446882}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3734699487686157\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3815253973007202\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3725541830062866\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:13:37,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3702380657196045\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(inf, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(inf, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(inf, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(390.5030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:05:59,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.375758171081543\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4132, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:13:37,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4087, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3703407049179077\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.0571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.1250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<2:03:06,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3689777851104736\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:23<1:38:29,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3737422227859497\n",
      "current_loss: tensor(1.1622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:24<1:23:15,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3741707801818848\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.6088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:26<1:12:56,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3872319459915161\n",
      "current_loss: tensor(1.1639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(36.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:27<1:05:23,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3695359230041504\n",
      "current_loss: tensor(1.1651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1195.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.9320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:29<1:27:57,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3874, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.376134991645813\n",
      "Early Stop at iteration 11 with minimal loss tensor(1.3690) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:17:19,741] Trial 22 finished with value: -2.494502365589142 and parameters: {'penalty_decorrelation_ridge_first_difference': 4.134892514323171, 'penalty_decorrelation_ridge_second_difference': 0.22896827644356055}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.379317283630371\n",
      "current_loss: tensor(1.1853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.6702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5646, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3826005458831787\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(9.5919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<52:36,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3669371604919434\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.7157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:18:54,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3833483457565308\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:02:18,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3812992572784424\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:08:54,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3891679048538208\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:54:36,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.387052059173584\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:22<1:46:54,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3848613500595093\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3669) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:17:43,247] Trial 23 finished with value: -2.5083617746829985 and parameters: {'penalty_decorrelation_ridge_first_difference': 3.793341720942194, 'penalty_decorrelation_ridge_second_difference': 0.06496676353662312}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3970, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:39,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3792494535446167\n",
      "current_loss: tensor(1.1847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:40,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3645967245101929\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.1111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4018, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.357825517654419\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:13:53,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.369459629058838\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:54:08,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3562424182891846\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.8523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.8047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:02:57,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.389671802520752\n",
      "current_loss: tensor(1.1836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:20<1:49:18,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3750741481781006\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(7.9989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1772, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:21<1:29:49,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3770583868026733\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:23<1:19:13,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3904, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.373888373374939\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(10.9453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(55.0902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:24<1:31:05,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3706437349319458\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3562) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:18:09,107] Trial 24 finished with value: -2.518212193250656 and parameters: {'penalty_decorrelation_ridge_first_difference': 9.496012108463281, 'penalty_decorrelation_ridge_second_difference': 0.2095337364129874}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(7.6132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3782200813293457\n",
      "current_loss: tensor(1.1830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3719682693481445\n",
      "current_loss: tensor(1.1783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.5183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(199.4169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3784080743789673\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(43.5170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:17:25,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3745911121368408\n",
      "current_loss: tensor(1.1667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:14<2:07:55,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3726381063461304\n",
      "current_loss: tensor(1.1623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.6427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<2:12:44,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3722211122512817\n",
      "current_loss: tensor(1.1609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:21<1:58:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3728944063186646\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3720) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:18:31,774] Trial 25 finished with value: -2.5070626497268678 and parameters: {'penalty_decorrelation_ridge_first_difference': 1.2975144751034673, 'penalty_decorrelation_ridge_second_difference': 1.0909001163361585}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(8.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3663225173950195\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3721154928207397\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:44,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3647940158843994\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:10:46,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3798047304153442\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:15<2:14:55,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3740227222442627\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3946, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:19<2:15:32,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3743385076522827\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:52:58,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.375959038734436\n",
      "current_loss: tensor(1.1772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:22<1:47:20,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3770958185195923\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3648) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:18:55,349] Trial 26 finished with value: -2.5250040709972383 and parameters: {'penalty_decorrelation_ridge_first_difference': 8.508585435042196, 'penalty_decorrelation_ridge_second_difference': 9.58833844203108}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<50:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3801875114440918\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3552, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3702569007873535\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3661394119262695\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:18:42,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3734540939331055\n",
      "current_loss: tensor(1.1745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:55:43,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3704403638839722\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3898, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:03:11,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.375625729560852\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3920, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:20<1:48:21,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.372499704360962\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:21<1:42:18,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3746790885925293\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3661) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:19:17,921] Trial 27 finished with value: -2.5120397448539733 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.016537416157321, 'penalty_decorrelation_ridge_second_difference': 6.476576977410289}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:56,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4052, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3575336933135986\n",
      "current_loss: tensor(1.2089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<48:30,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3958, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3697574138641357\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<48:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4060, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3564566373825073\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(10.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:12:07,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.364212989807129\n",
      "current_loss: tensor(1.1893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.0337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(18.8814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:59:30,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4092, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3534823656082153\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(20.0108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(22.1147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:17<2:01:07,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3707756996154785\n",
      "current_loss: tensor(1.1910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.8869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.9591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:20<1:52:02,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.369186520576477\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:21<1:31:34,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3770179748535156\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:23<1:21:03,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3916, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3782109022140503\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:24<1:32:09,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3924, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3772850036621094\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3535) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:19:43,932] Trial 28 finished with value: -2.528326392173767 and parameters: {'penalty_decorrelation_ridge_first_difference': 13.85257259258218, 'penalty_decorrelation_ridge_second_difference': 0.07665729932735715}. Best is trial 16 with value: -2.493683874607086.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.6727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<49:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3919, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3624728918075562\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:02<49:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3739228248596191\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<47:48,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3693448305130005\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:06<1:03:34,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3782135248184204\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:12<1:51:17,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3943, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3707613945007324\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:17<1:53:25,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3721580505371094\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3625) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 17:20:02,511] Trial 29 finished with value: -2.5384113669395445 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.163394711510154, 'penalty_decorrelation_ridge_second_difference': 0.5662473941176307}. Best is trial 16 with value: -2.493683874607086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter_tuning done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_freq = GTM(\n",
    "    number_variables = 2,\n",
    "    number_transformation_layers = 1,\n",
    "    number_decorrelation_layers = 3,\n",
    "    degree_transformations = 10,\n",
    "    degree_decorrelation = 40,\n",
    "    spline_transformation = \"bspline\",\n",
    "    spline_decorrelation = \"bspline\",\n",
    "    transformation_spline_range = (-10, 10),\n",
    "    device = device) \n",
    "\n",
    "study = model_freq.hyperparameter_tune_penalties( \n",
    "        train_dataloader = dataloader_train,\n",
    "        validate_dataloader = dataloader_validate,\n",
    "        penalty_decorrelation_ridge_param = None,\n",
    "        penalty_decorrelation_ridge_first_difference = \"sample\",\n",
    "        penalty_decorrelation_ridge_second_difference = \"sample\",\n",
    "        penalty_transformation_ridge_second_difference = None,\n",
    "        penalty_lasso_conditional_independence = None,\n",
    "        adaptive_lasso_weights_matrix=False,\n",
    "        optimizer=\"LBFGS\",\n",
    "        learning_rate=1,\n",
    "        iterations=2000,\n",
    "        patience=5,\n",
    "        min_delta=1e-7,\n",
    "        seperate_copula_training=False,\n",
    "        max_batches_per_iter=False,\n",
    "        pretrained_transformation_layer=True,\n",
    "        n_trials=30,\n",
    "        temp_folder=\".\",\n",
    "        study_name=None)\n",
    "        \n",
    "\n",
    "penalty_splines_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penalty_decorrelation_ridge_param\"],\n",
    "                            study.best_params[\"penalty_decorrelation_ridge_first_difference\"],\n",
    "                            study.best_params[\"penalty_decorrelation_ridge_second_difference\"],\n",
    "                            0 #study.best_params[\"penalty_transformation_ridge_second_difference\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "penalty_lasso_conditional_independence=False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7c3a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<11:55,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4134, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:01<11:58,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:02<11:31,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:02<11:24,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:03<11:14,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4743, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:04<11:03,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5251, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:04<13:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5349, grad_fn=<MeanBackward0>)\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.5298, grad_fn=<MeanBackward0>) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pretrain the marginal transformations\n",
    "_ = model_freq.pretrain_transformation_layer(dataloader_train, iterations=1000, max_batches_per_iter=False, penalty_splines_params=penalty_splines_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36290e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:05<1:30:20,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3713107109069824\n",
      "current_loss: tensor(1.2139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.9824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3922, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:12<1:41:32,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3719907999038696\n",
      "current_loss: tensor(1.2033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:15<1:21:18,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3813331127166748\n",
      "current_loss: tensor(1.1834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(316.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:17<1:00:01,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3903, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3777328729629517\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.0694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:18<47:07,  2.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3917, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.367738962173462\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(8.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:20<39:15,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.373083233833313\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:21<34:06,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3897, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.371626377105713\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:22<30:52,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3823, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.380102276802063\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:24<28:42,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3794221878051758\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.1270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.7610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:25<47:19,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3933, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.376896858215332\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3677) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = model_freq.train(train_dataloader=dataloader_train, validate_dataloader=dataloader_validate, iterations=1000, optimizer=\"LBFGS\",\n",
    "                penalty_splines_params=penalty_splines_params, adaptive_lasso_weights_matrix=adaptive_lasso_weights_matrix, penalty_lasso_conditional_independence=penalty_lasso_conditional_independence, \n",
    "                max_batches_per_iter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb434f3d",
   "metadata": {},
   "source": [
    "The GTM class contains a number of plotting functions so that standard analysis can be done soley with the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41ca3e",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tune and Train Model\n",
    "\n",
    "To find the optimal penalties one uses the `hyperparameter_tune_penalties` function. Then using the optimal penalties one can train the model.\n",
    "\n",
    "The training can be done by pretraining the marginal transformations with `pretrain_tranformation_layer` and then training jointly with `train`.\n",
    "In general empirically we found that pretraining reduces training time and improves results allthough direct joint training also works.\n",
    "\n",
    "Hyperparameter tuning can be done for the penalties `penvalueridge, penfirstridge , pensecondridge, ctm_pensecondridge, lambda_penalty_params` by passing the arguement `\"sample\"`.\n",
    "If a fixed number is passed, typically zero, then for that penalty no hyperparameter drawing is done and the fixed values is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807c8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters to be affected by the bayesian approach: ['transformation.params.0', 'transformation.params.1', 'decorrelation_layers.0.params', 'decorrelation_layers.1.params', 'decorrelation_layers.2.params']\n",
      "The selected hyperparameters for the transformation layer,\n",
      "the hyperparameters lambda_a=1.100000023841858 and lambda_b=0.0010000000474974513 were selected and will by processed.\n",
      "You are currently using the Full Bayesian Closed form coordinate-ascent VI (CAVI)\n",
      "The selected hyperparameters for tau_1 of the decorrelation layers,\n",
      "the hyperparameters lambda_a=1.5 and lambda_b=0.009999999776482582 were selected and will by processed.\n",
      "The selected hyperparameters for tau_1 of the decorrelation layers,\n",
      "the hyperparameters lambda_a=1.5 and lambda_b=0.009999999776482582 were selected and will by processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sanity] N=2000  current B=50  (training objective uses scaled likelihood & unscaled prior)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:08<27:45,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[1/200] \n",
      "ELBO train=3839.4429  val_ELPD=-0.0414  train_ELPD=-0.0326  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=3.00    N=2000 B=50 B50.0  priors/obs: decor24.9 trans3.8e+03\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.648012  rank=20  E_qf_mean17.1  E_qf_total34.3  tau*E_qf22.2  target22.2  resid-1.9e+05    tau4_mean=0.648   Elog_tau4=-0.48    a_tau4=11.1     b_tau4=17.1  _tau4=-1.11e+04      KL(q||p)0.00411\n",
      "Tau_1 obs and tracking\n",
      "tau1=264.34583375681126     rank=82  E_qf1_total=0.30154847651720046   tau_1*E_qf=79.7    resid_qf2-641    tau1_mean=264   Elog_tau1=5.57    a_tau1=42.5     b_tau1=0.161  _tau1=-3.99e+03      KL(q||p)0.0186\n",
      "Tau_2 obs and tracking\n",
      "tau2=265.9792793179335     rank=80  E_qf1_total=0.29205438382923604   tau_2*E_qf=77.7    resid_qf2-606    tau2_mean=266   Elog_tau2=5.57    a_tau2=41.5     b_tau2=0.156  _tau2=-3.88e+03      KL(q||p)0.0181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:16<27:33,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[2/200] \n",
      "ELBO train=17.0170  val_ELPD=-0.0284  train_ELPD=-0.0325  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.90    N=2000 B=50 B50.0  priors/obs: decor1.63 trans0.43\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.736147  rank=20  E_qf_mean15.1  E_qf_total30.2  tau*E_qf22.2  target22.2  resid1.33    tau4_mean=0.736   Elog_tau4=-0.352    a_tau4=11.1     b_tau4=15.1  _tau4=+8.81e-02      KL(q||p)0.00392\n",
      "Tau_1 obs and tracking\n",
      "tau1=255.335267996947     rank=82  E_qf1_total=0.3128956504166126   tau_1*E_qf=79.9    resid_qf2-1.5    tau1_mean=255   Elog_tau1=5.53    a_tau1=42.5     b_tau1=0.166  _tau1=-9.01e+00      KL(q||p)0.000767\n",
      "Tau_2 obs and tracking\n",
      "tau2=258.49727085888674     rank=80  E_qf1_total=0.30108656249940396   tau_2*E_qf=77.8    resid_qf2-1.2    tau2_mean=258   Elog_tau2=5.54    a_tau2=41.5     b_tau2=0.161  _tau2=-7.48e+00      KL(q||p)0.000765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 3/200 [00:25<27:24,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[3/200] \n",
      "ELBO train=16.2890  val_ELPD=-0.0268  train_ELPD=-0.0277  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.80    N=2000 B=50 B50.0  priors/obs: decor1.55 trans0.385\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.765497  rank=20  E_qf_mean14.5  E_qf_total29  tau*E_qf22.2  target22.2  resid0.426    tau4_mean=0.765   Elog_tau4=-0.313    a_tau4=11.1     b_tau4=14.5  _tau4=+2.93e-02      KL(q||p)0.00385\n",
      "Tau_1 obs and tracking\n",
      "tau1=258.94947033521964     rank=82  E_qf1_total=0.3082493685185909   tau_1*E_qf=79.8    resid_qf20.593    tau1_mean=259   Elog_tau1=5.54    a_tau1=42.5     b_tau1=0.164  _tau1=+3.61e+00      KL(q||p)0.000748\n",
      "Tau_2 obs and tracking\n",
      "tau2=262.41062255510514     rank=80  E_qf1_total=0.2962981715798378   tau_2*E_qf=77.8    resid_qf20.619    tau2_mean=262   Elog_tau2=5.56    a_tau2=41.5     b_tau2=0.158  _tau2=+3.91e+00      KL(q||p)0.000749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 4/200 [00:33<27:18,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[4/200] \n",
      "ELBO train=15.8010  val_ELPD=-0.0263  train_ELPD=-0.0268  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.70    N=2000 B=50 B50.0  priors/obs: decor1.6 trans0.314\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.812885  rank=20  E_qf_mean13.7  E_qf_total27.3  tau*E_qf22.2  target22.2  resid0.647    tau4_mean=0.813   Elog_tau4=-0.253    a_tau4=11.1     b_tau4=13.7  _tau4=+4.74e-02      KL(q||p)0.00383\n",
      "Tau_1 obs and tracking\n",
      "tau1=256.4167469502968     rank=82  E_qf1_total=0.311491609364748   tau_1*E_qf=79.9    resid_qf2-0.42    tau1_mean=256   Elog_tau1=5.53    a_tau1=42.5     b_tau1=0.166  _tau1=-2.53e+00      KL(q||p)0.000756\n",
      "Tau_2 obs and tracking\n",
      "tau2=257.3917708767119     rank=80  E_qf1_total=0.30246563218533995   tau_2*E_qf=77.9    resid_qf2-0.809    tau2_mean=257   Elog_tau2=5.54    a_tau2=41.5     b_tau2=0.161  _tau2=-5.02e+00      KL(q||p)0.000757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 5/200 [00:41<27:09,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[5/200] \n",
      "ELBO train=15.2287  val_ELPD=-0.0260  train_ELPD=-0.0265  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.60    N=2000 B=50 B50.0  priors/obs: decor1.52 trans0.237\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.877114  rank=20  E_qf_mean12.7  E_qf_total25.3  tau*E_qf22.2  target22.2  resid0.813    tau4_mean=0.877   Elog_tau4=-0.177    a_tau4=11.1     b_tau4=12.7  _tau4=+6.42e-02      KL(q||p)0.0038\n",
      "Tau_1 obs and tracking\n",
      "tau1=266.41935946755245     rank=82  E_qf1_total=0.29904588423669337   tau_1*E_qf=79.7    resid_qf21.6    tau1_mean=266   Elog_tau1=5.57    a_tau1=42.5     b_tau1=0.16  _tau1=+1.00e+01      KL(q||p)0.00075\n",
      "Tau_2 obs and tracking\n",
      "tau2=267.1240388528368     rank=80  E_qf1_total=0.2907170753926039   tau_2*E_qf=77.7    resid_qf21.51    tau2_mean=267   Elog_tau2=5.58    a_tau2=41.5     b_tau2=0.155  _tau2=+9.73e+00      KL(q||p)0.000747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 6/200 [00:50<27:01,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[6/200] \n",
      "ELBO train=14.6219  val_ELPD=-0.0260  train_ELPD=-0.0264  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0514 min=0.0503 max=0.0520  _KL=2.50    N=2000 B=50 B50.0  priors/obs: decor1.67 trans0.172\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.94286  rank=20  E_qf_mean11.8  E_qf_total23.5  tau*E_qf22.2  target22.2  resid0.774    tau4_mean=0.943   Elog_tau4=-0.105    a_tau4=11.1     b_tau4=11.8  _tau4=+6.57e-02      KL(q||p)0.00376\n",
      "Tau_1 obs and tracking\n",
      "tau1=252.90312831326924     rank=82  E_qf1_total=0.3160970687866211   tau_1*E_qf=79.9    resid_qf2-2.27    tau1_mean=253   Elog_tau1=5.52    a_tau1=42.5     b_tau1=0.168  _tau1=-1.35e+01      KL(q||p)0.000772\n",
      "Tau_2 obs and tracking\n",
      "tau2=252.85460346806568     rank=80  E_qf1_total=0.3082518845796585   tau_2*E_qf=77.9    resid_qf2-2.34    tau2_mean=253   Elog_tau2=5.52    a_tau2=41.5     b_tau2=0.164  _tau2=-1.43e+01      KL(q||p)0.000767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 7/200 [00:58<26:53,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 1\n",
      "Iteration\n",
      "[7/200] \n",
      "ELBO train=13.8925  val_ELPD=-0.0260  train_ELPD=-0.0264  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0527 min=0.0513 max=0.0541  _KL=2.40    N=2000 B=50 B50.0  priors/obs: decor1.7 trans0.135\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.991187  rank=20  E_qf_mean11.2  E_qf_total22.4  tau*E_qf22.2  target22.2  resid0.541    tau4_mean=0.991   Elog_tau4=-0.0546    a_tau4=11.1     b_tau4=11.2  _tau4=+4.83e-02      KL(q||p)0.00372\n",
      "Tau_1 obs and tracking\n",
      "tau1=235.99295136425573     rank=82  E_qf1_total=0.3401802495121956   tau_1*E_qf=80.3    resid_qf2-3.05    tau1_mean=236   Elog_tau1=5.45    a_tau1=42.5     b_tau1=0.18  _tau1=-1.69e+01      KL(q||p)0.000743\n",
      "Tau_2 obs and tracking\n",
      "tau2=236.88228927343417     rank=80  E_qf1_total=0.33038499653339387   tau_2*E_qf=78.3    resid_qf2-2.8    tau2_mean=237   Elog_tau2=5.46    a_tau2=41.5     b_tau2=0.175  _tau2=-1.60e+01      KL(q||p)0.000737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 8/200 [01:06<26:44,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 2\n",
      "Iteration\n",
      "[8/200] \n",
      "ELBO train=13.1795  val_ELPD=-0.0260  train_ELPD=-0.0264  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0540 min=0.0520 max=0.0562  _KL=2.30    N=2000 B=50 B50.0  priors/obs: decor1.6 trans0.0886\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.04882  rank=20  E_qf_mean10.6  E_qf_total21.2  tau*E_qf22.2  target22.2  resid0.61    tau4_mean=1.05   Elog_tau4=0.00195    a_tau4=11.1     b_tau4=10.6  _tau4=+5.76e-02      KL(q||p)0.00369\n",
      "Tau_1 obs and tracking\n",
      "tau1=234.65384339840298     rank=82  E_qf1_total=0.342235703766346   tau_1*E_qf=80.3    resid_qf2-0.243    tau1_mean=235   Elog_tau1=5.45    a_tau1=42.5     b_tau1=0.181  _tau1=-1.34e+00      KL(q||p)0.00071\n",
      "Tau_2 obs and tracking\n",
      "tau2=235.45407446679405     rank=80  E_qf1_total=0.33251035809516905   tau_2*E_qf=78.3    resid_qf2-0.252    tau2_mean=235   Elog_tau2=5.45    a_tau2=41.5     b_tau2=0.176  _tau2=-1.43e+00      KL(q||p)0.000706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 9/200 [01:15<26:36,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 3\n",
      "Iteration\n",
      "[9/200] \n",
      "ELBO train=12.4897  val_ELPD=-0.0261  train_ELPD=-0.0265  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0552 min=0.0527 max=0.0583  _KL=2.20    N=2000 B=50 B50.0  priors/obs: decor1.66 trans0.036\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.12006  rank=20  E_qf_mean9.91  E_qf_total19.8  tau*E_qf22.2  target22.2  resid0.706    tau4_mean=1.12   Elog_tau4=0.0677    a_tau4=11.1     b_tau4=9.91  _tau4=+7.12e-02      KL(q||p)0.00366\n",
      "Tau_1 obs and tracking\n",
      "tau1=223.59682279190176     rank=82  E_qf1_total=0.36014851480722426   tau_1*E_qf=80.5    resid_qf2-2.1    tau1_mean=224   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.19  _tau1=-1.11e+01      KL(q||p)0.000708\n",
      "Tau_2 obs and tracking\n",
      "tau2=226.64571882287788     rank=80  E_qf1_total=0.3462103150784969   tau_2*E_qf=78.5    resid_qf2-1.61    tau2_mean=227   Elog_tau2=5.41    a_tau2=41.5     b_tau2=0.183  _tau2=-8.81e+00      KL(q||p)0.000704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 10/200 [01:23<26:27,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 4\n",
      "Iteration\n",
      "[10/200] \n",
      "ELBO train=11.9492  val_ELPD=-0.0261  train_ELPD=-0.0265  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0538 max=0.0606  _KL=2.10    N=2000 B=50 B50.0  priors/obs: decor1.62 trans-0.0222\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.20814  rank=20  E_qf_mean9.19  E_qf_total18.4  tau*E_qf22.2  target22.2  resid0.809    tau4_mean=1.21   Elog_tau4=0.143    a_tau4=11.1     b_tau4=9.19  _tau4=+8.81e-02      KL(q||p)0.00362\n",
      "Tau_1 obs and tracking\n",
      "tau1=219.65223860672072     rank=82  E_qf1_total=0.36697534173727037   tau_1*E_qf=80.6    resid_qf2-0.763    tau1_mean=220   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.193  _tau1=-3.94e+00      KL(q||p)0.000689\n",
      "Tau_2 obs and tracking\n",
      "tau2=221.73132472526632     rank=80  E_qf1_total=0.35432690307497977   tau_2*E_qf=78.6    resid_qf2-0.92    tau2_mean=222   Elog_tau2=5.39    a_tau2=41.5     b_tau2=0.187  _tau2=-4.91e+00      KL(q||p)0.000688\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 11/200 [01:31<26:19,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 5\n",
      "Iteration\n",
      "[11/200] \n",
      "ELBO train=11.3623  val_ELPD=-0.0262  train_ELPD=-0.0265  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0576 min=0.0549 max=0.0629  _KL=2.00    N=2000 B=50 B50.0  priors/obs: decor1.72 trans-0.0849\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.31531  rank=20  E_qf_mean8.44  E_qf_total16.9  tau*E_qf22.2  target22.2  resid0.904    tau4_mean=1.32   Elog_tau4=0.228    a_tau4=11.1     b_tau4=8.44  _tau4=+1.07e-01      KL(q||p)0.00358\n",
      "Tau_1 obs and tracking\n",
      "tau1=205.2579485618116     rank=82  E_qf1_total=0.3941130742430687   tau_1*E_qf=80.9    resid_qf2-2.98    tau1_mean=205   Elog_tau1=5.31    a_tau1=42.5     b_tau1=0.207  _tau1=-1.44e+01      KL(q||p)0.000683\n",
      "Tau_2 obs and tracking\n",
      "tau2=205.02300498882005     rank=80  E_qf1_total=0.3848326191306114   tau_2*E_qf=78.9    resid_qf2-3.38    tau2_mean=205   Elog_tau2=5.31    a_tau2=41.5     b_tau2=0.202  _tau2=-1.67e+01      KL(q||p)0.00068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 12/200 [01:40<26:10,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 6\n",
      "Iteration\n",
      "[12/200] \n",
      "ELBO train=10.6395  val_ELPD=-0.0263  train_ELPD=-0.0266  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0586 min=0.0550 max=0.0652  _KL=1.90    N=2000 B=50 B50.0  priors/obs: decor1.6 trans-0.151\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.44378  rank=20  E_qf_mean7.69  E_qf_total15.4  tau*E_qf22.2  target22.2  resid0.988    tau4_mean=1.44   Elog_tau4=0.322    a_tau4=11.1     b_tau4=7.69  _tau4=+1.28e-01      KL(q||p)0.00353\n",
      "Tau_1 obs and tracking\n",
      "tau1=204.8874174446622     rank=82  E_qf1_total=0.3948619820177555   tau_1*E_qf=80.9    resid_qf2-0.0769    tau1_mean=205   Elog_tau1=5.31    a_tau1=42.5     b_tau1=0.207  _tau1=-3.71e-01      KL(q||p)0.000661\n",
      "Tau_2 obs and tracking\n",
      "tau2=206.0676920666166     rank=80  E_qf1_total=0.38278026729822157   tau_2*E_qf=78.9    resid_qf20.21    tau2_mean=206   Elog_tau2=5.32    a_tau2=41.5     b_tau2=0.201  _tau2=+1.04e+00      KL(q||p)0.000655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 13/200 [01:48<26:02,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 7\n",
      "Iteration\n",
      "[13/200] \n",
      "ELBO train=10.1322  val_ELPD=-0.0264  train_ELPD=-0.0267  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0597 min=0.0556 max=0.0676  _KL=1.80    N=2000 B=50 B50.0  priors/obs: decor1.65 trans-0.223\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.59954  rank=20  E_qf_mean6.94  E_qf_total13.9  tau*E_qf22.2  target22.2  resid1.08    tau4_mean=1.6   Elog_tau4=0.424    a_tau4=11.1     b_tau4=6.94  _tau4=+1.56e-01      KL(q||p)0.00348\n",
      "Tau_1 obs and tracking\n",
      "tau1=198.37752237145799     rank=82  E_qf1_total=0.4084759637713432   tau_1*E_qf=81    resid_qf2-1.39    tau1_mean=198   Elog_tau1=5.28    a_tau1=42.5     b_tau1=0.214  _tau1=-6.51e+00      KL(q||p)0.000661\n",
      "Tau_2 obs and tracking\n",
      "tau2=200.17816360475823     rank=80  E_qf1_total=0.3946306400001049   tau_2*E_qf=79    resid_qf2-1.22    tau2_mean=200   Elog_tau2=5.29    a_tau2=41.5     b_tau2=0.207  _tau2=-5.89e+00      KL(q||p)0.000657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 14/200 [01:56<25:54,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 8\n",
      "Iteration\n",
      "[14/200] \n",
      "ELBO train=9.5674  val_ELPD=-0.0265  train_ELPD=-0.0268  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0605 min=0.0562 max=0.0699  _KL=1.70    N=2000 B=50 B50.0  priors/obs: decor1.66 trans-0.297\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.77476  rank=20  E_qf_mean6.25  E_qf_total12.5  tau*E_qf22.2  target22.2  resid1.1    tau4_mean=1.77   Elog_tau4=0.528    a_tau4=11.1     b_tau4=6.25  _tau4=+1.75e-01      KL(q||p)0.00343\n",
      "Tau_1 obs and tracking\n",
      "tau1=192.07688649698315     rank=82  E_qf1_total=0.42253112196922304   tau_1*E_qf=81.2    resid_qf2-1.39    tau1_mean=192   Elog_tau1=5.25    a_tau1=42.5     b_tau1=0.221  _tau1=-6.30e+00      KL(q||p)0.000653\n",
      "Tau_2 obs and tracking\n",
      "tau2=191.86880947823914     rank=80  E_qf1_total=0.412587247043848   tau_2*E_qf=79.2    resid_qf2-1.8    tau2_mean=192   Elog_tau2=5.24    a_tau2=41.5     b_tau2=0.216  _tau2=-8.31e+00      KL(q||p)0.000649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 15/200 [02:05<25:46,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 9\n",
      "Iteration\n",
      "[15/200] \n",
      "ELBO train=8.9342  val_ELPD=-0.0266  train_ELPD=-0.0270  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0614 min=0.0567 max=0.0724  _KL=1.60    N=2000 B=50 B50.0  priors/obs: decor1.58 trans-0.373\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.96407  rank=20  E_qf_mean5.65  E_qf_total11.3  tau*E_qf22.2  target22.2  resid1.07    tau4_mean=1.96   Elog_tau4=0.629    a_tau4=11.1     b_tau4=5.65  _tau4=+1.89e-01      KL(q||p)0.00337\n",
      "Tau_1 obs and tracking\n",
      "tau1=193.50107283334603     rank=82  E_qf1_total=0.41927405074238777   tau_1*E_qf=81.1    resid_qf20.313    tau1_mean=194   Elog_tau1=5.25    a_tau1=42.5     b_tau1=0.22  _tau1=+1.42e+00      KL(q||p)0.000645\n",
      "Tau_2 obs and tracking\n",
      "tau2=196.74667617430936     rank=80  E_qf1_total=0.40186227336525915   tau_2*E_qf=79.1    resid_qf21.03    tau2_mean=197   Elog_tau2=5.27    a_tau2=41.5     b_tau2=0.211  _tau2=+4.88e+00      KL(q||p)0.000639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 16/200 [02:13<25:37,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 10\n",
      "Iteration\n",
      "[16/200] \n",
      "ELBO train=8.4926  val_ELPD=-0.0268  train_ELPD=-0.0271  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0620 min=0.0571 max=0.0748  _KL=1.50    N=2000 B=50 B50.0  priors/obs: decor1.7 trans-0.448\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.14719  rank=20  E_qf_mean5.17  E_qf_total10.3  tau*E_qf22.2  target22.2  resid0.947    tau4_mean=2.15   Elog_tau4=0.718    a_tau4=11.1     b_tau4=5.17  _tau4=+1.83e-01      KL(q||p)0.00331\n",
      "Tau_1 obs and tracking\n",
      "tau1=184.04823803565938     rank=82  E_qf1_total=0.44183544591069224   tau_1*E_qf=81.3    resid_qf2-2.18    tau1_mean=184   Elog_tau1=5.2    a_tau1=42.5     b_tau1=0.231  _tau1=-9.45e+00      KL(q||p)0.000647\n",
      "Tau_2 obs and tracking\n",
      "tau2=184.59207353660958     rank=80  E_qf1_total=0.4296401090919971   tau_2*E_qf=79.3    resid_qf2-2.73    tau2_mean=185   Elog_tau2=5.21    a_tau2=41.5     b_tau2=0.225  _tau2=-1.22e+01      KL(q||p)0.000645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 17/200 [02:22<25:28,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 11\n",
      "Iteration\n",
      "[17/200] \n",
      "ELBO train=7.8769  val_ELPD=-0.0269  train_ELPD=-0.0272  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0626 min=0.0571 max=0.0772  _KL=1.40    N=2000 B=50 B50.0  priors/obs: decor1.61 trans-0.523\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.30699  rank=20  E_qf_mean4.81  E_qf_total9.62  tau*E_qf22.2  target22.2  resid0.769    tau4_mean=2.31   Elog_tau4=0.79    a_tau4=11.1     b_tau4=4.81  _tau4=+1.60e-01      KL(q||p)0.00327\n",
      "Tau_1 obs and tracking\n",
      "tau1=183.1705236798844     rank=82  E_qf1_total=0.4440484635531902   tau_1*E_qf=81.3    resid_qf2-0.204    tau1_mean=183   Elog_tau1=5.2    a_tau1=42.5     b_tau1=0.232  _tau1=-8.78e-01      KL(q||p)0.000637\n",
      "Tau_2 obs and tracking\n",
      "tau2=185.33335692187052     rank=80  E_qf1_total=0.42784167006611823   tau_2*E_qf=79.3    resid_qf20.166    tau2_mean=185   Elog_tau2=5.21    a_tau2=41.5     b_tau2=0.224  _tau2=+7.41e-01      KL(q||p)0.000632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 18/200 [02:30<25:20,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 12\n",
      "Iteration\n",
      "[18/200] \n",
      "ELBO train=7.4008  val_ELPD=-0.0270  train_ELPD=-0.0275  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0631 min=0.0569 max=0.0796  _KL=1.30    N=2000 B=50 B50.0  priors/obs: decor1.61 trans-0.598\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.43185  rank=20  E_qf_mean4.56  E_qf_total9.13  tau*E_qf22.2  target22.2  resid0.57    tau4_mean=2.43   Elog_tau4=0.843    a_tau4=11.1     b_tau4=4.56  _tau4=+1.25e-01      KL(q||p)0.00323\n",
      "Tau_1 obs and tracking\n",
      "tau1=182.55961791687992     rank=82  E_qf1_total=0.44560132548213005   tau_1*E_qf=81.3    resid_qf2-0.142    tau1_mean=183   Elog_tau1=5.2    a_tau1=42.5     b_tau1=0.233  _tau1=-6.11e-01      KL(q||p)0.000636\n",
      "Tau_2 obs and tracking\n",
      "tau2=185.24327484962944     rank=80  E_qf1_total=0.4280594512820244   tau_2*E_qf=79.3    resid_qf2-0.0202    tau2_mean=185   Elog_tau2=5.21    a_tau2=41.5     b_tau2=0.224  _tau2=-9.01e-02      KL(q||p)0.000633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 19/200 [02:38<25:12,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 13\n",
      "Iteration\n",
      "[19/200] \n",
      "ELBO train=6.8854  val_ELPD=-0.0271  train_ELPD=-0.0275  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0634 min=0.0568 max=0.0820  _KL=1.20    N=2000 B=50 B50.0  priors/obs: decor1.59 trans-0.674\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.52233  rank=20  E_qf_mean4.4  E_qf_total8.8  tau*E_qf22.2  target22.2  resid0.398    tau4_mean=2.52   Elog_tau4=0.879    a_tau4=11.1     b_tau4=4.4  _tau4=+9.05e-02      KL(q||p)0.0032\n",
      "Tau_1 obs and tracking\n",
      "tau1=184.75190560338126     rank=82  E_qf1_total=0.4400764457881451   tau_1*E_qf=81.3    resid_qf20.504    tau1_mean=185   Elog_tau1=5.21    a_tau1=42.5     b_tau1=0.23  _tau1=+2.19e+00      KL(q||p)0.000636\n",
      "Tau_2 obs and tracking\n",
      "tau2=185.94379548982928     rank=80  E_qf1_total=0.42637144178152087   tau_2*E_qf=79.3    resid_qf20.156    tau2_mean=186   Elog_tau2=5.21    a_tau2=41.5     b_tau2=0.223  _tau2=+7.01e-01      KL(q||p)0.000632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 20/200 [02:47<25:04,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 14\n",
      "Iteration\n",
      "[20/200] \n",
      "ELBO train=6.3888  val_ELPD=-0.0271  train_ELPD=-0.0275  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0636 min=0.0565 max=0.0836  _KL=1.10    N=2000 B=50 B50.0  priors/obs: decor1.56 trans-0.737\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.57402  rank=20  E_qf_mean4.31  E_qf_total8.62  tau*E_qf22.2  target22.2  resid0.223    tau4_mean=2.57   Elog_tau4=0.9    a_tau4=11.1     b_tau4=4.31  _tau4=+5.17e-02      KL(q||p)0.00318\n",
      "Tau_1 obs and tracking\n",
      "tau1=188.01069359552773     rank=82  E_qf1_total=0.4321019440889359   tau_1*E_qf=81.2    resid_qf20.737    tau1_mean=188   Elog_tau1=5.22    a_tau1=42.5     b_tau1=0.226  _tau1=+3.26e+00      KL(q||p)0.000638\n",
      "Tau_2 obs and tracking\n",
      "tau2=192.15041545715096     rank=80  E_qf1_total=0.4119532689452171   tau_2*E_qf=79.2    resid_qf21.34    tau2_mean=192   Elog_tau2=5.25    a_tau2=41.5     b_tau2=0.216  _tau2=+6.21e+00      KL(q||p)0.000633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 21/200 [02:55<24:56,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 15\n",
      "Iteration\n",
      "[21/200] \n",
      "ELBO train=5.9965  val_ELPD=-0.0272  train_ELPD=-0.0276  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0636 min=0.0562 max=0.0851  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.61 trans-0.788\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.61009  rank=20  E_qf_mean4.25  E_qf_total8.5  tau*E_qf22.2  target22.2  resid0.153    tau4_mean=2.61   Elog_tau4=0.914    a_tau4=11.1     b_tau4=4.25  _tau4=+3.61e-02      KL(q||p)0.00317\n",
      "Tau_1 obs and tracking\n",
      "tau1=188.4042585417342     rank=82  E_qf1_total=0.4311575308442116   tau_1*E_qf=81.2    resid_qf20.0888    tau1_mean=188   Elog_tau1=5.23    a_tau1=42.5     b_tau1=0.226  _tau1=+3.94e-01      KL(q||p)0.000641\n",
      "Tau_2 obs and tracking\n",
      "tau2=191.0527884919813     rank=80  E_qf1_total=0.41443490535020827   tau_2*E_qf=79.2    resid_qf2-0.238    tau2_mean=191   Elog_tau2=5.24    a_tau2=41.5     b_tau2=0.217  _tau2=-1.10e+00      KL(q||p)0.00064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 22/200 [03:03<24:47,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 16\n",
      "Iteration\n",
      "[22/200] \n",
      "ELBO train=5.9066  val_ELPD=-0.0273  train_ELPD=-0.0277  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0636 min=0.0558 max=0.0867  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.61 trans-0.839\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.63825  rank=20  E_qf_mean4.21  E_qf_total8.41  tau*E_qf22.2  target22.2  resid0.118    tau4_mean=2.64   Elog_tau4=0.924    a_tau4=11.1     b_tau4=4.21  _tau4=+2.82e-02      KL(q||p)0.00316\n",
      "Tau_1 obs and tracking\n",
      "tau1=187.97658959073124     rank=82  E_qf1_total=0.4321839675307274   tau_1*E_qf=81.2    resid_qf2-0.0967    tau1_mean=188   Elog_tau1=5.22    a_tau1=42.5     b_tau1=0.226  _tau1=-4.28e-01      KL(q||p)0.000641\n",
      "Tau_2 obs and tracking\n",
      "tau2=190.9489143229422     rank=80  E_qf1_total=0.4146712332963943   tau_2*E_qf=79.2    resid_qf2-0.0226    tau2_mean=191   Elog_tau2=5.24    a_tau2=41.5     b_tau2=0.217  _tau2=-1.04e-01      KL(q||p)0.000638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 23/200 [03:12<24:39,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 17\n",
      "Iteration\n",
      "[23/200] \n",
      "ELBO train=5.8418  val_ELPD=-0.0273  train_ELPD=-0.0278  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0636 min=0.0556 max=0.0883  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.61 trans-0.891\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.66729  rank=20  E_qf_mean4.16  E_qf_total8.32  tau*E_qf22.2  target22.2  resid0.121    tau4_mean=2.67   Elog_tau4=0.935    a_tau4=11.1     b_tau4=4.16  _tau4=+2.90e-02      KL(q||p)0.00315\n",
      "Tau_1 obs and tracking\n",
      "tau1=187.6743463151497     rank=82  E_qf1_total=0.43291219472885134   tau_1*E_qf=81.2    resid_qf2-0.0684    tau1_mean=188   Elog_tau1=5.22    a_tau1=42.5     b_tau1=0.226  _tau1=-3.02e-01      KL(q||p)0.000641\n",
      "Tau_2 obs and tracking\n",
      "tau2=190.2926337744496     rank=80  E_qf1_total=0.4161703258752823   tau_2*E_qf=79.2    resid_qf2-0.143    tau2_mean=190   Elog_tau2=5.24    a_tau2=41.5     b_tau2=0.218  _tau2=-6.56e-01      KL(q||p)0.000638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 24/200 [03:20<24:31,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 18\n",
      "Iteration\n",
      "[24/200] \n",
      "ELBO train=5.8232  val_ELPD=-0.0274  train_ELPD=-0.0278  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0636 min=0.0553 max=0.0900  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.63 trans-0.942\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.69655  rank=20  E_qf_mean4.12  E_qf_total8.23  tau*E_qf22.2  target22.2  resid0.12    tau4_mean=2.7   Elog_tau4=0.946    a_tau4=11.1     b_tau4=4.12  _tau4=+2.93e-02      KL(q||p)0.00315\n",
      "Tau_1 obs and tracking\n",
      "tau1=185.18712751474544     rank=82  E_qf1_total=0.438995186239481   tau_1*E_qf=81.3    resid_qf2-0.571    tau1_mean=185   Elog_tau1=5.21    a_tau1=42.5     b_tau1=0.229  _tau1=-2.49e+00      KL(q||p)0.000641\n",
      "Tau_2 obs and tracking\n",
      "tau2=187.74662461793932     rank=80  E_qf1_total=0.42208517864346506   tau_2*E_qf=79.2    resid_qf2-0.563    tau2_mean=188   Elog_tau2=5.22    a_tau2=41.5     b_tau2=0.221  _tau2=-2.55e+00      KL(q||p)0.000638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 25/200 [03:28<24:22,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 19\n",
      "Iteration\n",
      "[25/200] \n",
      "ELBO train=5.7001  val_ELPD=-0.0274  train_ELPD=-0.0278  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0637 min=0.0551 max=0.0918  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.49 trans-0.993\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.72594  rank=20  E_qf_mean4.07  E_qf_total8.14  tau*E_qf22.2  target22.2  resid0.12    tau4_mean=2.73   Elog_tau4=0.957    a_tau4=11.1     b_tau4=4.07  _tau4=+2.94e-02      KL(q||p)0.00314\n",
      "Tau_1 obs and tracking\n",
      "tau1=197.83009003999143     rank=82  E_qf1_total=0.4096616357564926   tau_1*E_qf=81    resid_qf22.72    tau1_mean=198   Elog_tau1=5.28    a_tau1=42.5     b_tau1=0.215  _tau1=+1.26e+01      KL(q||p)0.000638\n",
      "Tau_2 obs and tracking\n",
      "tau2=201.38502847603104     rank=80  E_qf1_total=0.39214583188295365   tau_2*E_qf=79    resid_qf22.81    tau2_mean=201   Elog_tau2=5.29    a_tau2=41.5     b_tau2=0.206  _tau2=+1.36e+01      KL(q||p)0.000635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 26/200 [03:37<24:14,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 20\n",
      "Iteration\n",
      "[26/200] \n",
      "ELBO train=5.7586  val_ELPD=-0.0275  train_ELPD=-0.0279  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0637 min=0.0549 max=0.0936  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.63 trans-1.04\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.75725  rank=20  E_qf_mean4.02  E_qf_total8.05  tau*E_qf22.2  target22.2  resid0.126    tau4_mean=2.76   Elog_tau4=0.969    a_tau4=11.1     b_tau4=4.03  _tau4=+3.13e-02      KL(q||p)0.00313\n",
      "Tau_1 obs and tracking\n",
      "tau1=195.70187547160182     rank=82  E_qf1_total=0.41433411091566086   tau_1*E_qf=81.1    resid_qf2-0.462    tau1_mean=196   Elog_tau1=5.26    a_tau1=42.5     b_tau1=0.217  _tau1=-2.13e+00      KL(q||p)0.000652\n",
      "Tau_2 obs and tracking\n",
      "tau2=197.6486484353115     rank=80  E_qf1_total=0.3999370992183685   tau_2*E_qf=79    resid_qf2-0.785    tau2_mean=198   Elog_tau2=5.27    a_tau2=41.5     b_tau2=0.21  _tau2=-3.74e+00      KL(q||p)0.000651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 27/200 [03:45<24:05,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 21\n",
      "Iteration\n",
      "[27/200] \n",
      "ELBO train=5.6238  val_ELPD=-0.0275  train_ELPD=-0.0280  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0638 min=0.0546 max=0.0955  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.55 trans-1.09\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.78484  rank=20  E_qf_mean3.98  E_qf_total7.97  tau*E_qf22.2  target22.2  resid0.11    tau4_mean=2.78   Elog_tau4=0.978    a_tau4=11.1     b_tau4=3.99  _tau4=+2.76e-02      KL(q||p)0.00313\n",
      "Tau_1 obs and tracking\n",
      "tau1=201.4821034726688     rank=82  E_qf1_total=0.4018736980855465   tau_1*E_qf=81    resid_qf21.22    tau1_mean=201   Elog_tau1=5.29    a_tau1=42.5     b_tau1=0.211  _tau1=+5.78e+00      KL(q||p)0.000649\n",
      "Tau_2 obs and tracking\n",
      "tau2=205.23668214075005     rank=80  E_qf1_total=0.38441113755106926   tau_2*E_qf=78.9    resid_qf21.53    tau2_mean=205   Elog_tau2=5.31    a_tau2=41.5     b_tau2=0.202  _tau2=+7.59e+00      KL(q||p)0.000646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 28/200 [03:54<24:06,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 22\n",
      "Iteration\n",
      "[28/200] \n",
      "ELBO train=5.6462  val_ELPD=-0.0276  train_ELPD=-0.0280  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0639 min=0.0543 max=0.0974  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.58 trans-1.14\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.81397  rank=20  E_qf_mean3.94  E_qf_total7.89  tau*E_qf22.2  target22.2  resid0.115    tau4_mean=2.81   Elog_tau4=0.989    a_tau4=11.1     b_tau4=3.94  _tau4=+2.91e-02      KL(q||p)0.00312\n",
      "Tau_1 obs and tracking\n",
      "tau1=203.67359895888282     rank=82  E_qf1_total=0.39733440428972244   tau_1*E_qf=80.9    resid_qf20.457    tau1_mean=204   Elog_tau1=5.3    a_tau1=42.5     b_tau1=0.209  _tau1=+2.19e+00      KL(q||p)0.000656\n",
      "Tau_2 obs and tracking\n",
      "tau2=207.86631521537115     rank=80  E_qf1_total=0.3792950950562954   tau_2*E_qf=78.8    resid_qf20.525    tau2_mean=208   Elog_tau2=5.32    a_tau2=41.5     b_tau2=0.2  _tau2=+2.63e+00      KL(q||p)0.000656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 29/200 [04:02<24:02,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 23\n",
      "Iteration\n",
      "[29/200] \n",
      "ELBO train=5.6312  val_ELPD=-0.0277  train_ELPD=-0.0281  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0640 min=0.0543 max=0.0994  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.63 trans-1.19\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.8426  rank=20  E_qf_mean3.9  E_qf_total7.81  tau*E_qf22.2  target22.2  resid0.112    tau4_mean=2.84   Elog_tau4=0.999    a_tau4=11.1     b_tau4=3.9  _tau4=+2.86e-02      KL(q||p)0.00312\n",
      "Tau_1 obs and tracking\n",
      "tau1=201.1662777416104     rank=82  E_qf1_total=0.40253602862358095   tau_1*E_qf=81    resid_qf2-0.53    tau1_mean=201   Elog_tau1=5.29    a_tau1=42.5     b_tau1=0.211  _tau1=-2.51e+00      KL(q||p)0.000659\n",
      "Tau_2 obs and tracking\n",
      "tau2=202.15856718025375     rank=80  E_qf1_total=0.39056879878044126   tau_2*E_qf=79    resid_qf2-1.17    tau2_mean=202   Elog_tau2=5.3    a_tau2=41.5     b_tau2=0.205  _tau2=-5.71e+00      KL(q||p)0.000659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 30/200 [04:11<23:50,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 24\n",
      "Iteration\n",
      "[30/200] \n",
      "ELBO train=5.5217  val_ELPD=-0.0277  train_ELPD=-0.0281  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0640 min=0.0539 max=0.1014  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.64 trans-1.24\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.8687  rank=20  E_qf_mean3.87  E_qf_total7.74  tau*E_qf22.2  target22.2  resid0.101    tau4_mean=2.87   Elog_tau4=1.01    a_tau4=11.1     b_tau4=3.87  _tau4=+2.61e-02      KL(q||p)0.00311\n",
      "Tau_1 obs and tracking\n",
      "tau1=194.78446616255073     rank=82  E_qf1_total=0.4163797676563263   tau_1*E_qf=81.1    resid_qf2-1.39    tau1_mean=195   Elog_tau1=5.26    a_tau1=42.5     b_tau1=0.218  _tau1=-6.38e+00      KL(q||p)0.000656\n",
      "Tau_2 obs and tracking\n",
      "tau2=198.94719078902557     rank=80  E_qf1_total=0.39719614014029503   tau_2*E_qf=79    resid_qf2-0.67    tau2_mean=199   Elog_tau2=5.28    a_tau2=41.5     b_tau2=0.209  _tau2=-3.21e+00      KL(q||p)0.000652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 31/200 [04:19<23:39,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 25\n",
      "Iteration\n",
      "[31/200] \n",
      "ELBO train=5.4305  val_ELPD=-0.0277  train_ELPD=-0.0281  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0642 min=0.0539 max=0.1036  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.55 trans-1.29\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.8896  rank=20  E_qf_mean3.84  E_qf_total7.68  tau*E_qf22.2  target22.2  resid0.0803    tau4_mean=2.89   Elog_tau4=1.02    a_tau4=11.1     b_tau4=3.84  _tau4=+2.09e-02      KL(q||p)0.00311\n",
      "Tau_1 obs and tracking\n",
      "tau1=201.14458277466605     rank=82  E_qf1_total=0.4025816023349762   tau_1*E_qf=81    resid_qf21.34    tau1_mean=201   Elog_tau1=5.29    a_tau1=42.5     b_tau1=0.211  _tau1=+6.36e+00      KL(q||p)0.000648\n",
      "Tau_2 obs and tracking\n",
      "tau2=205.39897524379452     rank=80  E_qf1_total=0.38409159779548646   tau_2*E_qf=78.9    resid_qf21.3    tau2_mean=205   Elog_tau2=5.31    a_tau2=41.5     b_tau2=0.202  _tau2=+6.45e+00      KL(q||p)0.000647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 32/200 [04:27<23:31,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 26\n",
      "Iteration\n",
      "[32/200] \n",
      "ELBO train=5.3788  val_ELPD=-0.0277  train_ELPD=-0.0281  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0644 min=0.0537 max=0.1060  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.49 trans-1.34\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.90075  rank=20  E_qf_mean3.83  E_qf_total7.65  tau*E_qf22.2  target22.2  resid0.0426    tau4_mean=2.9   Elog_tau4=1.02    a_tau4=11.1     b_tau4=3.83  _tau4=+1.11e-02      KL(q||p)0.0031\n",
      "Tau_1 obs and tracking\n",
      "tau1=215.08683191661328     rank=82  E_qf1_total=0.3751892328262329   tau_1*E_qf=80.7    resid_qf22.75    tau1_mean=215   Elog_tau1=5.36    a_tau1=42.5     b_tau1=0.198  _tau1=+1.39e+01      KL(q||p)0.000656\n",
      "Tau_2 obs and tracking\n",
      "tau2=220.6241264818521     rank=80  E_qf1_total=0.35620545595884323   tau_2*E_qf=78.6    resid_qf22.86    tau2_mean=221   Elog_tau2=5.38    a_tau2=41.5     b_tau2=0.188  _tau2=+1.52e+01      KL(q||p)0.000656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 33/200 [04:36<23:21,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 27\n",
      "Iteration\n",
      "[33/200] \n",
      "ELBO train=5.5128  val_ELPD=-0.0278  train_ELPD=-0.0282  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0644 min=0.0535 max=0.1082  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.71 trans-1.39\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.90723  rank=20  E_qf_mean3.82  E_qf_total7.63  tau*E_qf22.2  target22.2  resid0.0247    tau4_mean=2.91   Elog_tau4=1.02    a_tau4=11.1     b_tau4=3.82  _tau4=+6.48e-03      KL(q||p)0.0031\n",
      "Tau_1 obs and tracking\n",
      "tau1=202.34973690266645     rank=82  E_qf1_total=0.40006479173898696   tau_1*E_qf=81    resid_qf2-2.68    tau1_mean=202   Elog_tau1=5.3    a_tau1=42.5     b_tau1=0.21  _tau1=-1.27e+01      KL(q||p)0.000675\n",
      "Tau_2 obs and tracking\n",
      "tau2=205.5435717123215     rank=80  E_qf1_total=0.3838073261082172   tau_2*E_qf=78.9    resid_qf2-3.04    tau2_mean=206   Elog_tau2=5.31    a_tau2=41.5     b_tau2=0.202  _tau2=-1.51e+01      KL(q||p)0.000678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 34/200 [04:44<23:12,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 28\n",
      "Iteration\n",
      "[34/200] \n",
      "ELBO train=5.2966  val_ELPD=-0.0279  train_ELPD=-0.0283  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0646 min=0.0534 max=0.1099  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.51 trans-1.43\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.90145  rank=20  E_qf_mean3.82  E_qf_total7.65  tau*E_qf22.2  target22.2  resid-0.0221    tau4_mean=2.9   Elog_tau4=1.02    a_tau4=11.1     b_tau4=3.83  _tau4=-5.78e-03      KL(q||p)0.0031\n",
      "Tau_1 obs and tracking\n",
      "tau1=211.93830306485825     rank=82  E_qf1_total=0.3810601145029068   tau_1*E_qf=80.8    resid_qf21.92    tau1_mean=212   Elog_tau1=5.34    a_tau1=42.5     b_tau1=0.201  _tau1=+9.59e+00      KL(q||p)0.000658\n",
      "Tau_2 obs and tracking\n",
      "tau2=217.33955420962147     rank=80  E_qf1_total=0.3618909098207951   tau_2*E_qf=78.7    resid_qf22.25    tau2_mean=217   Elog_tau2=5.37    a_tau2=41.5     b_tau2=0.191  _tau2=+1.18e+01      KL(q||p)0.000656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 35/200 [04:52<23:02,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 29\n",
      "Iteration\n",
      "[35/200] \n",
      "ELBO train=5.3611  val_ELPD=-0.0279  train_ELPD=-0.0284  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0647 min=0.0531 max=0.1115  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.64 trans-1.46\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.89425  rank=20  E_qf_mean3.83  E_qf_total7.67  tau*E_qf22.2  target22.2  resid-0.0276    tau4_mean=2.89   Elog_tau4=1.02    a_tau4=11.1     b_tau4=3.84  _tau4=-7.19e-03      KL(q||p)0.0031\n",
      "Tau_1 obs and tracking\n",
      "tau1=207.58457746339857     rank=82  E_qf1_total=0.3894716531038284   tau_1*E_qf=80.8    resid_qf2-0.891    tau1_mean=208   Elog_tau1=5.32    a_tau1=42.5     b_tau1=0.205  _tau1=-4.35e+00      KL(q||p)0.000671\n",
      "Tau_2 obs and tracking\n",
      "tau2=211.2163606400752     rank=80  E_qf1_total=0.3729619838297367   tau_2*E_qf=78.8    resid_qf2-1.2    tau2_mean=211   Elog_tau2=5.34    a_tau2=41.5     b_tau2=0.196  _tau2=-6.12e+00      KL(q||p)0.000673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 35/200 [05:01<23:41,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 30\n",
      "Iteration\n",
      "[36/200] \n",
      "ELBO train=5.3095  val_ELPD=-0.0279  train_ELPD=-0.0285  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0648 min=0.0531 max=0.1133  _KL=1.00    N=2000 B=50 B50.0  priors/obs: decor1.6 trans-1.49\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.87732  rank=20  E_qf_mean3.86  E_qf_total7.71  tau*E_qf22.2  target22.2  resid-0.0653    tau4_mean=2.88   Elog_tau4=1.01    a_tau4=11.1     b_tau4=3.86  _tau4=-1.69e-02      KL(q||p)0.0031\n",
      "Tau_1 obs and tracking\n",
      "tau1=208.53431731128865     rank=82  E_qf1_total=0.3876067727804184   tau_1*E_qf=80.8    resid_qf20.194    tau1_mean=209   Elog_tau1=5.33    a_tau1=42.5     b_tau1=0.204  _tau1=+9.50e-01      KL(q||p)0.000665\n",
      "Tau_2 obs and tracking\n",
      "tau2=209.37860143099283     rank=80  E_qf1_total=0.37641109228134156   tau_2*E_qf=78.8    resid_qf2-0.364    tau2_mean=209   Elog_tau2=5.33    a_tau2=41.5     b_tau2=0.198  _tau2=-1.84e+00      KL(q||p)0.000664\n",
      "\n",
      "Early stop @ epoch 36: no val improvement for 30 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"transformation\": {\n",
    "    \"sigma_a\": 2.1, \"sigma_b\": 1e6,        #Ignored not used\n",
    "    \n",
    "    #\"RW2\": {\"tau_a\": 1e-3, \"tau_b\": 1e-3},   # A) nearly-flat proper   recommended\n",
    "    \"RW2\": {\"tau_a\": 1.1,  \"tau_b\": 1e-3},   # B) weak default\n",
    "    # \"RW2\": {\"tau_a\": 1.0,  \"tau_b\": 1.0},    # C) unit-scale neutral\n",
    "    \n",
    "    \"RW1\": { \"tau_a\": 10.0,\"tau_b\": 15.0 }  #Ignored not used\n",
    "    },\n",
    "    \"decorrelation\": {\n",
    "    \"sigma_a\": 2.1, \"sigma_b\": -1e6,              # mean  = very small close to 0 (weak)\n",
    "    \"RW2\": { \"tau_a\": 1.5, \"tau_b\": 0.01 },      # E[2]  0.05   (weak curvature smoothing)\n",
    "    \"RW1\": { \"tau_a\": 1.5, \"tau_b\": 0.01 },      # E[1]  0.10   (light shrink to linear)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model = GTM(\n",
    "    number_variables=2,\n",
    "    number_transformation_layers=1,\n",
    "    number_decorrelation_layers=3,\n",
    "    degree_transformations=10,\n",
    "    degree_decorrelation=40,\n",
    "    spline_transformation=\"bspline\",\n",
    "    spline_decorrelation=\"bspline\",\n",
    "    transformation_spline_range=(-10, 10),\n",
    "    device=device,\n",
    "    ## NEW ARGUMENTS ##\n",
    "    inference = 'bayesian',\n",
    "    hyperparameter=hyperparameters\n",
    "    )\n",
    "\n",
    "output = model.train(\n",
    "                train_dataloader=dataloader_train,\n",
    "                validate_dataloader=dataloader_validate,\n",
    "                hyperparameters=None,\n",
    "                iterations=200,\n",
    "                #verbose=True,\n",
    "                learning_rate=0.01,\n",
    "                mcmc_sample_train=4,            # will ramp\n",
    "                mcmc_sample_val=16,             # fixed & larger for stable eval\n",
    "                mc_ramp_every=60,               # 481632 at epochs 25/50/75\n",
    "                mc_ramp_max=64,\n",
    "                patience=30,                # early-stop patience\n",
    "                min_delta=0.00001,                # ~0.1% absolute of your loss scale\n",
    "                rho_lr_multiplier=0.1,          # slightly faster variance adaption (optional)\n",
    "                sched_factor=0.7, sched_patience=12, sched_threshold=1e-4,\n",
    "                #WARMING\n",
    "                warm_tau_epochs = 3,\n",
    "                warm_sigma_epochs = 5,  # try 510\n",
    "                \n",
    "                #Optimization method\n",
    "                beta_kl_start= 3,    # try 1.53.0\n",
    "                beta_kl_anneal_epochs = 20,  # how fast to decay to 1.0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0869c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-10.1774,   1.4886,   1.4886,   1.4886,   1.5007,   1.8845,   2.5384,\n",
      "          1.9117,   1.6491,   1.6411,   1.6411,   1.6411], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-9.1246,  0.2145,  1.9207,  1.4160,  1.2319,  1.6689,  2.5244,  1.1131,\n",
      "        -0.9183, -1.1672, -1.1215, -1.0815], requires_grad=True)\n",
      "12\n",
      "12\n",
      "Parameter containing:\n",
      "tensor([-10.1223,   1.5353,   1.5353,   1.5353,   1.5425,   1.8344,   2.6848,\n",
      "          2.2036,   1.6535,   1.6411,   1.6411,   1.6411], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-9.0968,  0.2253,  1.9468,  1.4214,  1.2038,  1.5092,  2.6053,  1.9487,\n",
      "        -0.8104, -1.1867, -1.1474, -1.1116], requires_grad=True)\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(model_freq.transformation.params[0])\n",
    "print(model.transformation.params[0])\n",
    "\n",
    "print(len(model_freq.transformation.params[0]))\n",
    "print(len(model.transformation.params[0]))\n",
    "\n",
    "\n",
    "print(model_freq.transformation.params[1])\n",
    "print(model.transformation.params[1])\n",
    "\n",
    "print(len(model_freq.transformation.params[1]))\n",
    "print(len(model.transformation.params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b467e",
   "metadata": {},
   "source": [
    "#### PROBLEM HERE, I was trying to introduce a early stop algorithm with the elbo loss, nevertheless, it seems that it overfits wenn i try to use more epochs. I was working with 1000 epoch. \n",
    "# It seems, that, it converges but to the wrong state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5eebff",
   "metadata": {},
   "source": [
    "### 4. Compare to Benchmarks\n",
    "\n",
    "We compare the learned GTM to a Gaussian Approximation and the Oracle Model. We expect the GTM to lie between these two in terms of approximation the true underlying distribution.\n",
    "We measure this by means of the Kullback Leibler Divergence which we approximate on the test set which is equivalent to the log likelihood ratio between the true distribution and an approximation of it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b910002",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_train_bgtm = model.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_bgtm = model.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_bgtm = model.log_likelihood(simulated_data_test)\n",
    "\n",
    "\n",
    "log_likelihood_train_gtm = model_freq.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_gtm = model_freq.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_gtm = model_freq.log_likelihood(simulated_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad6c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the Multivariate Normal Distribution as Model\n",
    "mean_mvn_model = simulated_data_train.mean(0)\n",
    "cov_mvn_model = simulated_data_train.T.cov()\n",
    "mvn_model = torch.distributions.MultivariateNormal(loc=mean_mvn_model, covariance_matrix=cov_mvn_model)\n",
    "log_likelihood_train_gaussian = (mvn_model.log_prob(simulated_data_train)).to(device)\n",
    "log_likelihood_validate_gaussian = (mvn_model.log_prob(simulated_data_validate)).to(device)\n",
    "log_likelihood_test_gaussian = (mvn_model.log_prob(simulated_data_test)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d759712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cpu\n"
     ]
    }
   ],
   "source": [
    "print(loglik_true_train.device, log_likelihood_train_gaussian.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c2f1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD BGTM      Train Data:  0.1308\n",
      "KLD GTM      Train Data:  0.0626\n",
      "KLD Gaussian Train Data:  0.1148\n",
      "KLD Copula   Train Data:  -0.0004\n",
      "\n",
      "KLD BGTM      Test  Data:  0.1339\n",
      "KLD GTM      Test  Data:  0.0605\n",
      "KLD Gaussian Test  Data:  0.1124\n",
      "KLD Copula   Test  Data:  0.0001\n"
     ]
    }
   ],
   "source": [
    "print(\"KLD BGTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_bgtm).item(),4) )\n",
    "print(\"KLD GTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Train Data: \",np.round(torch.mean(loglik_true_train - loglik_true_est_train).item(),4) )\n",
    "print(\"\")\n",
    "print(\"KLD BGTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_bgtm).item(),4) )\n",
    "print(\"KLD GTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Test  Data: \",np.round(torch.mean(loglik_true_test - loglik_true_est_test).item(),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee4e5d",
   "metadata": {},
   "source": [
    "### 5. Evaluate and Plot GTM Results\n",
    "\n",
    "We evaluate the model further by showing how to generate synthetic samples, plot the conditional correlation patterns as well as the model splines.\n",
    "\n",
    "Note that to generate synthetic samples the inverse of the trainsformation layer needs to be approximated  with the method `approximate_transformation_inverse` once which is then stored for future sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6690f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.approximate_transformation_inverse()\n",
    "synthetic_samples = model.sample(10000)\n",
    "model_freq.approximate_transformation_inverse()\n",
    "synthetic_samples_freq = model_freq.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22df00ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_densities(synthetic_samples.cpu(), x_lim=[-4,4], y_lim=[-4,4])\n",
    "model_freq.plot_densities(synthetic_samples_freq.cpu(), x_lim=[-4,4], y_lim=[-4,4])\n",
    "model.plot_densities(simulated_data_train.cpu(), x_lim=[-4,4], y_lim=[-4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598c157",
   "metadata": {},
   "source": [
    "The varying pseudo conditional correlation matrix values can be computed for any synthetic samples using `compute_pseudo_conditional_correlation_matrix` or can directly be plotted using `plot_conditional_dependence_structure`.\n",
    "The pseudo conditional correlation matrix is the standardised precision matrix so that off diagonal elements are the pseudo conditional correlations between the respective dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6637a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_conditional_correlation_matrix = model.compute_pseudo_conditional_correlation_matrix(synthetic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a30faa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_conditional_dependence_structure(data=synthetic_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e081b4",
   "metadata": {},
   "source": [
    "One can also visualize the splines of each layer usign the function `plot_splines`. For the transformation layer we additionally include the dervaitive which is always positive due to the monotonically increasing constraint as well as the inverse which should lie exactly on the spline to visually confirm that the inverse sampling path works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "149a1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:113: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type=\"transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8649bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5aa64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86eb78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
