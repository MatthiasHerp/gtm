{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5fecd0",
   "metadata": {},
   "source": [
    "# Demo of the BGTM on 2-Dimensional Joe-Copula\n",
    "\n",
    "In this demonstration we show how the GTM can be used to learn a probability distribution from synthetic data sampled from a 2 dimensional Joe copula.\n",
    "To sample synthetic copula data we use the [pyvinecopulib](https://github.com/vinecopulib/pyvinecopulib) library.\n",
    "Fore more details on copulas we refer to the Book [Analyzing Dependent Data with Vine Copulas](https://link.springer.com/book/10.1007/978-3-030-13785-4) for an comprehensive introduction to copulas and vine copulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b4550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gtm import *\n",
    "\n",
    "# Sample Copulas Package\n",
    "import pyvinecopulib as pv\n",
    "\n",
    "# Other Stuff\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_helpers import Generic_Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed17c60",
   "metadata": {},
   "source": [
    "### 1. Sample Synthetic Copula Data and Compute Likelihoods\n",
    "\n",
    "We sample data from a Joe Copula and add Gaussian marginals. Feel free to exchange the copula parameter, the rotation or even the copula itsself.\n",
    "The list of copulas can be found with `help(pv.Bicop)`.\n",
    "\n",
    "Notice we use Sklars Theorem to compute the density of the joint copula and Gaussian marginals density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91426a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "copula_pv = pv.Bicop(family=pv.BicopFamily.joe, parameters=np.array([[2.5]]), rotation=90)\n",
    "\n",
    "# Train\n",
    "N_train = 2000\n",
    "simulated_data_uniform_train = copula_pv.simulate(n=N_train)\n",
    "simulated_data_train = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_train)).float()\n",
    "\n",
    "# Validate\n",
    "N_validate = 2000\n",
    "simulated_data_uniform_validate = copula_pv.simulate(n=N_validate)\n",
    "simulated_data_validate = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_validate)).float()\n",
    "\n",
    "# Test\n",
    "N_test = 20000\n",
    "simulated_data_uniform_test = copula_pv.simulate(n=N_test)\n",
    "simulated_data_test = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a347f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133281/3463905256.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/tmp/ipykernel_133281/3463905256.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/tmp/ipykernel_133281/3463905256.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_train = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_validate = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_test = (torch.tensor(loglik_copula) + log_marginals).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ae322",
   "metadata": {},
   "source": [
    "We further estimate the copula on the synthetic data to get an oracle denisity estimator. Hence an estimator that knows the true underlying structure and merely estiamtes the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab3f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_pv_est = pv.Bicop(family=pv.BicopFamily.joe, rotation=90)\n",
    "copula_pv_est.fit(simulated_data_uniform_train)\n",
    "means = simulated_data_train.mean(0)\n",
    "vars = simulated_data_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357cb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_train).sum(1)\n",
    "loglik_true_est_train = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_validate).sum(1)\n",
    "loglik_true_est_validate = (torch.tensor(loglik_copula) + log_marginals).to(device)\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(simulated_data_test).sum(1)\n",
    "loglik_true_est_test = (torch.tensor(loglik_copula) + log_marginals).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cde9d2",
   "metadata": {},
   "source": [
    "The package is implemented to use Dataloaders for training. This is done to accommodate larger datasets trained batch wise as is common in deep learning and bioinformatics applications. Feel free to use the [`Generic_Dataset`](demos/dataset_helpers.py) class to easily adjust it to your data. For full data training, thus whithout batches simply seet the `batch_size` arguement in the `DataLoader` to the data size as we do in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83659cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and DataLoader\n",
    "dataset_train = Generic_Dataset(simulated_data_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=100)\n",
    "\n",
    "dataset_validate = Generic_Dataset(simulated_data_validate)\n",
    "dataloader_validate = DataLoader(dataset_validate, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c111eb",
   "metadata": {},
   "source": [
    "### 2. Define Model\n",
    "\n",
    "We define a simple GTM model with the standard parameters.\n",
    "Notable custamizable parameter are: \n",
    "- The dimensionality of the data `number_variables`\n",
    "- The number of transformation layers `num_trans_layers`, either 0 or 1.\n",
    "- The number of decorrelation layers `num_decorr_layers`, typically 3 or more. \n",
    "- the spline to use for the transformation layer splines `spline_transformation` and the decorrelation layer splines `spline_decorrelation`.  The two types of layers: P-Splines (`bspline`) or bernstein polynomials (`bernstein`).\n",
    "- The degrees of the splines, representing there flexibility, being `degree_decorrelation` for the decorrelation layer splines and `degree_transformations` for the transformation layer. When using `bspline`, then `degree_transformations` can also be given a list with varying degrees for each dimension of the data.\n",
    "- `transformation_spline_range`sets the outer borders for the transformation layer splines, this dependends on the input data and should be set a bit wider then the actual data.\n",
    "- `device` either `cpu`or `cuda`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8347a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 15:47:00,924] A new study created in RDB with name: no-name-ad3afd1a-85e1-4858-ad11-72d6f431c017\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:595: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  x=input_a_clone.T, t=knots.T, c=params_a.T, p=order, d=derivativ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5183, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:03<1:42:23,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4628, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.535739541053772\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4728, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<51:29,  1.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4588, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5358713865280151\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:03<33:09,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4546, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.536800742149353\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4110, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:04<24:41,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4552, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5374315977096558\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<19:56,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4550, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5343464612960815\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<17:10,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.5296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4541, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5399986505508423\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<15:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.539206862449646\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(283.7745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4575, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:05<14:20,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5406564474105835\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3978, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:06<13:34,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4537, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5426081418991089\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:06<23:31,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.9034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.5421111583709717\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.5343) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3254, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:03<1:44:48,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3777210712432861\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:07<2:00:38,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3714690208435059\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:09<1:40:43,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3703709840774536\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:11<1:27:49,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3655833005905151\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:13<1:22:52,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.357578158378601\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:14<1:06:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3596336841583252\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:15<52:28,  1.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3524328470230103\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:16<43:56,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3511770963668823\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:16<37:50,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.353897213935852\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:17<34:11,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3518000841140747\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:18<31:20,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.355905294418335\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:19<29:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.353630542755127\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:20<28:44,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3511269092559814\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:20<27:42,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3529465198516846\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.8531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:21<26:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3453240394592285\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:22<26:23,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3491047620773315\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:23<26:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3462573289871216\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:23<26:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3478078842163086\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:24<26:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3479167222976685\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:25<44:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3500289916992188\n",
      "Early Stop at iteration 19 with minimal loss tensor(1.3453) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:47:36,728] Trial 0 finished with value: -2.5394318461418153 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.6092752185358308, 'penalty_decorrelation_ridge_second_difference': 8.90712456191838}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3275, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:45,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3559149503707886\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3543533086776733\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:44,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3579201698303223\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<24:53,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3560653924942017\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:05,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3553723096847534\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538671731948853\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3543634414672852\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:08<53:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3542230129241943\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:11<1:05:42,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.354712963104248\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:14<1:11:13,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3550622463226318\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.9589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:16<1:10:51,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.353735327720642\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.8893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4396, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:18<1:10:33,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3551459312438965\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:19<57:04,  1.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3550070524215698\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:19<47:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3563714027404785\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:20<40:30,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.355296015739441\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:21<47:04,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3573359251022339\n",
      "Early Stop at iteration 15 with minimal loss tensor(1.3537) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:47:58,842] Trial 1 finished with value: -2.54535117149353 and parameters: {'penalty_decorrelation_ridge_first_difference': 17.4271660160143, 'penalty_decorrelation_ridge_second_difference': 17.62846148158924}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:21,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3578886985778809\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.355220913887024\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:06,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3561515808105469\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:49,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3572458028793335\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:53,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3609977960586548\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:29,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3575266599655151\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:05<30:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3582454919815063\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3552) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:48:06,306] Trial 2 finished with value: -2.548447370529175 and parameters: {'penalty_decorrelation_ridge_first_difference': 15.944334006458764, 'penalty_decorrelation_ridge_second_difference': 22.192640504407784}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:02<1:19:26,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.354445457458496\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:05<1:28:35,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.366256833076477\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:07<1:20:06,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3636960983276367\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:09<1:20:44,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3634271621704102\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3257, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:11<1:07:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3634039163589478\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:15<1:39:49,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3625123500823975\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3544) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:48:22,845] Trial 3 finished with value: -2.548952317237854 and parameters: {'penalty_decorrelation_ridge_first_difference': 27.895981610855674, 'penalty_decorrelation_ridge_second_difference': 20.132996859746978}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:02<1:17:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349764108657837\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:06<1:57:10,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3552912473678589\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.5261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:08<1:26:24,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3486027717590332\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:08<1:02:44,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3530491590499878\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.4079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:09<50:14,  1.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3503942489624023\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:10<41:55,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350682020187378\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:11<36:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3516393899917603\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:12<57:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3509989976882935\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3486) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:48:35,667] Trial 4 finished with value: -2.539760613441467 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.799497356296318, 'penalty_decorrelation_ridge_second_difference': 2.4965797875517226}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:04,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352281928062439\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:59,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.360914707183838\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.355848789215088\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3603787422180176\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.8417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:46,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3592932224273682\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<30:37,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3583368062973022\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3523) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:48:41,009] Trial 5 finished with value: -2.5441411972045898 and parameters: {'penalty_decorrelation_ridge_first_difference': 16.370324534164325, 'penalty_decorrelation_ridge_second_difference': 3.6688300788270025}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:33,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538234233856201\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:54,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3608980178833008\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3250, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:08,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3603309392929077\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<24:47,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3611359596252441\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<24:34,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.361473560333252\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3247, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<29:56,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3653830289840698\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3538) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:48:46,275] Trial 6 finished with value: -2.54806786775589 and parameters: {'penalty_decorrelation_ridge_first_difference': 29.225779676248436, 'penalty_decorrelation_ridge_second_difference': 8.654366988087643}. Best is trial 0 with value: -2.5394318461418153.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2224, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:47,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3560315370559692\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:34,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3555296659469604\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:37,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3571451902389526\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:06,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3582797050476074\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3554354906082153\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3570653200149536\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:29,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3577003479003906\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<24:56,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3554688692092896\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:06<25:14,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538604974746704\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:07<25:05,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.354585886001587\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:08<25:16,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3550812005996704\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:09<24:56,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.354509711265564\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:09<24:52,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3525058031082153\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:10<24:58,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3552166223526\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:11<25:12,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3522758483886719\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:12<24:54,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3537511825561523\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:12<25:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3510754108428955\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:13<24:54,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3527146577835083\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:14<25:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538305759429932\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:15<25:26,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3554307222366333\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:15<24:49,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3601869344711304\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:16<24:35,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3509306907653809\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2000 [00:17<24:47,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3512660264968872\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2000 [00:18<24:52,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3518455028533936\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 25/2000 [00:18<24:58,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3499850034713745\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 26/2000 [00:19<24:51,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.351090669631958\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 27/2000 [00:20<26:44,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3494454622268677\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 28/2000 [00:23<50:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3494709730148315\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 29/2000 [00:27<1:15:51,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3482916355133057\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 30/2000 [00:29<1:11:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3497532606124878\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 31/2000 [00:31<1:09:41,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3500105142593384\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 32/2000 [00:33<1:00:43,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3476300239562988\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 33/2000 [00:33<49:35,  1.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3532928228378296\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(inf, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(483.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3229, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 34/2000 [00:34<42:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.346766710281372\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 35/2000 [00:35<37:48,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3490675687789917\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 36/2000 [00:36<33:27,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3477421998977661\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 37/2000 [00:36<30:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3477548360824585\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.7935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 38/2000 [00:37<29:11,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3482013940811157\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 38/2000 [00:38<33:03,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3494787216186523\n",
      "Early Stop at iteration 38 with minimal loss tensor(1.3468) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:49:25,507] Trial 7 finished with value: -2.5339407682418824 and parameters: {'penalty_decorrelation_ridge_first_difference': 14.19453675550528, 'penalty_decorrelation_ridge_second_difference': 21.71937174924989}. Best is trial 7 with value: -2.5339407682418824.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3579620122909546\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(13.7866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:25,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3566228151321411\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<24:41,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.365829348564148\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.0947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3261, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:02<24:33,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3583674430847168\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3243, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<24:32,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3617560863494873\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3240, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<24:42,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3609009981155396\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3206, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:05<28:52,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3594563007354736\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3566) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:49:31,592] Trial 8 finished with value: -2.5512724995613096 and parameters: {'penalty_decorrelation_ridge_first_difference': 23.864931888217612, 'penalty_decorrelation_ridge_second_difference': 22.984790952513233}. Best is trial 7 with value: -2.5339407682418824.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:03<2:09:43,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3500456809997559\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:05<1:28:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350358009338379\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:07<1:14:47,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349291205406189\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:10<1:25:56,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3517768383026123\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:15<1:49:43,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.353878140449524\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.0747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:18<1:47:12,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3474643230438232\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:19<1:31:34,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.353092908859253\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:21<1:23:11,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3508403301239014\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:23<1:12:26,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349637508392334\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:24<57:44,  1.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3460967540740967\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3372, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(264.6485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:24<47:47,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3485589027404785\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:25<40:57,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3470977544784546\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:26<36:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3498005867004395\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:27<32:38,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.346042275428772\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:27<30:13,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466460704803467\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:28<28:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347266435623169\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:29<27:41,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3466439247131348\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:30<26:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3500932455062866\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:30<25:20,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.345200538635254\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:31<25:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.344923496246338\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:32<25:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3460519313812256\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:33<24:56,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3456768989562988\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2000 [00:33<24:59,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3455334901809692\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2000 [00:34<25:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.346058964729309\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2000 [00:35<48:39,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349195122718811\n",
      "Early Stop at iteration 24 with minimal loss tensor(1.3449) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:50:07,754] Trial 9 finished with value: -2.5329962730407716 and parameters: {'penalty_decorrelation_ridge_first_difference': 4.403057690197533, 'penalty_decorrelation_ridge_second_difference': 24.485143218812713}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3513474464416504\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(556.5256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<24:27,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3531721830368042\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<24:08,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3583492040634155\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:02<24:26,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.351862907409668\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<24:22,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3528354167938232\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<29:28,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.354658603668213\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3513) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:50:12,951] Trial 10 finished with value: -2.5454818487167357 and parameters: {'penalty_decorrelation_ridge_first_difference': 12.05758066040335, 'penalty_decorrelation_ridge_second_difference': 25.407176666848994}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3499603271484375\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<24:33,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3524688482284546\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(28.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<24:27,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3567023277282715\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:02<24:59,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3532705307006836\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(26.4217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4059, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<24:55,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3564027547836304\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<29:44,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3600560426712036\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3500) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:50:18,278] Trial 11 finished with value: -2.54657586812973 and parameters: {'penalty_decorrelation_ridge_first_difference': 11.588885513556233, 'penalty_decorrelation_ridge_second_difference': 21.846090083853863}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<27:46,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3545171022415161\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:48,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3535704612731934\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352242112159729\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.353063702583313\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:51,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3578178882598877\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:30,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349207878112793\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<26:55,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3505990505218506\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:08<54:07,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3561958074569702\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:13<1:25:42,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.353718876838684\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:15<1:18:50,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.354542851448059\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:17<58:33,  1.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350340723991394\n",
      "Early Stop at iteration 10 with minimal loss tensor(1.3492) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:50:37,098] Trial 12 finished with value: -2.537169086933136 and parameters: {'penalty_decorrelation_ridge_first_difference': 11.090150845126194, 'penalty_decorrelation_ridge_second_difference': 0.4790055306618754}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<24:33,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3489564657211304\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<24:10,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3531893491744995\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<24:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3519537448883057\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(103.3917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:02<25:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350622534751892\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:15,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3474732637405396\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<24:59,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352915644645691\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3481379747390747\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:07<44:50,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3526551723480225\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:11<1:08:10,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3451738357543945\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:13<1:04:53,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3531657457351685\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:14<1:01:28,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3501986265182495\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.6143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:16<58:14,  1.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349581241607666\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3299, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2387, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:17<48:17,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3458868265151978\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:17<45:42,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466453552246094\n",
      "Early Stop at iteration 13 with minimal loss tensor(1.3452) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:50:55,922] Trial 13 finished with value: -2.537873184680939 and parameters: {'penalty_decorrelation_ridge_first_difference': 3.444154899482756, 'penalty_decorrelation_ridge_second_difference': 18.597394529253044}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<24:50,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3527075052261353\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3492602109909058\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349472165107727\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3164, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:16,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3511532545089722\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.8512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3540623188018799\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:15,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3478097915649414\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3528059720993042\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:07<43:31,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3530426025390625\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:12<1:13:51,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3504688739776611\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:13<1:09:58,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3490866422653198\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.0657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:15<51:47,  1.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3522279262542725\n",
      "Early Stop at iteration 10 with minimal loss tensor(1.3478) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:51:12,676] Trial 14 finished with value: -2.5397766470909118 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.278544522484533, 'penalty_decorrelation_ridge_second_difference': 6.16852358591159}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<57:56,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3508422374725342\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<59:06,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3512465953826904\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<49:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3514723777770996\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:05<42:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3530197143554688\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:08<1:04:25,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3533421754837036\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:10<1:12:13,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352526068687439\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3508) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:51:24,579] Trial 15 finished with value: -2.5390292525291445 and parameters: {'penalty_decorrelation_ridge_first_difference': 6.703385713721556, 'penalty_decorrelation_ridge_second_difference': 28.39996730976037}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:01<55:34,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3484702110290527\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<1:00:58,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3467302322387695\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<53:52,  1.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3510873317718506\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.9664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:06<53:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3493247032165527\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:10<1:20:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466476202011108\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:12<1:14:43,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3494329452514648\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:14<1:09:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3553690910339355\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:16<1:07:40,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.344826102256775\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:17<59:25,  1.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3500179052352905\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:18<49:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347225308418274\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:18<42:19,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3448280096054077\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:19<37:04,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3442025184631348\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:20<33:16,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3427008390426636\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:21<30:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347205638885498\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:21<29:13,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.342893362045288\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:22<28:07,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3441269397735596\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:23<27:11,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3490164279937744\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:24<47:03,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3467614650726318\n",
      "Early Stop at iteration 17 with minimal loss tensor(1.3427) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:51:49,519] Trial 16 finished with value: -2.537332260608673 and parameters: {'penalty_decorrelation_ridge_first_difference': 1.7134869233033672, 'penalty_decorrelation_ridge_second_difference': 23.5227615192396}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3209, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3556634187698364\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2235, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3234, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:05,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3571738004684448\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3256, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<24:58,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3582078218460083\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:02<24:25,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3588746786117554\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2197, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<24:06,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3195, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3593369722366333\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3230, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<29:19,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.35968816280365\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3557) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:51:54,675] Trial 17 finished with value: -2.5447123646736145 and parameters: {'penalty_decorrelation_ridge_first_difference': 21.935463544309318, 'penalty_decorrelation_ridge_second_difference': 29.925302632421698}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3248, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3292, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3208, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:17,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3516981601715088\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3549187183380127\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:46,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3536906242370605\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:33,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538792133331299\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3189, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:35,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.353165626525879\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<30:45,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3526208400726318\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3517) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:52:00,035] Trial 18 finished with value: -2.543634128570557 and parameters: {'penalty_decorrelation_ridge_first_difference': 12.20927255928666, 'penalty_decorrelation_ridge_second_difference': 15.863190064812823}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2172, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:02<1:18:52,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3511097431182861\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:04<1:06:41,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3525052070617676\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:05<1:01:40,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3534029722213745\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.4409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:03:08,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.35233736038208\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:08<50:31,  1.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3524143695831299\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:09<1:02:14,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3537479639053345\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3511) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:52:10,400] Trial 19 finished with value: -2.5393364906311033 and parameters: {'penalty_decorrelation_ridge_first_difference': 9.276517216919597, 'penalty_decorrelation_ridge_second_difference': 14.781720239352895}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2228, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:02<1:23:46,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3579437732696533\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:04<1:07:42,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3541473150253296\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3213, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:06<1:06:16,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3568094968795776\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:07<1:03:32,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3566768169403076\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:08<49:55,  1.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3664227724075317\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3297, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:09<42:02,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3571162223815918\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:10<57:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3546948432922363\n",
      "Early Stop at iteration 6 with minimal loss tensor(1.3541) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:52:21,468] Trial 20 finished with value: -2.5451188564300535 and parameters: {'penalty_decorrelation_ridge_first_difference': 18.377927769462303, 'penalty_decorrelation_ridge_second_difference': 11.55038718994024}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(6.6287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3194, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:50,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3619964122772217\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3364, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<27:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3216, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3620333671569824\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3199, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3630009889602661\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3167, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3188, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.360327959060669\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3180, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:54,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3639063835144043\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3258, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:49,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3572219610214233\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3145, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:37,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3659313917160034\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2134, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2825, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<25:47,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.359329104423523\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.7128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3109, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(51.7982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3231, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<25:45,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3544011116027832\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:07<25:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3555800914764404\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:08<25:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3634843826293945\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2101, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:09<25:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3538256883621216\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:10<25:30,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3541821241378784\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3220, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3215, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3162, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:10<25:20,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3536776304244995\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3404, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3205, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:12<37:17,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3563705682754517\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3157, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3101, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:13<33:35,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3575196266174316\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3266, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:14<31:07,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3137, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3584305047988892\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:15<29:12,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3604300022125244\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:15<29:06,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.358156681060791\n",
      "Early Stop at iteration 18 with minimal loss tensor(1.3537) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:52:38,074] Trial 21 finished with value: -2.543690812587738 and parameters: {'penalty_decorrelation_ridge_first_difference': 22.173726523882685, 'penalty_decorrelation_ridge_second_difference': 1.8307333685639051}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3178, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3554116487503052\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<27:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3525980710983276\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:55,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3570492267608643\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3237, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.3499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:55,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3535070419311523\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(434.3512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<26:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3541041612625122\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<26:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350999355316162\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:45,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.350536823272705\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3246, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<26:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352576732635498\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(10.6436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<25:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(2.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3524985313415527\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3192, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:07<26:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3529855012893677\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3221, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:08<25:32,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3506489992141724\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:09<25:23,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3480935096740723\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3398, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:10<25:18,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347671389579773\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:10<25:32,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349656343460083\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:11<25:22,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3493636846542358\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3117, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3185, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:12<25:15,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3476784229278564\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3421, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:13<25:20,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3482728004455566\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:13<27:12,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.354379415512085\n",
      "Early Stop at iteration 17 with minimal loss tensor(1.3477) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:52:53,156] Trial 22 finished with value: -2.539273202419281 and parameters: {'penalty_decorrelation_ridge_first_difference': 12.680642318193527, 'penalty_decorrelation_ridge_second_difference': 0.4106104631001115}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3270, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:43,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2381, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3507810831069946\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3295, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<27:52,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3487788438796997\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3492666482925415\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3514779806137085\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.7031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2263, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:55,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3470951318740845\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<27:35,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3115, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3526760339736938\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:07<51:06,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3498492240905762\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:08<42:38,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3490656614303589\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:09<37:31,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3475037813186646\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2267, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2265, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2177, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:10<37:32,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3568143844604492\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3471) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:53:04,949] Trial 23 finished with value: -2.536306583881378 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.3520892548599157, 'penalty_decorrelation_ridge_second_difference': 0.03492344874148834}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3278, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:09,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3453700542449951\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.351548671722412\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(10.4710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2877, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<27:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3448902368545532\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.1467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<26:44,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3470875024795532\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3293, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<26:46,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.343693494796753\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<26:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3497517108917236\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<26:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.348060965538025\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2280, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2409, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2801, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<25:56,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347160816192627\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<25:31,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3467721939086914\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3328, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<29:02,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3475641012191772\n",
      "Early Stop at iteration 9 with minimal loss tensor(1.3437) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:53:14,672] Trial 24 finished with value: -2.536132073402405 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.1757711182195746, 'penalty_decorrelation_ridge_second_difference': 4.06915015062524}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3201, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3259, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3154, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:02<1:15:14,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3492416143417358\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3152, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3212, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:03<45:51,  1.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3504146337509155\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3158, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:03<36:09,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3544726371765137\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3271, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:04<32:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3495539426803589\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:05<29:21,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3507685661315918\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3091, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:06<40:12,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.352057933807373\n",
      "Early Stop at iteration 5 with minimal loss tensor(1.3492) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:53:22,199] Trial 25 finished with value: -2.5419063568115234 and parameters: {'penalty_decorrelation_ridge_first_difference': 7.334881285229674, 'penalty_decorrelation_ridge_second_difference': 21.78947734144665}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3153, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<24:36,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.351286768913269\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<29:53,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466545343399048\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<27:31,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347602367401123\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3179, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3090, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<27:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3476330041885376\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3102, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:04<26:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3461956977844238\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3514795303344727\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.346840262413025\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2842, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<25:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3453041315078735\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<25:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3447346687316895\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:07<24:47,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.347976803779602\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3175, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:08<24:44,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3468137979507446\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:09<24:51,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466726541519165\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3269, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:10<24:56,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3479875326156616\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2416, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:10<24:59,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3447046279907227\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:11<25:11,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3447480201721191\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:12<24:58,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3430970907211304\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3320, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:13<24:54,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3433727025985718\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:13<24:57,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3429123163223267\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:14<24:47,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3440165519714355\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3149, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:15<25:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3435182571411133\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:16<24:42,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3469314575195312\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3318, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:16<25:07,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3436378240585327\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3327, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:17<26:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3440274000167847\n",
      "Early Stop at iteration 22 with minimal loss tensor(1.3429) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:53:41,040] Trial 26 finished with value: -2.5338051438331606 and parameters: {'penalty_decorrelation_ridge_first_difference': 2.3524775615176705, 'penalty_decorrelation_ridge_second_difference': 29.7199647257345}. Best is trial 9 with value: -2.5329962730407716.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.4492, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2836, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2427, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3126, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2610, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3508621454238892\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3174, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2622, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466910123825073\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2843, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:52,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3498371839523315\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.346367597579956\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:09,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3497576713562012\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3108, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2788, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2795, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2556, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:37,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3459434509277344\n",
      "current_loss: tensor(1.2483, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.0554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.5524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(3.2128, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<26:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349839448928833\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.9340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<26:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3468798398971558\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3053, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3072, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:07<25:51,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349685549736023\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3021, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3310, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:07<25:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(4.9837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3459080457687378\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3319, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:08<25:56,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3446698188781738\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3605, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2767, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:09<26:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3442050218582153\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3013, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2656, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:10<25:25,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2964, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.348666787147522\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3578, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:10<24:59,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3484452962875366\n",
      "current_loss: tensor(1.2507, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2816, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:11<25:01,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(9.0191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2513, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.344268798828125\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:12<25:33,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3487833738327026\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:13<25:44,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.343071460723877\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:13<25:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3444530963897705\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:14<25:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3443477153778076\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3019, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3289, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2357, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3052, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:15<25:26,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3455967903137207\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2428, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:16<25:37,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3442246913909912\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3604, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2737, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3119, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:17<27:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2950, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3432705402374268\n",
      "Early Stop at iteration 21 with minimal loss tensor(1.3431) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:53:59,752] Trial 27 finished with value: -2.5329519748687743 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.5634707786226816, 'penalty_decorrelation_ridge_second_difference': 27.075246061862686}. Best is trial 27 with value: -2.5329519748687743.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2078, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<25:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3479337692260742\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<25:42,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466302156448364\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3060, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3388, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3138, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3036, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2778, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<25:35,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3041, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2581, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3460125923156738\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3082, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2831, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2791, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:08,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3466562032699585\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3630, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3610, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3083, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3068, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2397, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3495428562164307\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3135, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:35,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3497755527496338\n",
      "current_loss: tensor(1.2490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3056, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6144, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2576, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2569, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<25:29,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2558, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3473007678985596\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3033, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2832, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:06<29:14,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.349097490310669\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.3460) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:54:07,004] Trial 28 finished with value: -2.5408745884895323 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.5769416068842749, 'penalty_decorrelation_ridge_second_difference': 29.80661135314666}. Best is trial 27 with value: -2.5329519748687743.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2499, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2817, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2469, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3116, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2031, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2018, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2714, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2990, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2820, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2808, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3150, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3094, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<26:51,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.348913550376892\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3287, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3625, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2396, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2420, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3007, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:01<26:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3039, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3456982374191284\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3611, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3571, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1970, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2385, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:02<26:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2601, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3490853309631348\n",
      "current_loss: tensor(1.2491, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3583, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3023, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:03<25:46,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2471, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3482633829116821\n",
      "current_loss: tensor(1.2481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3597, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3337, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2651, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:03<25:25,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3455591201782227\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3330, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2402, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2969, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2000 [00:04<25:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3444195985794067\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:05<24:57,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2522, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3438869714736938\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3567, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3359, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2783, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2696, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3161, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:06<24:43,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2485, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3450039625167847\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3333, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(33.9111, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3204, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2750, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:06<24:52,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3444041013717651\n",
      "current_loss: tensor(1.2460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3309, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2753, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1926, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2669, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3147, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:10<55:48,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3442447185516357\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3570, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2781, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2689, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3029, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5618, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:11<48:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3439325094223022\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2904, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3315, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3313, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2377, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2953, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2805, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:12<41:39,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2943, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3433516025543213\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3294, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2993, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2991, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2000 [00:13<36:48,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2962, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3493881225585938\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3322, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2368, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2936, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2695, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2463, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2629, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2838, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2588, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2000 [00:13<33:37,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3465750217437744\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3016, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3308, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2362, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2947, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2800, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2000 [00:14<31:14,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2454, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2505, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3438448905944824\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2422, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2924, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3012, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2534, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:15<29:34,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3463003635406494\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2882, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3314, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3304, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2772, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2376, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2640, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2458, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2000 [00:16<28:34,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3409594297409058\n",
      "current_loss: tensor(1.2431, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2415, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3300, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2361, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2355, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3002, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2934, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2000 [00:17<27:31,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2901, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2496, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3437505960464478\n",
      "current_loss: tensor(1.2444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3281, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3277, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1869, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2360, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2917, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3030, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2960, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2000 [00:17<26:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3436263799667358\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3305, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2849, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3291, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2353, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:18<26:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3413476943969727\n",
      "current_loss: tensor(1.2419, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2667, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2679, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2624, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2911, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:19<26:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2448, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3421156406402588\n",
      "current_loss: tensor(1.2413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2999, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2978, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3282, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2748, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2723, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:20<25:38,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2972, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.340287208557129\n",
      "current_loss: tensor(1.2401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3288, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3301, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3273, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2641, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2958, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2437, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2521, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2945, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2000 [00:22<44:43,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2462, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3403009176254272\n",
      "current_loss: tensor(1.2406, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2414, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3545, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2956, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1639, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3321, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3279, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2761, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1864, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(2.4307, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2497, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2466, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2457, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2000 [00:28<1:25:55,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.340765118598938\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2804, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2971, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2648, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2903, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2655, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2786, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2736, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2529, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 25/2000 [00:30<1:23:09,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2423, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.342555284500122\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2433, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3022, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3255, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1859, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2356, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.6143, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2514, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2453, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 26/2000 [00:32<1:20:23,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2439, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.339298963546753\n",
      "current_loss: tensor(1.2407, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2688, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1862, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2343, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2878, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2707, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2907, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2440, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 27/2000 [00:35<1:24:26,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2424, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.339504599571228\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2400, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3316, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2729, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1927, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1921, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2350, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2879, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2613, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2432, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2520, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2940, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2538, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 28/2000 [00:38<1:27:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3398758172988892\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3516, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1642, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2852, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3284, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2716, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1858, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2616, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2623, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2524, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 29/2000 [00:39<1:08:57,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2434, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2446, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3403375148773193\n",
      "current_loss: tensor(1.2410, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(5.7429, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3324, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2329, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2704, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8276, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2443, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 30/2000 [00:40<56:14,  1.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2436, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2510, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2504, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2860, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.340272068977356\n",
      "current_loss: tensor(1.2425, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2684, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2829, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3312, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2740, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2726, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1875, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2913, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2644, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2694, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2560, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2447, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2441, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2517, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2895, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2886, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2456, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 30/2000 [00:41<44:54,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3393735885620117\n",
      "Early Stop at iteration 30 with minimal loss tensor(1.3393) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-10-27 15:54:48,815] Trial 29 finished with value: -2.5303560853004456 and parameters: {'penalty_decorrelation_ridge_first_difference': 0.02106918782160605, 'penalty_decorrelation_ridge_second_difference': 24.01519988070122}. Best is trial 29 with value: -2.5303560853004456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter_tuning done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_freq = GTM(\n",
    "    number_variables = 2,\n",
    "    number_transformation_layers = 1,\n",
    "    number_decorrelation_layers = 3,\n",
    "    degree_transformations = 10,\n",
    "    degree_decorrelation = 40,\n",
    "    spline_transformation = \"bspline\",\n",
    "    spline_decorrelation = \"bspline\",\n",
    "    transformation_spline_range = (-10, 10),\n",
    "    device = device) \n",
    "\n",
    "study = model_freq.hyperparameter_tune_penalties( \n",
    "        train_dataloader = dataloader_train,\n",
    "        validate_dataloader = dataloader_validate,\n",
    "        penalty_decorrelation_ridge_param = None,\n",
    "        penalty_decorrelation_ridge_first_difference = \"sample\",\n",
    "        penalty_decorrelation_ridge_second_difference = \"sample\",\n",
    "        penalty_transformation_ridge_second_difference = None,\n",
    "        penalty_lasso_conditional_independence = None,\n",
    "        adaptive_lasso_weights_matrix=False,\n",
    "        optimizer=\"LBFGS\",\n",
    "        learning_rate=1,\n",
    "        iterations=2000,\n",
    "        patience=5,\n",
    "        min_delta=1e-7,\n",
    "        seperate_copula_training=False,\n",
    "        max_batches_per_iter=False,\n",
    "        pretrained_transformation_layer=True,\n",
    "        n_trials=30,\n",
    "        temp_folder=\".\",\n",
    "        study_name=None)\n",
    "        \n",
    "\n",
    "penalty_splines_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penalty_decorrelation_ridge_param\"],\n",
    "                            study.best_params[\"penalty_decorrelation_ridge_first_difference\"],\n",
    "                            study.best_params[\"penalty_decorrelation_ridge_second_difference\"],\n",
    "                            0 #study.best_params[\"penalty_transformation_ridge_second_difference\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "penalty_lasso_conditional_independence=False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7c3a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4131, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4069, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3650, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3675, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4713, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4685, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4602, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3988, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4223, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4193, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4107, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5232, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4490, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4285, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4242, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4493, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<07:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4702, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3992, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3916, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4839, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4722, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4584, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3450, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3445, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4930, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8105, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4548, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4536, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3902, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4732, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4728, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5253, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4459, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4444, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4013, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<06:25,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4252, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4171, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4435, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4588, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3918, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4547, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3332, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3317, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4678, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4518, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3856, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3807, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4225, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4676, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3894, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4515, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5233, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5217, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4379, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3945, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4155, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4151, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4413, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4399, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:01<06:18,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3809, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4854, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3298, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3264, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4848, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4519, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4526, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3746, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3787, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4064, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5244, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5227, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4542, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4401, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4366, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4361, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:01<06:02,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3928, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4121, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4540, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4657, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4631, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3210, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4810, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4511, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3705, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3751, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3718, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3830, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3799, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5245, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5222, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4414, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:01<05:54,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4346, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3892, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3888, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4120, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4112, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4443, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4614, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4550, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4749, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4668, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4505, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3182, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3166, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4615, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4577, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4513, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4460, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3708, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3677, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3833, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3818, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4531, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5296, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5176, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4395, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4375, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4340, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3861, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4106, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4076, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:02<05:50,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4461, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4541, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3790, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3142, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4874, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4525, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3711, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3659, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3691, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4524, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5236, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4464, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4371, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:02<05:48,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4335, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3980, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3863, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4104, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4089, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4389, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4634, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3733, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4467, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3122, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4819, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4535, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4455, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3643, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4014, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3984, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3721, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4486, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(283.7745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5226, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4442, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4331, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3865, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4084, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:02<06:50,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4528, grad_fn=<MeanBackward0>)\n",
      "Early Stop at iteration 7 with minimal loss tensor(1.4568, grad_fn=<MeanBackward0>) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pretrain the marginal transformations\n",
    "_ = model_freq.pretrain_transformation_layer(dataloader_train, iterations=1000, max_batches_per_iter=False, penalty_splines_params=penalty_splines_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36290e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3653, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.4477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4190, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2821, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3530, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3262, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3181, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3311, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3286, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3099, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2871, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3383, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3267, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<11:32,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3184, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3133, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3973121643066406\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2870, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3900, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3339, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2260, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3358, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3326, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3563, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3241, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2503, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2743, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3290, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3274, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3533, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3472, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3186, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2932, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2910, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2754, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3777, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2724, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2912, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2887, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3338, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3306, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2995, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:01<12:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3764806985855103\n",
      "current_loss: tensor(1.2769, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2745, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3699, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3218, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2071, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3203, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3198, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3481, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3129, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3118, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2367, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2283, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2552, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2840, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3141, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3125, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2835, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2823, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3075, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3382, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3334, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2942, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2742, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2572, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2564, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2717, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3148, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3092, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:02<12:27,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2749, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3631958961486816\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2619, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3712, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3697, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(8.6612, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3136, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1922, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3393, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3391, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2214, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2202, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2495, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2845, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3080, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3070, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2774, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3040, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3371, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3268, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2905, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2914, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2562, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3127, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2784, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2739, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:06<32:58,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3638604879379272\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3658, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3124, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3097, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1880, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1868, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3403, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2986, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2939, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2165, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2484, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2480, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2827, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2811, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2768, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3037, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3196, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3159, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2919, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2672, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2555, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2544, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2693, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2674, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3139, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:10<49:16,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3146, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3123, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2731, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3575875759124756\n",
      "current_loss: tensor(1.2582, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2573, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3710, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3646, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1851, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1844, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3392, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3369, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2955, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2908, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2140, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2133, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3076, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3054, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3200, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3169, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2883, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2652, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2647, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2551, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3063, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:12<43:32,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3010, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2937, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3645938634872437\n",
      "current_loss: tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2906, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2537, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3100, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1824, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1815, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3399, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2944, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2931, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2156, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2132, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2465, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2452, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2826, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2764, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3035, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2741, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2961, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3238, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3187, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2834, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2654, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2633, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3103, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3098, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:14<39:01,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3074, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2663, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2657, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3539031744003296\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3635, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3079, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1814, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3017, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3015, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3008, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3363, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2933, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2920, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2081, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2470, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2735, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3034, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3028, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3003, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2720, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2935, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3219, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3183, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2638, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2608, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2494, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2628, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2653, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2620, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3160, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3046, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:16<36:50,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3532230854034424\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2546, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3690, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3632, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3043, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1789, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2996, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2994, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2987, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3352, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3347, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2897, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2884, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2065, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2449, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2430, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2760, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2744, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3004, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2998, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2727, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2719, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2948, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.8591, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2915, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3170, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3096, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2837, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2828, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2626, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2703, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2598, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3084, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3086, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3073, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2659, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:18<34:33,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2627, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3517165184020996\n",
      "current_loss: tensor(1.2532, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2565, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3649, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3621, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3062, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3042, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1776, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1771, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3000, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3348, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3336, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2890, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2872, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2426, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2478, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2418, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2982, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2709, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2706, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2698, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2952, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2929, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3130, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3093, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:19<32:08,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2493, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2489, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2603, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3523, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2617, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2607, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3501516580581665\n",
      "current_loss: tensor(1.2509, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2506, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3066, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3045, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1773, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2989, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3351, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3349, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3341, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2867, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2853, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2417, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2412, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2802, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2775, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2985, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2973, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2701, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2692, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2949, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3085, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2794, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.4600, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2587, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2488, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2599, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3058, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3069, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:20<25:59,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2609, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2597, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3503477573394775\n",
      "current_loss: tensor(1.2501, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3057, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3038, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1763, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2979, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2976, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3344, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3342, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2857, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2847, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2049, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2046, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2411, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2408, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2390, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2780, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3380, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2756, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3011, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2975, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2687, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2909, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3163, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3173, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3095, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2806, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2797, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2606, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2586, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2487, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3048, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2966, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2580, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2575, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2553, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:21<22:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss_val:  1.3532109260559082\n",
      "current_loss: tensor(1.2527, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2500, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3757, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3730, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3055, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3047, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1846, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1782, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2946, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3323, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3302, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2822, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2770, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2020, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2006, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2378, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2762, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2755, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2959, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2683, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2680, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2898, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2885, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3207, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3114, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2813, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2796, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2592, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2566, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2479, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2474, grad_fn=<MeanBackward0>)\n",
      "current_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 13/1000 [00:22<19:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2596, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2593, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3067, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3061, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2554, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2549, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3507226705551147\n",
      "current_loss: tensor(1.2502, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2498, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2475, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3682, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3666, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3024, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3001, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1779, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2954, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2951, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3325, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3303, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2812, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2765, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2027, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2374, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2373, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2365, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2766, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2758, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2974, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2957, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2673, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2665, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2896, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.5191, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3113, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3077, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2803, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2798, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2585, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2482, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2476, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2594, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2590, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3050, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3032, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2925, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 14/1000 [00:22<17:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2559, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2543, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3537094593048096\n",
      "current_loss: tensor(1.2539, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2477, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3686, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3681, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3627, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3009, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2981, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1738, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1725, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2977, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2967, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3354, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3345, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2876, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2855, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2005, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2026, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.1997, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2394, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2370, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2759, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2734, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2968, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2963, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2664, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2660, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2645, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2891, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3025, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2866, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3168, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3087, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2793, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2785, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2589, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 14/1000 [00:23<27:54,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_loss: tensor(1.2568, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2473, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2468, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2579, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2574, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3051, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.3044, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2983, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2561, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2557, grad_fn=<MeanBackward0>)\n",
      "current_loss: tensor(1.2542, grad_fn=<MeanBackward0>)\n",
      "current_loss_val:  1.3528625965118408\n",
      "Early Stop at iteration 14 with minimal loss tensor(1.3502) and patience 5 and min_delta 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = model_freq.train(train_dataloader=dataloader_train, validate_dataloader=dataloader_validate, iterations=1000, optimizer=\"LBFGS\",\n",
    "                penalty_splines_params=penalty_splines_params, adaptive_lasso_weights_matrix=adaptive_lasso_weights_matrix, penalty_lasso_conditional_independence=penalty_lasso_conditional_independence, \n",
    "                max_batches_per_iter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb434f3d",
   "metadata": {},
   "source": [
    "The GTM class contains a number of plotting functions so that standard analysis can be done soley with the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41ca3e",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tune and Train Model\n",
    "\n",
    "To find the optimal penalties one uses the `hyperparameter_tune_penalties` function. Then using the optimal penalties one can train the model.\n",
    "\n",
    "The training can be done by pretraining the marginal transformations with `pretrain_tranformation_layer` and then training jointly with `train`.\n",
    "In general empirically we found that pretraining reduces training time and improves results allthough direct joint training also works.\n",
    "\n",
    "Hyperparameter tuning can be done for the penalties `penvalueridge, penfirstridge , pensecondridge, ctm_pensecondridge, lambda_penalty_params` by passing the arguement `\"sample\"`.\n",
    "If a fixed number is passed, typically zero, then for that penalty no hyperparameter drawing is done and the fixed values is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807c8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters to be affected by the bayesian approach: ['transformation.params.0', 'transformation.params.1', 'decorrelation_layers.0.params', 'decorrelation_layers.1.params', 'decorrelation_layers.2.params']\n",
      "The selected hyperparameters for the transformation layer,\n",
      "the hyperparameters lambda_a=1.100000023841858 and lambda_b=0.0010000000474974513 were selected and will by processed.\n",
      "You are currently using the Full Bayesian Closed form coordinate-ascent VI (CAVI)\n",
      "The selected hyperparameters for tau_1 of the decorrelation layers,\n",
      "the hyperparameters lambda_a=1.5 and lambda_b=0.009999999776482582 were selected and will by processed.\n",
      "The selected hyperparameters for tau_1 of the decorrelation layers,\n",
      "the hyperparameters lambda_a=1.5 and lambda_b=0.009999999776482582 were selected and will by processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sanity] N=2000  current B=100  (training objective uses scaled likelihood & unscaled prior)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:04<14:59,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[1/200] \n",
      "ELBO train=2062.9069  val_ELPD=-0.0156  train_ELPD=-0.0148  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=3.00    N=2000 B=100 B100.0  priors/obs: decor66.4 trans1.99e+03\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.618831  rank=20  E_qf_mean17.9  E_qf_total35.9  tau*E_qf22.2  target22.2  resid-1.99e+05    tau4_mean=0.619   Elog_tau4=-0.526    a_tau4=11.1     b_tau4=17.9  _tau4=-1.11e+04      KL(q||p)0.00411\n",
      "Tau_1 obs and tracking\n",
      "tau1=264.48578521964004     rank=82  E_qf1_total=0.30137833058834074   tau_1*E_qf=79.7    resid_qf2-640    tau1_mean=264   Elog_tau1=5.57    a_tau1=42.5     b_tau1=0.161  _tau1=-3.99e+03      KL(q||p)0.0186\n",
      "Tau_2 obs and tracking\n",
      "tau2=279.21163767629497     rank=80  E_qf1_total=0.29240033626556394   tau_2*E_qf=81.6    resid_qf2-6.37e+03    tau2_mean=279   Elog_tau2=5.62    a_tau2=41.1     b_tau2=0.147  _tau2=-4.08e+04      KL(q||p)0.0187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:08<14:41,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[2/200] \n",
      "ELBO train=8.2531  val_ELPD=-0.0147  train_ELPD=-0.0150  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.90    N=2000 B=100 B100.0  priors/obs: decor0.816 trans0.229\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.665734  rank=20  E_qf_mean16.7  E_qf_total33.3  tau*E_qf22.2  target22.2  resid0.782    tau4_mean=0.666   Elog_tau4=-0.453    a_tau4=11.1     b_tau4=16.7  _tau4=+4.69e-02      KL(q||p)0.00395\n",
      "Tau_1 obs and tracking\n",
      "tau1=261.7740630835209     rank=82  E_qf1_total=0.3047074943780899   tau_1*E_qf=79.8    resid_qf2-0.44    tau1_mean=262   Elog_tau1=5.56    a_tau1=42.5     b_tau1=0.162  _tau1=-2.71e+00      KL(q||p)0.000767\n",
      "Tau_2 obs and tracking\n",
      "tau2=276.1409305158344     rank=80  E_qf1_total=0.29567408934235573   tau_2*E_qf=81.6    resid_qf2-2.57    tau2_mean=276   Elog_tau2=5.61    a_tau2=41.1     b_tau2=0.149  _tau2=-3.07e+00      KL(q||p)0.00104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 3/200 [00:13<14:35,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[3/200] \n",
      "ELBO train=7.9088  val_ELPD=-0.0142  train_ELPD=-0.0144  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.80    N=2000 B=100 B100.0  priors/obs: decor0.812 trans0.218\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.691281  rank=20  E_qf_mean16.1  E_qf_total32.1  tau*E_qf22.2  target22.2  resid0.41    tau4_mean=0.691   Elog_tau4=-0.415    a_tau4=11.1     b_tau4=16.1  _tau4=+2.55e-02      KL(q||p)0.00391\n",
      "Tau_1 obs and tracking\n",
      "tau1=259.4438341233219     rank=82  E_qf1_total=0.3076238974928856   tau_1*E_qf=79.8    resid_qf2-0.382    tau1_mean=259   Elog_tau1=5.55    a_tau1=42.5     b_tau1=0.164  _tau1=-2.33e+00      KL(q||p)0.000762\n",
      "Tau_2 obs and tracking\n",
      "tau2=275.6340155832645     rank=80  E_qf1_total=0.29622153788805006   tau_2*E_qf=81.6    resid_qf2-2.16    tau2_mean=276   Elog_tau2=5.61    a_tau2=41.1     b_tau2=0.149  _tau2=-5.07e-01      KL(q||p)0.00105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 4/200 [00:17<14:29,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[4/200] \n",
      "ELBO train=7.6735  val_ELPD=-0.0139  train_ELPD=-0.0141  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.70    N=2000 B=100 B100.0  priors/obs: decor0.782 trans0.202\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.72765  rank=20  E_qf_mean15.3  E_qf_total30.5  tau*E_qf22.2  target22.2  resid0.555    tau4_mean=0.728   Elog_tau4=-0.364    a_tau4=11.1     b_tau4=15.3  _tau4=+3.64e-02      KL(q||p)0.00389\n",
      "Tau_1 obs and tracking\n",
      "tau1=268.71551510347166     rank=82  E_qf1_total=0.2963196590542793   tau_1*E_qf=79.6    resid_qf21.47    tau1_mean=269   Elog_tau1=5.58    a_tau1=42.5     b_tau1=0.158  _tau1=+9.27e+00      KL(q||p)0.000757\n",
      "Tau_2 obs and tracking\n",
      "tau2=283.22283408201224     rank=80  E_qf1_total=0.288230836391449   tau_2*E_qf=81.6    resid_qf2-0.979    tau2_mean=283   Elog_tau2=5.63    a_tau2=41.1     b_tau2=0.145  _tau2=+7.59e+00      KL(q||p)0.00105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 5/200 [00:22<14:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[5/200] \n",
      "ELBO train=7.4760  val_ELPD=-0.0138  train_ELPD=-0.0139  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0500 min=0.0500 max=0.0500  _KL=2.60    N=2000 B=100 B100.0  priors/obs: decor0.825 trans0.184\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.776365  rank=20  E_qf_mean14.3  E_qf_total28.6  tau*E_qf22.2  target22.2  resid0.696    tau4_mean=0.776   Elog_tau4=-0.299    a_tau4=11.1     b_tau4=14.3  _tau4=+4.87e-02      KL(q||p)0.00386\n",
      "Tau_1 obs and tracking\n",
      "tau1=262.85078292495524     rank=82  E_qf1_total=0.3033773899078369   tau_1*E_qf=79.7    resid_qf2-0.948    tau1_mean=263   Elog_tau1=5.56    a_tau1=42.5     b_tau1=0.162  _tau1=-5.86e+00      KL(q||p)0.000777\n",
      "Tau_2 obs and tracking\n",
      "tau2=277.1841634672097     rank=80  E_qf1_total=0.29455373883247377   tau_2*E_qf=81.6    resid_qf2-3.04    tau2_mean=277   Elog_tau2=5.61    a_tau2=41.1     b_tau2=0.148  _tau2=-6.04e+00      KL(q||p)0.00103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 6/200 [00:26<14:18,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[6/200] \n",
      "ELBO train=7.1341  val_ELPD=-0.0137  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0507 min=0.0500 max=0.0510  _KL=2.50    N=2000 B=100 B100.0  priors/obs: decor0.833 trans0.169\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.825228  rank=20  E_qf_mean13.4  E_qf_total26.9  tau*E_qf22.2  target22.2  resid0.657    tau4_mean=0.825   Elog_tau4=-0.238    a_tau4=11.1     b_tau4=13.5  _tau4=+4.89e-02      KL(q||p)0.00382\n",
      "Tau_1 obs and tracking\n",
      "tau1=253.66273233786325     rank=82  E_qf1_total=0.315090611577034   tau_1*E_qf=79.9    resid_qf2-1.54    tau1_mean=254   Elog_tau1=5.52    a_tau1=42.5     b_tau1=0.168  _tau1=-9.19e+00      KL(q||p)0.000764\n",
      "Tau_2 obs and tracking\n",
      "tau2=270.38194652011634     rank=80  E_qf1_total=0.30201438069343567   tau_2*E_qf=81.7    resid_qf2-3.13    tau2_mean=270   Elog_tau2=5.59    a_tau2=41.1     b_tau2=0.152  _tau2=-6.80e+00      KL(q||p)0.00104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 7/200 [00:31<14:13,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[7/200] \n",
      "ELBO train=6.8811  val_ELPD=-0.0137  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0513 min=0.0502 max=0.0520  _KL=2.40    N=2000 B=100 B100.0  priors/obs: decor0.834 trans0.164\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.850719  rank=20  E_qf_mean13  E_qf_total26.1  tau*E_qf22.2  target22.2  resid0.333    tau4_mean=0.851   Elog_tau4=-0.207    a_tau4=11.1     b_tau4=13  _tau4=+2.55e-02      KL(q||p)0.00379\n",
      "Tau_1 obs and tracking\n",
      "tau1=247.77532393082961     rank=82  E_qf1_total=0.3230527251958847   tau_1*E_qf=80    resid_qf2-1.01    tau1_mean=248   Elog_tau1=5.5    a_tau1=42.5     b_tau1=0.172  _tau1=-5.89e+00      KL(q||p)0.000745\n",
      "Tau_2 obs and tracking\n",
      "tau2=260.1910263982553     rank=80  E_qf1_total=0.31392173320055006   tau_2*E_qf=81.7    resid_qf2-3.64    tau2_mean=260   Elog_tau2=5.55    a_tau2=41.1     b_tau2=0.158  _tau2=-1.02e+01      KL(q||p)0.00105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 8/200 [00:35<14:08,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[8/200] \n",
      "ELBO train=6.5812  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0520 min=0.0505 max=0.0530  _KL=2.30    N=2000 B=100 B100.0  priors/obs: decor0.784 trans0.158\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.872614  rank=20  E_qf_mean12.7  E_qf_total25.4  tau*E_qf22.2  target22.2  resid0.279    tau4_mean=0.873   Elog_tau4=-0.182    a_tau4=11.1     b_tau4=12.7  _tau4=+2.19e-02      KL(q||p)0.00377\n",
      "Tau_1 obs and tracking\n",
      "tau1=254.06085709772975     rank=82  E_qf1_total=0.314565509557724   tau_1*E_qf=79.9    resid_qf21.05    tau1_mean=254   Elog_tau1=5.53    a_tau1=42.5     b_tau1=0.167  _tau1=+6.29e+00      KL(q||p)0.000733\n",
      "Tau_2 obs and tracking\n",
      "tau2=269.4435002192316     rank=80  E_qf1_total=0.3030732341110706   tau_2*E_qf=81.7    resid_qf2-0.53    tau2_mean=269   Elog_tau2=5.58    a_tau2=41.1     b_tau2=0.153  _tau2=+9.25e+00      KL(q||p)0.00107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 9/200 [00:39<14:03,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 1\n",
      "Iteration\n",
      "[9/200] \n",
      "ELBO train=6.3867  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0526 min=0.0508 max=0.0540  _KL=2.20    N=2000 B=100 B100.0  priors/obs: decor0.847 trans0.15\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.897425  rank=20  E_qf_mean12.4  E_qf_total24.7  tau*E_qf22.2  target22.2  resid0.307    tau4_mean=0.897   Elog_tau4=-0.154    a_tau4=11.1     b_tau4=12.4  _tau4=+2.48e-02      KL(q||p)0.00376\n",
      "Tau_1 obs and tracking\n",
      "tau1=244.2899568027909     rank=82  E_qf1_total=0.327947174012661   tau_1*E_qf=80.1    resid_qf2-1.7    tau1_mean=244   Elog_tau1=5.49    a_tau1=42.5     b_tau1=0.174  _tau1=-9.77e+00      KL(q||p)0.000745\n",
      "Tau_2 obs and tracking\n",
      "tau2=255.51028932098427     rank=80  E_qf1_total=0.31970915794372556   tau_2*E_qf=81.7    resid_qf2-4.27    tau2_mean=256   Elog_tau2=5.53    a_tau2=41.1     b_tau2=0.161  _tau2=-1.39e+01      KL(q||p)0.00106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 10/200 [00:44<14:02,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[10/200] \n",
      "ELBO train=6.0064  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0532 min=0.0510 max=0.0551  _KL=2.10    N=2000 B=100 B100.0  priors/obs: decor0.839 trans0.142\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.925614  rank=20  E_qf_mean12  E_qf_total24  tau*E_qf22.2  target22.2  resid0.338    tau4_mean=0.926   Elog_tau4=-0.123    a_tau4=11.1     b_tau4=12  _tau4=+2.82e-02      KL(q||p)0.00374\n",
      "Tau_1 obs and tracking\n",
      "tau1=235.43570074730366     rank=82  E_qf1_total=0.34103275686502454   tau_1*E_qf=80.3    resid_qf2-1.6    tau1_mean=235   Elog_tau1=5.45    a_tau1=42.5     b_tau1=0.181  _tau1=-8.85e+00      KL(q||p)0.000726\n",
      "Tau_2 obs and tracking\n",
      "tau2=247.14699972666455     rank=80  E_qf1_total=0.3305955812335014   tau_2*E_qf=81.7    resid_qf2-3.29    tau2_mean=247   Elog_tau2=5.5    a_tau2=41.1     b_tau2=0.166  _tau2=-8.36e+00      KL(q||p)0.00108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 11/200 [00:48<13:57,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[11/200] \n",
      "ELBO train=5.7607  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0537 min=0.0513 max=0.0561  _KL=2.00    N=2000 B=100 B100.0  priors/obs: decor0.842 trans0.133\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.958243  rank=20  E_qf_mean11.6  E_qf_total23.2  tau*E_qf22.2  target22.2  resid0.378    tau4_mean=0.958   Elog_tau4=-0.0884    a_tau4=11.1     b_tau4=11.6  _tau4=+3.26e-02      KL(q||p)0.00373\n",
      "Tau_1 obs and tracking\n",
      "tau1=228.6638315014372     rank=82  E_qf1_total=0.3517247259616852   tau_1*E_qf=80.4    resid_qf2-1.26    tau1_mean=229   Elog_tau1=5.42    a_tau1=42.5     b_tau1=0.186  _tau1=-6.77e+00      KL(q||p)0.000709\n",
      "Tau_2 obs and tracking\n",
      "tau2=235.79811336474938     rank=80  E_qf1_total=0.3466032981872559   tau_2*E_qf=81.7    resid_qf2-3.8    tau2_mean=236   Elog_tau2=5.45    a_tau2=41.1     b_tau2=0.174  _tau2=-1.13e+01      KL(q||p)0.00109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 12/200 [00:53<13:53,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED! Congrats\n",
      "Iteration\n",
      "[12/200] \n",
      "ELBO train=5.4771  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0542 min=0.0516 max=0.0572  _KL=1.90    N=2000 B=100 B100.0  priors/obs: decor0.802 trans0.122\n",
      "Tau_4 obs and tracking\n",
      "tau4=0.996343  rank=20  E_qf_mean11.1  E_qf_total22.3  tau*E_qf22.2  target22.2  resid0.424    tau4_mean=0.996   Elog_tau4=-0.0494    a_tau4=11.1     b_tau4=11.1  _tau4=+3.81e-02      KL(q||p)0.00371\n",
      "Tau_1 obs and tracking\n",
      "tau1=228.55213644111777     rank=82  E_qf1_total=0.35190639048814776   tau_1*E_qf=80.4    resid_qf2-0.0208    tau1_mean=229   Elog_tau1=5.42    a_tau1=42.5     b_tau1=0.186  _tau1=-1.12e-01      KL(q||p)0.000697\n",
      "Tau_2 obs and tracking\n",
      "tau2=241.15456985173418     rank=80  E_qf1_total=0.3388602212071419   tau_2*E_qf=81.7    resid_qf2-0.809    tau2_mean=241   Elog_tau2=5.47    a_tau2=41.1     b_tau2=0.17  _tau2=+5.36e+00      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 13/200 [00:57<13:48,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 1\n",
      "Iteration\n",
      "[13/200] \n",
      "ELBO train=5.2074  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0547 min=0.0518 max=0.0582  _KL=1.80    N=2000 B=100 B100.0  priors/obs: decor0.843 trans0.11\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.04093  rank=20  E_qf_mean10.7  E_qf_total21.3  tau*E_qf22.2  target22.2  resid0.475    tau4_mean=1.04   Elog_tau4=-0.00561    a_tau4=11.1     b_tau4=10.7  _tau4=+4.46e-02      KL(q||p)0.00369\n",
      "Tau_1 obs and tracking\n",
      "tau1=220.23349206962132     rank=82  E_qf1_total=0.3659540131688118   tau_1*E_qf=80.6    resid_qf2-1.61    tau1_mean=220   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.193  _tau1=-8.32e+00      KL(q||p)0.000697\n",
      "Tau_2 obs and tracking\n",
      "tau2=231.7578624550792     rank=80  E_qf1_total=0.35268052369356157   tau_2*E_qf=81.7    resid_qf2-3.44    tau2_mean=232   Elog_tau2=5.43    a_tau2=41.1     b_tau2=0.177  _tau2=-9.40e+00      KL(q||p)0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 14/200 [01:02<13:43,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 2\n",
      "Iteration\n",
      "[14/200] \n",
      "ELBO train=4.9566  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0551 min=0.0521 max=0.0593  _KL=1.70    N=2000 B=100 B100.0  priors/obs: decor0.825 trans0.0975\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.09125  rank=20  E_qf_mean10.2  E_qf_total20.3  tau*E_qf22.2  target22.2  resid0.512    tau4_mean=1.09   Elog_tau4=0.0416    a_tau4=11.1     b_tau4=10.2  _tau4=+5.03e-02      KL(q||p)0.00366\n",
      "Tau_1 obs and tracking\n",
      "tau1=218.43517682944434     rank=82  E_qf1_total=0.369131463766098   tau_1*E_qf=80.6    resid_qf2-0.35    tau1_mean=218   Elog_tau1=5.37    a_tau1=42.5     b_tau1=0.195  _tau1=-1.80e+00      KL(q||p)0.000683\n",
      "Tau_2 obs and tracking\n",
      "tau2=226.1267093998189     rank=80  E_qf1_total=0.3615130066871643   tau_2*E_qf=81.7    resid_qf2-2.71    tau2_mean=226   Elog_tau2=5.41    a_tau2=41.1     b_tau2=0.182  _tau2=-5.63e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 15/200 [01:06<13:38,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 3\n",
      "Iteration\n",
      "[15/200] \n",
      "ELBO train=4.7075  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0555 min=0.0521 max=0.0603  _KL=1.60    N=2000 B=100 B100.0  priors/obs: decor0.792 trans0.0835\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.14995  rank=20  E_qf_mean9.65  E_qf_total19.3  tau*E_qf22.2  target22.2  resid0.567    tau4_mean=1.15   Elog_tau4=0.094    a_tau4=11.1     b_tau4=9.65  _tau4=+5.87e-02      KL(q||p)0.00364\n",
      "Tau_1 obs and tracking\n",
      "tau1=222.47711161204765     rank=82  E_qf1_total=0.36206177473068235   tau_1*E_qf=80.6    resid_qf20.772    tau1_mean=222   Elog_tau1=5.39    a_tau1=42.5     b_tau1=0.191  _tau1=+4.04e+00      KL(q||p)0.000681\n",
      "Tau_2 obs and tracking\n",
      "tau2=232.85076946747188     rank=80  E_qf1_total=0.3510157972574234   tau_2*E_qf=81.7    resid_qf2-0.448    tau2_mean=233   Elog_tau2=5.44    a_tau2=41.1     b_tau2=0.177  _tau2=+6.72e+00      KL(q||p)0.00113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 16/200 [01:10<13:35,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 4\n",
      "Iteration\n",
      "[16/200] \n",
      "ELBO train=4.4702  val_ELPD=-0.0136  train_ELPD=-0.0136  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0559 min=0.0525 max=0.0614  _KL=1.50    N=2000 B=100 B100.0  priors/obs: decor0.804 trans0.0679\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.21841  rank=20  E_qf_mean9.11  E_qf_total18.2  tau*E_qf22.2  target22.2  resid0.624    tau4_mean=1.22   Elog_tau4=0.152    a_tau4=11.1     b_tau4=9.11  _tau4=+6.85e-02      KL(q||p)0.00361\n",
      "Tau_1 obs and tracking\n",
      "tau1=224.04496920055655     rank=82  E_qf1_total=0.3593881219625473   tau_1*E_qf=80.5    resid_qf20.297    tau1_mean=224   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.19  _tau1=+1.57e+00      KL(q||p)0.000687\n",
      "Tau_2 obs and tracking\n",
      "tau2=235.46867583307431     rank=80  E_qf1_total=0.34709101915359497   tau_2*E_qf=81.7    resid_qf2-1.24    tau2_mean=235   Elog_tau2=5.45    a_tau2=41.1     b_tau2=0.175  _tau2=+2.62e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 17/200 [01:15<13:37,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 5\n",
      "Iteration\n",
      "[17/200] \n",
      "ELBO train=4.1930  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0561 min=0.0526 max=0.0624  _KL=1.40    N=2000 B=100 B100.0  priors/obs: decor0.841 trans0.0509\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.29876  rank=20  E_qf_mean8.55  E_qf_total17.1  tau*E_qf22.2  target22.2  resid0.687    tau4_mean=1.3   Elog_tau4=0.216    a_tau4=11.1     b_tau4=8.55  _tau4=+8.03e-02      KL(q||p)0.00358\n",
      "Tau_1 obs and tracking\n",
      "tau1=215.48513005888674     rank=82  E_qf1_total=0.3744587734341621   tau_1*E_qf=80.7    resid_qf2-1.69    tau1_mean=215   Elog_tau1=5.36    a_tau1=42.5     b_tau1=0.197  _tau1=-8.56e+00      KL(q||p)0.00069\n",
      "Tau_2 obs and tracking\n",
      "tau2=228.05066488301023     rank=80  E_qf1_total=0.3584462195634842   tau_2*E_qf=81.7    resid_qf2-3.06    tau2_mean=228   Elog_tau2=5.42    a_tau2=41.1     b_tau2=0.18  _tau2=-7.42e+00      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 18/200 [01:19<13:31,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 6\n",
      "Iteration\n",
      "[18/200] \n",
      "ELBO train=3.9529  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0563 min=0.0527 max=0.0634  _KL=1.30    N=2000 B=100 B100.0  priors/obs: decor0.775 trans0.0333\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.39025  rank=20  E_qf_mean7.98  E_qf_total16  tau*E_qf22.2  target22.2  resid0.731    tau4_mean=1.39   Elog_tau4=0.284    a_tau4=11.1     b_tau4=7.98  _tau4=+9.15e-02      KL(q||p)0.00354\n",
      "Tau_1 obs and tracking\n",
      "tau1=226.04414942625766     rank=82  E_qf1_total=0.35603273659944534   tau_1*E_qf=80.5    resid_qf21.99    tau1_mean=226   Elog_tau1=5.41    a_tau1=42.5     b_tau1=0.188  _tau1=+1.06e+01      KL(q||p)0.000676\n",
      "Tau_2 obs and tracking\n",
      "tau2=237.90426795676066     rank=80  E_qf1_total=0.343517130613327   tau_2*E_qf=81.7    resid_qf20.0498    tau2_mean=238   Elog_tau2=5.46    a_tau2=41.1     b_tau2=0.173  _tau2=+9.85e+00      KL(q||p)0.00113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 19/200 [01:24<13:26,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 7\n",
      "Iteration\n",
      "[19/200] \n",
      "ELBO train=3.7547  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0529 max=0.0643  _KL=1.20    N=2000 B=100 B100.0  priors/obs: decor0.813 trans0.0149\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.49329  rank=20  E_qf_mean7.43  E_qf_total14.9  tau*E_qf22.2  target22.2  resid0.766    tau4_mean=1.49   Elog_tau4=0.355    a_tau4=11.1     b_tau4=7.43  _tau4=+1.03e-01      KL(q||p)0.0035\n",
      "Tau_1 obs and tracking\n",
      "tau1=225.49527877883367     rank=82  E_qf1_total=0.35694802552461624   tau_1*E_qf=80.5    resid_qf2-0.103    tau1_mean=225   Elog_tau1=5.41    a_tau1=42.5     b_tau1=0.188  _tau1=-5.49e-01      KL(q||p)0.000693\n",
      "Tau_2 obs and tracking\n",
      "tau2=237.39604631110979     rank=80  E_qf1_total=0.3442568197846413   tau_2*E_qf=81.7    resid_qf2-1.83    tau2_mean=237   Elog_tau2=5.46    a_tau2=41.1     b_tau2=0.173  _tau2=-5.08e-01      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 20/200 [01:29<14:08,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 8\n",
      "Iteration\n",
      "[20/200] \n",
      "ELBO train=3.5436  val_ELPD=-0.0136  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0526 max=0.0652  _KL=1.10    N=2000 B=100 B100.0  priors/obs: decor0.844 trans-0.00461\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.61115  rank=20  E_qf_mean6.89  E_qf_total13.8  tau*E_qf22.2  target22.2  resid0.812    tau4_mean=1.61   Elog_tau4=0.431    a_tau4=11.1     b_tau4=6.89  _tau4=+1.18e-01      KL(q||p)0.00346\n",
      "Tau_1 obs and tracking\n",
      "tau1=218.5169933956154     rank=82  E_qf1_total=0.3689857661724091   tau_1*E_qf=80.6    resid_qf2-1.36    tau1_mean=219   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.194  _tau1=-6.98e+00      KL(q||p)0.000692\n",
      "Tau_2 obs and tracking\n",
      "tau2=226.78969167707274     rank=80  E_qf1_total=0.36045033633708956   tau_2*E_qf=81.7    resid_qf2-3.66    tau2_mean=227   Elog_tau2=5.41    a_tau2=41.1     b_tau2=0.181  _tau2=-1.06e+01      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 21/200 [01:34<13:49,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 9\n",
      "Iteration\n",
      "[21/200] \n",
      "ELBO train=3.2429  val_ELPD=-0.0137  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0525 max=0.0661  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.804 trans-0.0237\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.7375  rank=20  E_qf_mean6.39  E_qf_total12.8  tau*E_qf22.2  target22.2  resid0.807    tau4_mean=1.74   Elog_tau4=0.507    a_tau4=11.1     b_tau4=6.39  _tau4=+1.26e-01      KL(q||p)0.00342\n",
      "Tau_1 obs and tracking\n",
      "tau1=220.24559748698738     rank=82  E_qf1_total=0.36593279987573624   tau_1*E_qf=80.6    resid_qf20.334    tau1_mean=220   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.193  _tau1=+1.73e+00      KL(q||p)0.000681\n",
      "Tau_2 obs and tracking\n",
      "tau2=229.542897874732     rank=80  E_qf1_total=0.35610299855470656   tau_2*E_qf=81.7    resid_qf2-1.15    tau2_mean=230   Elog_tau2=5.42    a_tau2=41.1     b_tau2=0.179  _tau2=+2.75e+00      KL(q||p)0.00113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 22/200 [01:38<13:33,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 10\n",
      "Iteration\n",
      "[22/200] \n",
      "ELBO train=3.2338  val_ELPD=-0.0137  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0523 max=0.0670  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.808 trans-0.0443\n",
      "Tau_4 obs and tracking\n",
      "tau4=1.88203  rank=20  E_qf_mean5.9  E_qf_total11.8  tau*E_qf22.2  target22.2  resid0.852    tau4_mean=1.88   Elog_tau4=0.587    a_tau4=11.1     b_tau4=5.9  _tau4=+1.45e-01      KL(q||p)0.00338\n",
      "Tau_1 obs and tracking\n",
      "tau1=220.46527953182428     rank=82  E_qf1_total=0.365548238158226   tau_1*E_qf=80.6    resid_qf20.0423    tau1_mean=220   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.193  _tau1=+2.20e-01      KL(q||p)0.000683\n",
      "Tau_2 obs and tracking\n",
      "tau2=231.5367167558117     rank=80  E_qf1_total=0.3530192866921425   tau_2*E_qf=81.7    resid_qf2-1.31    tau2_mean=232   Elog_tau2=5.43    a_tau2=41.1     b_tau2=0.178  _tau2=+1.99e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 23/200 [01:43<13:25,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 11\n",
      "Iteration\n",
      "[23/200] \n",
      "ELBO train=3.2097  val_ELPD=-0.0137  train_ELPD=-0.0137  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0519 max=0.0678  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.819 trans-0.0638\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.03248  rank=20  E_qf_mean5.46  E_qf_total10.9  tau*E_qf22.2  target22.2  resid0.822    tau4_mean=2.03   Elog_tau4=0.664    a_tau4=11.1     b_tau4=5.46  _tau4=+1.50e-01      KL(q||p)0.00334\n",
      "Tau_1 obs and tracking\n",
      "tau1=219.11448098700035     rank=82  E_qf1_total=0.36792506873607633   tau_1*E_qf=80.6    resid_qf2-0.262    tau1_mean=219   Elog_tau1=5.38    a_tau1=42.5     b_tau1=0.194  _tau1=-1.35e+00      KL(q||p)0.000684\n",
      "Tau_2 obs and tracking\n",
      "tau2=229.13735657305298     rank=80  E_qf1_total=0.3567367911338806   tau_2*E_qf=81.7    resid_qf2-2.11    tau2_mean=229   Elog_tau2=5.42    a_tau2=41.1     b_tau2=0.179  _tau2=-2.40e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 24/200 [01:47<13:17,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 12\n",
      "Iteration\n",
      "[24/200] \n",
      "ELBO train=3.1754  val_ELPD=-0.0137  train_ELPD=-0.0138  S_train=4 S_val=16  lr=[0.01, 0.001]  =0.0565 min=0.0517 max=0.0687  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.791 trans-0.0835\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.19205  rank=20  E_qf_mean5.06  E_qf_total10.1  tau*E_qf22.2  target22.2  resid0.808    tau4_mean=2.19   Elog_tau4=0.739    a_tau4=11.1     b_tau4=5.06  _tau4=+1.60e-01      KL(q||p)0.0033\n",
      "Tau_1 obs and tracking\n",
      "tau1=224.50860476307574     rank=82  E_qf1_total=0.3586046427488327   tau_1*E_qf=80.5    resid_qf21.02    tau1_mean=225   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.189  _tau1=+5.39e+00      KL(q||p)0.000682\n",
      "Tau_2 obs and tracking\n",
      "tau2=235.23213938182022     rank=80  E_qf1_total=0.34744204580783844   tau_2*E_qf=81.7    resid_qf2-0.597    tau2_mean=235   Elog_tau2=5.45    a_tau2=41.1     b_tau2=0.175  _tau2=+6.09e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 25/200 [01:51<13:07,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 13\n",
      "Iteration\n",
      "[25/200] \n",
      "ELBO train=3.1591  val_ELPD=-0.0138  train_ELPD=-0.0138  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0515 max=0.0697  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.794 trans-0.104\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.36247  rank=20  E_qf_mean4.7  E_qf_total9.39  tau*E_qf22.2  target22.2  resid0.801    tau4_mean=2.36   Elog_tau4=0.814    a_tau4=11.1     b_tau4=4.7  _tau4=+1.70e-01      KL(q||p)0.00325\n",
      "Tau_1 obs and tracking\n",
      "tau1=228.0174502747725     rank=82  E_qf1_total=0.35277848690748215   tau_1*E_qf=80.4    resid_qf20.654    tau1_mean=228   Elog_tau1=5.42    a_tau1=42.5     b_tau1=0.186  _tau1=+3.51e+00      KL(q||p)0.00069\n",
      "Tau_2 obs and tracking\n",
      "tau2=241.78748413012931     rank=80  E_qf1_total=0.33796796947717667   tau_2*E_qf=81.7    resid_qf2-0.603    tau2_mean=242   Elog_tau2=5.48    a_tau2=41.1     b_tau2=0.17  _tau2=+6.56e+00      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 26/200 [01:56<12:59,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 14\n",
      "Iteration\n",
      "[26/200] \n",
      "ELBO train=3.1872  val_ELPD=-0.0138  train_ELPD=-0.0138  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0514 max=0.0704  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.831 trans-0.12\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.51853  rank=20  E_qf_mean4.41  E_qf_total8.81  tau*E_qf22.2  target22.2  resid0.688    tau4_mean=2.52   Elog_tau4=0.878    a_tau4=11.1     b_tau4=4.41  _tau4=+1.56e-01      KL(q||p)0.00321\n",
      "Tau_1 obs and tracking\n",
      "tau1=224.2586324370679     rank=82  E_qf1_total=0.35902665853500365   tau_1*E_qf=80.5    resid_qf2-0.712    tau1_mean=224   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.19  _tau1=-3.76e+00      KL(q||p)0.000696\n",
      "Tau_2 obs and tracking\n",
      "tau2=234.5596741857799     rank=80  E_qf1_total=0.3484438702464104   tau_2*E_qf=81.7    resid_qf2-3.04    tau2_mean=235   Elog_tau2=5.45    a_tau2=41.1     b_tau2=0.175  _tau2=-7.23e+00      KL(q||p)0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 27/200 [02:00<12:52,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 15\n",
      "Iteration\n",
      "[27/200] \n",
      "ELBO train=3.1556  val_ELPD=-0.0138  train_ELPD=-0.0138  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0514 max=0.0710  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.816 trans-0.132\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.64662  rank=20  E_qf_mean4.19  E_qf_total8.39  tau*E_qf22.2  target22.2  resid0.537    tau4_mean=2.65   Elog_tau4=0.928    a_tau4=11.1     b_tau4=4.19  _tau4=+1.28e-01      KL(q||p)0.00318\n",
      "Tau_1 obs and tracking\n",
      "tau1=223.06942891544736     rank=82  E_qf1_total=0.3610472843050957   tau_1*E_qf=80.5    resid_qf2-0.227    tau1_mean=223   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.191  _tau1=-1.19e+00      KL(q||p)0.00069\n",
      "Tau_2 obs and tracking\n",
      "tau2=233.05683999293433     rank=80  E_qf1_total=0.35070365816354754   tau_2*E_qf=81.7    resid_qf2-1.98    tau2_mean=233   Elog_tau2=5.44    a_tau2=41.1     b_tau2=0.176  _tau2=-1.50e+00      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 28/200 [02:05<12:45,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 16\n",
      "Iteration\n",
      "[28/200] \n",
      "ELBO train=3.1278  val_ELPD=-0.0138  train_ELPD=-0.0139  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0513 max=0.0717  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.795 trans-0.146\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.78508  rank=20  E_qf_mean3.98  E_qf_total7.97  tau*E_qf22.2  target22.2  resid0.552    tau4_mean=2.79   Elog_tau4=0.979    a_tau4=11.1     b_tau4=3.99  _tau4=+1.38e-01      KL(q||p)0.00315\n",
      "Tau_1 obs and tracking\n",
      "tau1=228.02298387944535     rank=82  E_qf1_total=0.35276944041252134   tau_1*E_qf=80.4    resid_qf20.923    tau1_mean=228   Elog_tau1=5.42    a_tau1=42.5     b_tau1=0.186  _tau1=+4.95e+00      KL(q||p)0.000688\n",
      "Tau_2 obs and tracking\n",
      "tau2=236.95313368604772     rank=80  E_qf1_total=0.3449040427803993   tau_2*E_qf=81.7    resid_qf2-1.02    tau2_mean=237   Elog_tau2=5.46    a_tau2=41.1     b_tau2=0.173  _tau2=+3.90e+00      KL(q||p)0.00112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 29/200 [02:09<12:39,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 17\n",
      "Iteration\n",
      "[29/200] \n",
      "ELBO train=3.1011  val_ELPD=-0.0138  train_ELPD=-0.0139  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0511 max=0.0725  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.771 trans-0.159\n",
      "Tau_4 obs and tracking\n",
      "tau4=2.93062  rank=20  E_qf_mean3.79  E_qf_total7.57  tau*E_qf22.2  target22.2  resid0.551    tau4_mean=2.93   Elog_tau4=1.03    a_tau4=11.1     b_tau4=3.79  _tau4=+1.46e-01      KL(q||p)0.00312\n",
      "Tau_1 obs and tracking\n",
      "tau1=236.55442748329958     rank=82  E_qf1_total=0.3393253400921822   tau_1*E_qf=80.3    resid_qf21.53    tau1_mean=237   Elog_tau1=5.45    a_tau1=42.5     b_tau1=0.18  _tau1=+8.53e+00      KL(q||p)0.000696\n",
      "Tau_2 obs and tracking\n",
      "tau2=251.86565548458475     rank=80  E_qf1_total=0.3243644654750824   tau_2*E_qf=81.7    resid_qf20.701    tau2_mean=252   Elog_tau2=5.52    a_tau2=41.1     b_tau2=0.163  _tau2=+1.49e+01      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 30/200 [02:14<12:35,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 18\n",
      "Iteration\n",
      "[30/200] \n",
      "ELBO train=3.1354  val_ELPD=-0.0139  train_ELPD=-0.0139  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0509 max=0.0732  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.837 trans-0.174\n",
      "Tau_4 obs and tracking\n",
      "tau4=3.09312  rank=20  E_qf_mean3.59  E_qf_total7.18  tau*E_qf22.2  target22.2  resid0.583    tau4_mean=3.09   Elog_tau4=1.08    a_tau4=11.1     b_tau4=3.59  _tau4=+1.63e-01      KL(q||p)0.00309\n",
      "Tau_1 obs and tracking\n",
      "tau1=229.57493648106941     rank=82  E_qf1_total=0.3502494767308235   tau_1*E_qf=80.4    resid_qf2-1.29    tau1_mean=230   Elog_tau1=5.42    a_tau1=42.5     b_tau1=0.185  _tau1=-6.98e+00      KL(q||p)0.000711\n",
      "Tau_2 obs and tracking\n",
      "tau2=243.5531003587798     rank=80  E_qf1_total=0.33550340235233306   tau_2*E_qf=81.7    resid_qf2-3.27    tau2_mean=244   Elog_tau2=5.48    a_tau2=41.1     b_tau2=0.169  _tau2=-8.31e+00      KL(q||p)0.00108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 31/200 [02:18<12:29,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 19\n",
      "Iteration\n",
      "[31/200] \n",
      "ELBO train=3.1187  val_ELPD=-0.0139  train_ELPD=-0.0139  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0509 max=0.0740  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.834 trans-0.186\n",
      "Tau_4 obs and tracking\n",
      "tau4=3.25557  rank=20  E_qf_mean3.41  E_qf_total6.82  tau*E_qf22.2  target22.2  resid0.554    tau4_mean=3.26   Elog_tau4=1.13    a_tau4=11.1     b_tau4=3.41  _tau4=+1.62e-01      KL(q||p)0.00306\n",
      "Tau_1 obs and tracking\n",
      "tau1=225.07670453014788     rank=82  E_qf1_total=0.35764903426170347   tau_1*E_qf=80.5    resid_qf2-0.849    tau1_mean=225   Elog_tau1=5.4    a_tau1=42.5     b_tau1=0.189  _tau1=-4.50e+00      KL(q||p)0.000699\n",
      "Tau_2 obs and tracking\n",
      "tau2=235.27485285822632     rank=80  E_qf1_total=0.3473786056041718   tau_2*E_qf=81.7    resid_qf2-3.24    tau2_mean=235   Elog_tau2=5.45    a_tau2=41.1     b_tau2=0.175  _tau2=-8.28e+00      KL(q||p)0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 32/200 [02:22<12:24,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 20\n",
      "Iteration\n",
      "[32/200] \n",
      "ELBO train=3.0562  val_ELPD=-0.0139  train_ELPD=-0.0140  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0509 max=0.0747  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.802 trans-0.199\n",
      "Tau_4 obs and tracking\n",
      "tau4=3.43901  rank=20  E_qf_mean3.23  E_qf_total6.45  tau*E_qf22.2  target22.2  resid0.592    tau4_mean=3.44   Elog_tau4=1.19    a_tau4=11.1     b_tau4=3.23  _tau4=+1.83e-01      KL(q||p)0.00304\n",
      "Tau_1 obs and tracking\n",
      "tau1=225.89882655347674     rank=82  E_qf1_total=0.35627464205026627   tau_1*E_qf=80.5    resid_qf20.155    tau1_mean=226   Elog_tau1=5.41    a_tau1=42.5     b_tau1=0.188  _tau1=+8.22e-01      KL(q||p)0.000691\n",
      "Tau_2 obs and tracking\n",
      "tau2=239.51904834686195     rank=80  E_qf1_total=0.34118773639202116   tau_2*E_qf=81.7    resid_qf2-0.989    tau2_mean=240   Elog_tau2=5.47    a_tau2=41.1     b_tau2=0.172  _tau2=+4.24e+00      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 33/200 [02:27<12:20,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 21\n",
      "Iteration\n",
      "[33/200] \n",
      "ELBO train=3.0654  val_ELPD=-0.0139  train_ELPD=-0.0140  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0565 min=0.0509 max=0.0755  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.81 trans-0.213\n",
      "Tau_4 obs and tracking\n",
      "tau4=3.6563  rank=20  E_qf_mean3.03  E_qf_total6.07  tau*E_qf22.2  target22.2  resid0.66    tau4_mean=3.66   Elog_tau4=1.25    a_tau4=11.1     b_tau4=3.04  _tau4=+2.17e-01      KL(q||p)0.00301\n",
      "Tau_1 obs and tracking\n",
      "tau1=226.65758219678074     rank=82  E_qf1_total=0.355015030503273   tau_1*E_qf=80.5    resid_qf20.142    tau1_mean=227   Elog_tau1=5.41    a_tau1=42.5     b_tau1=0.188  _tau1=+7.59e-01      KL(q||p)0.000693\n",
      "Tau_2 obs and tracking\n",
      "tau2=239.14616583332503     rank=80  E_qf1_total=0.34172284305095674   tau_2*E_qf=81.7    resid_qf2-1.82    tau2_mean=239   Elog_tau2=5.46    a_tau2=41.1     b_tau2=0.172  _tau2=-3.73e-01      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 34/200 [02:32<12:58,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 22\n",
      "Iteration\n",
      "[34/200] \n",
      "ELBO train=3.0113  val_ELPD=-0.0140  train_ELPD=-0.0140  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0566 min=0.0508 max=0.0764  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.755 trans-0.227\n",
      "Tau_4 obs and tracking\n",
      "tau4=3.90835  rank=20  E_qf_mean2.84  E_qf_total5.68  tau*E_qf22.2  target22.2  resid0.716    tau4_mean=3.91   Elog_tau4=1.32    a_tau4=11.1     b_tau4=2.84  _tau4=+2.52e-01      KL(q||p)0.00297\n",
      "Tau_1 obs and tracking\n",
      "tau1=242.65395153495766     rank=82  E_qf1_total=0.3302930802106857   tau_1*E_qf=80.1    resid_qf22.8    tau1_mean=243   Elog_tau1=5.48    a_tau1=42.5     b_tau1=0.175  _tau1=+1.60e+01      KL(q||p)0.000694\n",
      "Tau_2 obs and tracking\n",
      "tau2=256.403135336363     rank=80  E_qf1_total=0.3185889035463333   tau_2*E_qf=81.7    resid_qf21.01    tau2_mean=256   Elog_tau2=5.53    a_tau2=41.1     b_tau2=0.16  _tau2=+1.73e+01      KL(q||p)0.00111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 35/200 [02:37<12:40,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 23\n",
      "Iteration\n",
      "[35/200] \n",
      "ELBO train=3.0942  val_ELPD=-0.0140  train_ELPD=-0.0141  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0566 min=0.0506 max=0.0772  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.856 trans-0.241\n",
      "Tau_4 obs and tracking\n",
      "tau4=4.1946  rank=20  E_qf_mean2.65  E_qf_total5.29  tau*E_qf22.2  target22.2  resid0.757    tau4_mean=4.19   Elog_tau4=1.39    a_tau4=11.1     b_tau4=2.65  _tau4=+2.86e-01      KL(q||p)0.00294\n",
      "Tau_1 obs and tracking\n",
      "tau1=229.87774072016904     rank=82  E_qf1_total=0.3497617691755295   tau_1*E_qf=80.4    resid_qf2-2.36    tau1_mean=230   Elog_tau1=5.43    a_tau1=42.5     b_tau1=0.185  _tau1=-1.28e+01      KL(q||p)0.000723\n",
      "Tau_2 obs and tracking\n",
      "tau2=242.83560673739794     rank=80  E_qf1_total=0.33650060594081876   tau_2*E_qf=81.7    resid_qf2-4.2    tau2_mean=243   Elog_tau2=5.48    a_tau2=41.1     b_tau2=0.169  _tau2=-1.36e+01      KL(q||p)0.00108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 36/200 [02:42<13:06,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 24\n",
      "Iteration\n",
      "[36/200] \n",
      "ELBO train=3.0206  val_ELPD=-0.0140  train_ELPD=-0.0141  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0566 min=0.0503 max=0.0780  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.8 trans-0.254\n",
      "Tau_4 obs and tracking\n",
      "tau4=4.51459  rank=20  E_qf_mean2.46  E_qf_total4.92  tau*E_qf22.2  target22.2  resid0.787    tau4_mean=4.51   Elog_tau4=1.46    a_tau4=11.1     b_tau4=2.46  _tau4=+3.20e-01      KL(q||p)0.0029\n",
      "Tau_1 obs and tracking\n",
      "tau1=233.19788636194235     rank=82  E_qf1_total=0.34449730068445206   tau_1*E_qf=80.3    resid_qf20.605    tau1_mean=233   Elog_tau1=5.44    a_tau1=42.5     b_tau1=0.182  _tau1=+3.32e+00      KL(q||p)0.0007\n",
      "Tau_2 obs and tracking\n",
      "tau2=245.555280841903     rank=80  E_qf1_total=0.3327515058219433   tau_2*E_qf=81.7    resid_qf2-1.33    tau2_mean=246   Elog_tau2=5.49    a_tau2=41.1     b_tau2=0.167  _tau2=+2.72e+00      KL(q||p)0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 37/200 [02:46<12:43,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 25\n",
      "Iteration\n",
      "[37/200] \n",
      "ELBO train=2.9976  val_ELPD=-0.0141  train_ELPD=-0.0141  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0567 min=0.0502 max=0.0789  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.776 trans-0.268\n",
      "Tau_4 obs and tracking\n",
      "tau4=4.91958  rank=20  E_qf_mean2.26  E_qf_total4.51  tau*E_qf22.2  target22.2  resid0.914    tau4_mean=4.92   Elog_tau4=1.55    a_tau4=11.1     b_tau4=2.26  _tau4=+4.05e-01      KL(q||p)0.00286\n",
      "Tau_1 obs and tracking\n",
      "tau1=242.95466098636876     rank=82  E_qf1_total=0.3298595160245895   tau_1*E_qf=80.1    resid_qf21.71    tau1_mean=243   Elog_tau1=5.48    a_tau1=42.5     b_tau1=0.175  _tau1=+9.76e+00      KL(q||p)0.000705\n",
      "Tau_2 obs and tracking\n",
      "tau2=256.424249402425     rank=80  E_qf1_total=0.3185625061392784   tau_2*E_qf=81.7    resid_qf2-0.0679    tau2_mean=256   Elog_tau2=5.53    a_tau2=41.1     b_tau2=0.16  _tau2=+1.09e+01      KL(q||p)0.00109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 38/200 [02:51<12:26,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 26\n",
      "Iteration\n",
      "[38/200] \n",
      "ELBO train=3.0101  val_ELPD=-0.0141  train_ELPD=-0.0142  S_train=4 S_val=16  lr=[0.006999999999999999, 0.0007]  =0.0567 min=0.0502 max=0.0797  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.786 trans-0.282\n",
      "Tau_4 obs and tracking\n",
      "tau4=5.37351  rank=20  E_qf_mean2.06  E_qf_total4.13  tau*E_qf22.2  target22.2  resid0.938    tau4_mean=5.37   Elog_tau4=1.64    a_tau4=11.1     b_tau4=2.07  _tau4=+4.54e-01      KL(q||p)0.00281\n",
      "Tau_1 obs and tracking\n",
      "tau1=249.11407295874582     rank=82  E_qf1_total=0.32120914608240125   tau_1*E_qf=80    resid_qf21.05    tau1_mean=249   Elog_tau1=5.51    a_tau1=42.5     b_tau1=0.171  _tau1=+6.16e+00      KL(q||p)0.000723\n",
      "Tau_2 obs and tracking\n",
      "tau2=264.2839332223555     rank=80  E_qf1_total=0.3090291231870651   tau_2*E_qf=81.7    resid_qf2-0.686    tau2_mean=264   Elog_tau2=5.56    a_tau2=41.1     b_tau2=0.156  _tau2=+7.86e+00      KL(q||p)0.00108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 39/200 [02:55<12:13,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 27\n",
      "Iteration\n",
      "[39/200] \n",
      "ELBO train=3.0025  val_ELPD=-0.0142  train_ELPD=-0.0142  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0568 min=0.0503 max=0.0806  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.82 trans-0.296\n",
      "Tau_4 obs and tracking\n",
      "tau4=5.92205  rank=20  E_qf_mean1.87  E_qf_total3.75  tau*E_qf22.2  target22.2  resid1.03    tau4_mean=5.92   Elog_tau4=1.73    a_tau4=11.1     b_tau4=1.87  _tau4=+5.49e-01      KL(q||p)0.00276\n",
      "Tau_1 obs and tracking\n",
      "tau1=244.08728576614553     rank=82  E_qf1_total=0.3282360821962357   tau_1*E_qf=80.1    resid_qf2-0.875    tau1_mean=244   Elog_tau1=5.49    a_tau1=42.5     b_tau1=0.174  _tau1=-5.03e+00      KL(q||p)0.000735\n",
      "Tau_2 obs and tracking\n",
      "tau2=262.33865307925714     rank=80  E_qf1_total=0.3113354504108429   tau_2*E_qf=81.7    resid_qf2-2.28    tau2_mean=262   Elog_tau2=5.56    a_tau2=41.1     b_tau2=0.157  _tau2=-1.95e+00      KL(q||p)0.00106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 40/200 [02:59<12:02,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 28\n",
      "Iteration\n",
      "[40/200] \n",
      "ELBO train=3.0049  val_ELPD=-0.0143  train_ELPD=-0.0143  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0568 min=0.0502 max=0.0813  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.818 trans-0.307\n",
      "Tau_4 obs and tracking\n",
      "tau4=6.44939  rank=20  E_qf_mean1.72  E_qf_total3.44  tau*E_qf22.2  target22.2  resid0.908    tau4_mean=6.45   Elog_tau4=1.82    a_tau4=11.1     b_tau4=1.72  _tau4=+5.27e-01      KL(q||p)0.00271\n",
      "Tau_1 obs and tracking\n",
      "tau1=242.73327016491996     rank=82  E_qf1_total=0.33017861396074294   tau_1*E_qf=80.1    resid_qf2-0.237    tau1_mean=243   Elog_tau1=5.48    a_tau1=42.5     b_tau1=0.175  _tau1=-1.35e+00      KL(q||p)0.000726\n",
      "Tau_2 obs and tracking\n",
      "tau2=258.0027341290994     rank=80  E_qf1_total=0.31660127490758894   tau_2*E_qf=81.7    resid_qf2-2.65    tau2_mean=258   Elog_tau2=5.54    a_tau2=41.1     b_tau2=0.159  _tau2=-4.34e+00      KL(q||p)0.00107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 41/200 [03:04<11:53,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 29\n",
      "Iteration\n",
      "[41/200] \n",
      "ELBO train=2.9880  val_ELPD=-0.0143  train_ELPD=-0.0144  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0568 min=0.0501 max=0.0819  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.783 trans-0.316\n",
      "Tau_4 obs and tracking\n",
      "tau4=7.01119  rank=20  E_qf_mean1.58  E_qf_total3.16  tau*E_qf22.2  target22.2  resid0.889    tau4_mean=7.01   Elog_tau4=1.9    a_tau4=11.1     b_tau4=1.58  _tau4=+5.62e-01      KL(q||p)0.00266\n",
      "Tau_1 obs and tracking\n",
      "tau1=249.9247050935715     rank=82  E_qf1_total=0.3201024323701859   tau_1*E_qf=80    resid_qf21.22    tau1_mean=250   Elog_tau1=5.51    a_tau1=42.5     b_tau1=0.17  _tau1=+7.19e+00      KL(q||p)0.000723\n",
      "Tau_2 obs and tracking\n",
      "tau2=266.85452767795556     rank=80  E_qf1_total=0.30603299736976625   tau_2*E_qf=81.7    resid_qf2-0.559    tau2_mean=267   Elog_tau2=5.57    a_tau2=41.1     b_tau2=0.154  _tau2=+8.85e+00      KL(q||p)0.00107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 41/200 [03:08<12:12,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPROVED! Nr. 30\n",
      "Iteration\n",
      "[42/200] \n",
      "ELBO train=3.0113  val_ELPD=-0.0144  train_ELPD=-0.0145  S_train=4 S_val=16  lr=[0.004899999999999999, 0.00049]  =0.0568 min=0.0499 max=0.0825  _KL=1.00    N=2000 B=100 B100.0  priors/obs: decor0.83 trans-0.325\n",
      "Tau_4 obs and tracking\n",
      "tau4=7.59661  rank=20  E_qf_mean1.46  E_qf_total2.92  tau*E_qf22.2  target22.2  resid0.855    tau4_mean=7.6   Elog_tau4=1.98    a_tau4=11.1     b_tau4=1.46  _tau4=+5.85e-01      KL(q||p)0.00262\n",
      "Tau_1 obs and tracking\n",
      "tau1=245.1545797595219     rank=82  E_qf1_total=0.3267200171947479   tau_1*E_qf=80.1    resid_qf2-0.827    tau1_mean=245   Elog_tau1=5.49    a_tau1=42.5     b_tau1=0.173  _tau1=-4.77e+00      KL(q||p)0.000737\n",
      "Tau_2 obs and tracking\n",
      "tau2=258.73137843859627     rank=80  E_qf1_total=0.3157040238380432   tau_2*E_qf=81.7    resid_qf2-3.29    tau2_mean=259   Elog_tau2=5.54    a_tau2=41.1     b_tau2=0.159  _tau2=-8.12e+00      KL(q||p)0.00106\n",
      "\n",
      "Early stop @ epoch 42: no val improvement for 30 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"transformation\": {\n",
    "    \"sigma_a\": 2.1, \"sigma_b\": 1e6,        #Ignored not used\n",
    "    \n",
    "    #\"RW2\": {\"tau_a\": 1e-3, \"tau_b\": 1e-3},   # A) nearly-flat proper   recommended\n",
    "    \"RW2\": {\"tau_a\": 1.1,  \"tau_b\": 1e-3},   # B) weak default\n",
    "    # \"RW2\": {\"tau_a\": 1.0,  \"tau_b\": 1.0},    # C) unit-scale neutral\n",
    "    \n",
    "    \"RW1\": { \"tau_a\": 10.0,\"tau_b\": 15.0 }  #Ignored not used\n",
    "    },\n",
    "    \"decorrelation\": {\n",
    "    \"sigma_a\": 2.1, \"sigma_b\": -1e6,              # mean  = very small close to 0 (weak)\n",
    "    \"RW2\": { \"tau_a\": 1.5, \"tau_b\": 0.01 },      # E[2]  0.05   (weak curvature smoothing)\n",
    "    \"RW1\": { \"tau_a\": 1.5, \"tau_b\": 0.01 },      # E[1]  0.10   (light shrink to linear)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model = GTM(\n",
    "    number_variables=2,\n",
    "    number_transformation_layers=1,\n",
    "    number_decorrelation_layers=3,\n",
    "    degree_transformations=10,\n",
    "    degree_decorrelation=40,\n",
    "    spline_transformation=\"bspline\",\n",
    "    spline_decorrelation=\"bspline\",\n",
    "    transformation_spline_range=(-10, 10),\n",
    "    device=device,\n",
    "    ## NEW ARGUMENTS ##\n",
    "    inference = 'bayesian',\n",
    "    hyperparameter=hyperparameters\n",
    "    )\n",
    "\n",
    "output = model.train(\n",
    "                train_dataloader=dataloader_train,\n",
    "                validate_dataloader=dataloader_validate,\n",
    "                hyperparameters=None,\n",
    "                iterations=200,\n",
    "                #verbose=True,\n",
    "                learning_rate=0.01,\n",
    "                mcmc_sample_train=4,            # will ramp\n",
    "                mcmc_sample_val=16,             # fixed & larger for stable eval\n",
    "                mc_ramp_every=60,               # 481632 at epochs 25/50/75\n",
    "                mc_ramp_max=64,\n",
    "                patience=30,                # early-stop patience\n",
    "                min_delta=0.00001,                # ~0.1% absolute of your loss scale\n",
    "                rho_lr_multiplier=0.1,          # slightly faster variance adaption (optional)\n",
    "                sched_factor=0.7, sched_patience=12, sched_threshold=1e-4,\n",
    "                #WARMING\n",
    "                warm_tau_epochs = 3,\n",
    "                warm_sigma_epochs = 5,  # try 510\n",
    "                \n",
    "                #Optimization method\n",
    "                beta_kl_start= 3,    # try 1.53.0\n",
    "                beta_kl_anneal_epochs = 20,  # how fast to decay to 1.0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0869c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-10.2321,   1.4470,   1.4470,   1.4470,   1.4704,   2.0220,   2.5595,\n",
      "          1.9755,   1.6554,   1.6411,   1.6411,   1.6411], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.9247,  0.2950,  2.0512,  1.2464,  1.0515,  1.6318,  2.4768,  0.3147,\n",
      "        -0.2926, -0.2987, -0.2857, -0.2957], requires_grad=True)\n",
      "12\n",
      "12\n",
      "Parameter containing:\n",
      "tensor([-10.1351,   1.5266,   1.5266,   1.5266,   1.5332,   1.8089,   2.7712,\n",
      "          2.2565,   1.6698,   1.6411,   1.6411,   1.6411], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.9021,  0.2916,  2.0777,  1.2437,  1.0370,  1.5169,  2.5355,  0.7144,\n",
      "        -0.2346, -0.3106, -0.2998, -0.3121], requires_grad=True)\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(model_freq.transformation.params[0])\n",
    "print(model.transformation.params[0])\n",
    "\n",
    "print(len(model_freq.transformation.params[0]))\n",
    "print(len(model.transformation.params[0]))\n",
    "\n",
    "\n",
    "print(model_freq.transformation.params[1])\n",
    "print(model.transformation.params[1])\n",
    "\n",
    "print(len(model_freq.transformation.params[1]))\n",
    "print(len(model.transformation.params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b467e",
   "metadata": {},
   "source": [
    "#### PROBLEM HERE, I was trying to introduce a early stop algorithm with the elbo loss, nevertheless, it seems that it overfits wenn i try to use more epochs. I was working with 1000 epoch. \n",
    "# It seems, that, it converges but to the wrong state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5eebff",
   "metadata": {},
   "source": [
    "### 4. Compare to Benchmarks\n",
    "\n",
    "We compare the learned GTM to a Gaussian Approximation and the Oracle Model. We expect the GTM to lie between these two in terms of approximation the true underlying distribution.\n",
    "We measure this by means of the Kullback Leibler Divergence which we approximate on the test set which is equivalent to the log likelihood ratio between the true distribution and an approximation of it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b910002",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_train_bgtm = model.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_bgtm = model.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_bgtm = model.log_likelihood(simulated_data_test)\n",
    "\n",
    "\n",
    "log_likelihood_train_gtm = model_freq.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_gtm = model_freq.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_gtm = model_freq.log_likelihood(simulated_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad6c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the Multivariate Normal Distribution as Model\n",
    "mean_mvn_model = simulated_data_train.mean(0)\n",
    "cov_mvn_model = simulated_data_train.T.cov()\n",
    "mvn_model = torch.distributions.MultivariateNormal(loc=mean_mvn_model, covariance_matrix=cov_mvn_model)\n",
    "log_likelihood_train_gaussian = (mvn_model.log_prob(simulated_data_train)).to(device)\n",
    "log_likelihood_validate_gaussian = (mvn_model.log_prob(simulated_data_validate)).to(device)\n",
    "log_likelihood_test_gaussian = (mvn_model.log_prob(simulated_data_test)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d759712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cpu\n"
     ]
    }
   ],
   "source": [
    "print(loglik_true_train.device, log_likelihood_train_gaussian.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c2f1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD BGTM      Train Data:  0.2087\n",
      "KLD GTM      Train Data:  0.0426\n",
      "KLD Gaussian Train Data:  0.1115\n",
      "KLD Copula   Train Data:  -0.001\n",
      "\n",
      "KLD BGTM      Test  Data:  0.2127\n",
      "KLD GTM      Test  Data:  0.05\n",
      "KLD Gaussian Test  Data:  0.1102\n",
      "KLD Copula   Test  Data:  0.0019\n"
     ]
    }
   ],
   "source": [
    "print(\"KLD BGTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_bgtm).item(),4) )\n",
    "print(\"KLD GTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Train Data: \",np.round(torch.mean(loglik_true_train - loglik_true_est_train).item(),4) )\n",
    "print(\"\")\n",
    "print(\"KLD BGTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_bgtm).item(),4) )\n",
    "print(\"KLD GTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Test  Data: \",np.round(torch.mean(loglik_true_test - loglik_true_est_test).item(),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee4e5d",
   "metadata": {},
   "source": [
    "### 5. Evaluate and Plot GTM Results\n",
    "\n",
    "We evaluate the model further by showing how to generate synthetic samples, plot the conditional correlation patterns as well as the model splines.\n",
    "\n",
    "Note that to generate synthetic samples the inverse of the trainsformation layer needs to be approximated  with the method `approximate_transformation_inverse` once which is then stored for future sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6690f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.approximate_transformation_inverse()\n",
    "synthetic_samples = model.sample(10000)\n",
    "model_freq.approximate_transformation_inverse()\n",
    "synthetic_samples_freq = model_freq.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22df00ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAIaCAYAAAAdnSbqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9e4yl13neCz7r8t33pbqapMUyJTaboqRYF9ojJzk6CQL7xMk5RuCJE2HGQQzScQwECZRMOAYGgSAMTgLkQAY8GDg4mBMYB4gdcOCRc3BGMZyZKONgohieRLFlm6RkmSJFsnRrymx2de3Ld1+X+eNd36q9q3ZVV1+ru3r9jDa7a9fe9e1dpVrPft/nfV5mrbUIBAKBQCAQOAP4WV9AIBAIBAKBh5cgRAKBQCAQCJwZQYgEAoFAIBA4M4IQCQQCgUAgcGYEIRIIBAKBQODMCEIkEAgEAoHAmRGESCAQCAQCgTMjCJFAIBAIBAJnRhAigUAgEAgEzowgRAKBQCAQCJwZ51KI/MIv/AIYY3jhhRfO+lICgUAgEAicwLkTIr/3e7+HX/7lX8bHPvaxs76UQCAQCAQCN+BcCZHlcomf/umfxv/8P//PuHDhwllfTiAQCAQCgRsgz/oC7iSf+tSn8Ff+yl/Bj/3Yj+Gf/tN/euLntm2Ltm39v40x2Nvbw8WLF8EYu9uXGggEAoHAucFai8VigZ2dHXB+czWOcyNEPve5z+EP/uAP8Hu/93un+vzPfvaz+Cf/5J/c5asKBAKBQODh4dvf/jaeeOKJm7rPuRAi3/72t/EP/+E/xG/91m8hTdNT3efTn/40fv7nf97/ezab4X3vex++/e1vYzKZ3K1LDQQCgUDg3DGfz/He974X4/H4pu/LrLX2LlzTPeVf/+t/jb/21/4ahBD+Y1prMMbAOUfbtmu3bWI+n2M6nWI2mwUhEggEAoHATXA7Z+i5qIj8xb/4F/GVr3xl7WM/+7M/iw996EP4R//oH91QhAQCgUAgEDgbzoUQGY/H+MhHPrL2saIocPHixSMfDwQCgUAgcP9wrsZ3A4FAIBAIPFici4rIJr74xS+e9SUEAoFAIBC4AaEiEggEAoFA4MwIQiQQCAQCgcCZEYRIIBAIBAKBMyMIkUAgEAgEAmdGECKBQCAQCATOjCBEAoFAIBAInBlBiAQCgUAgEDgzghAJBAKBQCBwZpzbQLPAvWE2m2F3dxeLxQKTyQRPPvkkptPpWV9WIBAIBB4QghAJ3DJvvvkmXnzxRVy5csV/bGdnB8899xwuX758hlcWCAQCgQeF0JoJ3BKz2eyICAGAK1eu4MUXX8RsNjujKwsEAoHAg0QQIoFbYnd394gIGbhy5Qp2d3fv7QUFAoFA4IEkCJHALbFYLG7r9kAgEAgEgCBEArfIeDy+rdsDgUAgEACCEAncIpcuXcLOzs7G23Z2dnDp0qV7e0GBQCAQeCAJQiRwS0ynUzz33HNHxMjOzg6ef/75MMIbCAQCgVPBrLX2rC/ifmA+n2M6nWI2m2EymZz15TwwrOaIjMdjXLp0KYiQQCAQeMi4nTM05IgEbovpdIpnn332rC8jEAgEAg8ooTUTCAQCgUDgzAhCJBAIBAKBwJkRhEggEAgEAoEzIwiRQCAQCAQCZ0YQIoFAIBAIBM6MIEQCgUAgEAicGUGIBAKBQCAQODOCEAkEAoFAIHBmBCESCAQCgUDgzAhCJBAIBAKBwJkRhEggEAgEAoEzIwiRQCAQCAQCZ0ZYeveAsrr1djKZ4MknnwxbbwOBQCDwwBGEyAPIm2++iRdffBFXrlzxH9vZ2cFzzz2Hy5cvn+GVBQKBQCBwc4TWzAPGbDY7IkIA4MqVK3jxxRcxm83O6MoCgUAgELh5ghB5wNjd3T0iQgauXLmC3d3de3tBgUAgEAjcBkGIPGAsFovbuj0QCAQCgfuJIEQeMMbj8W3dHggEAoHA/UQQIg8Yly5dws7OzsbbdnZ2cOnSpXt7QYFAIBAI3AZBiDxgTKdTPPfcc0fEyM7ODp5//vkwwhsIBAKBBwpmrbVnfRH3A/P5HNPpFLPZDJPJ5Kwv54as5oiMx2NcunQpiJBAIBAInAm3c4aGHJEHlOl0imefffasLyMQCAQCgdsitGYCgUAgEAicGUGIBAKBQCAQODOCEAkEAoFAIHBmBCESCAQCgUDgzAhCJBAIBAKBwJkRhEggEAgEAoEzIwiRQCAQCAQCZ8a5ESL//J//c3zsYx/DZDLBZDLBJz7xCfzbf/tvz/qyAoFAIBAInMC5CTR74okn8Au/8At45plnYK3Fv/yX/xJ/9a/+VfzhH/4hPvzhD5/15T20rCbATiYTPPnkkyEBNhAIBAKecx3xvr29jV/8xV/Ez/3cz93wcx+0iPcHgTfffBMvvvgirly54j+2s7OD5557DpcvXz7DKwsEAoHAneR2ztBz05pZRWuNz33ucyjLEp/4xCc2fk7btpjP52t/AneO2Wx2RIQAwJUrV/Diiy9iNpud0ZUFAoFA4H7iXAmRr3zlKxiNRkiSBH/37/5dfP7zn8cP/MAPbPzcz372s5hOp/7Pe9/73nt8teeb3d3dIyJk4MqVK9jd3b23FxQIBAKB+5JzJUQ++MEP4qWXXsJ/+S//BX/v7/09/MzP/Ay+9rWvbfzcT3/605jNZv7Pt7/97Xt8teebxWJxW7cHAoFA4OHg3JhVASCOY7z//e8HAHz84x/H7/3e7+Gf/bN/hl/+5V8+8rlJkiBJknt9iQ8N4/H4tm4PBAKBwMPBuaqIHMYYg7Ztz/oyHkouXbqEnZ2djbft7Ozg0qVL9/aCAoFAIHBfcm6EyKc//Wn89m//NnZ3d/GVr3wFn/70p/HFL34RP/3TP33Wl/ZQMp1O8dxzzx0RIzs7O3j++efDCG8gEAgEAJyj1sw777yD559/Hm+//Tam0yk+9rGP4d/9u3+Hv/SX/tJZX9pDy+XLl/HCCy/4HJHxeIxLly4FERIIBAIBz7nOEbkZQo5IIBAIBAK3RsgRCQQCgUAg8EAShEggEAgEAoEzIwiRQCAQCAQCZ0YQIoFAIBAIBM6MIEQCgUAgEAicGedmfDdwf/Hrv3u6pXY/9WfCKG8gEAg8zAQhErhjnFZ8nHSfIEwCgUDg4SIIkcBtMZvNsLu7i1cWO+CMQQgJxtktP14QJoFAIPBwEYRI4JZ588038eKLL+LxT/wsgBoAwAVHnuUQUtyRr7EqTIIoCQQCgfNHECKBW2I2m62IkAOMNqjqCqNidFuVkU0EURIIBALnjyBEArfE7u6uFyFSCoAxWGvBGAOshdYKkkd37esHURIIBALngyBEArfEYrEAcAFRFKFpGiit/G1SSERRfM+uZRAlQZAEAoHAg0cQIoFbYpd9CFK2R0QIACitUNc1GGNgDLdtYD0toUoSCAQCDx5BiARuCSkket4fESFwu5z7vkfXd1C9uuMG1pOwxkJphRd/56qf4vkb/9XWXf+6gUAgELg1ghAJ3BKMMwguwBmDsXbtNiE4jLGw7uN308C6ilYaVV3BaOM/xgXHr/0nAyFFqJIEAoHAfUiIeA/cMlxwSBkhkhGklJBCgnMnQuCMqw6jzdHqyR3EGntEhAxft6orWGPx6787u6XQtUAgEAjcPUJFJHDLSCEhpPCHvzYaxhp/Gw5VSuzKv4cWirUWnHFwzqGNdv9m4FzAGA3j/n0jn4nS6ogIGRhEUOSmeIKXJBAIBO4fghAJrDEkpS4WC0wmEzz55JOYTjcf1owz5FnuKxEMJBSkkEjTFH3fr3++q5AcbqFEUYS2bQEGcMZJzFggSRL/GDfymdhDoue0t4eJm0AgEDhbghAJeIak1CtXrviP7ezs4LnnnsPly5c33kdIgVExouqGMVBawxpzRIRwwSGFPNJCkVL4yRvOGJiMoJWCseQxSZIYSukb+kxW20CbuNHtQZAEAoHA2RA8IgEAB0mpqyIEAK5cuYIXX3wRs9nx3grGGaIoQpwkSOLkiHl1qGYwzo62UBjz3hFjLYwx/v5KK+CUPhMpJLjY/OM8iKDTMPhIgpckEAgE7g1BiAQAUFLqYREycOXKFezu7p7qcYYKSV7kyPIMeZFjVIx8S+Vwi+TIv3GD249psQxtosNiZFUE3SxBkAQCgcDdJ7RmAgCGpNRbv30Vxpk3hh6GMwYZSR8HzxkHA/MCZPCZ+MdiJ/97lbU2kXt8eQfC1ELbJhAIBO4eQYgEAADj8fi2bj8NWmnUdYO2bXz7JUszRFGEvu/BGMA5BzeUTUKTNwe7bAAAliZujhMXJ4mg2yUIkkAgELjzhNZMAABw6dIl7OzsbLxtZ2cHly5duq3H9yZVYyCkBHfComkaRJFEFEUQUoIxBiElIhkhTVMwxtC2HaqqQte2WCwXWCwWUP3dyyS5EaFlEwgEAneOIEQCAIDpdIrnnnvuiBjZ2dnB888/f+wI72lZNalydhCEJqRA1/coRgVGoxGyPMNoNMJ0OkUcx+hV78d6ldJQSqFpGxIj6uzECBAESSAQCNwJQmsm4Ll8+TJeeOEFnyMyHo9x6dKl2xYhwFGTKS3EY2u3x/H6xl5tNKyxMFofmcTpVY+u6yC4uCcL9U4itGwCgUDg1mH2RklQDwnz+RzT6RSz2QyTyeSsL+eB4LhqwHpqKqWiaq1QltWxj5UXOaJo3dvRdR3KZYle9dgTjx25D2MMYOv21g9c2JyuerdZfc7PTt4+MQguEAgEzhu3c4aGikjgjnLc4rkszSCEgNb6yH2Oy/lgjOFPcAFwYarlfG/ttqIoyFMiBKSUaBXw2vX1buO9ECaHn/OXqi387tUF/punrh0bBBcIBAIBIgiRwB3jpMVzdVMjyzLUdX1EpByX8/HWMgFgUc6vHXwN0AgwYwxN08AYQ22dJEGe54C1fj+NsmJNmDw1ateqNKdp6Wyq7qze76Tn/P99K8bFi7NQGQkEAoETCEIkcMe40eI5a+2pcz4GARELi1ZKb0xloGpIFEVo2hacc1hr0bYtjNaIosh/rhACWZYBAFrN8MbiwIPy/dH8xN01wPHVndX73eg5/+ZXe0TRLPhHAoFA4BjC1Ezgljl8uJ5m8ZyPg49jRFF0ogjJYo5ISkwmE5qoyWiihnOOpm0hOIc1JAKM1tBarxlgtdboOhr97euF/wMA3+0neH1Ou282XusJlY6qrvz9TrtsL0zYBAKBwGaCEAncMW538dwqWXzwoyklbfON4hjW7aPhnMM4EWIt5bJa2I2R8IfHfFdFyWszat8c9pbcqNIx7Ly52eccxEggEAisE4RI4I5xpxbPbbw/5xCcHtsY4yshqzCwIwf/jSoWAsqLnlVBYo0FFxxCCjLDRpISXg897q0851AdCQQCgQOCEAncFqvtmbuxeG4VIYRLXj3q6+BuemZTXslJDAmvWcy9IPn6dY63qgRt02K5WGK5XGKxWKBtWz9iPDwu4wxZmoExBm20N8+e5jkHQRIIBALBrBq4w9zu4rnDLZJVOOcUesYY6rqCVtp/PIoiRHGE/lD0O2MMUkq3u4aEzHBdw+jvKomk/BLNIrzLHwFiYFu/A2MMur4HwJBmqa90aKXRNA2E4BAyIRHirvMkI+wqv/67wcwaCAQeXoIQCdxxbnfx3Ko/5DBSShIeUkIbA7iDn3OOuq6BlYqIEAJxHCOOY3R9vyZeGGOIkwSx85sMKKWglMJiuQ8GYLT1CK6Jx8AEsNV/D1prSEnC6jhDqwYZZ0fF6NQC7HNf2ofSCpfsq5hMJiEQLRAIPDSE1kzgtrnT7+bbtkVd12jbdnMAmquApEmCNE0RxzGklCiKAkVRIMtz//dBuKi+BwNVR6SUkFEEawzlmgyTN4f+bQEsZ9ewnFGOyX70HlyTj/rrOK2h9UZopbEsl6jKCl+r3ocvfW8Lv/RLv4Q333zzZl62QCAQeCAJQiRw39D3PYw1mM1mWCwWmM1mmM1m6Pv+lh/TGIO+7327JIoi/2cQKYPY0W4EeIABsMbAGIPZ9auoFtcBC7xVpgBOP7p74uccU1V5/BM/ixdffBGzWfCQBAKB800QIoH7AqMNloslttU7KCbb/uNKKSwWi42VkVWUUijLEmVZoq4qlFWFpm2xWJLZdPgDkOBZLhYoK/r8qqqglIKxFswFpEVS+rHgVZpyBqgGr13nXpAcx2nGlU+qqjz+iZ/Fb3711kVYIBAIPAgEIRK4I9xse8Yai76nDbqq76G0OpL3MTD4No5jaKlorQFnTo2jCFopcJfCCgBxHKNuGnRdB8Y5jCGhobVGXdeU2uoeL0kTCHlgoWI4yDPp+h6SaTAAb5stvG22jlzTaceVT1NVCZM1gUDgPBPMqoF7zqbodAuLNE3RNM3G+xgXZKa19rtkhBC+tTKIkEhKNG1DQkcpEhCRpD00AJq2BayFFNyLAMaYT2UdFvP1Xe99KBYWggtwIdB1nd9nk8UcSim0muFts4XH+T6Ao+PKJ+2rOW0g2iBGfurP0HbL3d1dLBaLYGwNBAIPPEGIBO4YP/Vnpjd8935SdLrqFaI4Ag53YRjlfZRlCa01pagas7ZLBoxBCoGmbaCVBuMcDMC35PeR67SjQ91GY/+w72N/AikElFJkXrX2YDGfMei7Dj1oJFkm0osQ4CB/hHwmJJC+Zy8AAD5QaC80brSvZghE29Se2VRV+bX/tIeqrvB7/+p/8h/b2dnBc889Fzb9BgKBB5LQmgncU5RSUL1aC/8C4CPbBT+avZGlmZ+gsdZSK0cptG2LxXKBvu8RSUmVDUWL73bZI/h29B76WDNHPX8XwrSoZldRzd5FX+3jW/L78IbdxlvsEbyupz5zpCgKjEYjP3mTxIn3jUgpEcfx2sjvMMWTxyR+Xnex8afZV3MzIXCrj/fxT37Gf/zKlSvB2BoIBB5YghAJ3FFO8opopdH1HXpFQoL+S5Myw0bdoRUxGFaHg98YAwsSMqu+Cq2oQtK2LSwskiTB63oL1losr/8JFnt/gr5XSNMU1hpI5/uwFmgW12C7EkxVYGB4eRHjy3sMf7BP+SNJksAYura2a8kI68aKB4PrYVYTWl+biVON9w4hcHmRI8sz5EWOUTE6Eoh22Nj68U9+xguSK1euYHd394TvTCAQCNyfBCESuCcM7+YHGBg444DzZwwHfpzEuDxqwRjDdDol7wMbvBZms7nTWhhrIIVE23UAgGp21aWnwlVP6ONJkiJJEgAWeZ6j7ztUVY2+mkE3c9iuBAB8eY/hpXmEPM+hlDrIIHFiaTC4mg07b4CDULbjzKx02QfP5TRbiY8ztg5iZLFYbLz9fmY2m+Hll1/G7/zO7+CVV14JVZ1A4CEkeEQCd5xNXpHh3Tx37Q9rDJTWsIYOV8MNoigC55ySSyuGJE7otmMO+1UGL8U3+aNgAOI4Qdu2Psp9iF7v+xZJkkCIDFVVA2CQUoC7g98YDd6VKIoCVQ/84UzC2imeZnsASAzB+U8Gk+xqm2aViGmUVYkoG+Nts4X3sOtuJNjSgj7c3O6dk4ytH//kZ7DLcvz5m3rEs+XNN9/Eiy++iCtXrviPBb9LIPDwcW4qIp/97Gfxp//0n8Z4PMZjjz2Gn/zJn8TXv/71s76sgGN4N6+URp5lAJgXIQDFsSdJgqZu/Mf7vvcVjuMO+9VQsmW5hLUW5f470Fohz/M1D0rf92ia1ldg+r53AkWsHfLGuIj2hCFCB2stvmEu4BvmgvO49D5jRGuNtusojO2QYBKCNvf29QJdNcf3zBb+xF7w7aVe9VA9Pd4wxrz6mhx5rqfY9PugLNKbzWZHRAgQ/C6BwMPIuREi//E//kd86lOfwpe+9CX81m/9Fvq+x1/+y38ZZVme9aU9lBz2iqwf9AZCChRFgbygOPY4idH3PbTWUErhcTlDZ7gPJ5NR5LfvDggpkOU52rZFr9TaIa41CY08z8E5g9bKj+fGceQ8KRJRJH01ZBVrDYyx0NqgWeyhWVBFZJc/irfYI+iVglaKWjRV5cPUVn0jnHNkWUYR80qhnNNj7InHcJVdRNd2fqtvXdUoywrLcun34QDreStaK2RZdmRR3yZj6/0uRnZ3d4+IkIHgdwkEHi7OTWvmC1/4wtq/f/VXfxWPPfYYfv/3fx9/4S/8hTO6qsDA6piqsZZGYR3Uronc1IogL8lqYcB9fhxFSLMUym3YtdbCrjyWtRZgQ/XFou87JEkMa+FDzdI0QRTFR1oqw2PRH/q3UgpaKwhBFZdBjKTjbeyyR8AYw5+yS/8Yg2+kKAr/2FJKLx6stYBu6b9Rhu+ZLWzrdxAnsX+MYaJmVIxgjNk4+pulGQDKMjlpu/Fq9shxDJkk165dA2OMdvVkGd73vvfd1WySG/lZHkS/SyAQuDXOjRA5zFDa3d7evsFnBu4Fw5hqVVdrVQ3OGIQbvaVPZOQlcQd5lI3R1wsvRoqIDsoh2My4IDKAAs/AAca4FyMAJapmWQqtDaKIfuQpDE3AGA1jLIzRUEq7yZoIdd341kqaZi5MTVF7Z3ENnAsk4wv443YEAHhGzgBrN/pGjLVH9uWYboYkn2BPPIbrLcN7XBgaQGJEa4W6aTaO/tZNjVExgjzlZt/jBMng0Xj11Vfx+uuvoyxLPP300/iJn/gJ/MZv/Ab+5t/8m3fNqzEej2/r9kAgcH44N62ZVYwxeOGFF/Dn/tyfw0c+8pGNn9O2Lebz+dqfwJ3l8ME3jKkmbjQ2khGkjGh6ZoVBlDy+cjgPGGc6jaIISRyDuQOfgfnDXwjh2i4RooimUKqqQtfR2G1ZlrDWIM8zl1+yLkKSJAbnDG3bYD5f+LFday1Go5GrcHCgK1HPr8HC4nV1MN1jDk238GNMpuV8z7drDk/WaG3uyGbfVVbbNYNHY3d314sQAHjjjTfwm7/5m8iy7K56NS5duoSdnZ2Nt+3s7ODSpUt35esGAoH7j3MpRD71qU/hq1/9Kj73uc8d+zmf/exn/XjodDrFe9/73nt4hQ8PR7winEFGEb2jj+R6dUTwtSyRTRw+1AXnR/I2rLUwxkIIAaV6l/mh0fcKfU97a6qqBmMcaZohz3NkWYbxeOw8JRxKUaUEoPaHMRpt26IsK1/10E4oNPM99NU+XldTvK63jl6jq6xsQkgB09cA1kd9j67bW+c0m303MZhZB4/GYrE44qN64403kKbpXfVqTKdTPPfcc0fEyM7ODp5//vkQWR8IPEScu9bM3//7fx//5t/8G/z2b/82nnjiiWM/79Of/jR+/ud/3v97Pp8HMXIPGaojww6WwesAAK1o16oBQ3tmONBXd84wBhR5cSRgTEpqqZRl6cyo1L4BmJuKgUtqNS7DBH5x3mg08l9rqJjUtQZAvpE0pSySvle+5dP3HRLdwIgULy/I8/HD2wcTO0N0/LBFmLkx5SRJ0CsFqIV/rm+bLTzNDzw0mzjNZt+TeGWxg49/8jP4f/3f/sHG2+uaxNHd9GpcvnwZL7zwgt+bMx6PcenSpSBCAoGHjHMjRKy1+Af/4B/g85//PL74xS/iqaeeOvHzkyRxwVaBu81xO2gYZ4h4dOTjeZbTNlwGvJct8Z12hDiOfcLq6oEO0EGf5zktrmvIcAlYXzXQ2sDaA2HDGHc+EgPGODgXqOuaRotzipNvmtZ9LnlMRqMCTdO4+wKLxdKN61q/lRcA8shCCI5la/HlPbYmRtI0hTYGcO0lzjkd+CvVDdNVyLIMb5UJjI03tqdOu9n3JAYh8+N/75/htf/jjx+5fdjhc7e9GtPpFM8+++xd/RqBQOD+5twIkU996lP4tV/7NfzGb/wGxuMxvve97wGgX3R+MVrgvuK4rbRCCqRpSlUOrWBRACJBVZWQUUSH+QrGGHRdhyzLwFoGKzMknEZr4zgCEFHeR9uBBIqhtFQ3zkvTMQZJEqNt2yPXOeR+xHGMpmlgDImnodKiNX39yWTiWzCjhHkxAgAfjMo18TQs7CuKYuNGYQmg6oxv1Ry32fdWGaaYrLX4+/+X34SxFv/T/+l/CwB4+umn0TRN8GoEAoF7ArO32my+zziuVP0rv/Ir+Ft/62/d8P7z+RzTKa1Yn0wmd/jqAsC6WfKkrbSccyzL5dptb5sttOWM9snEycY9L0VRIIoifHmPwbS0DK/vld8xkySJS1O1iKIIk8kUUSTRti2WyxLftBm1iYCNDo0PZgZN00DKaG38GKCfv62tqR8THjDGouwOHu0Zse//LoTwo76r7aZVQWKMQeOe6uVRe+yo7q0wfA+Uy0Qx1pJA+db/B1evXsVP//RP37CyeLMM48KLxQKTyQRPPvlkaMUEAueA2zlDz01F5JzoqYeCG22lTZP02IkRrTRYsvkgNta6jb7c/ZcOe63hhUuSUIZImma+XcMYwzdNCjCgX7wLYLif9tWaaPwIXm8EgAJWWTyBAyEybO1d/RmkMDRNEzluZFmkE7yut7wYGUyvm9pNQ8VESok8BurO4K0ltRI/cOHGkfenYc2nY4bXgoN95JP4Gx+J7rhACJHugUBgE+dyaiZwfzJM0BzeIruK0Qba6CMff5zvIylIZR8nOrlbRgeQOKBEVe3211ClIklSpGkKpXowxtD3Pf5oYQDGEKnSh5pppfyYsIwioJ0jFwq8WwBg+A4f4Tu8WEtnpcdT6LoOy+UCZbn0kzp9r6BqGhF/XW/hdb0FY8goW5YllF5/zoeX6q1t9b1+5/5n65ftJQniJEEU0/P9wh3ejhAi3QOBwHEEIRK459yoenX8Mjjml9gdxk/UWItnxD54Mgbn3Hk2hkqJ9XtkBhGyXC5hjYF0ImRorVjQgrvhMSIpXT5JhFhXSEwNBoa3dIq3VIIoitxocI+2bSl2vldgDF6kaK3RVzOoeub31xhj0Lat31+zylAxWWUQJK9d53dUkGziTu6tCZHugUDgOIIQCdxTfurPTG84eioE37jc7XG+j3yyfeT+QxuDc76W4TG0TGjShYylNCXDnXA4OPybpoGxFkWeI01TLzxgLYSbeKnrmvbCNA2FojUzFJwSU79eMXy9cov62s5P0QzCSakeStEunSGdVdUzfLXKsMsf9ZHygxSxIBOuUmrjQr3V6si9ECS3S4h0DwQCx3FuPCKBB4fVvTOH4YJDCOnj4A+bWZllJBSi6IixE1gJD3OFBM5puZ11I7NxTBkfVUUhXrsmg1q+CwtK2+3aFuPxGCaKqEISx5BSoqooyIxxjogxf9tySWO8SmvEk0fxjU4CiPC+lsZwq6pGHMdeaDBG48Rknk0B3UDzBLv8UQDA+811gDE/qTO0blY9IwCJFMnI3Koh8dp1fse8I5s4zd6aw6waU/u+xwc+8AG8+eabG43GIdI9EHh4CUIkcM/5G//VFn7tP21e6DaMpgq+OfDsg9zgtescWXw0fwQ4CA/7EBZ4FWOYduHGdCXynJbPHZ54GaoPA8NmXSkpJn7Ysuth5KtomwZd33tx0M2vgjGGePwIvsVysBZ4XPUwRiOOKbdm2G9DI78toiiGqmdQSiMdb+Mb9gKe0u/CWgshxUoWysFCvU3m1igb4+vXORjunJl1E7/+u7NTiZHDxlTyzSzxYz/2Y3jllVfWxEgYEw4EHm5CayZwJvzN/3obo2KEvMiR5RnyIseoGK3FtXsjZUz7Yk47tiqlRFEUYIwhyzLkeYGiKHzGB3O7bSyt2aWKyqF2jwWFenFX/TgMA44YTAfa+VWIfglY4Ltigu+wEbqucyFpFnXdoOs6MsVqSmqVUqBZ7EFVM7zFHsGueNS3d6IogpQSnHMvSA57R/p6Ad1SleesvSObjKmxqyz9+3//79cmZEKkeyAQCBWRwJlxXLLqaag7430SmxhaNZ2NMIqPeko4pz00AMCzLaC6DgF4Qyrn3Ps1NnlaVsXJaoD8UL0BgMQ2mM/niCeP4juswFOyg7UUP6+U9p/X9z3iOEGacrfXpoURKb5WF7CwuKSv+q/V9z1VaVxC6ypaa6RMI4oivHadPjZUR44Lj7sdjquOHGdMnUwm6LoOP/RDP4Q/+2f/bIh0DwQCAEJFJHCG3IzfYJXTth6GePXDcM785t33ogQYQ+wi/9M0pWkVdZCtwYVAHEUQQkAKAcG5FxFDxYRx7md9rKuyCCmRZhlsMwPaOd7SCV5ruPe4UKUjghDS+1eklDRarGr01T5g4f0jAImNpm0gj1miN2z+XTWzfv06BcRVZYW6qlGWFZblElptrujcDJuqIycZT4eo/j//5/88nn322SBCAoFAqIgEHlxuVBUZGNJVGeOuGkIG1zwvaN/Q0qJz0e510yByAsJYi67raMqlaaCG9FEpkec5eUOshdIa1hgSI9ZCunYSZwxxHNMem74H+nchRxfx9YoBLMXTpoNSnZus4Rj21kgZgXMGzgXa5R6sBXbHzszKrpPp9ZhQt9UWUxZTsFvdW3y3n6ztrRnC40bF6I4kta5WR25kPL2bxtSQ3BoIPHgEIRI4U45biHcS1lg8NWrx5jJB3/drUzOrKKXwwajGq90YxvknOBfIshRkD7HOtxEjdgsQOWNQWqPvOkgp0SkF5gywyv19CD0bFQWquga3FnBf32/U7XtqnTifCoOrVtgGggvUNsY3OtqD83TUIYoiNE3jJmoEtKaFemmaomkatMvr3swKDvwps3S7hA/wE0MraK3R16Xf6gsc7K0x2kBpdcvtscMM38f/7oOXsLOzs7E9czeNqadNbg1iJRC4vwhCJPBAsbqjxtoYneUwTbk22gpg42QJQOJksVggimI3TcOB3kKJHN38KixoZ43qe7Rd56c7RqMRtDFo69o/VpqmKNzWX+tEB3dBaUJKaK1J1DhRItyWXq01bDejXTLxGG/2Md6nqpVrJWGlVI+u61wSrEKz2IO1Ful4G692Y1wyV11OClvLUlllaNX0NbVLBkEyiJG7sRrhC18HnvlL/wD4rf/xiCi4W8bUGyW3vvDCC5hOpyFmPhC4DwlCJHDmnLYqcnhHzeN8H2+brbXR1uEgPpxKypMxdDNf2aSbgHOGum6xoxW+KybkFYkiNC5afdgfkyYJ6rr2RtThcfuuQ2kM4iTx76611rDD13dprkVRoCpLaKXQNA1Nw1gLawx0uYckSbArcoAB368XPvOEMQ6tjRMl2osGVc8QFVvkHTHAs+POT9UcZm0aiDHYvgaPMnzPVUeeZt2R+9wJhBT44H/7D/GT2TexWCzuujH1NMmtly5dOpVYOYlQTQkE7jxBiAQeGFZ31AztkcdwDe9k2+jqpd8rAxxUAgDaePu63vL3Ge4PsCPhWlIItG3r2yoAIKRE07a+8uAeABZA0/Zoew0wgdl8CVgLxiiITAqBxImYvChQOjHCGaPQMuctgbXo5lcRTx7Fd8UYzACXeeeMq2rtuqUUSNMUfUMVDp6M8YpbhrfJnDu0a7QxiKRE0zbQVQUAKCbb+MYixjMTtTY2fadgnOHV9hIQAz/17N09rE+T3HoasfLss88e+xihmhII3B3C1EzgvuA0EzTDYWysgVI9etWTkLCA6vv1CsimfTTZwWpqNky7MO6nYOPxI35kF8PtOMgbYXQRdDOX0MZCL99FgRapqZCo0okX7m4H2q4DZwxGa8Rujw2coGGAq3y4GPjFu+DdgnbYqAS7OkGW0YRNnucoigJx7Pwn7rpUPYO0ZLT98h61hVpnsDVuV06WZYijCG3bwhgLLijmvilnaMsZXp/LE7NHrLFQfY++69G1HbphN445fVtnmK65U7trDnMag+ztxMyHpX2BwN0jVEQC9w03atEM4kG76ZWBbf0OMH4MxnT+8PWVACdOnhH7eE2T2JGS0k1pioamVXbUDG9L2oPDsCpUDhbtWboIGtllDGr+DhVOOENTNk4glACjSkSSJOhQwBiNrtfI8xSMc7+7RvU9ur4Hd9eaxDG6voeavUNR8qOLeK0R+EjMofV65cYYu9JmMui7GUQ2xkvzyD/f1Vj4ITnWGgM1ZJC452KW15GPtzfGxGul0XUtGOOoG/LcMDBwwWl6KMtvupqy+j0+7Qj3jVoily7d2CB7o8V6J4mZb37zmxiNRvjYxz6Guq6RZRmapsGbb755qmpKIBA4niBEAg8M0uVtrIqQVYwxvj0zVAJWDasMDOlkG6yv0TQ1ooj2zhxs6SWiKILSFAwm0xRCUDtErbR+tKZ2SRInUL2isDB3fwZAKQ2gg5QaQgj0coSqbgBQq2e5XEIIgcLtvsnzHOVyib7vfUaJKvcghcBXsQXGYlyW5OfwC/KshZQC1rrlePM9SCkQ5Vt4XW/hGex77wyluOqDKHv3NYy1gNKAapCkqa+MfOCCgTU0vqyURttWvo3FOIOEhIa+7RHgw8JzkzA5TUtkOp3iueee2/h5g0H2NGLlOGazGf7Df/gPeOONN/zHnn76afzET/wEXnnllbC0LxC4DZi9G7b5B5D5fI7pdIrZbIbJZHLjOwTuGidVRbqWdpaolQqBFDSN8q22gITyYoUzRn83Bsa1Vl5exujLmV9Al6ap2z3D8E1DkeqJJcFQN42feMndJI2xFkpbqNk7EFJgPBqjrCpqVcAeWEss7c4ZjQ7eZUspsNAHo7JZEqF1e2+KPEfd0NddDUYbRFc0fsS3pp4SDfpeeb9I27bo+4PXoygKKNWDJ/S1f3BCbZr9/f1jRdzWdOp369QdiZXLoxbz+QJRFKEsy7XPZ5whjmJwzpEXOaLozowAH8Yai2W53Lgg8e3//CtHDKarlZNNBtnjRM3zzz+Pp556auM1zGYz/ON//I/xhS984chtTz/9NH70R38UP/ZjP7axIhLMrYGHhds5Q0NFJPBAwTlDksRIWHIQp26ta4vQJtq6PHh3OrQnkihyogKI8ikS3fj753kOYyx+QAj8cWkRidhPyQyVkrZtyXwax9B1i2jr+yC7BYylNscQZmaZ9V9XGw2lFJRSiOMIZdmCwwmMdIKq6cAYUOTZ2uK94Tn5aHlrEekKnDG0PMOuyQBu8Uxs0Pf9kRFc76VpF+DJGC8vqOpySUoY5y8BDgSPlNJ7YgAKQqs7gzeWMSy2sYP5ke+DNYeNv3eHVYPyYR7/xM/iN7/aI4rWWz2DINgkAi5fvowXXnjhRLFymN3dXezv76NwhuNV3njjDXzyk5/cWE0J5tZA4HQEIRK47zjJKyKEhLENzKF4cmstvg/X8Q621z6+trXWWj9BM+yZWSWKJBizKLWEcQLi8GO1XYciz1E1ZELljBbRccF9u0YIQaLCAoJzQAqf0MoYg5QSev4ueUnGj6KsGgAWxlV5Bo+KcBkhg2m263uMcqo8LJTAaw3H09FwDxIDcRw734u7r6qRJAlaI/AWLuIp+S601pT86gyzQghYY1B3HTgn70cWcwpYg8QVNcUWqg3fDWfc3WAMvlPcSOQcvn34udFK4/UNOSaDCLgZP8disUAcx3jmmWfw+uuvr4mRoijw+OOPHxEyp801CQQCYWom8IDBOEOe5eBi/UeXc44kSWBBoV2rDJkiq5M0Q9sCIHEjZQRjLD48dtr8hAPQ+v9SJYZEiAFnzPlYBF1HFJGPQ0hfjbHGAs7gCgvEagnRzJzpVQKM7mucKXcQJNZd05BTIvoleDvHG32MXUPjuxR8prFYLFFVJcqyRN9T1SWTdNVvsUfwLfl9sNaibRrUdY3lcommof01tctQGV7TakHb8/bj9+B6/J6VbwRtMeaCQ4q7937mRiJn40JClzfz+Cd+Fh//5Gf8x291wmUwsU4mE3z0ox/Fhz/8YXzgAx/Ahz/8YXz0ox/F448/fuQ+pxkVDgQCRBAigfuSk6YphBQYFSPkRY4sz1C4/1pYPBEvwHDQbhgwwyI6IfCM2Pcfj6IIXdeiqio0TY2qKgFYsHwLLgf+yB+2ct+2a5GlmW/FaJcNIpwwatvWjf8eXD9VTWj7LWec2jfzq0hUSQcrEwAT/pqHyPheKarwVBVNwlgLU10HLPAdPsY3OgpgM0bDmKG1w1BVFVVjVA3bLWGtxTfMBW945Zz7ZXqrgW3DTh3TVYBuwRnDfvIeEkdc+KmZO7Gr5jikkEdE58BxIuhwO+fjn/yMFyS3IgIGkytAFaeLFy/iPe95Dy5evIhLly5tbMvczqhwIPCwEYRI4IGEcYbILZdjjLutsiWqqqJWhkwRrYiRwbiaZZn3ffBkjKZpnDBwplZj8KGcDnDGOSzg/wDrAqdCAqON34ZbOHFUjApIF4JmrFlfCAMADE6sCFdZoDHauqkhuzlS5wfhXKLtlL9+sXI9qu/9XpvY1EidwfbbyN3iPAkpBRgD2raDtQZ1XUEIgXZ5He1yD9+JH8e35PdBaU0CRNF/B0OrMQZKazRNg+VyiXK+B4CqI9OtKUaj0V0JQlt7qY6rgAl+rAg6rp0zCJKbFQHDRM4gRgZOiqw/y8V/gcCDRvCIBO5bThP97mPfDbVGjLXY1u9gTzyGpm2QxMma6VRKiaIo8INpj5cWMQAGYwyspXfQcRyjLEsw5Ignj6KbX/WtCiElCRkpwesaBgzGGnDD0XSNr3DEcUyHu7tGY6xPSR1aMjRhY8EZHbBD1aR1Ca7GUHVETh7DYlkCYLgwHaPtugNfB+DTXo0x0EvaRfPN0UUwAJecOBmSWa2FG+GlMV61/w6Krcfwbfl9eArv+s/ljPldPdYYyCiiBFgAbTmHlBK7bAQAR3JH7gZDBUxp5Q3G0lWUNnGjds4u+xC+u7It+DTcrMn1dkaFA4GHjSBEAg80Qxl+8FJgJewszadgpiNj5soeliFnhAGQ2QRqsedvE4Kjrns8zma4Iqc0huZmcofKxfX9fRhjwLhEJKO16RELi6ZtURQF+q6jjBGlkKQJWMeou+MOdSmochG7LJHhkDXWkKBJYoh+CaUUdDrF9dkCjDFMJyPydEhJOSlKIXPL98AYWLkHUWzTdA0snoDyhzOZX4HB4FruXwVjwFvTRwEOfITXPgjuIH8FYCuvnzEGkmkoKzaGoN0NGGen3hI8tHM2TdustnMGkXtaQTKdTk9tcj1NrkkgECBCjogj5Ijcv5yYK9J1qKuDjbj+3T8s3sE2JDSSJNl437Zt8fIiRrMiRNI08e2dtyM6LNrZVf/Y08kE8/ncVSMEGGdg9T6N0Rrrw9GSlNo2QpIvZah8GEtBYUM1I4okVK9Q1TXUMFrLGJI4hpQSvfNxCCEgOEcjci98BAcZWjlHHEV+2y9VDMjDYRL6Wf7wmKOqanDO0fedq4xYMGc6FYIjHl3w1/nRUYu62jQpQ2R5jsQJqCF35F4IktOyuqV5YGjnbGon3Ux15Ga4Ua5JIHBeCDkigYeWw2X4IY4dAGAYNDv+XTRjDE/zPbwx3vZi5KBywPEkq/FNmx18/qGvZ60GrITgApNJBqUUmU+1Ql3XiGSEVKbo+x6aGWCYsuEcWZZDCoGyKmGMQZIkSNPEtYkO3htorZDECZq2geoVRmOLsiwhx4/SuDATgDXo+h5ZmoI5UyvjnB6nmYGlU/zRXIOxBO8zNdI0RdM0ALQXTlJK5NJCSoZla/GVZYL38+OFyOoE0pA7sprKetbcbDvnZqsjp+VmqiiBwMNKqIg4QkXk/ua4qshJyZtccLytpsjizZ7svu/RdR3+qMkBCzSLa4jjBHrl8AKAb9ocol9SBUNKtF3nA88YlwAsbLmHJEmQuKV0QoqDd+Vu/00kI9qcq0iMpEmK6lDVwRiD3mWcZFlGz4tRPL21FlEcuVFbiaZpwEYXAQBS0LUmcQzmskBogoZCz5RSEPkFat0A+FMj7jy3zIsRvnJIL9uDwLLVKSOA/ClFUay1uwbux+rIrXC3KiSBwHnlds7QMDUTeKC50VTFBy4Yfzgeua8LC/uBhIyhRTGClAJ5nvtR3zRNAVhoWaBrWywWCxhjMCoKqiQImrCJJE3waE27ZZq6QdM2JCTcqIvSCk3TUCibNtBGH70mzsAYJ0OrtYjjGF3b0URQXaEsS2ilEcUx7ZyZvQM1fwdKW2htD1VsDrJIIimBdg7U+7AA/ri0JJySGFEk10QIAIwShjwiIfK63vIfH5JqN4kQAF70vXadn7jR937nbm0JDgQCRwkVEUeoiNz/nHQ4WGOPLcMPB+JqZaRXikSFM2V+UzwGAGCqgtYao9EI1gJVVUJrjV2TQi33AGt9WFme51BKYVnWAKz3iuRZjqquEUnpqxsMrmXE3C6YXvkWiW3I48JSagMZa6B6hbzI0bYduq5FkiR+8mcY+62rGr3qkec52rYF8m24IgfSJPb7Xw4nxAKATSY+ZuUHt9NjX1djLKqVENr/zZY+VoQcJlRHAoGHh1ARCTz0rOaKRFG05gU4fBAaY1CVJS2xMwZcCFzGNQC0NTdJkrVgVRIADHJ00S+GG7wocRwjS2NYS6O/49GYPkdKDKpgaJEMse/DYzezGWxLI7aRrmDbBrZtwLoOkTVQyyUAiyIn4bJcLrFcUmWkqioURYE8IxGilYZeXIVevguAoWl7LJbV2lbhIegtkhIZWhRCAxZ4aa858bVNuEbMSI38wf7pc0OymCOLeaiOBAKBE3lwfzsEHjpu953p8A59dTQVoHFaYwwumasQ6RjGWFhr3B8SEZc4VS386K/zWjDAL6hreI7lcoleKbRd52Plh0oIQNUOBsA2tF9mGlkktkEUReDtHKbcg1nuAfU+eLsA73uoqoQ0GsPIrbVU5aiqyge6yUjS2CrjQLUHVl0HrMVsvgTcPWUUoW1bVHWNpmlQliVEv8RIGry01xwRJFprFxJX0phwM4e1Fl/eY/jy3unTVM9Du+bXf3cWBEkgcJd4MH8rBAI3yWpVZPBepGmKNEspx2PlXDUiJZ8GgL5X6F0WyBNmAROPXWXDeo+JkBJJJABYGGugtUIkSRhkeYY8y1HkBZIkQRRFdH8GpGjRdi2SOHbbg6ntwjnFrGujIdo5ZLeAXryLjDGkjCFy3pJeKQomU2RGVVod+E4YYMs95GjRtD3qtofRGnFEhtnBS6KNQV1VmNAkrhckxlhUVQ2z4mOx1kLVM+iGtvHerBg5LEgGs7Byo88PAkGMBAJ3njC+G3ioqDqDvq7Rti2NygLUqkgztG2Ly7iGt9gj4JyjbTsIQbtgjCHHqRUASyaw3cJVOqgyojW1OeT4UXTLa5hMxqjKCsvFEtJt0R1GSuG8J4slRY3neY6moaqI0srlydPUyrAp1wIwFXlU2OgiUuY27jIXhAYG7rJGhimbwXAbN0u0ssDS5a3EkaQFeX0PCxIjWilsJeQp2W8tXr7e4rLUa6msw24axoBCVjAi82Lkh7epcqS1hnHprDSJs/5eJ4vp9Ww1wxsLUj+P8/0TMz5uhlWvEF3D5pFda6ybjhoi4YcMmONHfAduNOq7mh0ymUzw5JNPhuyQQOAEghAJPFCcJvb9OJ6Zanx9n0OmI3Rd5+PW+76HsRbSRaXDArVi0H2PJElhTAVjyPD5/XqOK3KCNE1RNw3yPAcw7KIxACjivVyWvvJC4WE0JaMVCQvm/s8608iQHyKEoOqAOwupMsPc5I2lQ76ig1srjZ4xZO6wby0dwkOlJo4TZ661EO0MRhvY/AK6XqPrS1zYmlDsvL9+YithuN5YvNHHgLV4kjdQqvdR97QYz0B3FPfO4gJf3mP4YFSutbyGCRspD37NDNHxyi0HTIoJ3jZTwDB8P+YYFaNbXqJ32hAzrTTqmsLdmqaB0opEi9vRc1pBtEmQvPnmmxvTVJ977jlcvnz5lp5XIHDeCa2ZwEOD0gqP830AZNrkjHvnqFYKURwhyzI8I2f0jjoZo+taSBmRMTTPURQFAIbGOoGhNaQzrxIGJpn4SZVe9bT4DgAsoI12cekW0+kUSZwAbspHK02R8FpB9QcbZIVwHhBJkfJCCPRdDxlJjHiPiaTPS2CRgiFLM4yKEbKMckqEkGBgtCRPlUh0BQZgf+amhoxB13Xous7H4xdCQZd7AAO+aVMvQgD4qohSigLXuILtSrzajddGfbWmA3/1vlpraiO5bJNytodyRpWe7/ZjvDa7tYqI3zl0KE/GaIOqrnzrZ/g8xuBFCEDbmbVSXszcTKto8I/MZrMjIgSgjb8vvvgiZrM739aZzWZ4+eWX8Tu/8zt45ZVX1r7GSbcFAvcToSISeOC41arI6qR6nE9gyxlVD+BaG4yjVwqwFj+QlvijhuLU+75be5wnAHyXj2DiMaxVNK3jvB9DG0NOHgWq67DGerOqNRbWWBjXvugViYlIRui6DlppgAHCRcfDut0oUQTetlTRcNc6iJLZbE4CSQi0XQsVjaDrChpAG0WIo5jGmSPpNw1zxgHWIpIRKoypEsMsas6RJAnyPKe9OpzDlNdhrcWVYhsAsKNmkFJC64O2jdaGvCTtAjw5ECPPiH1vDB5aNORpUUc25JbzPTDGMJlM8Nr1gzTc047+DjuHNmG0gdIKEY/85/FIehHiP889n9XPvxl+86s9Hv/Ez+LK//o/HLntypUr2N3dvaMpqydVXwCEykzggSEIkcBDw1C1eJzv422zBQD+3bodmhMrC+wYGKJ8C7xZQAi+lrb6AW7w9Zr7RXh5UQAA2q5DkiQoqxpxEiNhie97KK0o72OYoNFUiZAjQZURt1xPKwXd08ZezjnqusZ4NHZtHAAMaJsGtcsfiSKJxXIJ1SugbsAYIEYXaeKm75FtbR3sjbFUpeHO+yK6DqzYhrYM0AZCKdRV5cLOEieQFLrZO4inj+FtOQUYwxPdAsNo8mrKvmnJ9zIIkmfEvq+yDBwXXTR8fDC1rsbGAyeLksOPubpziIH5RYOrCwo3Pg5Ovv0khvt8/JOf8R/7/RVRslgsbvoxj+Ok6su/+Bf/ApcvXz62MvPCCy8Ez0rgviIIkcADyWpV5LQGxcNbWZNiAjWjHTNCirXDR2mNZ8cdXl7EUKpH0yhQHDpDHCcuS8Si1BJbESCFwGg8Rure7Vd1i06OoOdXnfeUpmtGoxH6XqGxFlzmUFUFa4G2a5EOgWYRLa5TWpOJVUqUZYnxeEy3GwMZRSiEdBUdF1rmnrIFoBbXaNR4tI1mNoOwFh1jzqBLVZFeKxjTY6RKEkjFNtpOoe0UZBShqiqMigI2jqGNge2XVAlJp/g2G+EJs/Q5JRQpT7txABIkgxhhS4Yf3qbXdjDtanU0VVZIsZYMuxpAdyNRsno/Y8l8aw59P4XSa1uIN8Fw8u0nsek+q6JkPL5+0495HLu7u0eExsCrr76Kxx9/fONtd6MyEwjcLkGIBB5oNhoUOUeapu7APRAmQxx8VVd4HFQVKSbbaKoZ0iSltoxDuP0rH4zmeHV0Aazcd5kiFk1TQ6keH8hyvN4cHD6cMWrRWIs8jVHW7fD+mqZetEbf91RpkRGs0WAMa5WOxdxVFDiD8RUYaq2UVXnwTt9YcM6QZrRsbzCoDjtphmkaVPsoRiMsrUTsDubazyqvv/tn9XVwxqHTKWbzJfIshbHWi6G26+hrtVQd+a4YgSmG9y6WMEZDCIksS/0osmkX4FwAzsz6w9v0fNIkRYNmTYwIKZAm6bEC4EaiZBCZWukjIkQKCWss2q6FlBIyokWFURRB9cpXQYbMFy44pLj5X42Hhe4qXHD8cf0kXr1Dy/VOqq70fY+6ro+9/U5WZgKBO0EQIoEHlv/ug8D/8uV1EWKsQd926PseSRJDKb02ObG6lfWybfFWmSJLM3R979syw7THkIY6tGiaxTVYS0JnaOk8HSu80UhspQcHqHb5HgB5RVhFPgtjDdqmxWg0oqpAVYG5cLQokrSFN03cIUhtGmsMGOdo25a+rqZrMpame4yxyPMMUgg3nbM6ceNGaAUHr+a0Hbi4gIwBMBo+ud0ls1lr0esedn4VcvooyqoBYwx5GqPtOkghkCQJfbqpwRlDy1N8y2Z4H6+h3S6dYXEg5wJ5nkG4hXxf3gOAGB+MGiRxApYw3+4aguNWk2CP4zhRcnmcoWs7cMHBwKANTSulCUXYN3Xj/TpaaWRZCgZG4pABQkoIKZBn+S1N7qwK3U2TO6uPuepxuhVRMlTHNhFFZLq+lfve74TR6PNJECKBB5bd3V0YfcH/e1jyZqyF0Yr8GTiYnBhGQxln3ojISgAyRRFFvtowPJYXG2wP37AXALA1PwR9joaFxH5rsZWwg487A6h2b8wZY+Dg4JJyPuqyRmwteLENpWqkaQZrDdq2Rdc6cyxzO23iBJ2LcTerXgcL9H0Ha1MnjixkdDAWbI2FEJQEKyNJ0ypLirKX40eQMboWrbVLimUAZ5CRQGRq2jCcb6OqWwBAmlLuh3DCqOs6CNkA1uJbxQWAA5fQIIqk342zukxvlDAsW4uv9xNYa/GnkqUXIdbaE5fpHccgSpRS+MY8AiABCzxi3nWjuBm0ptdVaUXLCaMIiGhpYJqmbgTb0tbiU+SInMSq0N2092gTh43XpxEmly5dws7Ozsb2zIc+9KFjhcjOzg4uXbp0w8e/Hwmj0eeXML4beGBZLBZrZsBBAKz+e2CYhDjM4DVgjKFtW9Q1HcBlWfrJEAC4ZK4iHW/78CvgwLj64fH6/4wYYwcLZQDYbIuEgcv5GHwaynk8BOfoVY+u66kQwpl/7H5oh7gqzIGpdniOlP6aZRn5SnrlR2Rpe3AGBoYiLxDFkY+m14trkD0JAdZ1EEodpLsKgaZpkCYpeL2PRFewsFiWFSWhao2mbck3Ygx6pdDP3wUA7JoUX1vajRt9ASCTBrYrAQBfawv8UZNDa430UN7IaTDG+HTWsizR1Qu0JaW+vssfwffMFnarDEIIylcB7QZq2w5lRTt75ou534h8eEfRrXLS3qPTcJo4+el0iueeew47OztrH9/Z2cHP/dzP4Ud+5Ec23vb8888/kBWEsxiNDtw7QkUk8MByuMTsD2nHYb/BcZMQQ9DZahgXAD+OO/wdHMgmF1HNrkJKuRLwxQEYXxWhEj9VIAQDtKWqg+ACaUqR8rF7R94tF2jaFkmcQGkFGUn0XQ9tV6LVYSl0zBpgw3NinIytQgokSQzGOThjkDKCsQYc9E5/Mp6g7VqfAqu1Rgaa4qmRIGUAIom2owpIrxSy3L2zXl4HGEOXX0Dfk0DjnB+8Ptain7+LKI6BbAsv7TVHtvquxcavTNe8pqb4UL2AKArf9rpRQqtSCnVd+/ZT13c+XbZaXPfXVUy28c06gxUpHpczXxlZeyyt1ipmd5vTmqtv1L65fPkyXnjhBd+qGI/HuHTpkhcaJ932oHGSOTcYcB98ghAJPLAM5ekBhoNf5lLItaoEcPwkBB1MMaJsjL5erHycNvGSh4DhvepP8G35fRQMliRo28a3IH5wW/qlcZwxFDm901d9D84BjB4Ba/bBOUe5LJ1Q6aGtRZJMYE1zYBp1raPV0VPuNgAzym9HxrR7zoBZzsHYwf+YLRg0LEoeIZL0jnzYe5OlmYusp303jDFUZQWrhvHeLUgAjbVQvaK0WWuQ5zkl0LZz6GQCxiUsgCQ9GDs2WoMLgXECzDvgpWsNLKhiRGLN+t01PoOk2ofMp3i1G4P1DD84IaPlSQmtQzrrkIwqI0mjywC41oiiyFezyvkehdCJBN/TVJnaxjvrPxdgt5wdcrOcNv31MMfFyk+n02MP4JNue9C4kcE2GHAfbEJrJvDAMpSn3/7PvwIAPtNDCrdLZWUq46RJCGutT1w9dAM6lwsymUwwKgowxpCMttE0DTjnSJLUtyB+cDvFfktiQkqJyXiM0WiEIs/BOKeqh1J+z4vW2pszh8mZtaqNG4dt2hZ5liFyPpbUUCR5ig6F0IhNg0g3sPUcGVPg/RLWWiS6B29LsHoJpXrUFVUQkiRGlqXI3PK7oRXEOIMtr0MvryEFLdgbgti00ShGI+RZhhwNxoLaOFXVeNEgpUSakC9nJA2Eu46vzjWqqkTX9TCGJo9610IyxqJbXkdXXoeFxR/OJF7t1itdhxNaB09L0zTUTrJDs+wgME26uHbOObgQ6OoFVFvCAtgTj2FPPEY/F+ygDXYr2SE3w2nTX0/ic1/ax//9//fuQ5eWeiOD7YNswA2EikjgAWcoT//mV3tv4FRaoe/8TMjGqYVV1oLOsq21qshgWu0VVQd+IC3xtaZAOr4IpmoARw+PoUUjpQQXAlopxHGMvX0g4xzLJR3QXHBobSAt0IkcjM0o2t1VKzijJWxccHRdhyzLEKmGFrXVMzQUUII4TtxGXRI0xhjYmrwSSZrQdEvLYFpgWc0x+b6DKhJn3CW1CuhhGgeALq9BjC7C1DWYtTCcYt6ZyyJpmxbMGKC4gLbXQK/AYFE3DdIkgXRJs7yjjcVv9DFYDzxhFYkDTq2wKJJuOR+HsB2ltIp0LZ0VwFpCq3EVmH5Y2qc1pGuFDWJkWBhII730+ltrsdh/FwzAeOsREiMMeJzN1n4O7hanTX89jtVqytfwPqACPv/5X/JmzfM8UXKSOfdBNuAGCGbv9tuAB4T5fI7pdIrZbIbJZHLWlxO4BTYFnJ1masEai2W5hNHGJ64OYmTwICi17it4XW/BtAvkeYEoWtfzL+012EqY319CPg6Ovetuh029T6O0nNJNszyDqWskpiYzqDtgpZCIIoksz70IaK9fA+8WVAEwlGrK3MGepSmsBWazfQBAXhT0eO7aGWMQ+dbagTt69HGUZelNtMPSPzAKaYviGJWN/f1lMaLXp++QxAmZVrUCcppeEm4MFgCSJFl73Ww8hgXwJKuoYpMkaNsWURSj69w2ZOv2AHEamR54Ruwjy3MkcYy+79E0DZYlmV4ZgCzLfM4JZ2QWBcNaPgwZVVvvOwEAHpEH5vujBYqiuKseka7rUFfH53tkeYY4jjfetvozehghBP7rnTn+1b/6V+d6ouS4qZnnn38eTz311BleWQC4vTP03AiR3/7t38Yv/uIv4vd///fx9ttv4/Of/zx+8id/8tT3D0LkfHCrm3lX322+bagqMngTDnsWAPh37EXMjkyHvLTXABYQ/RJ6ZeGb4Bxl3SIzNfkzwPy79s71uCNVUjCWM20qRbts6qZGEicw5QxquQfGOSIZQaner7IvRgWMNhCSzJ1t2x5s13WeDBnR0rwiLzDvVqaKkhxt1/nnGUmJLKOdM0PbgBUXAAukW1MsFkvEcYxqEAOcQ0oBmw2CxKIoCi8CGAAZRehY6k3FT5iSKjHDrhrA5bQwXzWJ4wRWklhgjELRBo/IfMUXwEBCY/CRxHFM48pae68QYwxxktBElAuBA1xLabQFhtPvtrkV+r5HVVbH3p4XOQmom7zv8Bpaa9emyAA6qP/O3/k7eOedd85FpWS16vOgG3DPG7dzhp6b1kxZlnj22Wfxt//238Zf/+t//awvJ3CLnFV5eTX/gS0Z4nyCVFJ42RExwhg+nFX4WlNAqR6M8bXMjI9tJXh5r1kTIQDcvy1qniHqFpCRRN3USNMUrQUSRuO6PKFR4iGUrW5q9F1PHhHQlI51S/O4W9oHgNpS7uCXqUTbtAepoS4pdtjwK4SA1BpZnmPeWrCmRAoABfXatdZYlkuXuxFT2BqnVNjl/r77xREDbhwYrhUiquuw+QXoQ34XISWaukbfz6nCE43wHVbgmcig65Zrn6v1UIXSSBIG3S4QRRGMyPDlPQZA4KOFxKgoXJy7RtdRiJ0xxifrHq5iCSFQV5UTZPIgzp1z6LaETAofjnY3BMlxyatSCjDOYY2B6vuNUzQnvl9kDEorCC7w8U9+Zk2MvPrqq/jCF76AL33pS/5jD3Kl5DwZcAMHnBsh8uM//uP48R//8bO+jMBtcCcCi251My9wMK3ywQuU1tkqIIvpHXNRFGu5Ik3T4P38um/RDCmijHHnXbCw8QhoyKsxBHfFUqBTxo2+0uE0TMK4qwAXAn1VwQIQQqLrKneLe3PPAGZp0kNEEWDpXf8gTpTqEccRpBz8F8I/P2MMmrqB0QZ13cBYiyyOUS6XJCqG6gEAy2iyJ05iMM5QLkt6jk0Jm05gmxopA9pBBxkLJhhkt0CvFJZOMGVpDAaaQmLO2yHtAl3T4HX2KKyYYEfN/POn6RqKsLfWInbtGNvPKZadJ3h5EQMsxpP6KgTnKIrCp8+mWeaf92olizHm4/A5l1g96rXWSBlN3AxprXdajGxKXo2iyC9C7BmJoE1TNCf5V4Zo/4Fhv81//n/893j99dfx8Y9/fO3zw/K7wP1GmJoJ3Bfc7cAia6wPv1J9f8MJheEQGkKzhhaDEAJt2/oJDoCyMIzRKMsSTVOj7zvsqAWJhmQCo+kduzGGWgUAWlkgjiOMRiNwwRFHMXrOgXzLbY1duXYnPuggX7lhiGY3tFBPa+12zcB7MIwxaNsGXdeiaRpYYzCZjBFFEnmegTPuo+JhAdvMwdol+S6sQmKoCtK1HUbjEbjLQil4j4JRAqwLlEWSJsjzHHGSoChyjHjnpls6GvVNEuRF4YO+kjSF6JcAgCtyOBDJ18MYVXGiKCITqrUQQqJpGjTzPTSLPcAC3xSP4k1chFIKRVFQTotrP2VOkBy8js4zJNdFyMAQhpfFHFnM8dp1vrbT5jhu5mdrqLzlRY48zw+EETv4OpumaIZqyia4WxNwmD/7U/89yrLcmLI6ZG/ca2azGV5++eWHbuoncDLnpiJys7RtS+9EHPP5/AyvJnAnA4sOV0VuNbvBAqh7i74u/ceGg0wbA1iLZ8Q+XtckHrquhxDCWRIsvl/P8V0xgdIanDFol3Za5Bnmywpt22JUjBBFEaIoRl1XNKXiDhXO+FpoWNd2yBlD5CZEmDunhBRI4gRVVa1sl+XousYnukpJSZ90M1sTVHESu+dL76yNNUAzJ2NtNoVe7iMCQ7kElKIRXIB8GJORwHK5RJpNga7DUilnGHUejyRGmqZYlLV7506vGxcCgnMkaYq23INWClemNFL7hCFxMgSZHQTHsbWR7GaxR2O6+QSvmy3wmuNjo9ZP2DDGkKSJXwRojAEX7vVk7IgY4YcO8yzma7tsNlVIbuVna6i89X3vxdFhDk/RnLTHJo5jGoU+1PKxsPg//F//36i+9v/ceB33OnsjRLQHjuOhrYh89rOfxXQ69X/e+973nvUlPdTcrcCiW81usMZiRx59t6a1RtM2kIeWs/F0fBDS5cZJaTcNQzx5FGmW0Z80BRcCjAGtKKjKwRmkewfPGEPDUhrH5Qy96r0Bc2hVRFGMvCgwGo+R5zmkEKiqyvtBpJRribCpe0e8XC4xm8+xP9vHYrGgykQcu/HWoyZJwQUi3WAcUTVB9jV9BXdudn2H5XKJYlQgNSQ0pKvKGEsTOE3ToGs7iHaGQeqIoSLBGNqmoecgJdoZBY19l4/AGEeW5ZQm6xiqJAdmVmrj2HYJaVpYa/HyIsbLixiz2QyL5QJ931MKa9N4z4hSiioXqx6WlRbWKokEJNOwAL5+na/9vNxuLsiN5gQO375aTcnyDHmRY1SM3E6d/EjFZMjTGX/0f7fx8e9l9kaIaA+cxEMrRD796U9jNpv5P9/+9rfP+pIeau50YNGQQHma7AbgaHldKbrf43wfUXYoYEvptXexQ9YFwWi0NUlQFAXea8mIWZUlBXC5Q5Azimyvqwpd12M2m2F/fx+d21MzLGMTnKMYFRiNR/4rNCxG6wLVYIG27WBBceF5nqEoaNolz3NMJhP/3FYP9eFwHqoFWZa7NFpQxcJNrQjB0fcd1HIPutxHZhVyaKRpgiLPId3osgVgltegF+8igUW6IkbA6Ovxeua+toHS1ptLhRDIiwJb0ykSU0PqCt+yGb620C6RlbwUNEVE3xulemhtQNUdatn01YxaNgB2+aN4w2yjc5uYOzdBlCYphBS098fljgxtnNUYeWMMuq7DYrHAYrFAW85grcHX97kXJKf92TqOG+WWbLr9uD02G0XKaOSrSR//5Ge8dwS499kbp6l4Bh5eHtrWTJIkSFwKZODsuVuBRad517mpvC4jSXtahoPQxb8z148//LjvZ9fxjck2bF/BWvh9KYAbLZ0+CrXco5FaIRDHMeqmQxeNwNsKSZJQid1omLpGqSVQL11wlwIXHOPJhDbwljM/hhpHMba2tqBUDyEl6pqySLQxMNpQBH1XIrbDvhr4a0LXwfQUS98BGF141G/tNUZDaY227ZC41o2xBqyiPI+2BQyAGsK3jxhjFPVeXQcvtpGCoQOjRX7MtViq63QB+TYsyDw7pMx2HXlOhJRIRYOOZfijucIHssgl2QofXOa/d843o7Wh8WFrvRhJx9t4XW+BGYYn7Ts+mC6JE7BkqC5FiKJoTYQopSjzo6mhlfbha11/jRYITrbx2j4HWIz3sOPHcW/0s3fcFA1wchLwcaxulR7IsmztZ/vjn/wM3v7Pv3LPl9+FiPbASZybishyucRLL72El156CQDw1ltv4aWXXsK3vvWts72wwKk4aZvorf7S/Kk/M73htAEssCyXUL06cnAMYWSr8e8M8NHhq0hJm3QRFW4qg9JQtdb4fkO/ZAdhorWmd7SSDnBtNJZlicViQfHnjLsx3QMTY9e2KJcl+r6jWPS2ddHnFVUerEVZljBaQyntws4YeEsVGaEa9OUMup5BVTOoao4YCqyvADc+W+/9CZq9q+hm11BVtUt51RgmWQCqTHRth35JZtHMathyTjtvzCBiDNT8XajFu4hhoeuKxIIx6HsF1Suo+VUAFgYcYIyMrHmOoigoCK3vUfAeWynD12uOXZ36StPQ9hpaVcPrf/j71yz2KDq+W2KXP4pv2AuAq4QMBmSaNFK+OjNklAwClTkRYqz1rZZyvgerKCtmCMDbxA0rHs73cbilcqMk4JthU6Xkg//tP7znAWAhoj1wEucm0OyLX/wifvRHf/TIx3/mZ34Gv/qrv3rD+4dAs/uDOx1YNJvN8L98eXG0j28pQTTLMswXZFTmjPwLnFE4V9t2XlQAWAs6y13a6eqGWGMM/nAmoeo5hBCoqtJljNCo7reQo5u9A+5aAU1dw1jKAemdP2JUjFBWFRI3PSLaOW22dTtViiKHqRZAPYcFVQSKvICUwrVagL5XlCpqqMKgqjmyPENVln5sOEliZ/y0EEKAMQ6lKBafJWOKi3fTO9F425s9ZSTRtS0al1EiuIAotgAALY9hjPZmVsDll4wvUqVi5ePDIS0mj/pJoDRZTxUtcgr46roOS31QHXgmUf55DObhpqndhNNBO4S7HTpxTAmuQnDIjH6W3s+vQynll/kB1KJJkgRVXXvfDefcT0wNPyND2wtw8fIptc1WBSsX/NTbfNeSgEETQwc/VyenAt8Omzb63i1msxl+6Zd+6diKZxglfvAJgWYAfuRHfuSuL60K3H3udGDRdDpFnq23XoZKSJIkazkTxlpAKTAZQSmNNE3Rq35tnUyUjZEIu9HcOIxRRvkUETp3sDNYa+iwNUA8fQym3ANcK6PIMyyWQ04IZYgUeU4ioKkRRZE/KAGfvg5kE4huSQe9FFAu42T4n8BQSWE9HaaHl7sJIdG2HYTgWK140H1KdyBXENkEyrU6GhZDdAJxHGEynUArBc4FtG7QixSJ6cgPg4PckiRJkEuDueJIOaCEoKqJNZBCIlYlGGdoRYG66ZClJEYE5z4qHowBzYz6StkWXm8lLvHajfkyxHEMzoVvD1nncRl22QwJtdYKoJ6DMYZvpBcADvwASr9MULnlelKIg9dqwy4huiSGXilkWYaurcDj3FdHvj+a31RFY2ip3Op0163y6787u2diZKh4HhfRHkTIw825qYjcLqEicr753Jf2/btOuAqDUhoykijLcu1zI3ngGSiK3Pk36ZB7a5kgi0/uaH55jyGPKO1XqZ48HpxBa4Pv8BF4O4d0h5/gHEprVHWLWC2htfaJqJnzXGRoUZUVjDEoRgXKskRqFEy1DykFkjSFlBJVVXkTiNIaiW7RlzNIKakC09Q+Crwocje+TmKBcwZtjDOvkoF02FOjlIIsKAKdMYZOpDCG2hbGeTPiOCHzZjQCYCHGWyTULC3Ca9sWSRxDxxOAAfF4jL7r0XYd8iwDGEPNUgDAKE+RuWkgpTW6tvVTL9YYxJNHvXZ6SrYYjydgDNROUtROUkpDCI4kSWhHT9u5pXnMvRa0PDB21Zyn+R7SJEXXdX5BXtu1ZPQ9VBGRkfSblIui8DuDjDGwIvFjwTcTiHbSLpmbqa7cCve6MhIi2s8nYdfMHSAIkfPPkC2yunxsaMGsTjhIKSG42HgADJkSpxEjmTRYLpdoW2qRcM7xLVD6qlq86/bM0HZecAnRztx0C2CNARhDygDezBHFEZQTNHXdIGMavKV9L3VdYzIZo65rKJcnYaxBBgXj2kRJmlKrZ6VysFwukaYpuq71+RycM0gZIc8zZ7rVzhxKnozGSF8lUDL1UxlCSCRJDMY5KiN9JkfLY5qace0iBkCMHqG/pyn6XmE6mVDEuTVYKOlrEBe3t8ivYQykM+IOooAzhsi1dd4faxRFAWDY0qvIJ2ONCwzj3sPDOYmS1TwUgIytYMAPJKWvdkRSous6CqNzZt8oilylTEG4FNfm0C4iIQREUtyUILmdPTR3inspSALnj9s5Q8+NWTUQOC2rJsKhBbM6oUAtks2GweFQqbsbHy614sjzAkVRYDSiPx8eS5834owY5DnIEuh44rYFi/VR0nTix3iFi5sXoylsMkZV08RN3ytkWY7YHVaDEOBcIElSNHWNtmlgDBlcleqRpuSd6LphjJbDGIu2bbFcLtE0DcqyAsBQ1yTcbLuEqYcFfQ1i0/nWBxcCTV2j4BqJ7dznUFWBcZqesQD08ho9sbZFmiRucoXEX6xLRN0C1lpc29v3oWtd1/mo/SLPkeU5MtaBtwu83gq8fL2ljb2RdG0Z5ffO0FSN8uLjsI8FIGNrM9/DH7cj/HE7gnDekCiKMJlMMCoKjEYjeq2dCMk2iBDAiaG2ROJ+pE6T0HqzmSJ3g1tdjRAI3C5BiAQeGoZ3fIfjsoflckUxiIYRipwWqm2K7T7NO9wf3qbPH5bhNU2D5bJE2zYU/DW6CM4YmRJdC8MCYMVFd6hzxFEEE5FnQsoIDAxSSMhIOoMptZGShNbbLxZzRFGMLM+Q5TlVDSJJu11k5I23WUYBYlEU+0N02MtCfhbaB8MFtRzatkUcR35LrhAcpl6A9TVFwUMhtR200uh7BWMNrDWING0Zjk3nU1L9fr6SxnhNU4NxBmss6rqm6kUkkVkaK1aaDLkWVMlq6ppi3uuappoA8I6E0Ut7DV7aa3z2yCpCSPcaAHCG0EEQ0iFPf7hukEfA1/sJvqG3ELmNvnmeI0kSRHGMwk33DOPDmxjSXYe4eOBkQXIrmSJ3gyBGAmfBuTGrBgKnYYh/PxyXrZT2VRAAKKvyhqbBujM3bNFUPWB6Ct9yBRDsqBmuSBotjtzYqRACglkYMEQu5dS6yQkAWGgB3szQOeMqZwyJBZCM0DQVtFY0amq0K/FbZLDo+h6CcwCU42EtVQeGr0nZG2TO5PV6loOZ1wDPoFTvskSYa+twCEF/t10Jayx4OoKtZkiSHLBUiTHGQC9JcESjC2AAuog8FFwIjGOLOJJ49513AAtEoxGalhbyURungc22oAwQH/ZqugmnwZwacdpOPO+AP5orWBvjctT5xX91TVM1WUZTMlRxcoFrru00TOBwzjBKgGVr8ZUlZQ09OyYxFa1Uqla9I5swK1WM4edkiIy3AJ4qGj8ZcyuZIqvTNndywuZemlgDASAIkcBDypCv4McmGfO/7DeZBofY7sEz8oEL5obl9h/etvjy3hCcRdMbw6QHAPBiG6j3/cHIhYDRFiadwpY0qSK4AEtSoGsPltrBwliLlkdIbe+zPhjg4+WH1FASMsx/bVqAR9Mto9HYp50CgGoW7vEpkK0oCqSafAtmQXtrkvyC2y4M/xoxxhDpBkZm4G0J01VANoa19DorpaCWe5CjbUSqRSdixEKAgaHtOkwjjlkHtIs5ZJYD8sAcrNo5rDHo8guwlkFy+npZlqEdDKxwIWRCYORMrvsN8KaK8X6uyDujlGth9c5c2jshNvwKpOqR1tS2sdbAdjWM0eDJGC/NSRz+0FQdRO7foEqx6faIU06J1hpvWsrOGKZsjtsls6lFeLcnbIbKSBAkgXtBMKs6gln1/mPVYT+ZTPDkk0/eMYf9cSXomzUNvnadn1gVabsOryximHbhD9dh/8l3xQS23vcthlFRoO97NF0PW+6BMY44jpDECerZPgDAVtdhjfWG0RwavFt6k6qFRZ7laLsWkWrAugqcMxhjEccxmqb2461SRmDVdcRc07CNtdDGoOtaapEIgaZtwRlDMSrQGTrgrLXoohGsNeBcIIok0jRzsek9ehbDWkCOtwAAdT3sebGQo20ADOmFR9C0jW/VJGmCpZZH8kaGCRUuOBpOXyNLExit0bYtuBBryajkpRm5r1uj4ymsBd4fK0gpsFgsSMS0rZtmIpOslBLj8RhaG58JQ+m4KxMzCQkHxhh+eJtyVcqy3NieEUL4iZqB4z5/WCHwwS1XnVsRx4IL8rSsVD2AzWIZ2DxhY42F1oomplz2i5Snr54EMRI4DWFq5g4QhMj9xb3Y1LlJjKxO1GwiyzPE8UHw1qYpmiHe3bhR4VdceX8QI5ThQYfzFTmBqfbBOY2aWmuxLOnrT6QCA0PXdSirEpGLSLduuy9AwVp6uQ/WLml81lU+kpii3XNJrZSqqpxZ0/jMjUSVVF1pSufroI26eZ7BGAvtRne10a59QBt7kzRBbw+KqSbbQte1vlKQpCk660y56RhJEvtJGCkkFi4WxaYH+3OSNEG5LGHcYd8MN1iaVBmNR7AWKK177a2FEMOmYeaXEBprUeQ54KaCBiNtPHkUjDG8P+5RVTVF34uDuP5BnNV17SpKGlIKmpBZyXEBAJEe/H74wUnvKxz+dhdYd1BtIYZdRqt5J0prP3Id5xMwHHiQjqt6JHHizcObWBXLWlF0Pk1UHUwcxUmCIi9OXT0JYiRwI4IQuQMEIXL/cC9TGA+LkVsZo1ytiiil1g4mCxrFfcNuw7TkwbAWEIKDc4HXGrrfJKZ32NYJib39OS5mzB9eZemECGjqhIGBcYY0TWHLBe134QJDBBcDo4oIA3IJNE0NISX5Ody7dDV7B301R+RyM4ZpE84oJK1pGkRRhDzPsVgskOc5upayReKEqhJWUvZHI3JISZWEOI7BGFVhbESbf8X4Arq2A+ccaZbCGoNSC8jxBXqXLgRm+7ODceDxRTAArRNbtCdmRRDk2253jnam3AjavX6j8Rityy6RUnovhxQCoqAx3R01hzG0a4Yx5lJWM9R1Ayml//4NGSmrlZEsIzG6bA9+dT477tZSdg+vAFBKoSxLl91CCCmQJjQKDGuR5TmSOPYTWY/L2caqh4wk+q4/1sA6iGVrLOqmRlM3RxbwccaQJClGo5vLJwmCJHAcYXw3cK44y02dhydqVjlpEVndHewpWX13PISAWdiV0j7dkqYJfuhiCsZckqhL9BxC167VFlJI71/p3MEjhSRTJePQSoExgOdbVH43BlppgIFGfFdSRquyRFWV6wFujLwlnDG/W0cbDSkjxFHsfCUtxqMxpag6ocA5R9f30M0Sul0iMxWibokszyHcRE7btuiW16m6sriOXvUURV9VKMsKpp6hn+9BzfdXlubRizaM+CYMaLvW5YFQKBws0M/eoSoLExSBr5TP7WCgvTYYppLc62asRTe/CtEtcUVM8L14C99mBeKYJqaGqaLD492HD/xhKmeUMIwSuu3lRYyvLBMYN0kzCCoAG38uAKpWNG3jqznDdWYxh2Qa3+0nx+6yOen943C9Q4tn0xZg43bu3GhD8GHCVE3gbhCESOC+415u6jz8Du9WFpH5Urob2TwMYwzPiJk3WQ7ZIqsR8fuNRblcoqwqVHWNJIlgLYmbKIpodNRVYmw6de0CCxlFkJMLGNo0eUbr3yMp0TQNAOZ8IcBwyjMGf1DGUUQtHecPockaGmXtVY++7ymV1NDUD+fMtVmGLBQgTVOYzi2Km12Fnl1F27bIixwAg6ro8Ep0h6YZwtPcozRz+lqzPUi5XklQrvIjNQkr8kxwME5VBz2/6sQHx2ArGdohdqgeKeXFhTEGXAgwziF1BVPuwVqLb7QCrzecrjnPjoiR1UOf86PR/pk0ND1kLV5ZxHhpHrlUXbX2czFsbgajFliapohkBOG2Ma8+rrEWvZtiettsrQsSa08llg9GkzdjcfLtx/HrvzsLgiRwRwlCJHDfca83dR4WI5s2lo6K0Yn99A9cMOjt8bcPx1pnIxe6dXDQfWwrcZWI9TK8tcD1jpbYMU7tB5kXYJxhMhkjy3LKN3HZaC1LqPzftd50yRjQs4QCw3zL4GByR5tV4URNnWFnDR2OElIKSCGgtUGeF0iTBJzTY8Vx4gPR+nqBvqYFgqy6jq5tkSTkj4nQU+WnH9peB8+ftQtqV3UNIinpeUqJSErEhj5fKEU5JW5TLucMQgpkaJEY2jujDLU3hoOfRAtF6HPnI2GM+R1D1lqY6jpMvQ8A+JbN8fWaRnj9NmUcVBg4F06oHFy7MRZVRdM1pl349tur3Rh/OJN+MeLwjKWUyNIMfd+jrCr6U5boXUT8wFAdodf0QJBYSyPZmUvKXRNJh8Ty6oTWRqwbAT6Uk3Na7hcxMpvN8PLLL+N3fud38Morr2A2uz+uK3B6wvhu4L7j0qVL2NnZOdYjcunSpbt+DcMispslysb+4DjMs+MOLy/WN8waY70Z0sZjROYgqCtLY9RNBwsyki6XJQCLjHOUNoaav+t3rmR5Ad6UVLFwUzVRFCG58Cia61cxBLlywV14GlUzVhflAfTvSMqVZFLm0kgN6qoiMeMW/iVJAinJeMvchVgLqGYJmY4g2wXE5FE3XcORQqOqakROhKgoxVCh0fU+RL4F0TUwMvFjyoILiG4BHY8RWQPtzlXOOFVytEbbNAAaoNjGbL4kI6uUvhrChaD6i39uGn3X+Y9xxqDcIkIAeB2PwCIBWIIP5sZnkQwLAvteueA37r6H61WwQYzwZIw/2BcABN7PSVBFUeTTYg/Sbzmsa98MkzbDUsWhwtbVC1hj8L18C2AMTxr6XsjoYB2BPJQjIrjwCbCwJDr7rvfihXEGpXo0jb7l0d+zHvO9F6b2wN0nVEQC9x3Dps6dnZ21j9/NTZ134hfpB6abUzYB+IPlh7etNzlqrVGWJcpyie83S1q01raQUeTrBUkk3DI42nWSxAmUm3pZZThgRHEBo1HhkkDjITDULa/T0EpDa4O+68DA1kZVGeOIIok4SdC2nRMXzC2fU+7gUmjqGrPZbKUNQtt0OePO68KhmgVUs4RZvAvRzH2gmDEG2lVNZF+vTBcBqauaxJomc7I0ozYM59CLazDLPaRgSN0umGEUWhtNomTxLni9DzAGbahtZey6CThJ07XKwwCNs9Kvw0hXEN0CjAFfrzn+aKHRtpSMO5/P0Pc0hVJV5Lk5bgeMaReIGYnM1/UWXtdbzueifbWCu6rN8PMwCA/uBIQQ9L1WfU+eF5dm+606hxACqu/R9d0REaKVRlmVqJsGXduhqiuoXiFNU98aosV99PWGnJxbqYwAZ1Mdmc1mR0QIQD6yF198MVRGHiBCRSRwX3L58mW88MIL93RT55C6eqswl855uCoyjHOuZ0oclPSH8vkTtsR30imaZoYkoe2uYIOvg6ZkhJToqgoJaLLELK9hsH/UEMhhwDhHXS6glEZe5LDZCAwWrF4AsGQ61Qbp9DGo2TsYxy7mXUqovkfdNHR4A2DWIkqGKg5bO8TrqsJ4MoaMhoAv7k2nXHKAAaNEYNlqRO0CPMto3FhrtPUMPJsgMS16niJJExq1ra5DFFswyxl0nKHIc8RJQsZYpWGqPfBiGwkseJKiqir6eoz716hgLUoTQ2kLMIE8pzaGWfFMDM+PMwbmKg9SCFghIKMISZqirksST/EYb/Sxr5hcso2fpDHGoGmaI5M1/meCcYxiMtlWPcPXmgJPonS3URtotXmymsY6RMu3bYs0TVHXNQm6ssRo6xHsVikYy/AeS5ulhwqeNdaP/XLGwQRzeSlkRJ5OplCuxbWK0WbtcW6We10dOY2p/dlnn70n1xK4PYIQCdy3TKfTB+4XyQdd4mpRFMeOcw6Jq0NJf3h3PBySWimwhA5mwTnGRYxFaSFlMzRA0DKGZNhP49oxg6BZdPRfeseskOc5mnrhqh50DZwzCMHRw6KsKn9bEideNAkh3Lv/BpwzJElMI7sA4NJdjR5i4zWiiISAVlTlGNJkbV8DMkV3/U+gEpq+SbMMdTWDzKeIVIsoL6D1sEWX2iZtx9B2NeLpNqSUSJLE7dtRWGoJ4/JehjTYLEvRti2qsoK1S6oGFdtYVrTfZ5SniOMYqu+9TwRwxl1roQAkSYI4jqFXPBu8o9dO9T3k6CJ2dQrWMFyO4EZ/j07W0Gt8YGwVQqBg1IbbFY8CABmYD9/n0OMMVaSmbdeEw2L/XQDA5MKj+J7ZwlP2YCyYWlYHgnHVKzJUjwYj7WHuRJrDvRIk99LUHri7hNZMILDCnfrlqaxAEsdrqZ+HWU3qHMyRT9gScnSRMjEstRfAGKwFbHYBQtJeEsEFwBjk+BFEMqJqDOeIJtsA6MDrVe99AABDPNpCnucoihxCUAw8A/PXZy3QtC26rqWtwIDzM2ifP2LcxwfPibGWcjVcHkffKzKKCto83LQt7CBGAEgX6ma0xnS6hZRrMtTOr6GqKlRVha7raamdW4zXz69T6wFwwWsWavEuAIvUiZA4pnFhWpBnoZSmdtTsHaDaA2MMVdP69lecJGCcexECUDskTVPwQyZQ/+KAJnmUGy1+o4/xpkqOBJfRYx01tnJnOKZlgQzfcO2ag9YYO/KzYlyFSR8jHKoFrQJ4q0xXLvWE0V5seG6rt98gtv4w1nmcNi2HvNvtmnttag/cPUJFJBA4xO22aE6zh+bZcef3lwDDISVpPb0BdDRCHrXeT7A1GWG2KL3xs1cKGkACwFpKD42iyEe/A0PiqETX9VAyQaQaVFVNwWQdbdRtRIYksSiSYaSWDqrlconp1pabLgGsVRj2sSilwDkD58J7F7I8p0PMWt9e0ErRCLGr3EhrEMcJWEseEZukdN3cooNEajs0iPyoq2CArvYhiwsw5Qwtj8CFQBIniKMI/XIPjDMk+TZY16GDpYPWVYcov4X8EiPbIE8zXNujzJIcVP1gLs12+NxBcBw5kN2/h1c3MjVU38MkE7ylE7CG4SOTwptYuRM5WnduSaBwrxlDlqWoqiWUUpDZFN/ABTzD972Yit3GXwBeFDHGwDaM4zIwWNWARxleu87xgQvmRDExiB2No36mk3JyNnGafTd3szpyFqb2u7l24mEmCJFA4BY4zebTTdt5h/j34UDhyRi6ma9lPlyWPd5SMRaLub9fmtGelZplSGM62Pu+o2vJtpD1JdI0AcBgkpz+h93MYYxB2zbI8wJWNZD5BFo33gRJDwBUlfMt8INQL2sNsizz7QfOGIw2ft9J4hJU265DuVy68WNLmScy8uPIjDGkSYIsz3xOSaMYuuvfg0rGKIoE9XwOa4E0n6ADB2cCvaZ32Ilt0SBGYhS0jNC2DcbjCZbLJbq+gyn3IEYXkQDQzlgLeyAahnRbpRWmEVCVFSqMAHTI0vUppsTF9wspySQ7PAf3OMbQFI3qe/RKQVoy7epohD9aUNXio1OBqqrWpmmGCgkA1+riiKIY3FDb6BvyAmxpcclcpb03kwkiKdfaej6OfnhM928pJRL3c/badQBI8LhsNqayCkmZJdrtJvLXd0JOziZWfSirHF4OOXA3NvoOpvZNUzN3w9QeJnTuHiHi3REi3gOHOa4qctrNp0P0+yA+hsTN4d8ykvhaXaBZXPMjtELQzpnXGzct4doA5KmoYMCBcg+RD8Cy0FWFgvVomtplZnBEqoFt5oijGGVZgjGKJmfNEpHtIGUEay3m87nfsKvbJfiwZM0YTCZTzGcz3/oYj0ZoXDaIMRpwrRylemit6XCVEeI49h6RITKd9rhUlIkCUKhYNgIDg8m2KFK+rqmakI4AMDSc8kSkoLh5XlwAA9CJGNPp1LdWhgrIXNFh3Pph4oO0ktF4hCiKEMlobWFcFx3suxnlqV+YpxWl1Br3PWuaxqfQRnHsKz0yijAZj30FY7+xXiw8HXVeYNJrIFbGoelxhwWIjHFkk4sAgEvmKpIkwXg8dpuCFebzObqu89fKOC0lHMaoh03CnHPUHRlxdw5FxK/+jK4K6aFydjNR77eyCmHgTguS1SrF3TK138u1Ew8qt3OGhopIIHAT3Ow7waoz0G0JpTX10K31O0aGt7bp+CKYqsAYhzEay2WJ90qBb7Fi5Qs7M6ozYKr6OrSmkdzYWJQ8AkcNozWYADqZIEom0P0SMpIw2kBrA24tWkSo5jNsbW0hTVMoJSDbhWsnaL+DZTCmUjaJQVlVACyMkahrWhx3sDuFIUtpq21ZltBu5wztcqFdN32vVp6Oga6XENkIvL6OePtxqL6H1gamXYInY6SmB49ylFVJm4GXexCjbcS6g1IaWRaDR86EqQ3idoFO5EjcCzuMOXPBD9o1Ljl3+B7G/RIA0McjVE2LqmmRp8lBuJwzwxSjkc/+MMZVikB+jCFi3hqDjNPWX8RjvNnTsr8P5fT8u650goWyU/I8R103/vXoyn0YY7A7fhRQwA9p5bYkS4xGI0pr1eTrGVpJXHAslgtIQUFwWZYhiyXqzuBtNcVTo3aj2LjVnJyD79/J719Puv1OV0fuhak9TOjcXYJZNRA4hk2/LA9PJKwyjD8OPDOlFozWmgyb3jtBO0Y453hSvwNrrXtn3PvJCOV2p8gRvUuWUtIUDtyER09Jo5wztEMwFuNgjJJEjaYpGCklRsUIURxRKJl77yFcsFeapgel/yj3226LgoymkZRgjFoUfd9DSjLfZmkG7tbJS0njycZaxAlN3RRFgci9Q7fW0v6bAbdrxxgD21UAGNq977lxVRrZHcUuir7cd/dhlKPhDKxqcd1PvSitUVUVsjQFb+ZQ83epCqEVuOAo8gJKKTL4YnNy7sWUYztx/piqQd10qJvOfV/p8a21aJoGVV2jdsbaqq7Rti1N69Q1vUZCQFfX0czeAQC8Wlq8pVPfDqPKmEVdN5T14qGfj8YZUA+H30VRhDzLkWWZa39JWiTIuM9BadsWXdchcW8x31omB4LwJtouxxlQ/bfwGB+KlBSyNkwZHZdL8qDFxIcJnbtLECKBc8udiH4+LEZu5p2g0gqP831EGbn3h/0iaZr6ra9D70BkVMokMyFlhzwd92TyjCL0fQ/Buc8MEZNHYEFhXcNh1keFi4/n0EZDjLbQsgSLBb1jLoocRZ5TdkY8Qtf1zj+SI724A8YYpltTpGmK2WzufRDW0hgxvbOm51hWlRdPRhvnF3EHlHsOXAhELmOEdsUMB5hrnLi/R4zEm1lcQ9f1tElXa3BF1YLM9lQFcAFrvCuRsh7VtXcw/5MraNvWtX5qRFGE0XiEzLbUvlAKzXyGLM9oiqZXVB1xEyyrh3Tf97DlddjyGmx5DYBF3fZoe7crBm5MWUqkWYbEfS85Y66tRNNPTdP4BYKiW6DZ/xMAwLdQOGFGIpGmi1aTTA+i2U1DB9uX98iDQ5Ud4W+3LqiNxqYprXW5WGBZLrFcLmlbMyfBfCPj9CpaaSzLJaqyQl3VKMsKy3K5LiSxeTkkXUeHuqqhlELbUZBa13UnChLg/o9pDxM6d5fQmgmcS+6WsexG443HLUuLk5h+Qa8sxdMJVSQuNVexyx7196epC+NMowBLp2jmV5HlObqWNtFaxv3obZqkWPYK0moopSG4oBFfIaAZHbiUbBpDKQ3DYiT2wG9QliX5FwCULbWSoihyORrW78FhDOSxWC5p068WEIJ2wgx+B2q/0POWMgJj9O696zq/58Y478XweZwLjCKJZaPA6n3YgioYWZZhuVwCcU4TNSyGlAJpmkBpjUkGzFtamMdHUzRt65NiaYMxeRj4aBv1/j6QpLTkTylfCRJC+BwWpanChGFnUD3zmklnW1iUNIJslYKqa//9iqIIURzT66A1tDGI4hipe3wZRVCLdyHHj+CbNoMVGZ5EtfbzQnHx1osZzjm4pgrLK5YOucu45n+m+r6HcC2bqqoOwu9cvL/W2kfGtwp+ouYkbqbteLjFJSX5eIwxyPIMbdP66iBnDEmSIs83R8j/2n/aw+u/9T/e1ybQ+2HtxHkmVEQC5447Hf28WhXZ9E5w4PD443DIvDdegIn06Bp4o9F1PZKYgrp4MvYHkZQSSmk8YcrhwdD3PaLVlfXjRyClpKrFYDjJt3wmBWNAK2LoqEBR5NSmGY8QxxEAC+2uiXNBB/P4IlVbuKAdLJzGUAUXiKOIxImlrbxUvu+QpimSNEXTNFC9olHdIVa+71HXFYyhSRqtBp+M8a0EIWhCZ7lYIOYGYEBz7QpVdbRGksRIGI0wZ+gRRTF6N6rc1DVMTWZaU8593oY11lcMjDG0kwcAmhrtYu7Hk5u29e/2h1ZY3yt0XYeu79ArCv4y1sAsryGztGF4SGxN0xR5UUBISVUmd81DemxZltAr3iBT7kEv9yiiHbk3sVJVhoRjFFGrK3JVMABgqoaFxRt22wlC54txoWt2CHXBwaQQcBAZn/mJmpN/3d9M2xFYb3GR6GRIs3RNhACUhaKU2hghP4ifxz/xs/j4Jz/jP36/xbSfxdqJh4lQEQmcO+6msezwO8GBTeOPXrSwg3eR9I51GL0EGKPD6Bm7j9f1Ft3PpYj2fU+ioQai0UV086tUWWAMcRSh7TWU1shcaJpmHEIrRBHdn3O6Jr2kLAtrLcqypGrJaAumnCHLckgp3KGfoF4CiDNw3aHvO2hNVZE0TSFl5GLMGRinUdayXGI63YJyI8nDpMpw3PQ9mTgjGVFUe9vCWgomy1yLqu06yCii5wWDznDoxVVg/AiEoFaH0TVYMgKqOcRoC1IIlGVJe26We4jGF5HoDpWlyZTDLbRYlQBjaHkG2zZQjCFhCbQyaLvOtTkUBOdQxrjgLwNLTx9xHJOZd/au/xmoOwbbOrFgNdIsQ5ZS7DwAl+tCUzZ938O6to4q9yBHF/EdPgKrGD62teUExcEivWGcGiBB28z3kI638U3+KJ4GBbQZY9aECdzPFVvJax0yXbKYpmlOqozcigF1ML12tvNj316E2OH/uVbShgj5w+Ln45/8DH7/f/0fANx/JtCzWDvxsBCESODccTeMZashZ8M7wU3jj+v5ImTqbLsW2/odYPIYyjkZEYdxT+amIuI4BlswiHSCPILPGmnbFk8JgTdt5A93Y61v8dhsCwwtkjghz0itoeIxUq5Q1w3153kMqy1Yu0SSxK6ELiHAUCnALPeRuokXKwtEHU2SZFkGzshvIqXEYrFAnhc+Y8THkNiDdNJVETIw7DiRQiCZTKgtw2iZHcWNU0snkhJKa6RJAiMS6MW7SB99L6JIYtgSvOwsTDWDji7Su2tnfOXdEgBDJnMwq9Hy2B/QUgowTpMzavEuppMJrInRL5dgaUo60VoX9kZZH9poEiEgkZlmmU9tjWSMpm2g+gVgATF5FGACTdu7yRwO5aaJlFLIC5p+Uq7CIYVApEpkeY6lYvjKrMMPbh8ko7Zt5ysdw3PgnKFd7iEZbeMNbOMp8e7B602Jc77VtMpqZPyNxMjNtB2Pu42uhYTmwQ+Cq1BZc0TMbBI3q2LkfjOBPohrJx4EQmsmcO64F8ayTWbHo0a/Ek3TIJKUXwE3xRK5d9ecczDAhVtF+OHtwTNxsJ+G9pXQO81k+hiEe9cJa5GndNiWZYm6qdE0DTp3G43QaurJu/OjVz3atkWSpsjzDCahAzJ3rR6Kf6e/Gx67cnoNpTT6vgd348XRkUhzGovd9H6a+48zlM7LQK9RCQugaVqoXg2+VQBOyPVUVaiufsePvBqjkUs66Lr9a2SAda9f11GbCC61NTad36ciXA5JFEmqFjAGVPsAANs0aOdzXzmoqhpCChR5gcLF4UspoTVdI2eU3zE8NuMMZnkNpqS8l7rp0Lb9sPTYPWZFIWXjMb3GoxGK0YgqVlzBWuAPrzXoe7chWWsflS+9/4baROX+O4AF3mKPkPEVVHmREaXOWmv9Nt9h4/MqJ7VpbqbteNx9GdghEeJ2IVlLO5QObdc5TtwMbZpgAn04CEIkcO4YjGWbuB1j2UnZB8cZ/bSmJWNSSjzOZ0iK6dqv4k2HxbK1Xowo1aMsSzze0wGb5Tkm4zGKokDm0lZRXFi/GMZgkgllb7iFbCrOIIsL/uCyFn6ipdEcxhpUVYnFYok+HpEXQmkkLm6863rakKsNkjTxomVUFM6MmEAc2pPCOTu0lfbgeDZuEscY7dJch6RXai1opZG7jJDZlV0sFnPM5wvyDHRLFBGQ6JbaITlNsHRdSxNAjCoTBTcQUtBSP61R1TUyV/EQUiCzLXK4Ed26Quq+MW3TomkalFWFqqzQtTT1oZSCGCpZa3thSByx6jpQ7lEzgglqk7g/bdOgbhr6N6ittVzQ8+nnV2GNwVdmHdqWFgyST4Qi35XqIb3Jk6GaUTVklz8K1fdUTXMCdNjmu2nj88BxYmRoOR0WI6dJXR3uC4Z1nxRntNXY0tbnw7rjJPHzp//3/+dgAn1ICEIkcO44C2PZSUa/vuvJDHroF+7qYTFMnXx0RCV9rSma3Rjje++wFj3PUDeNjxtPY6oWrMKzHABgnGnTmvW8c9X3MJYCzlg+oUOVcRfdbp0vBGBRhq7r/BSHUhpZTomZ1liovkfX96ibGnGcIHGej0hKRJFEFA1L/4QPPhsO5sHcmGU5sixHnufO18Ioj8QdrhGjFhRvZtQCAgmpslwCXQmz3IdZ7rv9N9yP8eryOuWutBVyaHC3iTiOYp+fMrTQYlUi0TQFkzIg5UM7hPw9Qgpoc7DPh0Zw4dsnw9cd2g+prqDmV2HAYeCqWS5fxTgfzZD3MVR0dEX5KK/VHMZYlxVC6bld1yFJEpfhQs2vanYVjDG8xR+BBTAZjzGdTpEXBQr3Z9MyvoHDYmTIDtFGI01SFCsZK6NitHHa5TBCCsRRjNFohCRNICNazmiMhRBk7jWHWjE3Ej9f+PoNv2zgHBAi3h0h4v38cbeinzcFMXUd5SccR5ZniGQEpRXeXCaImPbtF6UUHZ7O9zGYVrlu/NTJwHdYAbW8htFoBBlFqKrKB2+JdgaAIY5j9EvqrfNm5t6hU6VBdBVSUFbHYjFH3yvkjAyoCaNldsOiO7Ogd95FItB1LaKIqiN9TxWC4XDWmtoLk8nYR5ozZ8YdzK1lWUJK4UO98jxH23ZomtpN2VBcepalMJoMpJxzt1QPEMmInsPoIh2YWrmYegPEIwAWNh2R72Kx8F8fDLAxxbb3UYpRQZ/bdTTJEscx2o4WzVljUTc1bDr1+fDGiamuowWEUlCLpaorv70YzI3TusC0vMhpgogBnaTrzlJqdRlj6DUwBnGSuJ00xomyDF3bQoy28T4c/CyRcZkEoVjJEuFcoAcZPz9+wRy75fkkThMHfzMM0e9S0nZo73NxFbbjot9vFDl/N5bmBe4sIeI9ENjAvTSWncboN0wYMMD/MjbGrIkQAHhG7OM1PUXbNkgSGo1dfb8gRxfBBbV7BOfI0hh10/nldFopIEmBtqER0JUWgXDVk9p5PxhjEKML0MvrWC4XLsOEDrl48gj0/F1YS3Htfd+jbRr0qocxFlIIxEmMrmtp18t8gdGooPwRS4fZ4HdIkwRpmqJ3lYuyLDG0YawLN6OdNXRgDwZMYwy1mqo5onwCLK+BZ1uI4sy3OYAerY3AmhI2TaFc+NiQW4JmDqQTRH0DYzIopZFmKbjbkkvX2PsUWkBDG40aCYTqYVSPbDSC0QZcCCyXFJtvjUWnesoKERJxcrA111hDbbH+OuVw2ItgDIgljUYrrWGaxoeRDZt3lVJAeR3fKrbxTKJdlgtoazGjhXmD8BtGfmU2xR/sC+8xuhkSCdS9xXf7CR7n+/7jx60suBFDq0Wpm9vue6PI+buxNC9w/xBaM4HAHeBmjX51RwfMkPWw8TGzqTOySl9NuCQaP3HCGUOW596boZSGtfTOOB62yLqIeGvcVMVoipbRYc84vQtvO2qbRMUWKFTr4HBmjKFRzI3hWpfmav1h2rYdRqMRsixHmiYkhnrl/RBxHCPLUi8+6rrGMEWhFEWwD+0G4CA1lHPyrQwwxqDqBRlUq+uoyhJ1VTlBpVBE5EHtZnuQUvooda0p5E2X1wEwqMU+bLVA13bOn8OR5RkEF+i7Dl1HYmAxX0Avr0EvKESsXy6ha9qoO5hn0zTFqCiQZSmKUQGtNPquR7ksUdeUq8JcgJteXIW1QNtrL8aUUjRJlCRIkoS+B1JSC6O6jtcajqqqsFwuaPzXWidCKOHWDO2UhvxDg2i5GbTW6Guqnr1tttZu25QdciNux2dyIx6kSPjAzRGESCBwk2x6Z3Yzv4BXRycP98wHnhH0S9daszZNMbzTXGoSNlIIFKMRti9MwYptjMdjCvtqGvA0A2O0ayV33o7lkkZzh025XHD0XY8aNB5sLbww6LoecvoYrLXoDF+51kE0wFVKFKqyRFlWKMsKvVKunaCwWCxcEFuENMswnUxAEzDWRaYbAMy1HeSwUoaqIoZizTmnalKSphCa2lCprsEF+Q+ahoLJhKbKUdQ3zlTK/LI7KSVGkUGkKTZeL2fo+46mdpRCkibIshxRHMMY4wy9JLxseR1jQa+7LkuYuoZSPZq2oRRTpVGVFY1Uu+h2zqllo432S/f04qoLPx3Gil36rVJ+C68QtIVYK4V+fhVvS/LwDEmp5J3hLkGWKiZt20KYBr9/nftpntMyfE+PEyO30rnftMvntD6TGxHEyPkkCJFA4A5xs7+A686s5TysQvEYDFbm620ZKfCh3LUt3MeHx7DWYrFYUCpo16HtWlhYNJxCtrqWfBfx1kWYuHAJqUO2g0WDCLKYunfcQ4uGI9p6DADcIcd86NZaOwFOwLgxzbZtaYKDMWckpSmS4ZqHzb6A9VZbb8oFTQwJSUv1YOndOXe5I7olMSWbuTOw0hJAIQRYXzoDaovxeETGzVEBKSmy3sJCKtoi3Fx/F831q5jP5ljM597z0XWdb7MwMIxGBcqqhOyWiA1VdHjfIzIGfUdTK73qwd0kDVtphRkXjjaMsEbd0lWDjPeGKK19m0m4pFyzMoZ7RQxixHjD6mCcTVOK0B9ag384kydWRgZTdNt1VPFyHzPGoC3pkF8VIzdqOR7HpvH2kzjNor2BIEbOH0GIBAJ3kNP+Ah6qIpvGdwc+KGnXSVEUflw2jilx1YKEQT9MrtQ1IsHAios+q8Fog96JhmHZXjEqMLg46cCid+7Dr30GAPEIQnBfoQCALhqBRRkA8oYwF56lXTQ64wyC03QJGPyEC8XVk9mzbhosl0sSN3Hkn/+Qx0r7a7RrO2hopf1hLd0yPxIpEujdlIuuQeKIBEzfK/TlPgCLfk4JpE3TeKMoLL1uutxHYqklFesWSmnUTU3Jn66iFMkIk8kYfa8ghUSvqO3Sz99FP7tKEe1Goy+XvqU0mHiHDbvMXxv8biDrMkeMZejdTh1YS74heyDMAKBf0ud+06awxtDrshIjX9fUnirLklo0DPiD/c0/T0oplGXpW2Rd11GInWuTKaVQzfcAWLxttm6YHTJwkog4jcA47aK9VYIYOV8EIRII3AJ3yjjXKkowPSxGhBBIs4yqASI9cr+nRItSUUZG33Xo2pZEAABtzIppkloTfUTv6pu6xmw2RzzdRjTa9qFZAImGTlBC67C8Tintkl+duZYntBHYVTuEdEFWLoF1WNzGOYfR2rWAJNqW3oEbrVFXFbI0Q5qmPoGWBAgFYkkZQbhcEa2VF0mCc/QdVXvA4CsjqabwM7viKYlsh76cQS/3EasGSZqgc4mlxhoXa29gnb8iMR1k31BSqhSwxjrvjMsB6VoyAa+oBDV/F6KjlkbsFgOqldcT1NjxYpQLTiLSWIhuTrlqFXlp2rZFnCS0YXdQf656NIz2XommGKai2ral6x8+R1OLplvS5355b10AD6ZopbUbCSeBprVGlmXIsgxpRuPX1WIfAE7l6ThJRJxGYNxo0V6ojDwcBCESCJwRQ1VESumzHzJX+SiKAgzAZUZmyaqqUJYluq5d2flCDEvPkjhGkadQ8UF7KEkSaPeuljPuRyqHMUkTF5hMJphM/v/s/XusZel5Fwz+3tt612XvfU5Vddtx2U6X227buXYSJxZWCJf5AnwKyQiBIiMxdog0/JGIkZzAAFakoKCxogkRikCECCQI0xIz0ZB/BpHwIedDQAQI2Ukc8uHYTrfbcdKx3d1Vdfbe6/5e5o/nfd+99j77VNWpru7q6l4/6ai7zr6ttfY6633W8/wuK8TkXwZAlifIMo3tdovNZoMsy+CKE1qIZR4C2ShYz1kHKQSkVJDRRRbUGdJao+u7JOEEqFDq+j51acqyRFEUkFKgaRtYY1CUJZarFZaLJVarJaSQIZNGJi6L9ztugzZ1IusytnOr5aYBwOC2t4NHiYMUElrnGEfim/huDd+uaUxRn6URS64pFJBxIuDGCVl0gRVCwFmHpSSVTuYd2NBD6wxKqtCZYnCWOCeLBY3pIjk2GylPpu36YF5HWTe51tRJihlCxsBsqbvz7KgghJzsK0t8Ee9JPsvMeRk58YsMTOCisMDLGccRZ+s1ufL2A7z3WFQVMu7w7EbdMSjvoiKCM0b8m74jjxXB0/jHGrtXYFwmaO9Yd2UuRt4YmOW7M2Y8ZLSDQ5HxPR8I51wIe3P7d+HGwvsWWms8xRw+jyWY75DnOfE1ug5gHNvtFkopFGURpLIAq64g8x3KokA/DDBCQ5kOt2/fRqYylGUJY0awPIerb6OpayB0RzLtoHUO6Bzm7GtYLBbBOZTDWpM6L87R3a6UklZsDwhBpMwsI0dXwTkynSVVixACQ98DjKEqK3Rdh67vqXCwDjrPIaVA23YoigKM9YFUSwscTEdjo+YWpF5CCJnGP0M/QKsBg5dgXY3ltbfQmCaYmlnryBcFgGvOIKpTmM1tZAAY17TIe5fkutbZ1BFy1sIYWhy19xj6Hi4/gWsaiEyjKIsQnucxjAPObp9RhyRwRqqygt2+DLl8DINxkMJjW9ekmnEO3rkdf4YxFOjRQgfXVZkKytgZobA/ygHS3OJTN3eSXhc8X2IHhXOONoysIk8kclqcd1gulimb5iIcKyLiWMt5B2fdpPDT6LounBI+hd/F7bnIdyR1fEIBc8zrZMajj7kjMmPGQ8RFSag2tNCllHiXfwn58urkMbfXFeGMYRx22SocHmxxFcYajMMIZx2GMGLwzqOOstfwelGeYhgGbOstjLFEbBUasjxFqoLCorfZrGH0Ep1FcFRV6Y6XcypMlMpQ5AWsJdJqUeQpwG8YBnR9j81mmySsxtigGOHoJiMmAEmFMgwD8pBILKVEUeRYLBaoqpIW5ZBNI/sNpBRYr9cw40hurYwBQ0M+HC9/LXU3nPOUK1MtkOmMukjMoJLEnXHbMxolhG6CD4uq4ILItp5C97zzaJuGDNl8D8Y5+DiCgWG9WVPRF+TSkczqHbmw6iyjZGAAZrLIVosFytAhW52cJPM6APh8R5ft2GWgkVR0g6XvII6ppiOaKek5koiB8yGFdlIAFBm/sCtyqKiRkjJ9jN0VN5GT0/c9VKYosHE0sMbChGNEXioD6rpOnb++H6ijxUjVFbsrckL8juOb/89/u310+94MODs7w2c+8xn8+q//On77t3+bIhAeQcwdkRkz7hPTRN5XitgViYjqEiJqKsCGFNnAH4jeI+9WA54bNTyapEqJy4OzLpiFAZnO4PsegyhhuzYMDRgaiGCBTkWBzjSGcYC1HhkDVHUCDHVwMfXJGRUe8DLHMJCkNM8DuRW7MQD5iOiQ9uuSTTnCAr6zTGdYLBfgjMOELsk4DEjEVHgMgyGibtfBO1LTtE0DxsnPg3MO7ywGCDJhEyV5n3hyJhWCw/ZbML2Ab9ZomUqFxGKxADxlzNCxd+SSqhfITA9vB0hJ3isIxchoXEi7lalobNuWEpcLh44XlO7LOLwL7+dDqm/4gjgnMqiQAsoNqKHhQqfHjGOyjfeByDqOI1hzC7y8gt9Hhev+jA5lHKkxJA8VxjgWGcO2351HQorEz3DOpfPlkAVyqJShYmRXNEcXVOeoU4Tg2cI5dY/iCDAWqLEY0Vqnf3t41HUDnWv0fXfOr8RaiyGMzvq+x2hicjH5rIwhyTiOb96MhmfPPfccnnnmGbzwwgvpd9evX8dHPvIRPPnkkw9xyy6PuSMyY8ZDxlMn1O6Pksq4SEQwAO8VZ1DlabqjPrTzjtbhSkoil0oBvrwGa2wajXTOx9x44liEsDbvAZavdi6nkQtR0YXdex+IjQYuGKONGS3ekAXapsV2u4UxI8bghaGiaogxDMMY/p9Mzc7OzlBva2w2G0gpYUaDru3QtHQ3bAJHJMqHAYZMKUgpUZYlpJKo6wYeSMVGPFAK5OWR2yYoWahjQHb6Aq7bwHVr5H5EyQxWy1Xy8OCTjBljRvh2DTHWgPfQdkCmslRExecVRR62q0JZUF6O9x5uexO575DDQ1gDDw8hJTKVIcsUyqJApjLqnnCOYRxRMeJotE2DbV3j9tkZWcAHD5GyLGlc06+TWZwQPJ0TMpihxYIRABaa4VM3qRuW6zxJyV14zk4yHQ5heJ/D8yt2RqYE1K7t0DYN+mEI4YYWJqQEm2CAJ8Qu/Tmm8kZJNhA7f/5c8cM5dUKCk0v6vbEGXdftdUZiZ+bNxBc5Ozs7V4QAwAsvvIBnnnnmkeuMzB2RGTMeIhJ5z69gIDA2GyJK5nly20y+EEFsIIRElmXhIm7x3sLjc/4qbHMLgvPkSwEPmGyJio+wwcUUHuCLa1ADFQFk+AX4hkYlPMh9WTA7HWQOzRj67W0Amu6qw93vmC2ghi1ksQSzHaRUye1UShEWRInlYkF5Ol27R7LNVIa2bUPhxYN3SQgAHAZonaNtiWwaEe3unSNuCWXW9Og7at0nRY8qkI1bdKJEMJmFlBS+t1hU6PstfFbBbG6i9yIkw0q6owe9j7UGWpfotzchF1chxw6KAapYYVQKQpBqKXZ/SIKbYbGoIISEyhS4GVE7BWEMDBdJaaTzHGAMRU6EWJ1l6PoOUArGebDAlbDGoGc7Yunq5CR0YoAv9SXet/CJ3xH5ImVIGKYizQFQ+Mwmw/uyDjrTYJqBcQ4rJZhzJBnmLHBXOOQdJOVfWEu8jYdQxLAvzjrUdU0yZNDXFbnJ0f/FWZcIslSshe5KsPGPSqPIoQFi92j37whjDTTT6d/363XyKOP5558/V4REvPDCC3j++edfs3iLB4EH1hFxzuF3fud3jh6ccRzxn/7Tf3pQHzVjxquO12L2OlUdxJyPyKWo65oUDWdn2G63aNsW72Y3wfMlypIUJuQvUpG0ljGoQBBN8fOgnJa+78CFgBASXmfJqXM3k28wKg1RnZI3hiRViZTUYfHeQ1YnGMcRRZ6nMYD3Hp0IZEFZoG2aZEXuvcc4jMGBtA8FzISTwMi8y4zUZUE0/wrvOxoT/ESItCmECCMIQGcZyrJCURSpg0SWrLQp1lq4oZl0RnYLY57rZMJmGpLu5qAxgw0FXFwcAUYOJ5wD3QZm+zKc9xjXt+i7axoKt4uNJtDiSTb2SEZsJSgHqChJyaSUgjUGmVI7Wa2hrhDqm2F0walACFyO6NkCkFqHh2Px+ZaSfZWiBb6qKgAI3y35hdhuDe89Pjes6NgG5UmWZeBBdSO4CKOiXSL0IWRIQp4ank3zesBAxVdILY6dDMFFGMtJSEV+LLGLwcLzPEIEQdiO+NpoDHdo/JdItwdeJ2+Wrshms3lFj7/e8EA6Il/60pfwfd/3ffjsZz8Lxhj+/J//8/gX/+Jf4No1yrm4efMm/vSf/tMXZmrMmPF6wms1ez2mOsiKJcz2NoZhSAtCXBg5p45GdDal0QX9CT99heMzt1aUj2It3dlKCWM9TLYCG7dBVQFakYtTYPNSsqyIibujyAFDJM/NdkN3o7KAMl3wvWigVDaZ03t4X8JvX4aXOYSLKh+WMlno7z64pjEGxsjALMpgCX6S47IjS0br9yIoSYqipIV7HFEtqtCmp/A/ck5FUu+U3KN3NMKIxRGws7kHPJQf0EMhx4jeMQjGkyIn2cPHIohz8H4Lr5dg3RaZ9zAQ4Z0QOhWCVEaZptFNSaMrZWqMWw+WF3tqj6ZtyAY+LL4egFl/DWr1lqQiAWPJATd6xhRliVMtcLv3UGp3GXfOo2napF5Kv+834HqJsiyDMsaDM5YUOvHfcVxzDM57jO0Gqljij9zprnjGjrRb5EUirHLG03mbZRnquiZ/nAnHA95T0u5B14OBEnhjMSakBILjLMJ3fFF+zZuBL7JcLl/R4683PJCOyN/6W38L169fx3PPPYdPf/rTaJoG3/3d3713Ib+fzIIZM15rvJaz18O/ibfiJgBam6cZNNPW81PiNprx/HvFLkVZlqgWi2RSJQTdq5txRFEUUEqiDxd9FVxPs0xDSQWbkXFaVVU7c7DgktoxBZ4v4T0wDAMpUNoGTdNiHAfw5WP09KwM2TgGozFBnkt3zWVVoSwLLBbLYIjG44FI+2mtg5IKSpFfhtY5GICz9Zr8NIyZdC7o5dYS2TbyLXbH1qPKBNqXXsBmuw25MmPg08j0WjbUsM0auR+gTA/GACUV8lxT0F8ooGSQILNhg8yT2VnFHRaLKgT/FcnB1cOHVF6RfGFWmQf6Ltn+x0LURwfWtByz0A/gwXN2dw4wxmCdQ9s06Rz5rZtdOg/isZGSjl/8b8RvnknydwkcHiHE3r8vKkKAXZTAYS5NKiIYdb8p6JAM0qoFuQJzzlFVFbTOdkUISI5OHjL798SkjCpSthJnPHnUaK2hs+yB5dc8irhx4wauX79+9LHr16/jxo0br+0GvUI8kELkP/7H/4if/dmfxY0bN/Bt3/Zt+Pf//t/je77ne/A93/M9+P3f/30Ab8453oxHD/cye31QOPybiO3oKTnvXmGtxXtzj4EXgY9KBNMsEEZRXU13mTLM/31xCu8dhnEIShkaR2xHji4oSMZxJGKjFAAYRLFKyb5ZlqXgNiklBkVjgaxcIWbI0KhHBeluj2EY0XVtGgEppSCkCPwQSsP1gUw7DAPGccAQFy4G9H2XXkcdCB6yV2waJcXOhBAS2+2W7uL7DRVMXIC6LzTuGYYhpd/SqMZDGVL5ZBn9vixLlEWJ5XKVJK9KSqBbw3kPW6+D2dyAMnSxhAiFhiN/Dxqn0OV2/eKLocDZfd82dINoRMFg1i+GfRbh90gcGIBM4awxONV0DsVixHuHYej3pLDD0EMpBddTAXHouhpxmENzmFkzjSOYFiOMMTKxC12nrmvRti26rkvjOSpeKexwCi6oW7JYHGQ0LRY0OpqESEar/0W1gLwgPiGanj3z6y8+0nLWu+Hk5AQf+chHzhUj169fx0c/+lGcnDxaHaEHMpppmiYR6wD6g/ln/+yf4Ud+5EfwJ/7En8C/+lf/6kF8zF3xj//xP8bf//t/H1/5ylfw9NNP4x/9o3+ED37wg6/JZ894Y+Cys9dXIuGVguzR43iGgeGq/RqweAuaza0Lw8ueXg74zCaD5jZ1LsZxRNM08Kgw8AK2u5VMpDg8HIB+6KEzDWMNjAc0ABRXgO3LaVYvFicwm1twzqYwNWss+V7oEnxo4CSF6GVZBud6jKNBntPffS8raFND5kuM7QZaZxiGPo06nLPU4h+pc7BYLNE0DfqOFtJYmAgp0TR1aO1TgRJ6AwBAhNwgcTUj2cB75+EZdX+kItlvzK4BgGysYS1xNGIQX8zc4ZyjLEswZjFAQtkO2y2NuJSUGMYRSioURZHs1J138PVtiOoU2o3owhghL8hczjmXOitd15OdPoBRljh78WsoT6+k730cxmRKxwWHhYXbvgy+fAx5nmMYR+g8hzEmhPEhpP0yrDKB9UBjmXEkhVK04I+GbV3XUWHFLXp3votgjCE+yWR8LgJfZNqt0Fqn5w3tBlmxhJA0buk7yq2JnZpDqe0wDKiqMjjjxrGXTAWF4mpvmwSnEEljzdHnH+LQ9OwfP/OPH1k5673gySefxMc+9jE8//zz2Gw2WC6XuHHjxiNXhACX6IjcKdHxfe97Hz71qU+d+/0/+Sf/BN/3fd+H7//+77+/rbsEfumXfgk//uM/jr/7d/8ufuM3fgNPP/00/tyf+3P42te+9qp/9ow3Du5n9nqZ5NApGGcoizLd9SVSHqP8meijEB+LQXORO9A0dNd7dkYW3Xme450gc6yYgJsplTzJR7UkQmGU1UaCZxi/KKlgrEELAa+XMKNJ9vNaa3I1LSLh0aAL1uRkWIYw+lHoJfEfVLGkIDew5OoZxyc7MzMDrTMslgv6WSyQFwX6vkMsOlyQhfro654cRS3yvEgESRb4NEJK5DmNSTKlUBQlFEjZ4rcvk8kZ53BBfUPBeC36vifPk24DeI/MDbDGBH8U2odhGMCD8RqRMgGzvQUGIPcmfGaQ6XjiAW22273ulzIN4D2a27fCdhObtus7ZFmGTGssFgusTsh2f9t0qMqS+BRSJjJzDLurt1vAA5+5FQqBaJ8ejm8elDmxUwPsd0UiYfaQw2eDbDi6stZ1jaZtIQSRT2O37Y/MCZRSKZwxBjQejmGANIWjc/oe/0buJUTymN38B/7STzyyctZ7xcnJCZ5++mn88T/+x/H0008/kkUIcIlC5Ad+4AeSs98h/uJf/IsXdj1+/ud/Hn/5L//lV50j8g/+wT/AX/trfw0//MM/jG/8xm/EL/zCL6AsS/zzf/7PX9XPnfHGwmVnr88999y5YK+2azH0wz0VJkLSXV9ZlSirEqvVCRgYuNoF4UVvh6ho6NoWT4nb4Ho5sfm25F4ZFsFs9TistantXZU5AEqHVUrtWt7eQ1RXw+KtU4YMALiswjCQ42Xd1IEIWaOFgiiWaWGu6wbWGgwDuZ5WiwXE6jEqdpyA9y4oY0Db4H0gXzpYS86qdd3QGMUY+DAi8H4n60QgoPKQ/Csl5avU2y0446iqEkWeY7FYIssyNE0T3GctmjCmGOozeO9hzl6ElBKLqkqBg4zxQPAMIYH1bZj6DDkMfHOWCJkxrdY7cgiN3w26DXi/Qe5G2qfAlaDnjbtCJJiOlYwWaK01BBeQkkY3dO70wcV2A7t+Ed45rDcbMqsL3zXjPHE2nHPIPMmaSWG182PJMnIt3XmOMCz0/mIerfaPIT6WChXvU+rzOI6wPRW+n79FBRUXPLimmsTviFBKoW3bS6Xs3isuyqyJxciDHKnOePC450LkV3/1V/En/+SfxFe/+tVzj3384x/Hr/zKr1z42p//+Z+/Y0fllWIYBnz605/G937v96bfcc7xvd/7vfiv//W/Hn1N3/dYr9d7PzNmXGb2Gomt0wugUgpd22G9PkNTN/d0sZ3e9WU6w3tPSY66XCxxcnKC1WoV7MyrtBBF7Ap8lngP7/C0OJRlSdbt2y2NbbxH7bNgciZQViV4WYIxkkDa4HoJAIOkUSsPduEMLHROdp8pylWyE6dRB6fOQtdROmy+oi1TZViII+ESKYcm/i4WHcYYDOOILAvGYNaFMQOSXbwUIh0DxlgyyqqbBk1TQwgap7Rtm7JhfPhg022pM9PcDp9LIw3nbJIRx+PJGGBqupPWtgdDdCKddBOsC8Rc4tKMm5swm9vUMeq7EEhHdu6xG9UHDoevb6G+dZNs5ssqkVq11mi7NiikGOz2JRhD51jbttBZRjyfsK0iuMwCHi+IVeDskHPsMAyQUgSTst1IJhqdAfvE6GOwQdp89DFrk6wX2I0bDxE9XA7XgXtJ2b0X3O1G91GTs77ZcM8ckX/4D/8hPvaxj+FDH/oQfvVXfxXve9/7Xs3tuhReeuklWGvx1re+de/3b33rW/G7v/u7R1/z0z/90/ipn/qp12LzZjxiuNfZayS2vi38e5q1Aezm4PFiu6gWd41VBxDMpQALiULvX9RHszMEe0rcxufLE5j1zfhKUnwoCWYZjCzhxzOSQAIQDLDeQypJmS9tB+sstPcw2QKaj/TZjPQbHVfI8yWwpcVyyqHtWAbtBzBdAeY2uq7H1atXQicDye47Wz2+JyU13RbRdUMq6ljI4AardU4LKqMRGN2NGwguIdgkPE9l4TiywIMwaNoGjHGY0aIsKwAM2+0meEyQHJhzKtZsRyZs6/UanHMsFgsolVHgHyKJ2MP74DJqWliRQ5kWjlOBJqQgDxE67Kk4kUqi4AbOenQjdTyiW60UdH4cFqXDeg1TlpCS8mQocZd8OaJPBxhQNy0YaDwzPQ8YaAzDa7J/j4TaqKSizho7alL2qZsMTy/vck7eZZGPhcznbnG8q+qI+Gso5yhtY9iHcwRtT52lYRggRIgJuIe/kUPcSQzxgb/0E1gub136PWe8drjnjshf/+t/Hf/6X/9rfPWrX8V3f/d34z//5//8am7Xq46Pf/zjODs7Sz9f/vKXH/YmzXgd4V5mr+fushjbjy2frNyHkeZ3w0VheJyRtDMGngFAvrya7NAp5Vbj/dURRQFIENrxElVJktPFYgG5WIABqJ1CrvOQnLt7nVxchc40xnEI/BK6Ge8ZjYFkdZost6uqRBlMu3Sw/VYqgytO6bn5AgB5X+R5Dh5GG0JIdG0bpJ8lvPeoqgqnp6fIg6qFMWC93mAYB1JjBIJuLH7IPVYkp9E41pFSIVMZOBeB7MiRcYdsJDJsXdfIcz0hZTJ6rpTQOqM7+W4DgEG7PgXwyejfEezylSS/k2EYYLY3kXsyO1Oh4ALYXhHCGIMKgXfw5AtT5AVynUPntM95ntOPbRELr8O7/+SR4j2G9Yt4QUZr/mjSxqGUDIUY8XuGYYDmtC1TNcwh7uQrMoXp62BP36JtWlhjUZY7FYycqIYinHchFoB+Xsmo5qJODEDKnEdNzvpmw6Xku3/hL/wFfPKTnwRjDH/2z/5Z/NIv/dKrtV2XwmOPPQYhxLmx0Ve/+lV83dd93dHXaK2xWq32fmbMuAwOiauHC8ShSdP98KQOY9hZMLeKRMQb9kWAIUhvfUox7bqOfCmK091oAkg23BuniMDngb4fMIa2fdPUUJnCcrnEoqogl1eISNm16Lo+SHYpRZUxBladgDOWHD2tc2jbjnglYTvW6zUVJ6dvpcW3WFHh0XVBhdHQ4l4UMIHTkYiYdQ0PoGs7DP2QQveMtckC3BgLzhlURqoLIagTYIyFsTZIkB3MOMIEW/yIbKwRQ+Kirb5SCicnKyIMD0MqlJQnCSraNYaBirJlINmuViuUZUl8EwBVWVE3rD7DcrkkhQ18SuCN0mN4IPcdbEscmTpIbn3IZKmbBk3dhBgAD+dDd2H/pAiqpx2oGKHOThzV7Nx06fg2De37b9wWyIsiyGtdMoabqmYuKlSoe2PS6CZ6izjn0PVd8oQ53GbvPeyBQRmwP6q5DAn8kPidti+Ynj2qJM43Cy7tI/KhD30I/+W//Be8/e1vx1/5K38FP/MzP/NqbNelkGUZPvCBD+DXfu3X0u+cc/i1X/s1fOhDH3qIWzbjjYxIbP30L38CwH57ONqsT3FZL53DrkhUN2itk5ETC26rxeoaiqKAdw5KSXjvkoIGwZk1yzJ0fQ+4nVU4jQJIckqFxVVSdASyZ9/34NUKvDyF8y7IQBUWFak6nKVioDEM222digsWiKn08Q7r9RpSCmRXaHzqeIYiz2HC6/NcY+h7WEuZOEplQYWTgTFKyBWSJLne+XSHTbH3ocgL61TXxQVQpm5BNCVjwT3UOQc/khW7MVSs0OJM/he0/wI6z1GWJbQm1YbypGSSI5E3mzaQS53HZrMlma0mt1LfUDpu+/KLKHLqEnnnU0aQMSYQYAciDRsTxhMC4zAEJZROailfvwzvAXGkQ5GFsD0GYAgeJIxFZ1p6/kWOq957/NaZ3Klhsgw6mJLFLlGUcsciJZ4/UXLsnENf7ytTpl3Aw47Focx3Ov5xlsjKhyTwi7olsWCxziLXORGXox9JMD2bSuxfi/iGGZfDffmIPPXUU/hv/+2/4fu///vx8Y9/HJ/85Cfx3d/93fjABz6A7/iO77hQdfBq4sd//MfxQz/0Q/jO7/xOfPCDH8TP/dzPoa5r/PAP//Brvi0z3hyIxNZnnnmGfhHsqp2zEMHHASDuCOMUB2/G8dJz8HZwKDKeFAzWuV14GWN4v9ngc+MqSUujJby1DkwAavUYxvVLEJyjDaRSDwDVVbjNSxiHEeMwYrFcYNxsYGPHxRqUZUEpt4whW15DjjHlgkRlhlQl5NjAqxKmvoUeDFqTSodcPcnUrOs6tG0HmS0h+zU6y1BpgWHg4fE++XlE/kpUAUEAVVmiHwb0w4A8eGo476GkgA3HXEqRfD7KogTnfSLSUlAeh9Y5hr4H4DG2a+QFwHkVrMh1GmE4R+OWmPuzWCxgrUWVKzSGQ40diuUV9EOPbZDoGmNgg9dHURbo2jWQL9Hffhn6yjXK3AmLKfFWOLqxA7e3qAgEUk4LyZNpPxkYEYcB3F5vce3qaVKxpEIlfG/RjfUFucL7CuKK2INOUIT3Ht3mJvLl1cQtibDWpq5QLGRjYSeVguAcfd/vSXS19/gjd4K3cVrcdwooj1znJI8OzrPAea+RuE2jGc+pYI5xrQ69Q4BdF+SY6+prFd8w43K4r0LEWotf+ZVfwXZLDPRPfvKTaWQDAG95y1vwHd/xHfjABz6Av/f3/t4D3eCL8OEPfxgvvvgifvInfxJf+cpX8G3f9m34d//u350jsM6Y8SARia3/5nfoYptlOl1sgaCS6Huyv44ZMXe4UB7ivVccPn+LXpfUDUFCCdAdb9d18HwJUawo5j7kkkgp8ZS2+Hy78x+Jyaree4w2eHKwqI4BvNYwALhbJ68NzjhsVoD3Lbqhg3ceWmsiIwYxzCByZLaHqk6BoUae59jWZKuutU6yV6UknPPoJal12FCDqQJSsuAVQT4ZHkBZVuj7LlnKw1OomtaUW7JcLtKYQymKlt9sN8jzHG3bIs8LZFmGXGuAAc7lSXpqY3ZPgF2/BLV6jMjGIU03+q2UZYVxHCGlIhVSXVP3Jaswrl+GKE+S2MZ5lzgqfdeTzHjYwmVLDLdfRr66koioPhSuea7hnIdtbkOWpzB81+GJqhzO6Dvk3W344gq6tg0qp11noSiK9N0z32FgRUopNuZILgAm/BIAX7CneErcpgcYjZA2m81ekSCkQK5z8qkJYXxT1OubqFZX6X1BI7Sx3VnQq0xBCw0X+Cvw/ojXyMUjmNhlUVwd9Q6JzzlGDr9bfMPHPvaxeYTzkMD8JQbXdV3jn/7Tf4qf+7mfwx/8wR9ASokf+qEfwg/+4A/is5/9LH7zN38Tv/Ebv4HPfvaz6Y/5UQm6W6/XODk5wdnZ2cwXmXFpTFu/3nlqSXskQ6jDsQwX/J5VNLEQkYxm/FMopdLvnhePow+OrNFxdbUiie3v1h45SDbKo8W79xhGA1+T6qaqKrRNCxHa6bnv0LUd8oIWdiEE5NDCNWfIixxNTQqXTGUhNM8jc2QNnzNyfa3rBlVVoq4bMmzj0fvCBy8Qj8xswcCgmA2dC9r2rmuTayoPDFla+HxwdaVCSsiQHCtlKo6oEMmDgysRRfNAJGWgggGI44UCzeDgitOwHy50K0QY/VCR1HUdfFD4+lAMquoUAAMrqSPlvANnDFlGDqSr1Yp8VLxHjwzZyTVSzoTjFR1tc52j6zt4vQIYQ+tozFJWJZqmTaMh7zwGtQAA6EwmozjOORioMHWevGJGUQBg+OYV3W82zf65A9BNpTEWVVXBiTwVItE4zXl3jpshpEAZwgezLEM/9Hsjk2p1FW9lpFLJMnXOT4QLjqqsyJvmiPcHGCmMDl8XUZRUYI7jSOfgBSirMhjqEcZxxH/+f/3Ehc//0R/9UTz99NMXPj7jzngla+g9d0R+4id+Ar/wC7+A27dvQ2uNH/3RH8Xf/tt/G+94xzsAAH/mz/yZ9Ny+7/Hbv/3b+M3f/M1LbcyMGY8qplbvjDMorlJL+hg35PDOLtpYUwLq/ugmdkWiuuHQR0RIQYuFB/TiCrrNy4nsOAxjWIgLdNDgvE2vjd4erLoK3p3RKIczjI5DeRcWaU3BaFJSVwAAK0/APBUcdLdtgkTVo+cZckcL8tDTCIVUKKGr42JarIMx5GpaXHs72pf+EL1jQN9gHA0WiwpxxsCCKiV4isFYG2zaLfq+Q9d31DEIo5lc57CKDN7MaOjunjE0TYPFYrFzaGXBkbNpAJmDNbdgRBE6LCoVRFQ0KXjfhePGwRgt/qY5o45Iu4bxITNHCSJPliWNLkLsvSgz9LdfgsvK8AXQjzM2ueA225sQy2uUT8NpzFSWRTLIY2CQ4whXnEIKgTHY3MfsHRkM36wxYP0GLluiaeqUgDsMO7feeA5IKc51ReKYSQhxLvvIml06srHEy+iwkyXX65v46sk1fL2uz3U74rnvnEVZlKmjETszXHAUeYG2bXCR92r8e7rbPfQxdZGUEk8++WTqmhUFpQU/99xzs9fIQ8Q9FyI//dM/jbIs8WM/9mP4m3/zb16oRgGI2PRd3/Vd+K7v+q4HspEzZjyKuJcL5WVm3L2h9vvUjttYi6IoMQ4DbvQv4nn+OAAE6alOd/HvrTw+1zKUVYWmaWDGEWAMSjCMFtCZDl4cYSQxDqidgm3WYGCoFuTNMVoBZTr0LIdS1H0YzRDs1albYLISGFo4103uSP1kYXeJrxC3cQy8EcgCSgLOGlhnyY9kYoLFOIdkCt7TDQ/dNbNERLXGokMPnefo1z1Y6BRkWQaVZbsiLvAQbFgUNWOwIgMlAjOM4xjM2mxIgR1Tt4Q6O1QUjqOBqW8jW1xBDoMeGcAYdKZRN3XqJnDGkWMgV9qhQcfUjichZcrUidAAZEEdnaEfUlHAg4094LFtOpSFBgPQ9X2ytDfWQklJVvkAnh0zvFsNIYcmSx06ajLxQEK1cKaFl0U6Nw+VOBecxBiNSZyl+DrG2NEiJMJ5j0yRq/A4knw3vd84BnM5f07yywUP3jB3J3+f60Iyhm/91m/Fv/k3/wbPPvts+v273/1u/MAP/MDcCX+IuGfVzMc//nF86Utfws/+7M/esQiZMWMG4a4XSrA7zrinLfGooInZL1VVoShLVGWJPOTAVBVJRovVY9Ca1AwALcJRXdJ6hTzPUVYVijyHzkkt0wnKB1ksiHfRRffU6hrAgKamu+pqUYGVSzAGlGWRCJS0v4F8GIiqvFiG1v8YFlFaSBmLRQuDUhkpZTiDK07gy1MAgGHUKeKpMxQWRu8whiRXIsOS3bsIBQeAQO6kRZYzhqIsYYJNOUmCg7oluLfCA5ZnEMvHwBiNE/KiQFHkuw4KJotzuHt3zgX/FAblyQxNKhl8QyjrhwzZaGzEOIdtbu8t7iw44jJOnYnFcgEqH6jzkOcaKqMsnrwokMURzfZmIEeLVITEL8E5h2EcSeHkdh2w2BFwjjpJdV1js6Hk4BiOB0ZdkUgapqyi4+d28l3xO9t3Y0wqHKOU9+i5P/nb6AfqXEVbeMof0uTPMinmY4Eeu4V38w6JBUv6HRf45Cc/uVeEAMCzzz6LT37yk3j88ccv3N4Zry7uuRD5xCc+gWvXrr2a2zJjxiOND39wn+h2twslYzg+I8fFBmjt4FIrXocgMFrc6Q40zvido/EFLaQOTdPgCdbSKKKukxR4u92Cebu32DYNFUExFK/IC+ShYGGMoW0p16S2NLpZVAsKOlssoJRE2zbogtmZ4Rm6rocKke6xgMiyDFrnYAwYx+ki5mHzEwAeqlyBKRpjRLJmHDl55wAweI+k8LGBqAnQKCfLMujAC9nnqpEbaz/0wYCtTJ2gxWIJY3b5NE3TYhjGRIiNxyB2eDjnaXyVYYQcWrRtC85FKBgXKIoSmc4gOIfOshCQN4IzymeJnTEiE8vk2Op7GgWNIe9nu92irsnALc9zgAGbuqXuFoLZ3WThjgUZQF0RIei7SYTW4NpKfJcReV5grG/Dw6Pve7RtC2MMirzYN7iTVGxF35QpovdIfode+7RIuCgjZhxHZJlCWRbnpLjpW7yLd8gh/8o6mwr5KaqqglJqDkh9iLgv1cyMGTMIZ2dnyQp+tVrBu69PF8B4obxo9EIXxl2aLiMWZCLpHY52pgqaQ0z5I0+J2/iCPoXCEKSn1HHwHng7tvjD6gpMe4Ysy9B2XVDGOLSsQOG7lGJbFAVs06DnOcz25XD3blGUBZzV4H2NxklIN2AMEtNI4pRSwbISbGwhyhWa+iz4cZBDK+ci2bOTnTrSuMBYC5+tkBc57NmLUMUSMB3gY2CfCCZuu7wZFQy7rKcCJXZiyrIKYZ3kKwv4sJ0hF8gywBMBlgqiATv/Ezq21lo0TYMiEDRpbBNoJoyDC4FtvYV3DrJUyB15gHDO0TR1kA8LKCUhpEQpLFon6fhai37oE0+j6zpayL3F1kkM/ZCM26I3jbEWfughnYXVVPxyxui4HOFF8IG4InS8yfguklwBBq0zKu68o1Ha2OD31BW8R95KwYZFTiMbIWXi6YjQNXHOhXOI7TmxMubABT967se/kTuNL42xUFmGLMsufE4MjYwcKxaKuWMkcO89/vQP/z+R/7//blIDkSkdBSXOHJGHh7kQmTHjPnGRJ8FTf+b/lu7c7nShdIND3w97nY/oq2DMCB66HFMS60XgnJ/jj4zIMI5ngQMQjb08PAdYfoIMPbogqyWnVKBlOaRsIASpJowHcgBy8RhcfZMWskBw7EwGZXoaubBYPAEhfAVlWcAYBd+sUVVVSOjtUdcNcVhy4jcIIeE9eX0QF0JSITGOyE7fQh4Ym5cBAAbAQhGBMhqTxbA8Z8lsS0mRvDf6rgs27UM4jhwiX5DkOKyPXSColoyloo08MxD2yWEcHbKMukyZzoJrLilr6rqG4ByeMSg/YASZf/VDHJlQMJ/KMvQddRp4qGRGoVGVVfwg5JoSkEXgi/i+C7wVCvZz3iVfkLIs0QJgQkFKTp4iQeHjw3hkOgL5fMvw9czD2jg+YUSEHXr0PWW9WEuGeJmqiI+jFOB9Ug11wbIhnttFQeMbPVGnRDDgrkXCZXkeR58TyOF3fV54ryzLjnb3D52SZ7x2mAuRGTPuA3fyJHj7gYfBsQuldz74jexLFI2l1NayLNG23R5RkwuOdy9LPLtRKLJjCacyLPgW3+J6/I/tzpwr3uUzBrxtPMNX1AmMtdDBbTW+dr0hLogKd75aa/IX6cjR1TkHMxpkKqPHMo2+WSOTLrl7xhV8NAZt0wJQcPCwfY2yrBJfBd6j63sURYm+J1Jt9J/IsgxZRrHxAOBUBecctGmw6YPBV1ZC2J4KlXDXraREpjVGLwCpYBnxMFSh946VWD6Gum4og8USKTbKdq31yXtDBHtz53xSkriRTLrILj/aolORl+cF7X+7hmNZ6nblWR4C76gw4VKQKIgzDOOQSKZN01CxU2Uoxg6N1+CCgSw3Ir2VRkKccVTosUVGFujhcc45RPBX4UKAGQNpali12PMNiTk61LHZLfjGGCjv8QVzgqfEbUil0HYdzDjSYs4it8Wja1sgyIcPM2mKjOMLZ8B7r1xcTMTx5bHxTBzheEcdHOssWAjvE0JcOhzvTqPS69evz3k0DxFzITJjxn0gJu8ew1SaexFMuCsVUgKTzA2Axix93wMHXetIYgUuNl2KC4ILMs18eQ3N2c7y23sGxoL0UlaQqKGs3SsiXH4KyQZafDpDd+qMYVQVckckx9GQJXqmMkjGMIoCriXSY/TIkEqiLAu0bQd4QJYnsLbfmx4YY9F1Hdm/ZxrGjIkEuV5vgj15tGaXGPkCjFG2zWa7hQbABRC79x4eoweGULhQQaPR911wF/XIMgUZxghT0iUdO9LUOk+usNbYsA1UII1mhJIKeU4E4b7vUZZhbCGIQ+LrLVi+DMeckoyllOjrPvmkeOdhtrcgF1fQMSL4Nk2NIi8wjEPy6IADpDHwXIBJllxTyR2XQuZYmcFDwDviisQuUVEUGPoeZeBEbEci9xKvlYW8nz5sJw8FK9VRzdmLqE7fQp/HWMqTcd4nFVIMR4x+UfcSjneIu40vnXOomxpD3+9ZwhcFeYnciyng4Wddv379XBfzox/96Gxm9hAxFyIzZtwH7jRP/vQvfwJ//CP/jzu+Pt6VcsbBpEqdAAZqX/dDn9rzUzjr8K5Fjy9u9dGuSARnDN+gt/iffXXwCH3uu2SPL9qcMlvyHNYRP+Da1VPcvHWGjVNw1iZy5gAg8xRkFkcTxFcwUOUKrl5jNIZa7wxJ/eBDW99Yjsx0sEKDsSF0IGiL6PkmkClblCWl71Inwu7LdxmHUtShEFxArB6D90BdbxFD3gAG5neLqwgkWZLH2sCTYBCCJ7Kr9w5SqjQeklLChkweKmgUdYmKIvBb6HVtCKMrS1pMdZaRjBaAdgN4dRL2hSf7fQq+YxCSAvI4Y5RAOxp4D2Q6S4aQvF/D6RV84MdEXw8pJDgLo6z6FlBeQbVYROLKXhwAQqck8x2edwXeKV3i5gCU+ksFik1mbRFfsCf4JhUD96gIKYoC/TCg63swENdGKYWqqiYJxveOi8aXALDdbveKEICK+LZt4eFR8OJSnREhBT72sY8lXtdyucSNGzfmIuQhYy5EZsy4D9xtnnyZ2fdOiUGIBclFuBcz5GjjzsBQnjw+6YowSKmQZRpoPHqWQ/qaFhEh4LzHclnhbL1NUlV6IdB5IM9PoNDDRrJjeNioHBIezDTgXCY1hgdSMFpnHbTvIYoVFKO79zzXGEcT7qjHwBchmWnTtAf7GhQmoUDKMioc+n4IPBHyFInbzRiCjwlDpnVa3GJhQIt1MO3yDMPQByUPEVYjsVMICSkVtts60l+CumYE5yK5kBpjIYWAUgo5d2gtD+nBHlVZwTufvhf6bAcJILMjGEgFY6xBwQs45uCspXRikK/IaAylKnMWwgBZKAp6wPvksJsyjgJ51TrK3um7DnKZ0+gnyyAlbSttj0vSXjpGAMYaTFFxEXlH5KQ67OXSxJFVXdcUTnigpDnkOR0rHI6NL5OS6sj5HouWu3Uej+Hk5GR2UH2d4fK9tBkzZqTk3WO4fv06fuCb73xxvKO0l/M7FjKMMbz3ikM7HJf+xvcoigLvzzZplFGWJRaLBRaLCsMw4N0ZmZpZtaBFC0j5H4AHWxChj/JTgqqHMfSc7ogZWBhY+GTOZWRFi3XgJ5CKgkEqaqfL5RUwBvSeCoco96yqElLSKIfcQsW5tjtj+0UbkV4VGEPIlaH/j9WRlOSZstluMPQ9OKdiw1qD9XoTxiQeztmkgHHOUnpr2KYySDsBj6oqUZVVkPsCSmXkOqsUnCOexDCMwVG1Q/Q+icc1dnjifkkpgW5N+8Q5dZlCpcM4A2McbdMi9106xlJKMnkLIXb90JPF/vYlgB100ML35ayFjzED3uPZkfKPYoYPdZwid4RccLUmtUo83jJwhqKTLrBLmI7dl77vg5MsybH7YcDQbvDsJrtrgu4xxC7hHR+/h6J8ikOJ/YzXB+ZCZMaM+0BM3j0sRu513nwnD4Q7zb6PGTVdBFrYS3zrogdUlZw7u66HEFSoxByShNDal9E0Sgooqcg0TAiYeLfrPbx3afFkjMHnlIEy8uJgZ6nVLoSgsLmQz0KdBJIYN02Dtm3QNA04Fyn5NXY9ouOpEAKZ1jDWQEqRpMB930EIgbIko7fFYhFUO6Q+MsYG3gUpWrTOQgGToyyp8MhzHUIKiV8zDCOGfghcEo66brBen+HsjH7atkGWqZRbAyB5dMRxkpQSOqOQt7zIiRPkkSTS1MEB+q5HWZbEs/CY+JaAFDBB1m2tDfJZGt3ELgtnPDrGp8/1jmz6XViwGecYNy+FjhMZzC2XS2itU1fDBgWXEKQGyoXFb2818jzfy22Jn8Nj543vPEn6kKVTb7eB6+TTMTpm1ncRIr/mjo/fg6pmxusf82hmxoz7REzevd95852kvXci8E1b2+3gLuSKEIchpLRCw8sCwvXIMuoEREWK9xlud0AlDLZ1De9IBuudAYor4O3tNIaRSsJ7gC+uAe1tUq8IjgwZFQzZFZjNrbQQeh8cZLudkRYAyGKBoath7TbWPtBaJ9ks5xxt26Yxkg/+IM5ZtE2LalElFU/XUTCf4CIRbsdxRF33KEvqaEipIAQPUtWecnUYLbhZRt4mxhgsFotAahUoihwxUC6Oj2Lx4JxH1/XIc9ruxkdrcyD6mHCAug6cfE7apiUjOp0lmTDnAo3zUKbDAI88p89UUsJaByFkKF4YCkYJzonDYiwZooF4J1SJCEjBkQfycZ7naNqWvEcC74Yx4ItW4+ttS8TdoAyK4yxrbfBBERiGEQgyaa01uBBQYZ+cpfFRHN04RxLlpmmwXCz2uD3WGDBJacb3QuYGqGtI731+PCMDMfhei/IZr2/M3+KMGa8Ad5o3T4PwLsJFHgjHihTBqbU/DBacMTx1IvGFs+Odk+icGmf7T4nb+II9Rde1ySsi3k0+qQY8ZzQ2220wAjMoyxJSCPSDgctP4JubkJI8ThgYunEAilPkvqcWPoDNdkt8AEgiiQ7EGaA7YAcfjK8YGCAZxPIUgIfy5KJpQ+Q9bT/xPKJ5WCRKMsbp7lyqZB1vrSNVB8iZNWacKCWTAsl7oG1N4kDEBS5+XhZIpgDxVmJXxIexFEC+KE3TJA5KJLpqnaeiiDHsSWHBABEIsPReDkJwtB253AopyE1VlZS/orNQCPSkehmpI2PqlyCX1+A8Ka2cc1R4OCqmyqIE0KNlRUhcZnsFQvQVcd7DbV6GXFwLIzeydo++IpHsG9U9zjlAAJ8bV3ifWsNZS3JbF/dFJDUNFUc7gq+1NiU9p64Mu7uR2fRvoyxLePgLVTOXlfC+ljg0O3ziiSdmUuwFmAuRGTNep5gWKdbYc7HpXHB4nBztisS5/SFkcQLeb5O6IS6q78+Az7oVWHMrvZ4LgbKUaLsBeVFiHCk4re8HeDAoeLRMgw8DAJYknQwMrj6Dyyq0bQMuBPquT3fIZVliGIYg283hR2Cs65QOG8mqVVWirnedFOcdlKJChFJkox+GDmmtAPEy4liqQtPUsIH02ff9pIjYGaEZY5EXlBkjhEDXEb8jOqKCIaT4Alrn6fGYXuy9S0VK1xHhldQtu/GBczZsl0idFRYs/lUuYUEFhTUWwzikRTumACslqUsFKsisdxBMBIKpTwWAV0QKTWMUQTk8e2EBgTtSBh8UKsIsxnEISiY/eSqDYiMGr1KxpZRC13XoHR1P5ynzRmsdXGyRfj8tk/3B+94LhBRYLpYweTHxEeEXkl5fL7jI7PAjH/kInnzyyYe4Za9PzByRGTNeRTwIcpx3/sJwvOvyeMflmNLgG/Q2cAHGxMuo6xrD0COuC7y6kqy6m6aBNQaceXQsB0BcBjOOcN5jCMmonHM0bYN6W1MmSr3FIIl3MArKiomESK0z9ENPnRNHLqGDyOBVia4jl1ZjDLqux3ZbE0G0qrBYVDg5OUGe52SqZkxY+Dt0XYs8zykIsCiwWCxD8JwNShqfSKw70zIq0qL3B0CdEPLCICv0mHKLsDib0QRPEerMRAM2ay1u374NIQROTlZgjIqtRD4NPBApFaUCD0Pg2PhEBPbYkS/NSFyN0YzQWUYGb1oHIxgALGTvSIFMZxiHIS3yDMDLt84wjmPK2CnKcierZYxyauDx+Y4s6JumDVkzOab1AQX67YL+oorFGINMayxXKxRlgaosU3HiQSRW5xxkkBrXm5u4Kd8KHbhPKlNHpekXgXEGlRHxWOcaUqnXdRFyJ7PDZ555Bmdnd+6Svhkxd0RmzHid46JgMADJ1vywK8KP3HFGHkBWXUEXLNOBnanYkwp4bsyIkxBfI+lO3DkLl58iGzcQQmA0JtzlM2yshBlDiBvb5c0wmUOZDoJxlFUJeEq2resGUsWFMRiRQiHXFTLhAmdh917RZCzmtwAMea6DwiaSVmmERZkw9PssIyMyIlHSx0WOR5QCx1EJEUQFhnEMHRi3d9ceFTbex7t5nwicjCHkxjiMY0uZNJaBlSuUjIodYw0FCfZDqm2iTXz8HBpzmHTc4YF+GCCVhBQSAxgKwaCrRVKUWEMqHO/o3yV6NF6jbpq9bS/LEjYoZ/q+h+tvgZdXyBJfydDp6qEUdaWkFKFgIRKrZzzJg2n7BIq8gOACdbf7fSxih2GAznXguZD9fN009HgYGZVFeSlDskcFdzI7fOGFF/D888/P8uEDzB2RGTNeB/CB2zAMA9l1T1QFd5unv6vqzv0u2mDvfYb3eMJSwmi+3M/aIB8JhXf4Grw4pQUjWL3TKIHGCXXd0F12WKREcO2UQerr3c4DxVgDtbqKxqnUeRmGMXExrLGJuwAAo8zRO4GRKTRNi7OzNTabbRp5RG+Rvu+x2Wyw2W7BGLDebIIUlZQbdd1A50R8JaIqBbrtCqxod09FDXlyAH3f0V28d7CWOhXR5EsIGazpWeAuVHsJxnXdwBiDPC/QGBpL0HEDEAigMSU4qlwApLC+6FYag9jKokwyWhekvwtBx41xhqZtsD5bo65r1Ns62MRTt+nwbHHO0fEBKXDGYcBU1RPTnKOaaLlcoigKeE9dka7r0a1v4nn++O58MRZt14ILDq01hCS5dRoJMQYzGhR5nuS6pL5S4IxfSj3zqOFu4XlzuN55zIXIjBmvMu42nrHGYltv0dTNUb+F+wkGiz4iQlC6b2zNCyHwJF4+93rOeYh3p+eNskKe5+j6PnmLSA7I1eMw1qDve2idAR4YOceup79bWDjjycFTLa4GgzBaGJ11dCcPIoSmALvlVSq8sgpxlGKtxTiSpXye54mAaY1B3w9JaTIMffJJGYcRXdeGRXgkhYvOIaUKx4clFUme5+BchLBBs1fA7UYxJPXVOsPpyUlwfLUTkidgrUFrObmuyiKF/HVtm9QdMniJME4jkmpRBb8O8hHJ8wIeHpvNhjhBLippXCrwtpttUvOQSyst7P0wXKgicd5DBmdWKSWF2TGGL1qdzpdoeT8MPbquwzgOJGEehqP27daQZX4cQ9ngpuucg+Ac1WKRvGcQzrHpuRrVM3fDnYr01yPuZnY4h+udx1yIzJjxEHEn/ke8Y7yj+VnwFTlmcBaD7MoQNx+VDvFuOF9dhVJUfJDNt8BqdYJvWhFvQud5snkHdsoVuXw82bkjGGJZIcEXVycFCcIcn2EQFAQjqlM4Z4ObZ1hYAymTc1IFeXi0oPeV1Sm8R1KIxCLBhwRaFqSsMfsl+qQgeGIMwwCt87CP5CBaFAVOT08D30QHE7IBXUfZLlRgaWSZgpAiqEpMSCfm2G5reA8KsLM2yIqDqqmkgpNVJxjHEWMgwhpjw9hDoSgKlFWF5WIZRhc2FYlNSwVo31P+S3SkPTtbo2kabLZ0J51GSpJGNjFfyBoDDw/e3kbbDUdOtuA5IgS9Zjh/Zx4VQruiYVcMHoP3FN6YZVkyzasqKq6GsB93KqPv1u27W5H+esTdzA7ncL3zmAuRGTNeA1zUFbkb/8NYc0fzs0NfkWMg+Spd8ONM/oZ7kYy1gqqDcxHGOTQO+NZThdYpeIT2feCXSMkBBqjV4+TKaqiwiAWIWFwjC3GlwliHMmRGmcMDGGW5C0zDrrgQQiLLMhrXeKCDoqKnXEEUK3DGQhZMzIyhBTIvSMWy3dZo2xZ1XaNrO+S5hgcSZySOXvq+w2a7xWazhcduZEIdlw5KKTRNg6paoMjz4LBaQUmJrmsD/2VMfBtRnoAXK8hyBQZgVHm6Y49Gb87Z1NUZjUHXdjDG4OzsDE3dJKXJ9DxQmQq28btU3dgRsc5BcJEIrfEnkV1jl+FgkWeBnyEuCKeLkt3D10RlEIC98QxjDDw4q8ZjOP3vRcXL+fc/jnsp0l+PeKVmh29GzGTVGTMeIu52RzgtIC4yP5vikLQ6lfEaa5HrHB06WGNxw72I5/PHwcYWZVkk/wvnPJqmBSAgyisYNi+Bh9Y6AGRKYhgtpBTwgkPzHG3bYOQcyjlYvYToN9CaSJMMtMj1TEJ7g4FrCEmSWmssyWIzjfVmjVzrlCzbgRQjuR8BVcLUt+F9jqLI0TQNskynu+5ISiXFy4hhAHKt075YSx4jUrIgdWXgA/lUbDbrZFVOhmoDjBnROYF4iWRCQRRBOeQBppdQmgqEDhKM0WgL3oOHgLvwBSISY2XoYFhBLq+Cc1IJyQIM1K2AJUt9wQW6sQNAnJTpeeKDA1w0mUvOqkG2a62DBXWwImlZcA4hJThjKMoSbdMEozvg2THDU9pC6yzk+7h0jsWwvXEcMdS3kFVX6Hgwyu+5l7HhIVcp4m4uwfdSpF82Z+a1wis1O3yzYS5EZsx4iLhUON4F5mcR773i8Plb+3e7ezJe7zEaA51pMB2C4QYOllUQYvc5NuSYPJUzfL6Ld/UusT9UHCUghxo3ADPIMrIB54yjW5/B5SswZgBPnhdUXACtFyhgYWWJvqsTb0QIQXyT0ZBhVnIxBXqegTOOrDpF5xh8vyWCZFBncM6Cn4ZLBmTODYGsytD3XVpYIxdmJ9F10DqHk1RkDGBguUQfJLujpP3qB/JQgQe0zpJ013sPGb6baAcWizYzmvSZxC/RGMYhGa0ZM6b9V8tTtJstdYe4SOOq+DkMDM47IrUGQqgQAkxQAvJoDZSUGIcxeZZECM5RlGUqSqQQqBYL4nPYAS104qHEgLrpuRA7SnQSUocsxgfcrZCOwXxt2+CPslO8jd8GcG/dvHst0tO/nU+F+p0C9l4rzOF69465EJkx4zXCMafVyP84dud3tzvGYxdeYL8rck7GG6S1Ed+2HPCZTZb+7ZxPXRTnHN5XaHwO12A2L6dCRCqF09MKL986g8mWWEoqOGI8+wgG5R2apsViUaFtiU+hlCJCo1DITA+rKgjWQIX02mg6pjOdyIlc8NA54ODFKdz2Npiu4BiDwJg4Iy7YyUe5L8WzeOxPGqhUiGoWVZ2g9xxeUCdjlEXqZJRFgfV6A60y9P1Ai3sI+euHASerFbq+h5uMHzjnUEJis9kiyxR0RkRQlZHHxmazwWjI9VVKiSIvaGwGkg5XVUXdkFSMcDhvg8LGk9rEe6iMjqMdLWwYmSgpkQVjN845mAeqqkpy2cPzwDlHmTDOwQduTCTATkcqMQqgDF4hveNYLpchzJDvuaseIiq3OOeoqgqdAYqyuLCbd4jLFOnW2AsjEd6IEuE3GuZCZMaMh4jL5MpMcdGF993LEs9udl2TuBjcaaEAgG3vUUgqHjjnwQgMQVpaQS0fg7JNaslLKfHWx6/hqy++jI1VyMw2bUssWEy2wHpzG2VRItMZWaDngedgFFi7hVMLjMM2FT5SElG2qkoUZUFdh6Ca6NoOPCvhnUdVVRjXN8E0Obma5iyROMlW3E26AizwIwS8KiEnTSVenWCz3dD4KHiK+ODfsVot076M4+79oosqyWvJHIxxTp4adU3puYwl2W/XdVSwhN8jmJb1rAfyJRiIv2KjiiT4rZRliaZpknLHWAvmgXEYk7nXOIypY9U0NeABB3I0jaOaQzjv90YzAPCFjuMdfos8L0Luzn6BJaWCUgoKwGc2Gb7z6o7USh2Pdu8ci6nKcZzHOQeDQ5btit674V6L9LtxSRbV4nVtgDZjLkRmzHhNcawrcq/8j4i7XXgxsX0/ulAwhkwpCCkxGoOnlxaf2WRoxmhFziClgAnyzHfyGl9GhVGUyFwbHEGpC/P4Y1fxtRdfpkyYuOALgdECyjsgPwXnBk1TYxyJmBo5D0xkyOwAqypwT5JUGySxjDO0IYk3Ls5Ti3DrLFi5wjgMkGMDUa5o1+IxBcMYAuhkqTCVFZusJHdQlcGFXBow6nZQRgr5bggh0Ae30DzP0XYdtNIYxjEs1BY2ZKrERbGqSlhr0bYduq5HWZXou47C6wQHZwweDB7kDisB+LwCQO6hCio4k1K3qygK1HVNx624AjAgCyMeKSXatk38E0r1ZcHR9PhowwWH1HEcSVLLGPiwgc+WUCpDNGpjYRuIFIy943eIqM6KmTPR1OyY5PcyuFORTgZyBs4QT8Yae7SD8nrnkswgzIXIjBmvA9yN/zHF3Uh871r0+OJWp+Ax532Keo+LU9d1Ia+F8JRo8HlDRDprDXmIBImq1hpfPzT4kiswDANGYyAC76HreyzKHBu/gq9vgjEapRjn0HqHnDHUXqWslpgcG5UdlksUsHDZAra+hSiFVUoiyzTarkWwMw3jBdoXH0YGRVnACI6+78EZxdALKaDDa0UYedT1LuUXCKORIsd6s4EIzqsMbNIJ8HSMGYMzFsMwoshzMMbRBc6J9x7c81Q8GkOurBSYR9tBnZFJSFwYE0hIeL1AdnIVoyFfFtPRMeGMQwiOLBiFLZYLSjAGA9M5rDWBnMqT3TvnPPiRsKSymRaMdN5YtCG0zxiTsnBiF4qUQ2MweqPiRofP01rf8ZyMEuIHjWNFOmMMXRj3xecYM4YR1PltuJeAvRkPF3MhMmPGI4Z4YZVSJPVEavkbmxaiuq6Ptsvbtj0n07TWkgeFXsL1G4zjiCzTIQSuTcZUPj8BGzaw1mKz3abkXQBg1VX4+iaixxfzDL0HCgBicRV2+zKEpDtlxSRUlkFJGRZLnoqEzBNfQSqJ3Odh0Yxhbhl1a6zFYlHBe6AqyXwtZtdYa9E0DRUlihbIxWJJuS6Wui1912M0JkhASdnCOcNobFrMWAilY5xRB4aFhN2gZIndnyjlpddE8zgK0eOMh6A6IpsKz2GshQzqEwTL9cjbiRLd0RhyNq0khmEIah4ybVNSha6SIyJp6ETFAqPrewiAHFStTY6yzjnI4KfCONmuO+eoA+N3+TvhVArb1EHr/FyR8ambLI1nXm1Mi3TvPLb1dq8QjwF7MAZMqnOdkXsN2Jvx8DAXIjNmvMY4Np65DGK6atd1e86UUsikXLkuz/CHfgXbbshZNblmDsmsygTH1Igb9kV8SbwlFSPWmnCnbKCUxLvVgGfHDC5bAt0ZzBhD2aKk11Ax0tyiBZVR8aOqEuN2C7l6HAX6tGjW2xrDxG5cZQXk0GJgGho9FSyZolyaIIOlXBQyU/PwEII6FOMw0P4AEFygKHJYS0mxm+0mZPJ4CC5S+i+AxJ8hnwy+G+1IGUZTxGuwjgo1WqR3CpxxGBPPJibhTjNZqqpErnWwWKdijooQBpeTI2k0rZsGzDmDQGwNIXhqAYAOQzSWi8qcuC8xBbeqKvSMHu+6bscTCkWHVIqKkJCwHIsSIXgg+e7ONbL+l7tMHgALzbDtH06X4Wg30NPxm3ZNIu5G+J7x+sD8Dc2Y8TrGMWUM5wJ9vz1njx2t11WmdhdrxsiMqyfvEMYZnHXUbdB5uPPeLSrvzzb43WFnQT1thwNIxQjyFTC+jJg+SwFpHYbRAOUVsO1NCCGgc02eGEKCjQNqKKC5nR7r+x4ImSbjOMIJDWV6dMjA6i10rtG1bVocpVwEialLhmqUd5LDh1C8yPNQGWXcCL7rWJhg/pVlGYZxQFkUGIJCB8G8S0oBpTK0bewEUU5KpjI478gR1ZDEORwlxDRe6yyNVbIsdEoArXNIKSmITtOxZeUSq4q4KikNmMWvjIi1zsZk3uAlU1YQQx+cZSkDxhpDabSIUu2gihIsBOaRMZrtulRhxOTcYRio8yQELIAvo8ITMh7rGA5I2yYucPa9DIqM4/O3SGZ+vzg2ZjHGplHilEd0r4Z/Mx4+5kJkxoyHgHvpilykjNGZDtwAtucTwsOiGZ//Nn4bX8lP0da3d7k10Z3TWHTokKmMLuBBupkSb0NXZOe7gSCR9XiX6PBFS74bjDF4gLojWkNrje22AVs+Bm1qskUPltwOQA4A1RUM65eSh0frWpjgG2KMQVYtMfQDJIDOA0pROjDJeweMZqRiShKRlVkWlCZUXETSq/QyxM37RIAFGNqmxWq1grEGdV2jLCvoLBip5R6jGdH13V4CMBNs15nxHq1r4dwuPTfyLPq+R1EU6PoebduFY0ShgLLKkZ3QSEZKSYVUKhjDl+gpe8eF5zjvwMorgCeX2EVVpQ6MGRsopeC8gzE747qRjVB6Ba012obC+GKhIoNU2lkLFWW7SiGTHgMvQsgfS+Z2sTDzweOFSKgPb2G/aMwyjiO0zpLL771KhCPOzs6S+dhqtcITTzzxqpmPvZaf9ahgLkRmzDjA6+FCcSdlzGhIoSKlQoyDn/IEpneFAJCXJ6jXN+l9sbuYW2MBtbvL5JyDC4FvKhr8z66CyFfQkizN+37Yuxt9QjT40vIxeNem97XBrn2xKLGt27AoYBLex9HDQwOQy2sYty8jz4lHYewYwtEAhH3qIFHAwMgCosqRCYt6u01jlnjj7pkPC5EGA1mgc86pm5RC7DwYOJyn147jCCkkdKYhpYDzPhmkWUs8ERoZOUjGUw6NCIXZcrWi7Qi5N845rNdnUCrDMIzJMVZWV0OR4eHzKhFITdcT98RSR8cbT88LSh+AAvestYAAepARmZASw9BDCAnrbOoAefLrBwMglo+ByLY2FY+MUZqytZR4PBoDlWXwzsEE3xhWlkFyzCeqFxZ8ZcaQxOtQlgUA/op4IvdrPnYnSa/znpKUL1koPffcc3jmmWfwwgsvpN9dv34dH/nIR/Dkk0+m3z2I68K9ftabDXMhMmPGBK+XC8WdlDEA9joYEZG8Ck8mWt45vANbfLmvpi+EVAo2pKROLeR14DLAezwlbuP33JXkRWFCgFsEYwwMDCMvwEA+HHEMAABKMGyMRImeioYJmdNwAWENxOIavO8TETZWFrGgYgxovEBVVECzRuskWHECbG/tB6mFYsSHEYlSfPdAOFaM8/Dv3cLZDz3KooBHCNaLSpFcw4xjStaVUqJtWuq+hA4B54LMubxIRF8hJFxWwTkPQU0rdEwlP5GhbcEibyPIqruuQ1mU6NDtEVaFFMiLAlsrIYoSKyHCcSTOBg9pvVG9Q8fLp92ryiIFFibHV87ho1x577gEIisCp0dlydckFkNSSghRQEqBvh+ghMAIRWTXS6plXon52P367lyEs7Ozc3/vAPDCCy/gmWeewcc+9jGcnJw8kOvCvX7WmxFz6N2MGQF3u1Ccnd0/wfQYpkF456PO7zBH9/5cAJ5SCn0/oG0adF2Hvu8xDGN6XrW6mkYIkbAYrbqrikYTozHngtKaEUG1oQ/SVTWelMSr8HqFoiS+Aw8yW1JjAC0rJqoepA7OwEhR04sCLl/tZaV4H2LppYSSRFYVy1Oo1VV4AKK6ArG4SseBk4SVmgmkTIkyWbIhL6CUJLJuMCBbLpbgguNkdQLOObabLdq2xWa7Rde1YQzSou06OOfQtk3wMomusw4D1zjrHNaDR205GivhA/+j5wo9U+jYTo5tI5/EA5nKyLMjEF77oSeSaRmO76JCkVMRAgT+jBlRb2s0DaXQWmup2JxyIhiHWD22s7JXiozW5OR+c8L3iUVKNJMDY1gulyQP5pwKW1ARRWZxHn0/YLvdomlqeE/E3KlT7xSUXDwme3wq2ICu7/beH7hckF2U9JbB9K6sSiyqxX05qD7//PPn/t4jXnjhBTz//PMP7LpwL5/1ZsVciMyYEfCwLhTHos6NtXD+eDFijN1L46WWeQfnSKpJqag8OW6+TZ7RmEDtpI0MSGqIMSwkKhQmKhQpTy9JjcE1LU6UjbL7L+DxTUuS3daWFisE3ooPyo5FmUOu3oJULXhaoAQXUJkCdOCaVFfABUeWEYE1+m4AQN91qOsaHh5WFegY5dIgP4GoTsFD4FzsEklJIxdjyFjMGItMa5RFmSSwQ99js9mg63oUZZEKMJL+1tC5Dom/JBVm+QqsOAGvTuE1KVhGmUMur4BVK4jlCdTJFfDFCXE8QkEUk42ddaFrJKmoqGt0XZe+f2NIctx3ffAMIbmu4QL1ljJ5lssl8jyHVBJN20AK4sA458jMLBQZOpPYbrc7NY1zVIiF7z3Kjq0xYJyncwGh2LDWTVJ0iahalhVMKCY4Z7uCchiwrevzxGlD/Ju6rtE2DTbbLS3Y3uPLXYW6rqmzMnF+jeZj9wLGqWilPCF134TUzWZz18cf1HXhXj7rzYq5EJkxI+BhXCj+xDsb9AONJ6SS6S7Rh8XlmEqAC1ps412hDN4JUqo9QyfGGMxoUBYlAIasWKYxRAwj45xDKYl+6FHXdMdd13VSkcRiBKA7Yynp4h8XAO+Bbz0lsyuXBbXNZJvbtsXJagGxfAx5ntPdfkF3sierE2idQZYVLaLFFbRtAyA4ZYKRQiVYv5vRhIVYoYVACxE6JKdgxSntS+DN3D67jX7oUVVlWqCtNXCeCi8XPDSMMRj6AXleTCLtqXvh9QqtV2A5uba2TKJjEiYrMMTZC6ib5ayDCWTOvChSJ4dHngc8spChYw2Zuw0hXyeOP6JceRhConAg0JJJWo9tvcU4jBgH4sNs6y10nqOqKuRFDra4Bu+BIYxfjDEo8jyQXj24EOBByptrTQUWQnqvEInLYlPgIKUTG2PJn6TrQhEaHvfAs/4q2rZF13bk1hrOr6mTr/ce4zCgHwY0m1tEqA7Hvuu6vc7Ia20+tlwu7/r4g7ou3MtnvVkxFyIzZgS81heK5557Dj/zMz8TWt3N3l1idDQ9nL9PZ+HxrpBxdo4vMoWHx/tOqfjQxTIl1zbBHnyM5MqAnXsl5c68P9uA62Xw/LCo6xpnZ2epRV/XNb5pOWmLT7bDA3DW4uqVE5hshV5UwcGzwzpcwKWSUIslmZYtroFVV7BYUpFlRkNcB1BL3zmbCpqyKsHLJdTqKpwu0XqJDhmMKlO4X9t1dNftPYy1yX48knvBiI8jBBFWeXUFyJcYGBVXcnkFg9DoOWWkxEKPi0hg7fYKuO12lwwcpbkeHlIqFEWOtmkmdRp5iBRFgcVygeVygSIvYLMleF4kMqufyHK54BjNiL7vkWUZxmGADyMTqlzDmCWMw4ZA4i2LAkWeY7lcIssytEHqHDdFCAHvfBAFUSdK62xitrYbAjlHxnnd5mbYCyostttt6KKYXRECJHdfIJqk0ZjO+dABmZwvr7X52I0bN3D9+vWjj12/fh03btx4YNeFe/msNyvmQmTGjIDX8kIR587PPfccfv7//n9OvzfWJBOqcRxRFMUdZ+HekZw0ZrQcu6OMF/d36i29xsc8G3qfcRwTX0RKmUY4kTtQFAU8PFR5MlmYgvLGUuS8MSPeXwI+WyJTKhVQWXivzWYD72hhdvlJ4MP0aJo2FT756gQ2jFhqp7A+W8NYg7woEr+FlCsCUuy2VQiBvu8xSo2WCXQQEIurENUVeL3EKHL0TAPeYzQGNji1eu8gqyuQ1VX0LAPLVySBLpfITq8BxQLe72zZyXqdxkJKKbK7D10AOqaAGQ3q7RZlWVDHqiyxWCyoaBhN9GVDrnOcnJzAOou6aVBva2y3NTaGJ/WQd6Sw8diRUON/d2ogoGlboCSTNCkllJRUWIWugw2FAee0/VprLJdLFEWBPBZNosQ70QChaAJoXLPjf7BULzCGlEkU9917j67v6XsYx3Qe+qjoOYbAHU6qrVfZfGzKyYo4OTnBRz7ykXN/99evX8dHP/pRnJycPLDrwr181psVs2pmxoyAeKE4xo5/0BeKOHc+lo5qrIEOd+RgOPocYKc+4IEIOtpxEvu+u3OXghaUru3gUYLJHPX6JoQUxJvATr57COc9OICnOKlosuoK7PplWisZC94efXDgFPA+xyAKFAVD27bkr8E5xphr4y3ABOTqcdjNi3CTO/6uI24IAvE2X14DwDD2JIu1lsy7uOBUAHg6VizbeV4wMGidhQReBEM3hXF9Ey5bgE/CX6UGUJJnCWNk4+6dgxxHKEljFc6JGNl1XfIvYZylDkL0ASEFCpFgxpEUSTE4L9NkjpbrPAW2YY/oSeoVX9D55aVCJiSs7bFj9Ph0PkSQpbsN6iOP05MlNuv13rKf8maCNJsBsFRJkLttS1k+Mts5w2qdpc+LxYZzLnXqvItnTFRcyb0xTLSal+G8ZdjvkDEQxyPa6zPG7kv1cr8S4EM8+eST+NjHPpakucvlEjdu3Eh/7w/yunC3z3qzgvk5EQgAsF6vcXJygrOzM6xWq4e9OTMeIqZ+Aa/WheLXf/3X8cwzz2AYBvyP//E/UNc1fvTv///S42VJxMqLIswPMzemlu888EViocE5x3qzTtLam+ItAIB6fZNGO1HlElr1U8XOYrGA8x6b9Rpa6+S62py9hDzXoQ3vEBN7Oed4zlARtZQ2qEws1pvNTsILAJyyWNDcRFmWAID12ZrGTVLBOgfnLDRAYwbOIYYNlFQoyxJ1U2Po+/Bahs1mDSEksixD1wcpbFj1ijxHnhdo2wZdv1vci7JIviFE3rTJ1TRTioqf4NURXVXNGILpOMft27cDQRfps3hwZ12d0DXEe4/tdotMKWSZhnU2jVXquiaOxoIKLiMElFIYjUFZFhj6gfgeoZiQUoTsnw6ccSxXKzSeKispGFYnJ2gm+ULRbC6SUWPR6MMxlUph6HtqceQneLcagmtvDxHcaut6m84FrXOM4xDGQHTO6cUVvE+tKQUYwHJBRN5+6Hfmec6Rp0lwcVVKQeULPOZfgpIKVVVeuoi4SAJc5AWAXdjf9H2PdUQug9fiuvAo45WsoXNHZMaMA5ycnODpp59+VT8jzpWzLMNTTz2FL3zhC3uPc04OqhddnA99RqKzpGYa3vu0kDJOqarT5161X0vFiLEWRZ4nu+/IawBIJjmakSzSw93vO81X8WX5VgB0l22MSZ2UOGKJNvBbK1Fy6qik2b/3EFLCOwfrARRXYA3JY8uqRFM3ZMGuMozeofdk11YAsNkSq5wFFUcJERZNnedpwemHPhUh1LUhImg/0PNsMIRDUPU456AkGa/x4D+S6QxDP2AcSSHkQaMUnWtonU2s3AXJcmMxQrtHjqxgwWgOyLUGGAtBggqNMfBKAR4QoeszcA4GT8F4gicVDGcM1jkoRTlCfddDhdFX3/dAlkFKjiLPAe+hsgw2cH+iW20clTVNA53nJA+P0l3nIKqreLei77/vu1SwGLMjvTLGMY7EX6IOHeX+GMbAhaDzORxvFyz/zUikYIRCTzCGLKOCWeWUCVQtquTce6+4yOzPGIPNZoMsU4lwfK/+JPeC1+K68GbFXIjMmPEQEOfOL7zwAlarFb7lW74F//EXP47/5f/69ym8LrTxL4Qnkudh8m5CtnOYTCFtB5bw1eoq6vXNJHnt+36vCMl1jiHc/eY6TzJQAChPHocfduFu0zwaAHiX6PG81aitROZayMB5EVLCxUTgYM7VswqQgKlfhtaaSKne7/EFisCzuP3SiwAsHisFXEajgrqukWsND2C72dJ2cOJ0SEVjAzOaxPHIMho9RGMwY00YO9A4gdQh9DupFI1gnEUXxhh5XiSuRdd3e94XjNO4SiqJuq6JCOyoIFBShSJCYJQV5Io6QUP4/kjR5OGdA885tNYoyiI4uFKxU5QFvPMQUmBrFaoyBwOgQofFGEMmbUEVFIkdbcia8cEqnxKNyZMFQJBLU/+k7wdorVPR0bUdcWsCZ0ipDFpnaJoaqsxQb7e0f0oh02QGp3OdOl1TnxLvHI1gGMNytbx0EQIcN/vz3pNJn/fI9G7+Fv1JFtXi0p8z47XDTFadMeMh4JC4lmUZrl27BqUUqqq6YxFijUXbtntqjUNPhmlREIsEEczMAOqKAFSMCCmJFFuWybAsGpx5T0ZrSpGLps413uVfAgBwvQBjHCz4eEzJi8YYvLegBXrgBcqqojEQkIqhOC6AJ3krK6+GO9cw62BIklYuqDtTXrmK1WOP46XGYj2w1JWpmwac8eCBQmTWOHKKCyHnDMPQo25q9CGt1wTzrmi4FdUuLO7HGAi2obtAN/jkpRGNx1RGC7bKFIq8QFWVxMeJ+ylk+owGGVCe0sIpFXqwEG7nktol5sd478nArOuwrbdYrzdomhYeHhtLmSpaa5RVlYzJ4hhnW9dou46KmvC8vCggJuoqa8gp9l2iD90f6gAxhsDJsUCQUC8WVTC0q5DnNKJhh1JxYzD0PVnl90NSdeV5jjzPyadGKbLiD+Tj+8ExNkGUG3NO3aipFN5Zh28ovnRfnzXjtcHcEZkx4yHhOHFtiX/3uYtfk9rSYYFJssigttE62+smeOd38SUOe/k0b8UtfBVX4SABb5IC5BistciyDIwxVIsFvgUdfqctUJ48BtutAWBPtSMEh/ce71Yjnh0zdNAoyx2RkYVRRdM01LHxFuASo1xArSqw7ow6GFJASYWmqRNfkwuOxdVrcN6jvvkyxCILn98FozUEy3gPwWNgn4UQEkqRUZi1Fs46ZCpLxw/YLXKxy+ScAxccxlg451GULMlbpRBYLBZBnupSx8UGa/VMZTBqQfbq4SdbLDGMA6yxyDL6LmwoHgTjyRGVc462afeOafQ5aVkBxoCqoK4FZwwWZEjn/C5XJi8K9H2PbtLpIgt76qLYbAnAI89zZFkGH4ofKt4MhmHEODYh5I4Fp9oyHFo/Vd2mYzeMI1QIHxz6AQgkWM75HhnaDA6fu8Xxrqq7NNH0mMTXwweysYfNLNqupc5inmMcxze1WdijgLkQmTHjIeLY3PnDH8SFybyxLR07HAjt6PhYznOUgVsyJfQppdAZWqiFlBBMgAuOpwqDZzcqdUoOwcIddCwcpni/MvjcuILIV+g2N9NipxQZn9Hd9Y4z0rEc2rUYx5E6BBNrcA+AOYPlaoVN3cKXV1AKAzNSEm7MtgF27faqrJAtl9hutlDeoeM5+CKHWb9EuSsxCBBUgDnvqHshJcbRgHGWvEBoZ6le46EgcBNb9uh7QcXQ7lhxzsD57jL6UmPpucgQs3Nc6FRFgmpeEH+i73tIIVHkObynURF5rDRYLBapW+McES8ZZ/AljVJOlgvY0O3hsRsVxm+csRTSF4u+yKe11qLvOvh8BeaB92gbfEFi94tGUm3bpv10LhYdPhFto+W7ABUG8Ryc6peisVlVVftFiDEwfQuelWgbCk28DJfjMPiOxjJUhEgpk53+tDh/M5uFPQqYC5EZMx4hTNvSnHGwgwReSmgV5wh9kcwab2MzlQVpLcN7rzh8/pZId/NTMABZaKVPIYRAURT4jsri07d4UvnEnJPtdoNIaIzFCAA8NxZAUcB3Z3tjgkhiZYzhZLXA2XqDjZUAE/CmCZ8pgbCf8Q44yzSybEA/0F1/Dga5eoyKgfomvHPIMuJswPtkH980TSAEZyjKkqSmnrgxylqyWj+4Q890lhxah5HIlre6yFWgKmZ57TFsNpswoqCukB3HYJ1uoST5j3DBA0mWJffV9Wad9jPxTnyUuwZ5r/cAKMNlDDwWgCS0gnNY5+BBdv5d3+8s/TlPjrcuW4J54O1uC2tV8iOJ4xJS5rRpdBJ/T6MuGqONo9kbxSWXNrYT68buV/QwAfZdV6fDxymX426dkcPgu2Qap8jaP1rnA7vi/M1sFvYoYC5EZsx4HeLDHzw52hU5LAgOSaIxTfUYoW9KZs2y83HpQldAH+SfwfCM/Cd44l+kSPnw2DiOeI9Y4ws4gWnOEIPriGthd2TagPdoi98bJHx+At/cSrwIIUgy2/UUAAfvIDiH8QCrrsKuX4JzA2WrhDGIdx7gHkVZUNYMyFhLCIFxuw2KFMACYMMWvemo8xK6K0VRoO96eE/ZPmYk59KqqmCNhXWWuhDeI881pFLY1lv4/ATMMXgflBlFASGIf9MHjkQeiKxxO1k4/lrnGFqyz++6LnQLGAQXyPM8dRKmSiSeihAAcPGLhw0W6XE8U5Ql2rbdK+7c5PgzxqCCSud9JeBckcZU0byMczIui6MUIdjeOZY6IYKnLCBg5w8ig5GakCIVzVOCdJRzH0PMmlH8uG/O3rkagu+MNTTmchm88+i67iAIkOFt3WdwcvK/3vU9DzGV665WKzzxxBN3lOte9vkzdnhDFCKf+MQn8G//7b/Fb/3WbxGz/vbth71JM2a8KjhsS08xdaa8mz3Q4ePUFeGQukLOyPOha1uMgbgJ7LogU5IhKVJGgAGyOEG3uQlrLZl2od/v4HCBsizwzbnH76xHiPIKsnELxjlsCElzzsFI8gOxxsA7A5VlQOhyaNsAjLoRTdsAYFBSBvt5GlkNGCBCHk7bdpDWwGQLQAVHWQwoqxJDP9BCZi3KKig8QviczjSEFIipwS0yGADIc+qKSAljyDK+FJK8S0LWTFzY87zAEH07QicHCCF0UsKCAvGMsRj6PiT8UpHIhUjeJd5hrwiRQXnEOCcZtDHgSkEKgSLPsdluiZcRJLPRh4UXp2BgeCdqNA11N5wjf5LFYpFcVCMB+VhsQOSQ5HkOwzV1bDgniW4gHxtjkOs8jd6mYz93yfPyTmCcpaKlr/t0bKYdQsYY3vZ1b7vn94x47rnnjhqYfeQjH8GTTz75ip8/Yx9vCNXMMAz4wR/8QfzIj/zIw96UGTMeGI4ZMMW29KGq5tCZ8m6ZHccef+8VWuiMF7SABq+NCGtJrRPvhKPSw3uPG+5FAEC+vArnPNq2RZZlqKpFUOSQ6kIIAe8d3ptT98KoirgMdtc9ifblMU1XKYVMUhZMJwp0vCDXViGRZYrIn9bCBx8OgEZRfUehd9A5rJDoGXU3aq8wiBK+OIFcXINYUHCbkgqLxQK8uopRVWih0TiFFuQdYrjAAAZZVRiHMaQdC7RdSz4sk2M1mhFD34dxznkVE0CEXiE4yYIZ8SqiLHi73UJlFCroi1NMi5C42EshgMDPGMcxcUJ4NKgLx9JYC16cAozhHb6e5NfsxidtyBWiYo5yZo6dI5zzpKRiYPimosFyscDpyQmqkszzsiyjIiR0p+LoJ3a/YsLzsTP0frJmYnEeX885h+DUsRNSXHosE+MXDhN3X3jhBTzzzDOUIvwKnj/jPN4QhchP/dRP4cd+7MfwLd/yLQ97U2bMeKA4VozEtvSdMmimF+dD3CnT471XiGPAs/Lo49PWepTFxs89LEaiLTgl9cqgvqA7bu89vp61gAd4cUpFjffJrhuTO+8hSG3hLaJXqCtO0PIC8EDfUTfBjDuXVwSZrTWhYwNaCDvv0TkikLI8h5UKVqpd8REM4fTqBKpagBcl1GKJgdPiLoOMOea/iGCfT5kpbmL1DuomMZ62R0oJa01aLLOMjMMYZ8nzROc52cmPI7qug8tPcLKsUJUlFlUFrTWsMck6P3ZEttstztZr4qcMQ+L2KKWQrR4HALxbUfHEuQjdEJcUQNY6CEFdHCAmM+8TRzkXKIoS1hpwTeTPcRwxhGyZru/ou5oUITHh2YSOV9O2SXoevUfu5by8E+5WnF92PBLjF47hhRdewPPPP/+Knj/jPN4Qo5n7QR8CmiLW6/VD3JoZMy6HaVv6osenhL6Ie8n0eFfV4bmtvvDx2F53wb0zz/OU3vt+bPC5cYVidQ2am1R8TBHvkq21uO7XABheqK5CAOjPvgaETogQAoJzdNZCSQkW7OgBSvS13qNhOcQyg928BM98WJht4jUknoJzKXWX/u0hJS2QjDO4cKcvBI09tPeJH0OdCiLKYtL3EEJQtwNkoAZPTqWZUhj9CBa2R3ABJhmUytAGkiwXZFhWb7fgPDq0AiwLPiWLa3CMQTCSxJLcmMYx5JWBiQma2+soxZGIlBK8vAIG4KncgjGZ1EDO7fYlFhzeOzhHnZo+2Oe7YLUfHWM5F+n5T4nbCC/EaAyKPHJ1kFKOY5clElSj3XwcA00l55fNmtk7pyackV2oo8Rf/mOnl36vu0l9Dx+/7PNnnMcboiNyP/jpn/5pnJycpJ93vvOdD3uTZsw4ivvNyLiXzskxMMbwNn4bqjgueYwz/+ns31qLYSD1SjQ8G/z5QimqR+JYguDxTpBLqz55C5RSwWwsxMdHP48wckAkYDqL5YI6N2L5GOTy8ZCv4unu+By/gUi8pOQgMy8REocpxZgKHKUUxoFyXjjjYJxydKiwIVKl1jqYju1cST18Krw4o3walalgDa/BGFBWFVarFTKVhYWdLNF3hmYADyRbJUiSK8K4AyDpa1TMxNDBcRxTPlAcZ43GECHYe7wTDbnaBhUPfcfhu+QCQpB9u7UW2+0GXdeDc1LydF2HruvQ9x2apkHTNGBZde57jdt4bLRySFBljJFKiexJoJTaOy+98yGdeSA7+olz7Z0QDdSoA6fuu6i5m9T38PHLPn/GebxuC5G/83f+Trqruejnd3/3d+/7/T/+8Y/j7Ows/Xz5y19+gFs/Y8aDxUXFyN0u2vdzcZ6OdVSxJAVNmOtH5UzsMGRKYegjR4MWYDDgXf4leO+x7XfbY4wNi1pPBNEyuK2GUc0TrCXFRnUVPlsm5QalwrrEf6AdY2k1lZIjcijE8jHwxTWyQY9yZEbZMM5aIjDG7ocU4KG4AIgkWpQF8iLa61PR1Pc9MpUhU1myb8/zHEVewDm7k7mCRiwe1BkhWSv9nvg2LDmgRlmrykhhJIWEWD2OQVVh90jxEpVEdV1DSBncTUuURYEsFiETDw/nPQTn0CeUJfR2u6GiyTkMwxjMxUSyuid/GBPGRnHkZiZ8oAOFiyKZ9necWlRVhSI48eZFkUYubXD7jZbzxwioYUgHwYnnEs9Layy29RZN3aBtWtR1g229TR231wIxfuEYrl+/fo5zctnnzziP1+1o5m/8jb+Bv/pX/+odn/NK2Mha013KjBmPKi5KIH2lIV9xrPN2rPGH4wpZvkBb34azLpluxfm/ECIF5gkhki085xxPsK/hS+It2PZALiw2mw3GSXot4FEUZSJIMsbxTZLe7/d6iWz5GCR6jKG977EzWIP3YFJiHIb0d2yNAeMczgO+vALLGFh7O0hig3bFezCQ82z0CimLEt45dH2HtmnBhYAPCpxc5yGXhUy/oqnZaAwypZAXBbQm2agZiRiqGIPWVPi1XZsW+OT0GcLkxnFEkRfoRYU49smzLKXVWmvB8xw2mIjJCYE3jmSmeTIAdRuscxAA3l96eL8MRnQM4zikosR7BCt3copljKEJ5mKxTLDWJKKpD/wdBo/3sFuwdpG6NM451JPU33R+hmImz/M7n29RGnxBmN1lPEYeBGL8wjEVzEc/+tFznJPLPn/GebxuC5HHH38cjz/++MPejBkzXjeYeou82hftONZ5jx3we5sMeXWCod0mpYO1JHONRlc8mmn5yYLPGL5Bb/HZfoHW8FSEEDysdWjbJtjOu6TI6Loe71IWzxmNFhqs1BDN7ZCNguAyyhOxM9rP87DgidBJuX22gS8o14WNX6PFF8RRyDKNpqmp2MhzCqgLvAUVOBwx0yfLMrRNGxJ3ZTgGHv3QJ6kuYwxFWSRSalQWlUVJ3AhOnZfRjBjkLoBttAzLRZFUQvAeXJBqqQkhe0VRYBgGDMOw488Eu3URi6ZAXGUA1PIxPMFbWJuB8+jn4RO5OHZjgCjVJeO5+G/AY9rEiM6renEFN+yLMEByx42dlIu8QaJC55hZHrBPUD3mfZO24RIeIw8Cx+MXblxYVFz2+TP28botRC6D3//938fNmzfx+7//+7DW4rd+67cAAO95z3uwWMypizPeOIjFyGtx0WacwVvgbfw2/sidIiuWGNsd8S4m1ALYEUPj3S12xcg35jX+j65EvryKbnOTtnEyOtGaYxyDORjfBehFN9Znxwy8OEXudt2K0ZgdtyKMhaI/R7GkcVJV5rDOoetHqJO3kEeHrdOdOmWyCMAjkSc5p4RYcJGC/oQQybuEHmNpxOM8KYP6gcjv3nmUVZneTypJ6h4gVEFAke/SYYuigDEGTdPAml1OTpZlOD05ARjDdrvdFQ7B6Mwag7ZpsFguybLdexgAorxCKb1FAWsdpBQYRyQF0872nd5HCGAcLZyzyHOdTOiE4LCWvlORLyGwU0VFRPv2u3qDhP2MhNUppgTVy3rfvNo4Fr/wIJ8/Y4c3RCHykz/5k/iX//Jfpn9/+7d/OwDgP/yH/4A/9af+1EPaqhkzXh18+IMneObXX7zjc7z38M4nFcFlg8Wm7wPsipFzj4O6J1OXzQgRzKUA4N24iWdx9aAYcYG0KqBUllQWMTQuFjfvkx6fbxmGsKD7/iyYqDFkSoFrDRY+L45wlBCoQiBdnpOEd9u0GEQFLwDlzuCcTaF3KipyGG1XVNdYNyGSAskkK44swKhgc5YkvVJItKyAV7TfI2Mo8+zoIiqCMqiu610REmDGEbUxKEsqavxkBOODQZkN21QtFiThtXQ5/+YVJRjnuUgdCR86NaQUpOSZ2MmSktxUKUOmT8deSgmvSsDvFyHRNTV2Qg5zijyQyLPhEEEGfosNBGTOGIxneyPE+/G+mfHGwBuiEPnFX/xF/OIv/uLD3owZM14z3PWi7IFtvX3F/JHp57yN38YfFad7XRHvHHIdvD4mhEIpRLrDVqHD8S73Er7IHjvXGQGoAxAVJ3lOhl7TUc4NRQvZ76wtkK8gNWC2L9O4IqCqKpjA3aD3dujaljgXzoEzkqDqPMcm7NvgPYRrkwEXC3br1pJZGXU+IrWSuiA735Awhso92OIqqW4CfyV2PURwO23DdkQIzlGUZRqnxNFKPOaxcxDt3l2wa48uqfEYIyzqXCkw5/FtVw/5GCLZxU8VM0kGHYLzAPISiRySLNPoLOXTfL39aiqChBR7rqnOe6iQTxOLnvh+sTCL46CYwhthhv3i9V5dg++Ew+L77OxsHo88AnhDFCIzZrzZ8APfrPD//dQFF23Oj45u7oc/cmxxUGFEE0cowzhC53kaZQC06JkxWobvQtPeZfaLEaXkXhHiHHFEIm8hjncYY2jbDu/NBcZxwBeNhlxcg9m+jPAhYJxDha7IGNxC4/ZwzpEpRd4nxuDqlRM0dY1uGNHyAnJVpIXabl+GFALWWArLC8eBFm2TlEli9RgAho4aDLhysqTxTDhOgnOyxI/dGbPzuBCSsmmG4A0iJ9JkTAqRmCnDhYCMxUAMkIs+It5jvavHDs4FFkzIbCg+WOK2xuJhmmtjjEFRlGgN7dQ3ly3GsUjHEEAq2gDi6/Cwn03TJJdb530KYGyaBnkwNovv0Q7Hx4pa69Rd8tHrhDHokCh9JxyStz/9y5/A7802648E5kJkxoxHECcnJ/g/vetl/O9fzM51PXKdo2mao6+7LH/k0BgtjmhUsYQWYeEOHiJKSoxmTOqaOMLIUu5LCzCG97hb+D1/JZie2b27ZCJU7kYze9vudsTQd6KB9x5/sCDPDWmbxH9QQWrchwC92EEAY+AIScRBnaIEhwnZOJT34iEW1+DDZ1vGUDsPFOS4yicjlizIeM04knRZiL0U4lhsAEhdC+c9rDEw40jbxYiTYqzddUQCaTeqg6SUKfOHAvsAYy0Zp40jGkvH5NuuHVenxNwbIXggqpJJ2TiOe2MYgHxFOkvH6ylxG9bSdxpN4uTEmn1q3y6lTC6qTu0iALquo6yetoE66IjESAEAiRjMOScFUvBJkVJASgXsaDVHcRF5O9qsf+xjH5s7I69jzIXIjBmPKJ588klcu3aGf/M7456bZJSHXoTLkv4OXSvfzQZ8casxOoYi42n2770PPAN/zl0ToNHJGBbhb0KD/9lV6J1AX9coy6gcOX6nDOzGCXHhNMbgHb7GH/AFjCwBCUi/psXdk6upAaAmniMu/N5Fk7Sw6DdNA601Mk3jDqUUhnGksVJIGVZKTUitIeU4FCHhwFJA3wUw1qJtmr0RTeSmpO+EsXTcdmqcEmia5J4KhMyZPKcuSwa8JzNwbmeoNgXnNPrabDYhFM5gHIfJ4xxa5zBmBNdLeHi8V5ylbc51jg4drAnFEufgjCHTOnVuomrqogKY0owdhHPowsTNjGNwrAWatgFnlEhsrAEYjXaok8Pv2sm7E3k72qzPRNLXL+ZCZMaMRxgnJyeQ4nYqEqw158iDh7gf0t+hpXxM6wWw13I/hshDiP/1wRr+KXEbX7CngCpR11sURUEhb94f3cY4rqFxi02jm28sGIxx+ELHgfyE/EYceWLEoiMdk+lIIRYsnsL9uq5Ln7WoKphQiJhAGo1GZMnh9cj27e136H5Ecul0VBTJtd57ZMEHJXYBfBhr5FqjHwbY8PmRiCuEgDGG+DH5Cd6tBjgXrOH58Us6HVOE0UseOiA+8FEchqGHLKhj8B52C8nrMti360yDaZYKt2jbPs2UwV0KXO896roGz0q8jd9GXe86eM46cCWpCDk4ht77u3by7lZczzbrr2/MhciMGY8wnnvuOXzuf3sGb/vQD6ffxQTUKZEzPXafwWLHQMUIUGQXFyEx2XXqYTElPL6H3wrFSAUTOjlkm27PxdBzTm16KVUoaBwAhrZt0PcD3h6e9we8wiBKSNmnALaEMDIBqBAYh4EW12mXQkqYEGvvA6eEbOlF6pAwIMmVYwIxjymzntxuY9ieBxUpcVTEOYdUKo0gfPAKKYoicUKstThbryGFQKY1mmgM5hw2mw0VZYtrwf6eOiGxmxRt9MmojKdOUxzDWOtgzLhHLs5XVwEA31Q06IeD7zMcAw9AHzmvohyabOzZ0aIgHuPDMMXIW5JSXFhMeOy8aS7C3Yrr2Wb99Y3XrcX7jBkz7oxp/Pinf/kT6fdE1hyhsv27x3sJvLsfXEQ8nIadAbSgRBJr13UQQYFyw79IREmWYbvdQAY58Dia5IjKuUBZFuCcgXPqjEhJPJDD7sQ7XE128eUVyOW1PefRyGUYxhF5nofIeJ54JEpKZFrDWYtca9jgTRJ5MLHA29Y1ttstucUOA3RGgXbjOGK73WK9Xieb86Hv6TMCCTXyIKJk14fCZVvXaOoaxlp0PRF26TiM0FpDSYmu68BjEQLgHb5ODqjeU5hntNFv2xZNQ9sA7I6BtQZ5nkMG9VS+pCLk/dkmObgew0WdIHpP4pBkoRiZgjpZOyLz2/jt/fPEkjT5omIiSqnvVGzcKW16tll//WPuiMyY8YjiMH7807/8CXzgL/0EACLvKbnLhon8EcbZA/EXiYgjmnZw5zojMaAtIYxdPED8i5B1oqTCjfFFfJE9Br24im57E0pliSORZQpCyD1lTSS1GrMjXE7vmI0xeG9F1vGfY6fwABbCJK+RWBwVRUGvj10O0DgnbWcYjSilUheDgaSzfiKLbZoGRVFgs90CCMv+pHMSiZh931NGzDAku/pca8jJQi2DbX6U6rpQvDjvoZaPxUOJd/otwEhpQvJpg3Gk71VKQXby4wjnLPq+ozC/cWcvn2UaWjM4xvD0coCUVVLAHJqPidCZadsWF8F7j6osiUw78UWJfBbjxbkiBJgUGJ7kvtPxDA/f7d06eRelTc82648G5kJkxoxHFHebe3v4ZNgV8Wrk00z5IhGxCIkLknOOPDqkJN4EaMGP9uzWWtzgL+J5/jgVI5uX4ZxNqptYhJC1fHBFDWZocfxA3ZH99r3WGt9e0CmsGAAAQk5JREFU0n791s0OGIBTTd4edehgWGOS3DQWCXlRpMdkGNVIpTD0PcltY2hcHOuEBTM6vUZCalxkpRDQeU7y3lDkJPv2vkc/DFQAAci1RlEUZD4WCyJehELJ4x1uC61zKFWF/fWJSBuLsRgwmGUa1ho4Rx4hUTFDx9KA6yW+/cRAyt15csx8LFm0H45HGCNlUth3xhi5rU64OUKIQFA9PlqJxegwDMiDbb8JXCchJYQU99TJOyRV/+iP/uhss/6IYC5EZsx4RHFs7j3tihy2sl/NfJopXySOZKZGWj58PkCW6Sa08uPiFRe6d7qv4svyrciX12DadXj9jvvQNC2EoNEGZaDQHT6NXEoMQ586QFlIto0dlG9ccPwfG4fbnYf3HMy51P0ASCGCvodUitQwgYjpwvOAsJQ6B12WKecmqnT4YkGFw8Fi7YJ6p5zY1wPkZDoE3xEx6bA472GHATJwQMjyDXiX7DEMA4qiRN/36PsOQsig6JFB+WJCrUC8jizT6RgDmCicHAav0rE7xEUE5L3MGMZoXNR3JNkO0t5IXtXBWK4dyLTtulrjMMwXoEI4Jjtba0IXbydllpfo2E1J1bNK5tHBzBGZMeMRxUXx45/+5U8cbWXfSz7NK0U7uGT97b0/12WJnZFc63TnnTwshIAUAjfci3jCfg2yXIHrZcpFiTwEInlakOojyGiNQde1ySpeShrnWGtR1zWapkbbtnhS9nhv4XFD9HB6BVFdTYtuGn8oIsNKpUKejIcO21uWJZarFYZxTO6iManXg4oZHkYyh/sNAJlSUFIi1zrl9FhLFvSiukrbU5xClFfAALzDb3GDt3hfSWMipRS6rsU4DokkG9+Dxi8ZACKwkjW9xTiaSeoxSyZyAPCdV+9dyh3HNsk7RIhdESJl2udIXnXOoR0c3nuFfsqiPMfjmPKWGCefEpUpZFojmxyjcRxp/DSOyVBuxhsHc0dkxoxHFHeKH/9fnhzx31886Ii8yqFiT51YfP6MpKVRIZPrHJ3vMEy4IoLTWKPrOhofZVmSpHpy7YIUAu9ht/Csv4reCSggKT+i2mMXnEePGWOR5ywRWwGgado0ihAidiM8nLO4wVsYY5MpGkC28ZGbEdNwy6JIUtxoKubCSCmOU2J3J5JSGefAgRInBvMNwwAUJzAeYGWBSCl+u10DCN0VzrBYLGCMhtZkec+5gBAyyYyjJJfGVqSGyXMVFDR+YlTWg3OGMfh2CMGx7e/vu56ObWzYl5gcHGXKDADPSnQGeN/EtOxwdDLlLV2EV2OUOOP1h7kQmTHjEcad4sf/+4tne8+djmqkFGmkEB087+Y/cifEBePrmMNX+CmM2SQCqdY6GZ0BCGm1A41PVIamaYg7Enw6Ivk0kxLfXhn81lph23voWBxMEIPzKFOFhTwTFjoyO1tzpWTqpBQFkTilVAA83uFrAMAfsApycQ0jY4AAhO+QaU1W7F1H7qaMoQjqFwEao7gg7TXGJJMx6vxwCuBTigilLIfPc1gA8MA3LjjOzm5HV/eJuoftjYW22xpaayLKsiCF9TEzhoMxn4oX56gD5H3sfiiUJfmzNE0Dxji0zgDwS3VDpojdIxtGU9PvhDGGcnUFgMcTeQszij0y9KEfzZ3wSkaJH/7gzAt5lDAXIjNmPGI4OztLhcdqtcITTzxxdB7+4Q+e4Jf++64YkUImp9PkYBmgpILWxy3C74ZjC0a1uop6fZPIqqHQMcaAi8A98B4qUxj6gToEQRobRwac8yAxlfjOqx6fusnQO3GUtwDQR2SZRte1qbjaKWNKtG2bOik2jBJ2CyixMN7ha0gpkGUaX+g4pf1ywDiHYdwQX4PtEnDj+CaapiGQRauqIv5HSAsGAAPgvTll1dD+7Ui2O15HVP6QrbtzHuNowtilD2OXaecqhN8FuXPsEJFHywjO6fd9PwTzNyrcmnGXN3OIZD43IZoeO+YxkfiwMCyXVwAPXLVfg3UV+rq/7w7GnUaJnDFyh01OtPev/LoXHPubm0mwDw5zITJjxiOE55577ugo5qJgr2kxwjhDXuTYrDfnJJJgQNu1WIjLE1YPF4yv47fxFXeaihEfrNS11mTKBaSU17omS3APoA9GWSxsq8qyNLaIxYgTOZQKJNEQ4OZDHkvfd5hG3jPGMAbPkuliOo6kzqAREg/v5UMmSw5rLb5pRVwLay1u317jhZO3pNdbBuiTKoxkAOWRpL+MMXQAfPi4d6sBnAsURR5cY1UqQKI/CBBdVXf7orUOo6gdQVRrnoooa13iahhjg109Q98PsI6yc7bbOmyVSQVe5LI8vRwA7Hcmkvmcc0kJA4B4Gwc5MdGgTkgKBwSo+PQArgxfgchUUtjcSwfjmKT8olGhCjLqfhggOB2DV3Ncc9m/uRmXx1yIzJjxiGBqYDbF3YK9psVI7BYoqeDhKdo+Sk8vGYgXcWzBSMVIRd4UIixsKRAuLK5UdPBz7f3wxnvvGUcJn8IphHdoz15O6goqLEgNQs0JA6Vk6IyYtOBPP0MICSkBznVYZFn6b9M0oRtAJcZ1s957fVkWGIYBDCxlwCilsFwuE9mVCokKxEkhl1MpVZIiSynRNA2kVGn7YqdlGEbkOU/HLEqVqVOk0bYdnLPpc4QQUEqhbWNHiOP09DSQZH0qhpzI8ZS4DecPHE6j+ZxzSQkTCwzGGLTWKMsyEYtdsOmPOTR5SefdleErVNAFBU96/zucWxfxQPIjHTopRermKbl7rweh/DqG+/2bm3E5zIXIjBmPCA4NzKa412CvWAhc5FJ5P4TVC98LAGQOwWi0cGiQpbVOPhzH3DgvGgm8T9X43WGJ8uQx+GGbeCDGGAjBE3Eydhec2+cxZFlGnYOwPUrJlKFCBUUWChoG73cFVNgyYGJgRmZiIxhDksmS+6tMniduolmNAXNR8bNYLLDdbtG21LUxZkzur7sEWpnGN8aYxHMBWEjQjdLmOhR9KuxjR4ZsgcNSrB6LB/ccHygqneRBEQIg2dy3bZsKSx7GbaMxKKpTAMA7dQ2rKlhnMYwDONv//o6dW3figXRdB5UpjMPEFI+x5DFyLtsnFDv/lz/22LnPuV88iL+5GXfHLN+dMeMRwd0MzO70eCTv3S2T434C8S6y134bvw0GYPRirwgBaOHrug5lcDY93IYsyGUPERfMp8RtyiBRFbwsQ+FA2TMRkcBJcfUSUopgDS/T9kyLMrJaN3udm+hAGoudw+PUdT3atkHTtLB2V1BFz5NpEeKcR9d12GzW6Loem80abdtisVjg5OQEi0WF5XKVxkYRnDPkORF+YyZNNItr2xZ13VBonZSJxNq2LYZhhHMu/d57j/fwW8iUSmOdtG2hSGCM7RUhx449gHBMBVS+gAd1wDw82q6FGcdky374vR5iOtaLYXrW7QISD8+tNLqZ+LFM8UqVX4d4JX9zM+4dcyEyY8YjgrsFd93t8Q9/8OSOmRz3G4gX7bWPeUS8a9Ff+DrnyAQrenTEH601qrI83hGZLDTvYbdww71I/1DRj+T8iEcIek+lsqQ4iY9PDcbiIrbrGnFE19Isy1IRI5VCltH7jeMQQgZV4IHQohot6CPI24Rky+RxwjEMI7quRdM0UEohz3PkuT5nXkpy5PJcvk7c7tgRieTRSIClY0y/L1bX0naJA74HgNQhudtCHo9/9BQBJtkxnmIFjhUJF51b8fOcpyC+0VCBRf8lU7lFtUBZlSjKApmi0MPDbkvE/RTSd8Ir/ZubcW+YRzMzZjwiiAZmx1rF9xrsdVEmxysNxLvII2IMzqeqWGJsj989LhaLe1JqANgbKcSslhtuZw0PAO365dTpiJ4iQoidbbmziT8yXbjiOIj4GAXGkTwyuq6DEDx0RgCAXFuttSjLKnVQyOE0KlsmHiKBuzEMQyoy8lyjLAs0TYu+71AURXKCnbqfRmLr1OI+FjgxUyaOcIyx6Xl0/Oh7iCOZJ+zXwNTxS37scBxbyKMvSrSlp/3wsEyBMaAsS3jQd6d1jrZr7/nciscu2uxP4byHdXF8RnwQ7zyEHI6qabjg+IFvvhy/6W54EH9zM+6OuSMyY8Yjgmhgduimeplgrw9/8CQVDfEus6xKLKrFK1IcHKoeolEVY+xo0FkED4u/Ugo6y6CU2itCYvpsPwwYxzERXwEalMSOxg33It7NbgIAitU1LJcLFEWJPNew1iZn0dhViB4dsYtAdvGknhmGEev1Gn0/AGChU6OCgkUm+fM4jrDWwBj6LxmOhW0Ld+zRgGwn0SVESS6pY3zaRuf8nvsp8Vem4yaXRhjjMKRu0rR+iD4f+fIaqtPHAQDv8i+FY0ZDk+kxdUHVFAMAp+dBMkUL/BnnHDbbDYwX8M7hLXgZXd9BcAGpFKSSlzq3ZDieh0VIfMy7fcffO3XfyqJ84MTRB/E3N+PuYP5BD9UeUazXa5ycnODs7Ayr1ephb86MGRdi6mkwNTC7V0y9RR4E7uR+yTnHtt7CWYc/cqd7XZF4939R9yPJSUOeiwydktilcN4n2SxnLElvnXP4bL+Ah0e/uZVMzjgXyHONrutTXo0xFkLwYIwmknFYTKmVUlKEvXWQgdQa82uIx7DzBYmdF4BGInVN5FEyGHOw4fhwTmMf56ij0jQ1Tk5Ow5hn/30OMQwDzs7WaaRB/inkvxILNe8BL2ls8o7hjwAgpTDrPIeSkrxbJt9DURSB2Ov2jjuLeUHOpVRezjlUscR1ebbrKnnKsbmfjtrQD9hut3sFhxQypQcXZZHkxxHTwjd23/7yHzu99GffK17p39ybAa9kDZ0LkYC5EJnxZsKDKka886nQOAQXHItqQSZabYM/HOnvamw3e4sfcN5Ii3OOpmlSETKVlDLOUeR5uvOPo5z4fCkl+qHHs+5q2hbXbyClwjgOafGMlu+MIRBNd4TM2MFgDKiqBRhDKlykFLuuQ56fG59EECG3R11vg5mYTdJlYwzggbIqMQwDFotFKg44pwItvkcc0XDO0fc9um5nzhahdQamF4ki875sgz50YuK2Zloj15qUNwdJuodF4fT7QBg7McZgnYVQZfILAQCVKRQ5jZakuvxoxIwjJQ2zfaffuI9lVabRzEWYnVQfPl7JGjpzRGbMeBPi0HX1fnGv7pe5zvGefMCzW/KjiNks4zgCjKGLnY+AOBJwzkFlGZy1UFKl7kRcGIUgAuhU0cEYg+AC75fUffncuILIV/AMsF2XJLbej6kgads2yXijQiaOOzhne86ssZDx3qPvh7CAn+8E0LYp9H005xKw1iUiqUd0kC1StwSggsWYEX0/7BFe4zHJ8xxd10EWk8WXAZxxvAsv0djFUeFRBtJvXODXm/XEfdWkYiQev1iITNN3+2GgJF+t0TcNClWmIgQArCHTuLsVCxdBCAnnO7gjap17IVDPRcijj7kQmTFjxn3jsu6XTy6A5zYZhoaKBBnGBIfE0bgwFkWBruvQ9Tv1jQzdFBOek+7cAfLI4JzkraEweScaaK3xe/4KsuB5AQD99hakFBACiSfCmN8rNCIOi5CIaCrG+UUkULLVH4Yh2LojdYEOSblSKsQgO2td6oYkE7hiBQPieaiSzL6+QW/TtiqlMI4aOs+TN4t15MfhnENZloCnUVqHDjrT+6ZjF3yXkSDMABTLK3tFSDjoYUxyvCC9G14JgXouQt4YmAuRGTPepHgQXZFjKouL3C+tsdhutgCuJhUNqT2CcZdSe+4TNowHptwBADAToqcJaou4WEoRP3vfRGwYBry/3KTxwufHE+TLq2RixhiEaJOPSJQRTw3S4r7KI9LUOy3AnDMURXmu4xD5KJSIK9D3/WTcQqZqsljtFUM37IuJVBo5LJM6Ykd8TdLdXfdFSLH3XtZYMH0gsb1A+hoVNc454JC6EuxVXklgYty+yybzzkXIGwdzITJjxpscx3I+7pV0GH1J9sYzF7hfeu8xmhHvqLb4cr+AKpbwY5se8yGxFiBpLg8Lks40sszDGpt4FNba9N5R8hvlp7Gw8c6F92LQikio8bXvRAshJXKt8dlhkaS/AICxAWPEu1BK0XjoiNx3t7t3Fh/GcUo0FYujobYlWfC0CMmXu+3w3uN9ao1hJCt5H4qoY4j7Hwmley62Moxiwjhr6pdy+PpjiMXPYBneLteAKmHCd8EY2xmMXUA6vldcJpl3LkLeWJgLkRkz3sT4rsdexv/+xexoS/xe5LzH2uoXuV967wFPCoy34ia+iqvH3TFBz4ldhKZt4Z2DkBJFWaIPBUU074ojjqIoiNAaLM3txLK9H3pYY6EyBTgGZy3cMMA7h/fnHlmWwXtyPv2CPIVngAcDcWUlpBz3+BrpWPGLF/Ddcyir5dBplQzQPFi22LsQv4ffwjCOVEiFRR/AhR4rsQCJvI7oQxJ/fLBiBzCxi/cTw7fd64/BGIPeRifZLh33xaLCEFxUhRT3ZYZ3P5iLkDce5kJkxow3KWKg19s+9MN7v79sgNhhWx3ewwSr9PSeE/8L70FGZ8KDyRxC7rJNoqdGLCZMIFRyTim5Q98jy7LAueDIsmyPYCm4IEtzBMkqPATnNIoI3QDOGESQsyKk2w7jCBvUJE/i5V0YIOf4PXsKllXgRzgUsbtx12MUVCnNJDYlliTvwcu79+MccdJz+GnOe4hQjFRVdaEB3FRNVNf1eRKwUuCMJcfYOxnIxTA8npV4G78NpySsMbDOou8HaJ3Bef+KzPAug7kIeWNiLkRmzHiTIgZ6ve3IY3dL4j02zrnI/XLHW6DFL44Xrtqv4aZ4C4rqFF19tjdWoXA4Td0QehMyvgrZKYzF93LwgWcRCxjGGZyxaaFPHA/O4J2HdY4MukAUh7hQO+eoUxL2KY5i3iNvYbFYpM84LAA+dfNyxz2mCANkLFbX+0WAAyA4P5c+LIMKx3t/zlfjUP487RIdjmoi2fdYls8hrLXg2S6plzMOFki1/v/f3r3HxlWe+QP/nuvMeGwPCTU03iS+NUArStCGDSWb35YAW2BXsKxatj9R5cIitGlTVC8VJXTVpUVFKRXSVmTbLlHVUKUg4Lc0RNVSbaLSBtFySSGBBkKWJFiBmC0hIWNnPJ45t98fZ97jc2bO2HP1mbG/H9VSPTe/Ywefx+/zvM9TaH+vaXrTgxAGIHMbAxGieUoM7Hrlqfux4vP/UnJ/uRMx0zUwU1SlJF3jOA7sQjtycbuw0PoAp9XzEe88B4pjeE258vm821q9cEG2HQeSSCdIgKbryExMeBdrRVGgx9wuqmI0vX94m6woUAsFl4qiuI3QCq8r2LbtNUnzz58xTbNQJ6KF7hz4A4tqidRScCiguyukFTqVJqUOb325XB4xPRZ4jUDjN9/rxhMJwBe0TPVPKb8DUsxwFABOoDtuoFZGkhiEUN0YiBDNUzMN7Aqt35hmbLs/neNP11imBd3WC3NKcojpunfCQ5IkLNDyeCcTc4tcTROapnlFqY7jQFYUKPBdSGUFuXw+sGNgWRYms1koigLDNBHTY5BiklfPYNs28vl84GItUjsiOAEKh0CKLqxOodYkl88HdhvK7UJUI2zXQsJU2iSTyXg5GnFqp7gFfnEQArjByfjYGHRdnzo5M0MtSDnn4zQs25lKV/n+XTR6yFwxBiHzA2fNEM1TYqAX4O6K+JVrJDVdAzORzhEk2b2gKqoC0zBhmhYcx+3JYRpugGIaJiABFyywYRX+LnIcJ1Ao6xRmwoi/5q2irqDe1y+kb1DYxTAMd5KrZVlQNXVqqFvhQ5Zl6Jrm3S6O7YoaCzHoTcxCyU5MIJPJIJPJFFIq7v/33y6+rpjj4s6QCc51KaaqKpLJJJLJJBKJBJLJpNeILBFPTE0m1jSoqhoojvU3cvO+X3ADEZHm8j82m82GriHwfbRtTOTdj8X6uLcrJCbi2oUillqnNVeKQcj8wR0RonlKDPTasWNHYLrodI2kZpoIEXZ/6BFf39cSFzMJhSm9k2dL0isiUIjF45jMZr06EbGr4jgOzEKfjuJUh2iNHit0GhVtywG3RkPXda9ewmt/DngFnZqmeUeBxVrGx8fd6b9TN0KWZYyNjXm3i52UWCyGXOGEjqIo6OjoKNnZEDssYtfGdhyYhgFZcefjmIYZuqMR1oTMKQzy834ehTk9wSnB4WkmcUJGAtDjnMJExkI8EQfy7vfXdiNJqLF4UwtUGYTMLwxEiOaxwcFBDA8PFwZ6HceIdNG0jaRm2ooP7bNRYefMCxbYOPyRDC3eCWPyrJdeAQBV06CpqjdLRsydEUSvDH/Ld5EysQv9SSRZwuTkpHekFRKgyAoUVXVnuORy7hTg2FQNhlMoavUCrMKujAiERPt0AN6aVFUFZLnQbM2GVQhA8oYBqbArkkwmA8ePAXgpFlHcKxV2d4y84RWXFheYztRITJKCc3qAqUF+xQWrtm17x3QXx84ik3F3tyazk9BjOmKxOByI3i56yfHuevrR+DEImX8YiBDNc6lUCsuXLwcAnJih02qluxvFKu2ceeECG//zkQw90QUFZknthTvfJRcIQgC3gDaHHOK+YXiCYRhQFQX5XB75fD6wI2LJNuTsBFRFhaooMAyjpOFXd3e3W5MiLuqFlvPiZI1SKML1r0nsSrgXZwN6oWusaPcuWtsrqvt1RaGtSKuIY9AO3ABBTNctnlYcXuw69T2XZBnZ7ETp96uQphGvl83bcACvKNVxfKkxuN9zW7W9r108V2amAuZKMQiZn1gjQkQVE7sbshL81VHJXBBRM6LrbsfSco+9YIGNCxfYsKHCcNziU1FfIWpFindexG1h9Q/iYl0chIjGablc3ns9UYfh1mSokH01KaqieA3T/CzTndZb3FlUpGZE8kT0QrELtwNTjdvMQgBk25bbMr1Qo+J/rbB6EFHs6q8bkWTZ7eYac2fO+IMQ0RsFAGS9A5MmkM2737OB5GTgccUcX2eTQKO66QqYJyZgGgby+bz7Hm0Oe6dS3BEhIk8l82dqmQtSLcu0sEgdxwmjGyYUGBPjUBTFDWAKTbkCdRuFuoywmgn/boo/CBHHdMXrmKbpNvsSjwdgW4Z30ZUkyW2MJsuh7esl90GFpmSlAZEkSYH1+S/s/kBDPEbsBtm2uxOhaVrgBIxYpyh29aejJMmdGFx8wqWje0HhnbsGkpPe8V7D8P38HAeqogaLjwvPK975KlfAbDs2jFwesiK7RcmYfpeEuyHzFwMRIqpaNXNBZuLYDizL9GaxOI4Dy7YgSxIWyWfwvn0OtIR71Ni2clNBREixZbmaCamQrhGvLx4VCEiK590A0GOxQE8RcXtHR8fUbZLb6EtRVUC8tixP7bIUaltE2CE+Fxd2B5hqS+/b8bAdB7Asb7jf5OSkV+QqCldFjUdxOgoAksmkm85Jifk17tcL9gSZalbmT7uZpukesZ50vCZxkiSF7nyFFSiLOhf/7g9Qfddemh8YiBBRQCOm8lbKMt1aBVmWvYm9iqx4RanxeByLjDMAgPftcwAlBj0Rg5EdL3mt6Qa3KbLsHSMuvmwqqru7UPxXuv+UiujiKlJLovhTXGRVVUVnVxfyuVwhyHDTPIqiQNU0ZCcmvCLXmK5jMpeDIo4I2zbyloXu7m7361huekakVDRNQ2YiE0irFNd4hMmZACQNcIINyYTinQ2RdstMZAr1NAY0XUMsHnOLesWOVFEAEZrG8TWLK74/rGsvd0PmNwYiRBQJUVsgS5IXhADiIuZerCYnJxGL6TBNy7uYJhIJHEOwGZudn5i2WZcbVHQg60x4zdIAN4BIxBMwLQsxPeYWYYqJsr70hyzLUGwbdiyG7GQ2cKwYKJw4mZx0Z8AUOrSKFEkun0dHR4c3O2cyl4OiuHNxJLg7IolEwq2nEDsihRM1iY4OZDJnIcE9vuy/pItUjv89i3oPwK21AUQhqTztiSXv9kJ9iaIoU4PxHMed7aPIJUWqQHgBs0g7qYoa2vNlpmPgNL8wECGiEtXuitRydFPUFshasBbBuzo77mNiUrCluSxLuPAc2/t672TiUGNJGDZgFC7ECb2omFaW3eO/MbdQ1n8hlCQJhmlCKex8lAtm3F0T1Wtb779dVVWvmLb4Yi2Lo7yFOTkAvFbyABCLxZAvNDzzMwwDyGahazos20bYd9NfcyKCEBGACNXU9JiWCSNvlNwOlJ8/FHY8W4L7NeLxeMn7AoK7JNwNIQYiRFSXWo9uFh+TnbpDtFl3KzgCF31F9oIccUG8UA9eeP/nIzmwMwAAMdUdYe8WuqreEVnbtjGRzSKm6xW1P3d8HV4dOF6dh1CuWNY/pE6kX8SuieM4mJiYKHmeKKRV43HI1tT0YNPXWVaWpLIBSOC1KqzpqaVhHRAS7ECCYRqhQU2zO7JS++G/BiKqWaWzZ8L4T6MEXrNwVNa2Ha+BFlDZEWEg/IJ8+CPZmyJrA1B0HY456dV/+LurliN2PPxHhEUKwnEcqIVeIYZhTDt/priwNFfoK+L1DxGPU2RYtg3TMDA56R6tFY3bDNOEFu+E6Uw1g2uEWhrWefcVBTveceVpUkLcDSGAgQgRlRGWnilOwTgOZpw9o0INTdsosgJN1yBBgq7p3oXYgQPHkbw0ia7pbqBQ4xFhx3bQn8jCMA2v5uHdfBegxr39DMORYObtkpSOn2VZ7oA8VSlpECbem2magRoU/xTccsGJqCUpPpIs+pfIhRM47kkUC+iIQVfjgCQ1LAARam1YF2Y2jnnT3MBAhIgqEpaCUTUVtmNDlqYurKqqAIULp21ZyBrBLXpFURCLx9wCVdMdfheLxWDZhSOtDrz26R1Jdy6LFwCZwWBmptoUsWbTcIe2Ae7Fdmk8E6hd6Eh24J2zsZKUjpDQ3cF3pmWVzMEB3HSLqmnIF9VDTDcFV+zA+LujilMxdqEzq0htqZoGPdHpve5gZx6a3pjj036VtuOv5vUadcyb5i4GIkRUltgVKZeCAeDORVHdRmOapgVOwCiyO2zNX7QoScDZ8bNusCHJkFQJlmW5bdJta6pGxHEwmZ1ELB5DbjIXHGSnyIjH46G3i9oU/5qlwkkYN5gInsYRf+mX210QNScOVGhxNxhIqHHvfpHiETUo3u2Yatfun19TfPRWdEcVs2YEkYaBGoeIOZbo44AkwbIUSAZqnucyndnayWBahgQGIkQ0o3LdM93UgXvUU9PUQBAiFQpNLdsKXPghuYWMWiF4cSfrKshms+6pDNXX3dRxYIwb0PXS2SZnx8+W3O6vTfGv2Z0JowKFJlviNE4lf+mLAMWxHZzNnA18H963zwHUOBwAeode9EwHeiFecYfPxb3+J8VHb1VVhRpLwj/hpfA/79iyG+TlA9+jWua5VII7GTSb2n7WzMjICG677TYMDAwgkUhgaGgI9957byBPS0S1++LKVOhpCVV1dzs6OsRpE8kLQuTCMDjxPNMy3a0Q+E7L+FuLSVPPLW59bpiG99zpbhenYAzDcIfXFbVZlyUZqqpBUzWvV0ZnsrPii3jYnJ1F8hn8mTaGgc4cFslnAh/n4TQWWh9gofUBFsfOAgC0RJf3YTgKsnnb+xAzdi5cYOOClI1ebcwLQlRV8YI8f3t5EXi12wwX7oaQX9vviLz11luwbRsPP/wwPvGJT+DgwYO4/fbbkclk8OCDD0a9PKI54ZKuUbw0scD73J+CkSAhnnCn3qqK6u1yiMJTwWuRLk7LIBhESChcYB1M1YsUjsgWB0L+0yqAO9dEtBQHgLyRhyzLJfUr/oF5iqJUnW4ol7YAgJySC+yWiPcnmnoVdzftSHaENggDQmo1CoGaLHZ2UKgjwVTzN1goWyvTShiEULG2D0Suu+46XHfddd7ng4ODOHz4MH784x8zECFqkP7+fuz7cBy2ZQf+OgfcTQnLdNMMtm1BLaRcAHh1Ge7jChdGx/HSMoJbnCrBsmzYTvBiLssh03YxdfTXP9fE/3qObRfSG07J8+vpZVEubVHS1EuSoKkaYrFYSVOvSr6+P+ixTMv7njlwYJpGoSmaW3+TOZuBA8cLuhqdsqmlYR1Rpdo+EAmTTqexcOHCaR+Ty+WQy+W8z8fGxpq9LKK2lUqlcNXAKTz7jh5Io4i/0MWxWFEvInYeRF2GLCtTk28doLOrE5OTk95FW5bkkvQLUNj5kOTArgYwdZFHYaiaPwgROxCmOTUwrrg/Ry0nQGYStlsiSRIms5OBx1Xz9f1Bjxja5w+6NF1zf49JcAfuFYKVsD4utQYTtTasC1Pvbkg6ncbIyAjGx8fR3d2Nvr4+pFLcYWl3cy4QOXLkCLZu3TrjbsiWLVvwne98Z5ZWRdRewn7hDw4O4uUPziCXzxXmnkiBVIdpWu7pGNOAyMjIkgw1Fkc8HocDB3ps6gSGGDPvOG5VpjgF42/3rioqYvFYyfoUVfEe70//FLcVNwzDnZQrYVZ6WYTtliSTybpPoIj+HqYR3PlRZAU5OwdFVrxJt/76EdGSfbpgQpblsgFKPQ3ritUbhBw7dgw7duzA6Oiod1tvby/Wrl2LwcHBul6boiU5LTp9aPPmzXjggQemfcyhQ4dw0UUXeZ+fOHECn/3sZ3HllVfiJz/5ybTPDdsRWbJkCdLpNLq7u+tbPFEbm+kX/s9/9yEmMqUtyYVkssMdFVPFhTefzyM7kQ30IBG7LKZpIZGIu5Nqi17TsR0YRh55wwg83m+6Wox2YpkWzmbOBn5vJRIJ5HM5rwutqqpQ5KldikRHApqqlZz2ESTZHabn7/Pi3+0wDGPan3Wl39tG7IT84Ac/CPybFHp7ezE8PMydkYiNjY0hlUrVdA1t2R2Rr3/969iwYcO0j/FHwaOjo1izZg1WrVqFbdu2zfj6sVgscLafiNxf+MVBCOD+97Vjxw4MDw/jhos1/L8/lO++WUv9gH9XBXCDGFHs6u68hE9+lWQJmqYjl8+XdDsV62n1uSaVpEwc24Hj2EjEE1AVxZ3CU+jDMmlPertCxbNvpEIaLexn5TgOjFweihJMr/h3O6qZPVPufTSiOHVkZCQ0CAHcf5sjIyNYvnx53V+HotGy/4X29PSgp6enoseeOHECa9aswYoVK7B9+/YZB1cRUbhKf+F3JMpv9deS9hCpB8u0YDu+eS6O+7qGaRSm3/o6bfgufPFY3K05sRuzntlSScrEtmxYtlU4jiwhl8vDti0oqgpd06AoSsmxXvE6qqJ6HWWLidqasGBDpHUqnT1jmW6TNkmCt6MlywZW/9lZAPUHIuPj43XdT62tZQORSp04cQJXXnkl+vr68OCDD+LkyZPefR//+McjXBlR48xWkV6lv/BvWbUQj78o11374A8mYnoME+YEjLzhXRw1TUNHogP5vNtBVdQkhF3ANV1DTIkBEtpirsl09Rf5fN5tf29Z3gkZUf8Sj7tBl2WaMAtda0XBatiAwHLBhLeLUu7+wummmWbPOLaDbDbrdZcVNT4/uutGPHPxxbjvvvvwyU9+subvEwB0dXXVdT+1trYPRPbs2YMjR47gyJEjWLx4ceC+Fi1/IapKLUV6tQYu1fzC/7+fOadkKF41/MGE4zgwTRN6TEdXdxdM0+1PYtnuY2K625VVDNELu4AbeQOWYlVVQFmJWk+bzPS8cikT0WXWKzr1NYVzO9TGEIu5p5cURYGquIW7lm2FBoXlBtlJkLwTRmEkSapo9oxhGJAkeEHIj+660XvcwYMHsW3bNnz729+uK3Du7+9Hb29v2RqR/v7+ml+botf2gciGDRtmrCUhaleV1GwU/4Kv53RBtb/wwyb0VqJ4N8BNE9iYzGYhywpUTQ10Rxb1XE6hPftME38b1Z681qOr5Z6XiCcAFFIitgNVVUqKa8XxaDEUz0+0pjcN9zli2J54/TDlgglVVaGqamgXan9tzUyzZxzHASQJD935N6Ff/9ixY3XXcKRSKaxduzb03/W6detYqNrm2j4QIZrLqi3SqyVw8ZutX/jFwcTUEVwJpmmWFJL7u7JWU0BZj1qPrpZ7nmmaGB8fh65rME3Lm7DrP27sX39x4Wnx/UD5tEqxcsGEbdslP4uw2ppyTdy+uDKF1157DXv27Cn7tTVNa0gNx+DgIIaHh72dvq6uLvT39zMImQMYiBC1sGqL9BpxuqDaX/i17IoUBwveRVdyPwJzaFA4IVL4K93fZyRMpRfnmdS68xL2PH8jMj2me+u0iiYBi9v9haf+7rT+91ftiaCwYEKRq5+0W3wKpr+/H+eee27oY5PJJLq6uhpWw5FKpXg6Zg5iIELUwqot0mvU6YJqf+FXG4yUtGwvXHxtx21T7r9fzK8Rf6WrCK95ABp7XLfWnZew2/3dX/27O4qqwjKnBgKK2/VYzBtk558aLGo6GnkiqJJJu9MdwU2lUli9ejWeeeYZHDx40Ls9mUziggsuQH9/P2s4aFoMRIhaWLU1G1GeLqgmGCkuoAy0g1fcqb6JhDvVV5EVKIriHcuvpICyESo9ulrJ7aIfiqZrXt8OrwFboehU07RAykS8P1mSIakaZFl2hwvO4qyXSnuALFu2DPfddx+2bduGY8eOQdM0byeNNRw0EwYiRC2s2pqNqE8XVBqMhAUTxe3gJ7OTMEwDplSYa+Prr2E7NmK6Dnht5tHQi7NjO26ySHLTMP5W9mIt5XZewk6pSIVjtvl8Hhkj4w32E0dyVUXxik6B2lImjVRLE7JPfvKT+Pa3v80aDqpay7Z4n231tKclajb/cdyZfsGXOzWzbt06DAwMzMp6K90Z8R9xFRdbAGVbkuu6DtM0QxuXNWrSrP/Ei6ZphUZpbgMxWZJrOjWjqIrb68NxvHbsgqZqSKVSZU+9zKZGdEGl+ameaygDkQIGIjSXVBO4NEutPUbKzTdRVQW5XN6tJynqniwrckP6hzi2UxIEifk3AKBrujvwr8o+InAcZCYmvM6x3roLKanOzs5I5+EwAKF6zclZM0RUu1Y4XVBtAau4cFumBVVTSwfYTdNfw7ZsWJYJx0KggRiAqpqRhZ148a9B1/WKgx1/EWg+ny/UekhFM3Skio4kNxODEIoaAxEiappKgxF/KsO2bRim4dVPiB4b0/XX0DQNmYkJ+E/9SrIETdUCDbtmSqs0q0eJqC8prjUpvn82MQChVhF9UpKI5rSZLnjFDcDEUV7R0lxVlcDtxRdtVVXcOg5/gzTHQT6XQzab9Z4PTDUjE0dji9V6UmYmooA1TBQTghmEUCthIEJETTfdha84HSKO8opgBL7dBD0WKw0GJAm2bQVuF307/M8XRDOyMM0KGMQpoeLXnu0JwV9cmWIQQi2HqRkiaqhyA/fKpWnC0h2id4bjOFBkBXpSL+mv4aeoajAQ8eVoyjUYC9PMHiUzzWxpNH+x7PLu99HX19eUr0NULwYiRNQwMw3cCwtGpmsM5u6OKN6JkrD+GnAA0wjucPjrSKqtyWhmwFBJF9NGsEwLb+/Z6v0cnkflgw+JZhtTM0TUEDMN3Eun3QCkOD1QbTpEkiVomgZd193ps2rp80U9SdiY+0pSLMVfY7ZSJ7US39MvrkzhugsRCEKE4p8DUavgjggRNUS1A/fE7ki96ZCw54t6knKnZpoZWERdg9GIwYdEs4mBCBE1RC0D98RF+4mX03WlQ8qlUwBA1dSm12REHXz4NWrwIdFsYWqGiBqinoF7X1yZKkmHAG6X1Xw+D9Mwyh65FcLSKbORYmmlIASIdvAhUS24I0JEDVHvwD3/7kjxrBagcTNl/KdJ6plk22oBiBD14EOianFHhIgaQkwK7u3tDdxeblJwOdddiNAjujM1I6uEZVo4mzmLicwEshNZZDITOJs5C8vfSr4CrRqEAI37ORDNFg69K+DQO6LGqHfg3muvvYYf/ehHAIAVn/+Xkvs7kh01DYgrHmgnhtk5jgNZlhGPxSuagNvKQYhfKww+pPmDQ++IqGXUO3DPX0z5ylP3e/9fBCW1/u3k7+CqaRomJycDHVZNw0QymZw29dMuQQjQGoMPiSrBQISIWkq5YkoRlPyfdfeH3j8TEcCI2TTFbd5Ny8REdgKdyc6SmpF2CkCI2g0DESJqKTMVW95wsealGCqZ7Ct43VTFDJvi+yF5c2j83U8ZhBA1FwMRImopotgyrFV8cbFlcZAwXWAiOriGz7aZmurrOE5dwUe5WTtEFI7FqgUsViVqLc0otjx27Bj27t2L73//+95tyWQSF1xwgZcS+spXvlJzbcXbb7+N559/HqdOnUIikcDk5CSy2SxuueUWznihOY3FqkQ05zSj2HJwcBCJRAKvv/46jh07Bk3T0NXVBV3XAdTXZ+PQoUP413/9Vxw8eNC7bWhoCDfccAMee+wx3HHHHYFAijsnRC4GIkQ0ryxatAh33HFHRamfSqXTaWzbti0QhADA0aNH8ctf/hJr1qwJzHiZaUox0XzCQISI5p3BwUEMDw83LPUzMjKCY8eOhd539OhRXH/99d6x5JmmFA8PD3NnhOYVBiJE1HJmI23RyNTP+Pj4tE3WstmsV4PC6bhEQQxEiKiltGPaoqurC11dXUgmk8hkMiX3n3vuuV7tCafjEgVx1gwRtYyZ0hbpdOV9Q2ZTf38/+vv7sWzZMiSTycB9F198MVavXu3t6HA6LlEQd0SIqGW0a9pC9D756U9/CsMwMDExAdu2ccEFF+ArX/kKli1b5j22labj8uQOtQIGIkTUMto9bTE4OIhFixYhm80ikUggkUh4R4OFahq2NVM7psBobmIgQkQto13TFuVSSgDw7rvvlpyEafSpnUatlyd3KAoMRIioZbRS2qIataSUopyO264pMJqbWKxKRC1DpC16e3sDt8922qJa7ZZSarf10tzGHREiailRpy1q0W4ppXZbL81tDESIqOVEmbaoRbullNptvTS3MTVDRFSndksptdt6aW6THMdxol5EK6hnhDERERDsy9EOKaV2Wy+1rnquoQxEChiIEBER1aaeayhTM0RERBQZBiJEREQUGQYiREREFBke3yUimgM4wI7aFQMRImopvKBWjwPsqJ3NiUDkxhtvxIEDB/DBBx9gwYIFuOaaa/DAAw+UnJEnotbGC2r1OMCO2t2cqBFZs2YNnnzySRw+fBhPPfUUjh49ii984QtRL4uIqjDTBTWdTke0stZWyQA7olY2J3ZE/vmf/9n7/319fdi8eTNuuukmGIYBTdMiXBkRVYoTYWvDAXbU7ubEjojf6dOn8eijj2LVqlUMQojaCC+oteEAO2p3cyYQufvuu5FMJnHuuefi+PHj2LVr17SPz+VyGBsbC3wQUXR4Qa2NGGAXhgPsqB20bCCyefNmSJI07cdbb73lPf6uu+7C/v37sXv3biiKgnXr1mG67vVbtmxBKpXyPpYsWTIbb4uIyuAFtTYcYEftrmVnzZw8eRKnTp2a9jGDg4PQdb3k9vfeew9LlizB73//e1xxxRWhz83lcsjlct7nY2NjWLJkCWfNEEWo3KmZdevWYWBgIMKVtT4OsKMo1TNrpmWLVXt6etDT01PTc23bBoBAoFEsFoshFovV9PpE1ByDg4MYHh7mBbUGqVSKxbzUllo2EKnUSy+9hH379mH16tVYsGABjh49im9961sYGhoquxtCRK2LF1Si+aVla0Qq1dHRgV/84he4+uqrceGFF+K2227DJZdcgr1793LHg4iIqMW1/Y7Ipz/9aTz77LNRL4OIiIhq0PY7IkRERNS+GIgQERFRZBiIEBERUWQYiBAREVFkGIgQERFRZBiIEBERUWQYiBAREVFkGIgQERFRZNq+oRkRtR//gLbu7m709fVxngzRPMVAhIhmVbkJu2vXrsXg4GCEKyOiKDA1Q0SzJp1OlwQhADA6OoodO3YgnU5HtDIiigoDESKaNSMjIyVBiDA6OoqRkZHZXRARRY6pGSKaNePj43XdT9Nj7Q21IwYiRDRrurq66rqfymPtDbUrpmaIaNb09/ejt7c39L7e3l709/fP7oIilE6n8dprr+H555/H66+/Xld9DGtvqJ1xR4SIZk0qlcLatWtD/3Jft27dvEkjNHr3opLam+XLl9e8XqJmYiBCRLNqcHAQw8PDXi1DV1cX+vv7500QMtPuxfDwcNXfC9beUDtjIEJEsy6VSs3bv9CbsXvB2htqZ6wRISKaRc3YvWDtDbUzBiJERLOoGbsXovamOBiZb7U31J6YmiEimkVi9yIsPVPP7sV8r72h9iU5juNEvYhWMDY2hlQqhXQ6je7u7qiXQ0RzWLlTM+vWrcPAwECEKyOqTT3XUAYiBQxEiGg2+bugcveC2l0911CmZoiIIjCfTw4R+bFYlYiIiCLDQISIiIgiw0CEiIiIIsNAhIiIiCLDQISIiIgiw0CEiIiIIsNAhIiIiCLDPiJE1Db8TcC6u7vR19fHJmBEbY6BCBG1hXJt0deuXYvBwcEIV0ZE9WBqhohaXjqdLglCAGB0dBQ7duxAOp2OaGVEVC8GIkTU8kZGRkKn1QJuMDIyMjK7CyKihmEgQkQtb3x8vK77iah1MRAhopbX1dVV1/1E1LoYiBBRy+vv70dvb2/ofb29vejv75/dBRFRwzAQIaKWl0qlsHbt2pJgpLe3F+vWreMRXqI2JjmO40S9iFYwNjaGVCqFdDqN7u7uqJdDRCH8fUS6urrQ39/PIISoBdRzDWUfESJqG6lUCsuXL496GUTUQEzNEBERUWQYiBAREVFkGIgQERFRZBiIEBERUWQYiBAREVFkGIgQERFRZOZUIJLL5XDppZdCkiQcOHAg6uUQERHRDOZUIPKNb3yjbBtoIiIiaj1zJhD51a9+hd27d+PBBx+MeilERERUoTnRWfVPf/oTbr/9djz99NPo6Oio6Dm5XA65XM77PJ1OA3Db1BIREVHlxLWzlqkxbR+IOI6DDRs2YOPGjbjsssswMjJS0fO2bNmC73znOyW3L1mypMErJCIimh9OnTpV9fynlh16t3nzZjzwwAPTPubQoUPYvXs3nnzySezduxeKomBkZAQDAwPYv38/Lr300rLPLd4ROXPmDPr6+nD8+PE5PURrbGwMS5Yswbvvvjunh/vxfc498+W98n3OLfPlfabTaSxduhQfffQRzjnnnKqe27I7Il//+texYcOGaR8zODiIZ599Fi+88AJisVjgvssuuwxf+tKX8LOf/Sz0ubFYrOQ5gDtUay7/YxG6u7v5PueQ+fI+gfnzXvk+55b58j5lufrS05YNRHp6etDT0zPj4x566CF897vf9T4fHR3FtddeiyeeeAKXX355M5dIREREdWrZQKRSS5cuDXze2dkJABgaGsLixYujWBIRERFVaM4c361XLBbDvffeG5qumUv4PueW+fI+gfnzXvk+5xa+z5m1bLEqERERzX3cESEiIqLIMBAhIiKiyDAQISIiosgwECEiIqLIMBCZRi6Xw6WXXgpJknDgwIGol9NwN954I5YuXYp4PI5FixZh7dq1GB0djXpZDTcyMoLbbrsNAwMDSCQSGBoawr333ot8Ph/10hru/vvvx6pVq9DR0VF1d8NW9sMf/hD9/f2Ix+O4/PLL8fLLL0e9pIZ77rnncMMNN6C3txeSJOHpp5+OekkNt2XLFvzFX/wFurq6cN555+Gmm27C4cOHo15WU/z4xz/GJZdc4jUyu+KKK/CrX/0q6mU11fe+9z1IkoTh4eGqnsdAZBrf+MY30NvbG/UymmbNmjV48skncfjwYTz11FM4evQovvCFL0S9rIZ76623YNs2Hn74Ybzxxhv4t3/7N/zHf/wHvvnNb0a9tIbL5/O4+eab8eUvfznqpTTME088gTvvvBP33nsvXn31VSxfvhzXXnstPvjgg6iX1lCZTAbLly/HD3/4w6iX0jR79+7Fpk2b8OKLL2LPnj0wDAOf+9znkMlkol5awy1evBjf+9738Morr+APf/gDrrrqKvzd3/0d3njjjaiX1hT79u3Dww8/jEsuuaT6JzsU6plnnnEuuugi54033nAAOPv37496SU23a9cuR5IkJ5/PR72Upvv+97/vDAwMRL2Mptm+fbuTSqWiXkZDrFy50tm0aZP3uWVZTm9vr7Nly5YIV9VcAJydO3dGvYym++CDDxwAzt69e6NeyqxYsGCB85Of/CTqZTTc+Pi4s2zZMmfPnj3OZz/7WedrX/taVc/njkiIP/3pT7j99tuxY8cOdHR0RL2cWXH69Gk8+uijWLVqFTRNi3o5TZdOp7Fw4cKol0EzyOfzeOWVV3DNNdd4t8myjGuuuQYvvPBChCujRkin0wAw5/9btCwLjz/+ODKZDK644oqol9NwmzZtwt/+7d8G/jutBgORIo7jYMOGDdi4cSMuu+yyqJfTdHfffTeSySTOPfdcHD9+HLt27Yp6SU135MgRbN26Ff/0T/8U9VJoBh9++CEsy8L5558fuP3888/H//7v/0a0KmoE27YxPDyMv/zLv8TFF18c9XKa4o9//CM6OzsRi8WwceNG7Ny5E5/61KeiXlZDPf7443j11VexZcuWml9j3gQimzdvhiRJ03689dZb2Lp1K8bHx3HPPfdEveSaVPo+hbvuugv79+/H7t27oSgK1q1bB6dNmu1W+14B4MSJE7juuutw88034/bbb49o5dWp5X0StbpNmzbh4MGDePzxx6NeStNceOGFOHDgAF566SV8+ctfxvr16/Hmm29GvayGeffdd/G1r30Njz76KOLxeM2vM29avJ88eRKnTp2a9jGDg4P4h3/4B/zyl7+EJEne7ZZlQVEUfOlLX8LPfvazZi+1LpW+T13XS25/7733sGTJEvz+979vi+3Dat/r6OgorrzySnzmM5/BI488UtO46ijU8jN95JFHMDw8jDNnzjR5dc2Vz+fR0dGB//zP/8RNN93k3b5+/XqcOXNmzu7gSZKEnTt3Bt7zXPLVr34Vu3btwnPPPYeBgYGolzNrrrnmGgwNDeHhhx+OeikN8fTTT+Pv//7voSiKd5tlWZAkCbIsI5fLBe4rp+2n71aqp6cHPT09Mz7uoYcewne/+13v89HRUVx77bV44okncPnllzdziQ1R6fsMY9s2APfYcjuo5r2eOHECa9aswYoVK7B9+/a2CUKA+n6m7U7XdaxYsQK//vWvvYuybdv49a9/ja9+9avRLo6q5jgO7rjjDuzcuRO//e1v51UQArj/dtvl92slrr76avzxj38M3Hbrrbfioosuwt13311REALMo0CkUkuXLg183tnZCQAYGhrC4sWLo1hSU7z00kvYt28fVq9ejQULFuDo0aP41re+haGhobbYDanGiRMncOWVV6Kvrw8PPvggTp486d338Y9/PMKVNd7x48dx+vRpHD9+HJZlef1vPvGJT3j/ltvNnXfeifXr1+Oyyy7DypUr8YMf/ACZTAa33npr1EtrqLNnz+LIkSPe5++88w4OHDiAhQsXlvxealebNm3CY489hl27dqGrq8ur80mlUkgkEhGvrrHuueceXH/99Vi6dCnGx8fx2GOP4be//S3++7//O+qlNUxXV1dJfY+oOayq7qfh53jmmHfeeWdOHt99/fXXnTVr1jgLFy50YrGY09/f72zcuNF57733ol5aw23fvt0BEPox16xfvz70ff7mN7+Jeml12bp1q7N06VJH13Vn5cqVzosvvhj1khruN7/5TejPbv369VEvrWHK/Xe4ffv2qJfWcP/4j//o9PX1ObquOz09Pc7VV1/t7N69O+plNV0tx3fnTY0IERERtZ72SZQTERHRnMNAhIiIiCLDQISIiIgiw0CEiIiIIsNAhIiIiCLDQISIiIgiw0CEiIiIIsNAhIiIiCLDQISIiIgiw0CEiFrCN7/5TUiShHvuuafsY/793/8dkiTh+uuvh2mas7g6ImoWtngnopbw4Ycfoq+vD7qu4/jx4+jq6grc//TTT+Pzn/88li9fjueee65th/gRURB3RIioJXzsYx/Dxo0bcebMGWzbti1w3wsvvIBbbrkFixcvxn/9138xCCGaQ7gjQkQt4/3338fg4CA+9rGP4dixY9A0DW+//TZWrVoF0zTxu9/9Dp/61KeiXiYRNRB3RIioZSxatAi33XYb3nvvPTz66KM4efIkrr/+eoyNjWHnzp0MQojmIO6IEFFLeffddzE0NIRly5ahs7MT+/btw89//nPccsstUS+NiJqAOyJE1FKWLFmC9evX480338TLL7+M+++/n0EI0RzGQISIWs7NN98MALjqqqtCj/P+4he/wF//9V9j4cKFkCQJIyMjs7xCImoUBiJE1HIOHToEAFi9enXo/ZlMBn/1V3+F++67bzaXRURNoEa9ACKiYvv37wcArFixIvT+tWvXAgAOHjw4a2sioubgjggRtZxXX30VAPDnf/7nEa+EiJqNgQgRtZTJyUkcOnQI5513HhYvXhz1coioyRiIEFFLef3112GaJndDiOYJBiJE1FJEfQgDEaL5gQ3NiKhtHTx4EJ/+9KfxzjvvoL+/P+rlEFENeGqGiNrO6dOncfz4cRw9ehQA8Oabb+LMmTNYunQpFi5cGPHqiKga3BEhorbzyCOP4NZbby25ffv27diwYcPsL4iIasZAhIiIiCLDYlUiIiKKDAMRIiIiigwDESIiIooMAxEiIiKKDAMRIiIiigwDESIiIooMAxEiIiKKDAMRIiIiigwDESIiIooMAxEiIiKKDAMRIiIiigwDESIiIorM/wdZ0euxoGrHdgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_densities(synthetic_samples.cpu(), x_lim=[-4,4], y_lim=[-4,4])\n",
    "model_freq.plot_densities(synthetic_samples_freq.cpu(), x_lim=[-4,4], y_lim=[-4,4])\n",
    "model.plot_densities(simulated_data_train.cpu(), x_lim=[-4,4], y_lim=[-4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598c157",
   "metadata": {},
   "source": [
    "The varying pseudo conditional correlation matrix values can be computed for any synthetic samples using `compute_pseudo_conditional_correlation_matrix` or can directly be plotted using `plot_conditional_dependence_structure`.\n",
    "The pseudo conditional correlation matrix is the standardised precision matrix so that off diagonal elements are the pseudo conditional correlations between the respective dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6637a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_conditional_correlation_matrix = model.compute_pseudo_conditional_correlation_matrix(synthetic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a30faa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/conda/envs/bgtm/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_conditional_dependence_structure(data=synthetic_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e081b4",
   "metadata": {},
   "source": [
    "One can also visualize the splines of each layer usign the function `plot_splines`. For the transformation layer we additionally include the dervaitive which is always positive due to the monotonically increasing constraint as well as the inverse which should lie exactly on the spline to visually confirm that the inverse sampling path works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "149a1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:113: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNsAAAHFCAYAAADL8f+dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACcWUlEQVR4nOzdeZxN9R/H8de5s++MsQ1j32XfiWzZypKUkD1SVEihhUSUCqmkyFJRylJKkSzVT0IKKfu+DTOWGTNjtnvP74+jiVCWmTkzc9/Px+M87txzz7nnfa+6597P+S6GaZomIiIiIiIiIiIicsscdgcQERERERERERHJKVRsExERERERERERSScqtomIiIiIiIiIiKQTFdtERERERERERETSiYptIiIiIiIiIiIi6UTFNhERERERERERkXSiYpuIiIiIiIiIiEg6UbFNREREREREREQknajYJiIiIiIiIiIikk5UbBMREREREREREUknKraJiIiIiIhkkB9++IG2bdsSHh6OYRh8/vnn/7nP2rVrqV69Oj4+PpQqVYo5c+ZkeE4REUk/KraJiIiIiIhkkPj4eKpUqcLbb799XdsfOHCAu+66iyZNmrBlyxYGDx7MQw89xIoVKzI4qYiIpBfDNE3T7hAiIiIiIiI5nWEYLFmyhA4dOlxzm+HDh7Ns2TK2b9+etu6BBx7g3LlzLF++PBNSiojIrfK0O0BmcrlcHD9+nKCgIAzDsDuOiEiWZZom58+fJzw8HIdDjaBvhc49IiLXR+cey/r162nevPll61q2bMngwYOvuU9SUhJJSUlp910uF2fOnCFPnjw694iI/IuMOve4VbHt+PHjRERE2B1DRCTbOHLkCIULF7Y7Rramc4+IyI1x93NPZGQk+fPnv2xd/vz5iY2N5cKFC/j5+V2xz4QJExgzZkxmRRQRyXHS+9zjVsW2oKAgwHoTg4ODbU4jInLzTNPk0z8+5dV1kyjk3YYDh+riMsHliOSEz1DK5ilHpQIVKJGrBEVDilIsVzGK5SpGgaACOIz/vmITGxtLRERE2uem3Dyde0QkJ0lISWDH8Qu8tXofmw6eJcHxK2e83yQiqCT1i1aifN4yhAeFEx4YTsGgghQOLoyPp891PbfOPTdv5MiRDB06NO1+TEwMRYoU0blHROQ/ZNS5x62KbX81oQ4ODtZJR0SyrRRnCg8u7sWnf84H4PB5BwW8m9K6Yn6GtWhFsbABeHl4pcux1PXk1uncIyI5xf/276Hjp/cQHx9GWMoQfP0D6VOnK4OajCYsyDfdjuPu554CBQpw8uTJy9adPHmS4ODgq7ZqA/Dx8cHH58qips49IiLXJ73PPW5VbBMRye5OJ8TQbPa9bI1eBaYHIalduCP8QUbdVZsaRXPbHU9ERHKg/VEx9Fv8CmtOTMU04nF4BNGsrJOxdzemUK6rF3/k5tWrV4+vv/76snUrV66kXr16NiUSEZEbpWKbiEg24HKZTFzzJS+ue4IL5kEM05vK/i/w6t19aF4+n9u3AhARkfR39GwsjyyZxPLD00k1ToIBeX0qMK/jh9xZprrd8bKNuLg49u7dm3b/wIEDbNmyhdDQUIoUKcLIkSM5duwYH3zwAQADBgzgrbfe4umnn6ZPnz6sXr2aTz/9lGXLltn1EkRE5Aap2CYikoWZpskPe6J5YdkPrI3pDIYTL0J5vv5MRjZrj6eH+87WJiIiGSM2MYXxK1bx+m/dSTWiwQBfR26eqD2Cl+58Eg+Hh90Rs5VffvmFJk2apN3/a2y1nj17MmfOHE6cOMHhw4fTHi9evDjLli1jyJAhvPHGGxQuXJiZM2fSsmXLTM8uIiI3R8W2fzBNk9TUVJxOp91RJJ14eHjg6emplj+S7azc9Sezf4jlp32nAV/y+N5N6QKeLOj8FkVyFbA7noiI5DCJKU4+WH+QaWv3cTYhGXw88fXIy8PVBjO+5WD8vfztjpgtNW7cGNM0r/n4nDlzrrrPb7/9loGpREQkI6nYdonk5GROnDhBQkKC3VEknfn7+1OwYEG8vb3tjiLyn5bv2sBjXz3P3vOrKJj0BoEeJeleryiPNv6EPIHpNwC1iIgIQGJKMo8vncwnf8wjd8KLGHhROl8Iz9VdQPdatfH10rlHRETkRqjYdpHL5eLAgQN4eHgQHh6Ot7e3WkLlAKZpkpycTFRUFAcOHKB06dI4HOp2J1nTmn0bePTLZ9kZs8paYUCpiP3Me6APEaFqTSAiIukr1enkuW9nMnXTS1wwjwCQL+hHxrccTMdqhTRUgYiIyE1Sse2i5ORkXC4XERER+PvrR21O4ufnh5eXF4cOHSI5ORlfX12dlazlp8ObePiLEWw/s9paYRoU9W/GpNYv0LFSA3vDiYhIjuNyuZj84yJe/PF5Yp27APAkhE6lH2N6xxGE+AbYnFBERCR7U7HtH9TqKWfSv6tkRSlOFx9t2EP/lS1I5RyYDsJ9mjKxxRi61ahvdzwREcmB1u07RsdP23MqeTMADtOPO4v0ZVanMYQHh9qcTkREJGdQsU1EJJMlpiSyZucZXl2xm/3R8QR7dMHDbxcvNB7NgPoNcTjUhV1ERNLXrsjzvLpiF9/tOEmsNxgOT+rm78KcThMok7eQ3fFERERyFBXbREQyiWmavPz9HMb9+CwBF3rj76pPaIA3o5oM48G6xfD2VAtMERFJXxsO7abf589wLrIDDjM3DgO6l32BhxqWpnaRsnbHExERyZFUbHNzjRs3pmrVqkyZMgWAYsWKMXjwYAYPHmxrLpGcZv6WFQxePoyopO0AmN5fMrx+D/o3KkGQr5fN6UREJKfZeeoYvRc+w4ZTH2MaKQR5JvNgudEMvbMspfIF2h1PREQkR1OxTS6zadMmAgI0KK5IevnhwG/0XTKUvefXAmCYPjTI35sP7h9H8Tx5bM0mIiI5z/HYs/T+7AW+OzIDl3EBDMjnXY3X7h5E9xo17I4nIiLiFlRsk8vkzZvX7ggiOULMhRQe+HgEyw9PAcMFpoPywR2Yec8r1C9eyu54IiKSwySmOHlo4QQW7H7dmnTHgBCPMoxuNJbBDe/DMDQeqIiISGbRAEHXYJoQH2/PYpo3lnXhwoVUqlQJPz8/8uTJQ/PmzYmPj6dXr1506NCBMWPGkDdvXoKDgxkwYADJycnXfK5ixYqldSkFMAyDmTNncs899+Dv70/p0qVZunTpZfts376d1q1bExgYSP78+enevTvR0dE39iJEcoikVCczf9zPHa+u4de9IWC4CPdpxMKO6/lz6CIV2kREJF2lOl0s2HSYJq+tZemfm0jlHH5GIUbWmc7pZ/5kSKP7VWgTERHJZGrZdg0JCRBo03AWcXFwvT05T5w4QZcuXZg4cSL33HMP58+f58cff8S8WLFbtWoVvr6+rF27loMHD9K7d2/y5MnDSy+9dN15xowZw8SJE3n11Vd588036datG4cOHSI0NJRz587RtGlTHnroISZPnsyFCxcYPnw4999/P6tXr76Zly+SLSWmJDFo6URW74zGdb4FAJXyNuL+eqvpV6+xfuiIiEi6crlcjFn5Ad9sTeXUmYIAlA3uTrWydZna7kl8vbxtTigiIuK+VGzL5k6cOEFqaiodO3akaNGiAFSqVCntcW9vb2bNmoW/vz8VK1bkxRdf5KmnnmLs2LE4HNfXsLFXr1506dIFgPHjxzN16lQ2btxIq1ateOutt6hWrRrjx49P237WrFlERESwe/duypQpk46vViTrcblcjFn1Pq/9PIYE1zEM05+qQY0Y3qIW91YvjKeHGhCLiEj6mrZuKc+tfZazqdvxdVajnP/LDGpamm51iuDr5WF3PBEREbenYts1+PtbLczsOvb1qlKlCs2aNaNSpUq0bNmSFi1a0KlTJ3Lnzp32uP8lT1ivXj3i4uI4cuRIWnHuv1SuXDnt74CAAIKDgzl16hQAW7duZc2aNQRepRngvn37VGyTHG3Wpq94auXTnEnZAYCnmZtOZYbwXse7CfL1sTmdiIjkNAu3/o8nlj/N8cT1gDXpTv0itVjYtSG5/f1sTiciIiJ/UbHtGgzj+rty2snDw4OVK1fy008/8e233/Lmm2/y7LPPsmHDhnQ7hpeX12X3DcPA5XIBEBcXR9u2bXnllVeu2K9gwYLplkEkK/lh3+/0WPIoh+L/B4Bh+tGkUF/mdBpDRO5Qm9OJiEhOs2bvNh5eOpw955dbK0wHNfJ2YnbHl6lUsLi94UREROQKKrblAIZh0KBBAxo0aMCoUaMoWrQoS5YsAayWZxcuXMDPz7ra+fPPPxMYGEhERES6HLt69eosWrSIYsWK4emp/5wkZzsdl8Sbq/cye8PPHPb6CfCgSu5OzL73ZaoVLmZ3PBERyWFOxiYy5bs9zPz1PaK9rEJb2aCWvNdhIo1KVP6PvUVERMQuqo5kcxs2bGDVqlW0aNGCfPnysWHDBqKioihfvjzbtm0jOTmZvn378txzz3Hw4EFGjx7NoEGDrnu8tv8ycOBAZsyYQZcuXXj66acJDQ1l7969fPLJJ8ycORMPD40bItnf8dhonvtmPhv/LEtcUioG4dTLP5Ln7uxIm/LV7Y4nIiI5zKEzUby++n98u9WXxBQX/txJmdxHGN9iGPdWamh3PBEREfkPKrZlc8HBwfzwww9MmTKF2NhYihYtyuuvv07r1q1ZsGABzZo1o3Tp0jRq1IikpCS6dOnCCy+8kG7HDw8PZ926dQwfPpwWLVqQlJRE0aJFadWqVboV9ETsEp90gYc/H88nO9/AacZRMHkq1QtVYWTr8jQodZfd8UREJIc5HX+ehxaN48v90zDMQMJT3qFW0XwMb12OWsXa2x1PRERErpOKbdlc+fLlWb58+b9uM2bMGMaMGXPVx9auXXvZ/YMHD1523zTNK/Y5d+7cZfdLly7N4sWL/zOrSHbhdDl5Zvm7TP1lLIlmJAD+jqI8cWcETzW+HYfDsDmhiIjkJBdSkhn0xet8+MfrpHAaDAjwyMtLd4fTrWYtDEPnHRERkexExTYRkUu8/dNinlszknOpuwHwIg8Plh/GWx2G4u/tbXM6ERHJSZxOF899+z5vbBrLBfMIAD7kp3/VEbx21yC8NR6uiIhItqQzuIgIsOfkecZ9/RsfHeqNy4jFYfrRssjDzL7vBfIHhdgdT0REcpj/7YlmxFeLWBc7AAAPgrm/zONMv2ckwb7+NqcTERGRW6FiWw42Z84cuyOIZHm/HdvHxz/FsfDXo7hMyO3ZjeIFYpjb6WUqFEifWXtFRET+sm7/AaavOcWPe6KBwgT5NqBeRFVm3/ci4cGhdscTERGRdKBim4i4pUNnT9Hjs5H8ePxDwpKfwt+sT6uKBXiq1URK5g20O56IiOQw6w/toM/ip9gVs4ZCie/h65GbB+sWZWDj7wgL8rU7noiIiKQjFdtExK3EJMbz0KJxLNn7Fk7irEGoQ7ax8IFh1Cia2+54IiKSw+yLPk6Pz0aw/uTHmEYqGFC22B5m3fc0RfKou6iIiEhOpGKbiLiFVKeTYV+/xfRfx5PEKQACHSUYWX8sI5o8gMPhsDmhiIjkJKfjY+mzaAxf7Z+Oy0gAA/J712RK61d5oGpju+OJiIhIBlKxTURyvJ/3n6bTgi4cS14JgDd56VN5OFPufhwfLy+b04mISE7idJl8+ss+en/TkCQiwYBgRxmeazSOYY06YRiG3RFFREQkg6nYJiI51p6T53n5m52s2nmKFEcDHN7ruLv4o8zqNIo8AUF2xxMRkRzm+91RTPh6Bzsjz+PtVQs8NzGg2nO8etcAvDw87I4nIiIimUTFNhHJcX4/foDuC5/iyKkQglI74uEw6FerI70bDqBkWH6744mISA6zYtev9PtiKKln78XbLEGQrydP3D6WPg1KE+KncdlERETcjYptOVTjxo2pWrUqU6ZMuenn6NWrF+fOnePzzz9Pt1xXM2fOHAYPHsy5c+cy9DiS80WeP0fPz0ax8vAMTCMRwzOA9qV78myb6pphVERE0t2+6BN0XfAUG6M+AcOJn/d5Rtb6kEFNSpE7wNvueCIiImITFdvkmt544w1M00zX5yxWrBiDBw9m8ODBaes6d+5MmzZt0vU44l6SUlIY+MUk5v4xkVTOgAG5PSvy6p2v0rd2I7vjiYhIDhOfnEifhWNZuHsqLsOa2TrC73ZmdZhC8zIV7I4nIiIiNlOxTa7gdDoxDIOQkJBMOZ6fnx9+fn6ZcizJWUzT5J2flvP06keJdx0EwNcoyJBaLzCu5UOaYVRERNKVaZq8/sMiRn0/lAvmETAgyFGKsU1e4YnbO9odT0RERLII/RK9FtOE1Hh7lhtsTRYfH0+PHj0IDAykYMGCvP7665c9npSUxLBhwyhUqBABAQHUqVOHtWvXpj0+Z84ccuXKxdKlS6lQoQI+Pj4cPnyYXr160aFDBwDee+89wsPDcblclz13+/bt6dOnDwD79u2jffv25M+fn8DAQGrVqsV3332Xtm3jxo05dOgQQ4YMwTCMtNm4/jo+wO7duzEMg507d152nMmTJ1OyZMm0+9u3b6d169YEBgaSP39+unfvTnR09A29b5K97Tl5nh6zNvLSV4eIdx7GgyC6lh1F1PD9jG/dX4U2ERFJV4dPJ9BnzibGf7uSC+YRPMlNv9smEj1yhwptIiIichm1bLsWZwJ8atMYT/fHgWfAdW/+1FNP8f333/PFF1+QL18+nnnmGX799VeqVq0KwKBBg/jzzz/55JNPCA8PZ8mSJbRq1Yrff/+d0qVLA5CQkMArr7zCzJkzyZMnD/ny5bvsGPfddx+PPfYYa9asoVmzZgCcOXOG5cuX8/XXXwMQFxdHmzZteOmll/Dx8eGDDz6gbdu27Nq1iyJFirB48WKqVKlC//796dev31VfS5kyZahZsybz5s1j7NixaevnzZtH165dATh37hxNmzbloYceYvLkyVy4cIHhw4dz//33s3r16ut+3yR72hd9gqe/+ogtuyvidJkEeBSlW+kpvHRXZ4rmyvffTyAiInIDzibE8ep361i40UVyqotQj7upXTiAGZ2eISIkzO54IiIikgWp2JbNxcXF8f777/PRRx+lFcHmzp1L4cKFATh8+DCzZ8/m8OHDhIeHAzBs2DCWL1/O7NmzGT9+PAApKSlMmzaNKlWqXPU4uXPnpnXr1syfPz/tOAsXLiQsLIwmTZoAUKVKlcv2Hzt2LEuWLGHp0qUMGjSI0NBQPDw8CAoKokCBAtd8Td26deOtt95KK7bt3r2bzZs389FHHwHw1ltvUa1atbTsALNmzSIiIoLdu3dTpkyZG38jJctLSE7ioUXj+XTXJJwkUNB8g7YV6/JMm/IUzdPa7ngiIpIDTVgzjxd/fIpUJ4SnTuP2UgUY0+42SuVra3c0ERERycJUbLsWD3+rhZldx75O+/btIzk5mTp16qStCw0NpWzZsgD8/vvvOJ3OKwpQSUlJ5MmTJ+2+t7c3lStX/tdjdevWjX79+jFt2jR8fHyYN28eDzzwQFp3vbi4OF544QWWLVvGiRMnSE1N5cKFCxw+fPi6Xw/AAw88wLBhw/j555+pW7cu8+bNo3r16pQrVw6ArVu3smbNGgIDr2x5uG/fPhXbcqBX1nzCiz+OIME8BAYEOkoytkNZ+tapaXc0ERHJgbYdP0jHj/uxL84aDsPLkZen7wrh0dvrpA2DISIiInItKrZdi2HcUFfOrCouLg4PDw82b96Mh4fHZY9dWqzy8/P7zy+Pbdu2xTRNli1bRq1atfjxxx+ZPHly2uPDhg1j5cqVvPbaa5QqVQo/Pz86depEcnLyDWUuUKAATZs2Zf78+dStW5f58+fzyCOPXPaa2rZtyyuvvHLFvgULFryhY0nW9v2+bTy46FGOXlgHgCch9KgwnHfueQpvT318iYhI+nK5XDyy5HVm/v6iNcuo6aBBgZ581vV1CgbntjueiIiIZBP6tZrNlSxZEi8vLzZs2ECRIkUAOHv2LLt37+aOO+6gWrVqOJ1OTp06RcOGDW/pWL6+vnTs2JF58+axd+9eypYtS/Xq1dMeX7duHb169eKee+4BrKLYwYMHL3sOb29vnE7nfx6rW7duPP3003Tp0oX9+/fzwAMPpD1WvXp1Fi1aRLFixfBUwSVHSkxx8taaHYz4qTFO4yyYHtQv0I2PH3iNIrny2h1PRERyoD9PnKTpnLs4mbwZDAjxKMP77Wdyb6Vb+/4kIiIi7kfT9WVzgYGB9O3bl6eeeorVq1ezfft2evXqlda1s0yZMnTr1o0ePXqwePFiDhw4wMaNG5kwYQLLli274eN169aNZcuWMWvWLLp163bZY6VLl2bx4sVs2bKFrVu30rVr1ytmLy1WrBg//PADx44d+9fZQzt27Mj58+d55JFHaNKkSdp4cwADBw7kzJkzdOnShU2bNrFv3z5WrFhB7969r6uQJ1nbml2naDnlB95afYiQlAco6FOHFV02sm7AXBXaREQk3TldJu//7wAdp/1KzAUwTB/uKzWSkyO2q9AmIiIiN0XNgnKAV199Na1rZVBQEE8++SQxMTFpj8+ePZtx48bx5JNPcuzYMcLCwqhbty533333DR+radOmhIaGsmvXrrTZQf8yadIk+vTpQ/369QkLC2P48OHExsZets2LL77Iww8/TMmSJUlKSsI0zaseJygoiLZt2/Lpp58ya9asyx4LDw9n3bp1DB8+nBYtWpCUlETRokVp1apVWpFRsp9NR/bQecEA4s7cjr+rNvmCfHjjrmdoWzlc/64iIpIhfjqwk1e+PsLWI9aQF3cWfY5hLUrRqORtNicTERGR7Mwwr1XtyIFiY2MJCQkhJiaG4ODgyx5LTEzkwIEDFC9eHF9fX5sSSkbRv2/WdSE5ie6fvsDivVMwjUS8XOE8W3M5Q+8sR5Cvl93x3Na/fV7KjdF7KZL1uFwuBn0xhXe3Poef83aKOZ7kmTbleaBWBA6HJkCwiz4v04/eSxGR65NRn5dq2SYitlm47Qf6Ln2IWOceMCCPVyXebz+d9hUr2R1NRERyqF2njtJy7oMcSvgeDPD1O8mSfjUpnTfPf+8sIiIich1UbBORTHfuQjwdP3qSNcdmgOHCwwykb+XnmdbhSTwcHv/9BCIiIjdh8g+LeHpNP1I5C6YnHUoMYUHX8ZrhWkRERNKVvlmISKbaeOAM/Ra8x7akd8GAEgHN+KLbTG4rWMzuaCIikkMlpiRz99zBrDo6HQyTAEcx5rb/kHsr3253NBEREcmBVGwTkUwRn5TCy9/s4sOfDwGVyOvfjofrtGNsy752RxMRkRzsZGwi/T9axZpT88EwqRp6L6v6zibUP8juaCIiIpJDqdgmIhnu/Y3fMHTFMILjn8GDXDxQK4KRbRYS4qcJEEREJOOs2xvNE5/8RnQcFPZ+mvvq5OK1ux61O5aIiIjkcCq2iUiGiUtKpO3cx1l7/H0wXPgGfMKiB2Zze+kwu6OJiEgO5nK5uPejZ/hplxd+zrqUKxDE290ep2TeQLujiYiIiBtQsU1EMsTSP9bz4OIenHftBQMqhLRjea9ZROTSbG8iIpJxTsefp970+9gTtwLDy4+Hb/ucyZ0a4OulCXhEREQkc6jYJiLpKtXppOsno1i4ZyKmkYonIYyoO4mxLfvYHU1ERHK4DYd30uKDdsQ694DpQfcKI5l2350YhmF3NBEREXEjDrsDXK8JEyZQq1YtgoKCyJcvHx06dGDXrl12xxKRS5yJT6beW0P5bO94TCOVIn4N+e3hrSq0iYhIhnt/43Jun12XWOcePAnhnZZLmHv/8yq0iYiISKbLNsW277//noEDB/Lzzz+zcuVKUlJSaNGiBfHx8XZHs13jxo0ZPHiw3THEzW3Yf5o2b/zIyRO3420Wo3eFlzgwbC23FShqdzQREcnhnl72Lv2+bkcqMQR7lOF/vTYyoF5bu2OJiIiIm8o23UiXL19+2f05c+aQL18+Nm/eTKNGja66T1JSEklJSWn3Y2NjMzSjXRYvXoyXl2Z1FHskp6by8MK3Wbu1JKZpUDpvXpY9sJlKhULtjiYiIjmcaZq898N+3vn5C0zPFIr6N2LTI0vJGxhidzQRERFxY9mm2PZPMTExAISGXvsH/YQJExgzZkxmRbLNv70HmcHpdGIYBg5HtmkoKenk0NkoGrzXnmOJ68nteJjeVR7hxfYVCfDJth8tIiKSTThdJmO/+pM5Px0klAE0Ll6LxT2ex8tT5yARERGxV7asjrhcLgYPHkyDBg247bbbrrndyJEjiYmJSVuOHDlyw8eKT46/5pKYmnjd215IuXBd296MS7uRFitWjPHjx9OnTx+CgoIoUqQI7733Xtq29evXZ/jw4ZftHxUVhZeXFz/88ANgtQgcNmwYhQoVIiAggDp16rB27dq07efMmUOuXLlYunQpFSpUwMfHh8OHD7N27Vpq165NQEAAuXLlokGDBhw6dChtvy+++ILq1avj6+tLiRIlGDNmDKmpqTf1msV+3+zYRPk3q3MscT2G6UO32uV4/f4qKrSJiEiGi7mQQMO3hzL7p30APH/XbXzZZ4wKbSIiIpIlZMtvJAMHDmT79u3873//+9ftfHx88PHxuaVjBU4IvOZjbUq3YVnXZWn3872Wj4SUhKtue0fRO1jba23a/WJvFCM6IfqK7czR5s2Hvej1119n7NixPPPMMyxcuJBHHnmEO+64g7Jly9KtWzcmTpzIyy+/nDZg8IIFCwgPD6dhw4YADBo0iD///JNPPvmE8PBwlixZQqtWrfj9998pXbo0AAkJCbzyyivMnDmTPHnyEBoaStWqVenXrx8ff/wxycnJbNy4Me0YP/74Iz169GDq1Kk0bNiQffv20b9/fwBGjx59y69ZMtcLK+cwdt2juIwLeJOPj+75jPuqXL07t4iISHqKiouh8lstiUzaQLD3Tj66933aVgm3O5aIiIhImmzXsm3QoEF89dVXrFmzhsKFC9sdJ0tq06YNjz76KKVKlWL48OGEhYWxZs0aAO6//36OHz9+WaFy/vz5dOnSBcMwOHz4MLNnz+azzz6jYcOGlCxZkmHDhnH77bcze/bstH1SUlKYNm0a9evXp2zZsqSmphITE8Pdd99NyZIlKV++PD179qRIkSIAjBkzhhEjRtCzZ09KlCjBnXfeydixY3n33Xcz982RW+JyuWg/90nG/NQbl3GBvN7V2PbIZhXaREQkUxyNiab81EZEJm3AMH0Y26KfCm0iIiKS5WSblm2mafLYY4+xZMkS1q5dS/HixTPluHEj4675mIfD47L7p4aduua2DuPyuubBJw7eUq5/U7ly5bS/DcOgQIECnDplZcubNy8tWrRg3rx5NGzYkAMHDrB+/fq0otfvv/+O0+mkTJkylz1nUlISefLkSbvv7e192XFCQ0Pp1asXLVu25M4776R58+bcf//9FCxYEICtW7eybt06XnrppbR9nE4niYmJJCQk4O/vn/5vhKSrVKeLAQuWsPTAFDCgVlhX1vabhb/3rbUeFRERuR77oo9TY3oTYpy7cZiBvH/3QnrVbGl3LBEREZErZJti28CBA5k/fz5ffPEFQUFBREZGAhASEoKfn1+GHTfAO8D2bW/UP2cmNQwDl8uVdr9bt248/vjjvPnmm8yfP59KlSpRqVIlAOLi4vDw8GDz5s14eFxeTAwM/LtLrZ+fX1oX0b/Mnj2bxx9/nOXLl7NgwQKee+45Vq5cSd26dYmLi2PMmDF07Njxiry+vr63/JolY8UnpTJo/q+s2eVLHs9HaXVbGB89oO6/4h4mTJjA4sWL2blzJ35+ftSvX59XXnmFsmXL2h1NxG3sjTpB9el3cN61F09C+Ljjl3Sq3NDuWCIiIiJXlW2Kbe+88w5gTQZwqdmzZ9OrV6/MD5SNtW/fnv79+7N8+XLmz59Pjx490h6rVq0aTqeTU6dOpY3hdiOqVatGtWrVGDlyJPXq1WP+/PnUrVuX6tWrs2vXLkqVKpWeL0Uywe6oYzwybx37IgPw9XLw7gPP0rJiAbtjiWSa77//noEDB1KrVi1SU1N55plnaNGiBX/++ScBARl34URELOfik6n9bsuLhbbcLL1/Ja3L17A7loiIiMg1ZZtim2ne+sQBYgkICKBDhw48//zz7Nixgy5duqQ9VqZMGbp160aPHj14/fXXqVatGlFRUaxatYrKlStz1113XfU5Dxw4wHvvvUe7du0IDw9n165d7NmzJ62QN2rUKO6++26KFClCp06dcDgcbN26le3btzNu3LhMed1y434/foB67zclKTWZ8v5vMLdXM6oVyW13LJFMtXz58svuz5kzh3z58rF582YaNbpyvMKkpCSSkpLS7sfGxmZ4RpGcKi4plV5zNuGV0Alvn5N88cAyWpVVoU1ERESytmw3QYKkj27durF161YaNmyYNonBX2bPnk2PHj148sknKVu2LB06dGDTpk1XbHcpf39/du7cyb333kuZMmXo378/AwcO5OGHHwagZcuWfPXVV3z77bfUqlWLunXrMnnyZIoWLZqhr1Nu3obDu6gzsyHxroM4HClM7lJahTYRICYmBrDGqryaCRMmEBISkrZERERkZjyRHONCspM+czax5cg5CvrWZdND22lVtqbdsURERET+k2G6UZOx2NhYQkJCiImJITg4+LLHEhMTOXDgAMWLF9cYYjmQ/n1vzA/7ttPio+YkcRIfowDfdV/F7cUr2B1LMtG/fV66M5fLRbt27Th37txlszpf6mot2yIiIvReityA+KQkqr35APGnWxPqXZT5/epSqXCI3bEkg+nck370XoqIXJ+M+rzMNt1IRSRzrD+0gzs/akoyUfgZhfmxz2pqFC5tdyyRLGHgwIFs3779moU2AB8fH3x8NEuvyM1yuVzUmtaJPfFf4eWznoXdt6jQJiIiItmKim0ikmbr8f00nduMZKLwN4qyof/33FZAXX1FAAYNGsRXX33FDz/8QOHChe2OI5JjNZs5gB2xX4Hp4MU7JlGvpCblERERkexFxTYRAeB0XBID5/9CqhN8PQqyru9qFdpEsCboeeyxx1iyZAlr166lePHidkcSybG6fzKatSdmADCgykRGNOlqcyIRERGRG6dim4gQl5RKj1kbORodQOXgN3iz621ULVTC7lgiWcLAgQOZP38+X3zxBUFBQURGRgIQEhKCn5+fzelEco4Xv/uQj3aOBQPaFBnCO/c8aXckERERkZuiYts/uNF8EW5F/67XlpCcxH2zPmLH8QKEBXrzab87KJE30O5YIlnGO++8A0Djxo0vWz979mx69eqV+YFEcqClf2xgzP8eBsOkSu57+bLna3ZHEhEREblpKrZd5OXlBUBCQoJaKuRACQkJwN//zmJxuVzUm96VbWc+p4D3Y8zq9YIKbSL/oGK9SMY6E5/MuC+P4OUqSoifP+sHzMPhcNgdS0REROSmqdh2kYeHB7ly5eLUqVMA+Pv7YxiGzankVpmmSUJCAqdOnSJXrlx4eHjYHSlL6fDhU2w7uxhw8GijGlQunMvuSCIi4kZSnC4enbeZU+f8qJl7Ch8+VBU/b83mKznP22+/zauvvkpkZCRVqlThzTffpHbt2tfcfsqUKbzzzjscPnyYsLAwOnXqxIQJE/D19c3E1CIicrNUbLtEgQLWbFd/Fdwk58iVK1fav69Yhn/9Dl8enARAj/Kjeb55d5sTiYiIuxn46SJ+3u9PgLcHs3rVp3ieILsjiaS7BQsWMHToUKZPn06dOnWYMmUKLVu2ZNeuXeTLl++K7efPn8+IESOYNWsW9evXZ/fu3fTq1QvDMJg0aZINr0BERG6Uim2XMAyDggULki9fPlJSUuyOI+nEy8tLLdr+Ycn2dby6cQgYUD9/D+Z2HmV3JBERcTOPff4GM3YPJtjzHt69/23K5FehTXKmSZMm0a9fP3r37g3A9OnTWbZsGbNmzWLEiBFXbP/TTz/RoEEDuna1ZuMtVqwYXbp0YcOGDZmaW0REbp6KbVfh4eGh4ozkWAdOR9Jl8X2YRhIFfeqy5qH37Y4kIiJu5qs/N/L2luFgQL0ShWh5W0G7I4lkiOTkZDZv3szIkSPT1jkcDpo3b8769euvuk/9+vX56KOP2LhxI7Vr12b//v18/fXXdO9+7V4ISUlJJCUlpd2PjY1NvxchIiI3TMU2ETfidJl0+nACSeYJfIyCrOu3BG9PfQyIiEjmOXn+HJ0XWhd9CvjU4ssek+2OJJJhoqOjcTqd5M+f/7L1+fPnZ+fOnVfdp2vXrkRHR3P77bdjmiapqakMGDCAZ5555prHmTBhAmPGjEnX7CIicvM01ZOIG5m0chfRkXeSzzmA+fd8SvE8GsdOREQyj8vl4o6ZXUgwD+NFHtb0WYSXLvqIXGbt2rWMHz+eadOm8euvv7J48WKWLVvG2LFjr7nPyJEjiYmJSVuOHDmSiYlFROSf9O1GxE2s2xvNtLX7MDB4r+NztK9UyO5IIiLiZh5Z8iq7YpeD6eDt1h9SLl+E3ZFEMlRYWBgeHh6cPHnysvUnT5685uRdzz//PN27d+ehhx4CoFKlSsTHx9O/f3+effZZHI4r20v4+Pjg46OZfEVEsgq1bBNxA7tOHaXj/D44zXi61I6gfVUV2kREJHP9fHA/M34fDUCHEsPoV6e1zYlEMp63tzc1atRg1apVaetcLherVq2iXr16V90nISHhioLaX+NJm6aZcWFFRCTdqGWbSA7ncrloPvsBTpnryBMYxai7/2d3JBERcTMpThcvfXmcPMlD8M+1kc+6jbc7kkimGTp0KD179qRmzZrUrl2bKVOmEB8fnzY7aY8ePShUqBATJkwAoG3btkyaNIlq1apRp04d9u7dy/PPP0/btm01iZuISDahYptIDvfgghc5mrgOw/Ri1j2T8PPWlzQREclcb63ey+/HYgj3a8KKh0fjqYKBuJHOnTsTFRXFqFGjiIyMpGrVqixfvjxt0oTDhw9f1pLtueeewzAMnnvuOY4dO0bevHlp27YtL730kl0vQUREbpBhulFb5NjYWEJCQoiJiSE4ONjuOCIZ7usdG7l7we2YRgrdy73AB51H2x1Jsgl9XqYfvZfi7j7buo5hCw5iuHIxtUs12lUJtzuSZFH6vEw/ei9FRK5PRn1eqmWbSA6VmJJMt8U9MY0UCvs2YM59z9sdSURE3Ex0XCw9v7ifJO947i36lgptIiIi4hY0QYJIDtXl4+c4l7oThxnIlw9+cNWZq0RERDJS2w8e44J5HE/Dm1fbt7A7joiIiEim0K9vkRzoj+PRfLV/LgADqoyhaqESNicSERF3M2fTCn4+9SEAY+94k6Kh+WxOJCIiIpI51I1UJIdJdbp4ZskuCiROoUDB9bzZfrDdkURExM3EJiYwaPkAMEwqhNzN04072x1JREREJNOoZZtIDvPB+kNsPXKOXL6hfNlrorqPiohIprtv/tPEuw7iSS6+7P6e3XFEREREMpV+hYvkIFuP72f0yvcxMRnRuhwFQnztjiQiIm7mqz9/5tvD0wF4svbLlMhT0OZEIiIiIplL3UhFcpD7Pn6Uo44VlArtQpda8+yOIyIibsblMpm+5iyBzjsJC05ifMt+dkcSERERyXQqtomkF9MFcQcgdifE7oLEE5B0GpLPWo8BOLzAJ8xaAopCcFkILg++eW/58FN+XMyeuBVgOnip5cM4HMYtP6eIiMiNWLj5KNuPuCji/QTL+96uoQxERETELanYJnIrkmMg8ls4tgyOfw1JUTf3PAHFIW8DyHcHFLob/Arc0O7nky7w7JohANTK25n7q9xxczlERERuUtT5eF7+ZgcAQ+4sQ0RooM2JREREROyhYpvIjTBNOL/7YnHtKzj1I5ipfz/u4QtBZawWa/5FrBZs3rnB8LAedyZC8mlIPAVx+60WcPEHIf6AtRz8CDAgTx0o2hmKdwefPP8Zq+enL5BgHsaTXCzq9kaGvHQREZF/c9cH/diRuotqYUPpWb+Y3XFEREREbKNim8h/cSZD1A9w7CuryBa39/LHg8tC+F1Wi7S8t1tdRW9ESixE/wxR/4MTK+D0Rjj9s7VsGQ4RHaHMIKvl21X8cfIQX+ybCgYMqDKKiFy33iVVRETkRizc9gObohaAh4sH6vrj5aHuoyIiIuK+VGwTuZoLJ+D4N3B8GZxYCann/37M4WV19wy/GwrdBUGlbu1YXsFQsIW1VH4REo7BkSWwfxac/Q0OfWIteRtCxWet7Yy/x2N78NNhuIxEcnmUZ0rbJ24ti4iIyA1yuVwM+GoQGC5KBbbk8dvvsTuSiIiIiK1UbEsvLieYzr/vO7wuK4hIFudywukN1rhrx7+2ilyX8s1/sfXaXVDgTvAKyrgs/oWg7CBrOfMr7HkHDnwAUT/C2lYQVg+qT4awOuyKPM+JyNvw8tzIKy1fw0MtCUREJJON+GYGp1N+xzB9+LjzW3bHEREREbGdexbbjnwOQX7W+FuYf99e798XTsD5PXB+LySehOQzkHzu4uMXGZ7WWF0+oeBXGIJKWy2gclWCPLXBO1emvmS5isQoOLHcKq6d+Nb6d7xUaC0Ib2N1Dw2tDoYNhazQ6lBnBlR6AXa8Dnvfhej18G1dKNqVd3Y9gK+zJn3KtaF/3VqZn09ERLI2lxPMFHClWPc9A9L1fBZzIYGpv4wBoGWRftQsfIutvUVERERyAPcstq3vCf4ZfAwz1ZqZMinKGgT/5KrLHw8uC3kbQXgryN8MvEMyOJCQct6a0ODkKji5Gs5uufxx79xQsKVVYCvYEnzz2RLzqvwLQY1JUH4YbHsW9s/FPDifcV5LCAnrQ5/WE+xOKCIidnE5IWa7dV47uwVid1hDElw4fuWFJAzwCgG//BBYCgJLQq6KkKcuhFQEh8cNHfqhRWNJ4gRe5OHD+19Kr1ckIiIikq25Z7EtrB4EegGGtRjGjf3tG2a1VAssBf6FwTvUKtR4+F48gAmp8dYX3KRoiD98sSXcbqtbYNw+qwAXuwv2zbBmqgyrb43FVaA5hNYEh3v+06QrZ6I18UDkxeLa6Y2XzxwKkLuaVVwLb2O1OMzq77t/ONSdTUqJR2gwuwn3BSYwssDb+G7ZDnVm3vr4cSIikj0kHIdjSyFyJUSuhpRz17mjaW2bcs76HnIpzyBrop/C7aBQO+uc8y/OxiexbO8iMKBv5RGEBQbfxAsRERERyXmyeGUhgzRdDsEZ/IXQO5fVGulqEqOtmSYjv7O6McbussbjivoRtj1vDZifv4nV4q1Acwgup/HfrkfyOauLZdQ6azn9s1Vwu1RgScjf9OLSxLqynw09tWE9mxIT2JboTa9cHvie+h6+rgLVX4dSD+u/FxGRnCg5Bo4shoPzrItIlw5f4RVsXUDKVcUasiKgCPiFW620HT5/z5SdEmudLy8csy7+nd8DZ36zxi1NPQ8nvrGWTY9YFydL9oUincEr8Io4b63ZR97EiQSFrueNtoMz4x0QERERyRbcs9hmN98waxywQndb9+MOwIkVVvHt5GpIPgtHv7AWsL4oh9W3lrz1IbTGJa3o3JRpQvzBvwtr0evg3HYu++EB4FfwYmGtGRRoCgFF7UibruKTE3n3t5cBaFHsMfK2Hwgb+sLJNdaPo6NfQJ33/7NFgoiIZAOuVGtc0QMfwLEvLr+IlKfu3xP3hNa8vi6gnv7gVwBCygHNLjnOxa6ox7+xWsxF/2xdwIpeD5sHQ7EHraEMgkoCcOh0PB+sP4iBF9M6DMPbU18pRURERP5imKZp/vdmOUNsbCwhISHExMQQnNEt226WywnntliFt8jvrDHGXEmXb+Pwgtw1rG6PuatCaDUIrgAe3nYkzhwXTsKZTXD6F+v2zC+QeOrK7QJLQb7bIayB1RUmuGyOa+XVd+F4Zv3xLJ7k5viTB8kbGAymC3ZNhS0jrP9evHNDrXegaGe740o2lS0+L7MJvZdyw0zTmhX7wAdw6OPLz3fB5aH4g1C0CwQWz7gMF07AgQ9h30yr9RtYEysU6QwVn6H9wv+xZW84jUrn58O+dTIuh7gVfV6mH72XIiLXJ6M+L1Vsy+qcSXBmM0T/BFE/WS24rlZkcnhZAxvnrgoht1lFpqCy1hfxrD4O2aWcydbYdjF/WMu5363Xn3Dkym0NT6uVX96LhbWw+tm2W+j1OnchnvwTi5FMNF3LjGZelxcu3yDmT1jfw3rPwPoxVvMta1ZckRuQLT8vs6h0fy9Nl9UNMPmstfzV0skwwMMPfPKAd56Ls07mrIsNOZppwrmtcHgRHFkIsTv/fswnLxTrCsW7Q+7qmfvvappw6nv4c6LVvRTYkgTVDoOvWZB1fX+lekSBzMsjOZrOPelH76WIyPXJqM/LbFSFcVMePlbX0bz1oTwXu08esApvZ361rnyf3WINdPzXLGSXcnhZ45QFl4WA4tYYLv4R4F/E+ts3n3WlOjOlxELcQasbaPxBqxtt/EHrh8X5PWA6r7KTYY1dl6eW1VUmTy1rXBpPv0yNbrcBS14mmWi8ycu0Dk9fuUFIBWixHraPgz9eslpEnPoe6s62JuAQEfv8NgICva3PcS4uN/J38hk4v9caZ+uf41FejWeQNZlPcBnrYkxYXQitpdmvsxLTtFpqH14IRxZZ/7Z/cfhA4Q5Wga1gi7/HXMtshgH5G1vL2S2wfRyjNiwCoG3QSaqfew8KPuV252MRERGRf6NiW3ZjGBBYwlqKP2itM02IP3Sx2PabVbSK3WW1EHNeuHh/59Wfz+FtFdy884BP2CVLHvAKslpJePhbt57+1pd/66D8/SMQcCVDapw1C+ult0nRVku8pCjrNvEUOBP+/TV6BVs/DEMqXGytV93qKuvl3lflziZcYNGeaQD0vO1JQvz8r76hwwsqj4Hwu2B9d+u/gzUtofSjUG2i1dpFRDLfnnfgGv/b3hTPgIszYV8scpgu6/M16fTFz+TzcPZXa0ljQK7KEN7aWsLq2VfEcVep8dbsoce/huPLLm+57eELBVtDkU7WuK5Z7byXuypzfPvzZfwiPIBxeVzw+2jYPwdqTIFCbdWaUkRERAQV23IGw4DAYtYS0eHv9aYLEo5ahbfYXZBwCOKPQMJhiD8MiSesH2QJR60lM/mEQUAxawksfvG2JOSqCH6F9GX9Kj5af5S8ieNwBH57fbO+hdWG1r/BlpGweyrsmWZNxFHjDWtAbRHJXOWGQKDvxc+3i8t//X3pOq8ga1zKoFLgX9hq+Xw1pmkVdBIOW62FY3dbF2Kif7ZaRp/bai1/vmwVcwo0twbYL3Bn2uD3ko5M07rocXy5VWA7tdY69/7FM8C6OFKkk1Vou8qsn1nJiFXPAFAhVwfKNHkAfhtm/Xf1Q3srf403ILi0zSlFRERE7KUx29yZKwUuHIfEKKslRFL030vyaUiJs1rGORMgNeHi35eMDXTpj0LDy/qB4BkAnhdvPQKsmVd98lmt5/5afPJl+R8TWc35xBRuf2UNMRdSmNqlGu2q3OBMo5Hfwc+9/y6qht8F1SfrB5Fckz4v00+Wei8vnLQ+D058YxXfk6IvfzyguFV8K3inNZOzTx57cmZnpglx+62i2sk1cHItXDh2+TYBxazP4fDW1vucTbpgvrluCY9/1xFMT9b3/p26RctZ3xX+GA87X7O+Vzi8odyTcNuzakktNyxLfV5mc3ovRUSujyZISAc66Uh2Nem7bUz97ggl8gawcsgdeDhuouVfynlrLLddky/+IPKCsk9AhZGaQEGuoM/L9JNl30uX05pMJfJbiFxpjQVqpl6+TXA5awKavA2sWZ6DSqnl8T+5UuDcNojeYLUePLX2ykl9HN7W+xh+F4S3yZYzZbtcLvJOqMyZ1D+oFdaFjQPnX75B7G7Y/AScWG7d9y8M1V6HIvdlu9cq9smyn5fZkN5LEZHro2JbOtBJR7KjyNizREwujk9qTaa3ncqDtSvc2hPG7obNg9NmlcMrGMoNg3KDrW5qIujzMj1lm/cyJc6aUCVypbXE/HnlNr75IE9dCK0OuatZt+7U9d+Vak1ScW4rnN4IpzdYBct/TlhheEJYHcjXxJpYIKx+tmm9di1fbd9Lp087kuzYzdaHd1KpYLErNzJNOPaldY6JP2Cty98EarxpDRMh8h+yzedlNqD3UkTk+mg2UhE3NfCLl0klBi+v3dxXLR26fQaXgcbLrLGDtj5jtcj4fZQ1rlv5p6H0w1lvUG4RyXhegdZ4jn+N6ZgYDdE/QdQ6iPqfNWtm4ik4ttRa/uKT1yq85a5stYT7a8nOXVBNl9U67fweOLfd+pw8tw1i/rj6TLBeuSBPbavA9ldLwBzUhdI0TWasjSR/8njureV19UIbWEXXwu2s8f92vAp/TrC60n5TBco8DpVGazZcERERcQsqtolkYafjz7N0/3sA9Kk8BB+vdJo10DCsH9ThreHwZ7BtlDWA95an4Y9xUOphKPu41Q1IRNyTb5hVOCnczrrvTLRacZ3+5eIsp79Zrd+Soi52Rf328v19wqyiW2BJCCgKAUXAv8jft3a29DJdVuHwwrGLkwQds8ZZO7/HWuL2gyvp6vt6+EOu2yC0BuSpA2F1Iag0GI7MfQ2ZaO3uKLYejcHfy5NnWjb+7x08/aDSKCjeA34dCkeXWEMYHJoPlcZAid7g4Z3huUVERETsomKbSBb22NLXSOUcPkYBJrZ5NP0PYDigaGeIuBcOfgR/vgKxO60WCTsnQ5H7oVR/yNfIfbqJicjVefhaLbbyNvh7XeoFOPe7VXyL+dP6/IjdZc2EmhRttYiL+t/Vn88rF/jmtYpyPhdvffOCV8jFyXYuTrTz198OL6xJeRz8PVOrA8wUqxB46eJKhOQYSD4LyWcuv71wwlr+OT7dPzm8rAkjQipCrspWy71clSGwRI4urP2Ty+ViyFcTcVKd7vWqERZ4jVlwryawGDRaDMdXwObHrYs6mwZYLd5ue94qxjnS6SKSiIiISBaiYptIFhVzIYGFu6cB8GCFx/H3voEfODfK4Qklelk/fI5/YxXbTn1vtUI4NN9qtVGyLxR7EPwLZVwOEclePP0grLa1XCo13hofMnanNXZX/GFrSTgE8Yesx1POWcv5PXYktwpmvgWsMef8C1kzhAaVtiaBCCoN/hHWZ6Obe3v9UrbGvY7DN4iudQ/e3JOEt4T8v8Pe6fDHBOu/gQ0PWbOYVnwOinVTSzcRERHJUfQtUiSLGvLVG6QQjRd5mHz34Mw5qOH4e8ym07/A3vfg0MfWj+EtI6wlrD4U6WS1hgsokjm5RCR78QyA0GrW8k+mabUwSzxptX5Lirp4Gw2JUZASaxXjUuPBGf/3364UwLS6gP51a7qsllEeflbLu78Wh4/VQs47tzXbsndu8L5465vfKq75FlAx7TqM+2EcANXztqFY6C3MXO3hbQ1PULKfVXT782Wru+6GPrDteWt27FL9NaabiIiI5Aj6limSBSWnOlmw430A7i83kCBfG8Y2ylPTWqpPgsOfwv7ZVnew6J+s5dehEFLBGgi7wJ1WV1PNZioi/8UwrAKYzy0UbiRTvL/xG04lbwbTk7fbvpg+T+rpB+WGWIW1Pe/AjtetsfO2PA3bx0KpflZRLqBo+hxPRERExAYqtolkQd9sjyQ04SVy+69katth9obxCoSSfawl4RgcWQxHFsKpH60xmmL+hF1vAIZVfMtTC0JrWQOIB5UF33wa701EJBsatcYqsFUObUftImXS98k9A6D8MCjzGBycDztfs84nOydZY4aGt7Ym6wlvoxaIIiIiku3o24tIFmOaJu/9sB8PAhl2+3BC/bNQazH/QlD2MWtJOgMnV0PkSjix0hqXKeYPa9k/5+99vIKt8Y8Cil2ciTDCuvWPsLqh+uZzq8HGRUSyg/m/reZ44s9gOnjr7jEZdyAPHyjZ2xo39MRyq6XbyVVw/Gtr8StkjRlaoqc1OYWIiIhINqBim0gWs3LHAbYfj8Hfy5NudbJwNxqfUGvstiKdrPsXIuH0JjizyRrv7fwuiD9ojb90ZrO1XI3DC/wKg19Bq/Dmmw988v39t29+a6ZC79xW4c4zQC3lREQy2MjvXgCgQshdNCxxW8Yf0DCs1mzhra3JNfbNsIYvuHAMtr9oLXnqQLGu1kzZfgUyPpOIiIjITVKxTSSLefCLDsT4JNO7/HhyB2Sj2dn8CkDhttbyF2eSNQD2+d0XZyI8DPFHLt4ehsQT1qDn8Qes5XoYHlbRzSvkktuQSwZH97EGR3f4XH7fcADGJYU645L7xj8eu4RpXiXEda67Yt+b3e86903PrHGJV9lPRNzBn8fPcSbWH8PDhyl3vZD5AYLLQLVXofI4a+iCfe/DqTVweoO1/DoE8jWGQu2sCX2CSmV+RhEREZF/oWKbSBby8ZbviEr+HQxP+tavanecW+fhAyHlreVqXClw4bhVgEs8CUmnIPGS5dL7Kecuzj7otGYyTD6bqS/F7STYHUBE7PLuDwfIk/IYD5R5hjvLVLcviIcPFOtiLRcircl6Dn4Mp3+2hjE4uRp+HQzBZSH8bijYEsLqWWONioiIiNhIxTaRLGT06gkAlAtuQ60ibjA2jcPLmnHuemadM01wJkByDKT8tcRat8kx4EwEV5K1OJP+vu+8uM50kdaiyzQv/m1e+fdVu6he57rr2vdm98uE5790XXwyMPcq24hITnb0bAJfbTsBwBNNq9ic5hJ+BaxZSss+brWYPvoFHPsKTv0AsbusZefrYHhCaA1rhux8d0Ce2uCb1+70IiIi4mZUbBPJIjYc/oM9sWvAgLHNhtsdJ+sxDGu8Ns8AINzuNDlfbCwqtom4n6FfvsMF04umpepwW6EQu+NcXWAJKDfEWpJjIPJbOLYMTq2F+EN/dzfd8aq1fUBRCK1pLXlqWsU479y2vgQRERHJ2VRsE8kihix7CQyTAt516VSlvt1xRETEzRw9d4ZF+0fj8o2nTvmldse5Pt4hUOQ+awGr2HbqBzj1PUT9z2rxFn/IWo4s+nu/gKIQUvEfS/mLF3REREREbo2KbSJZwOFzJ/n55GIwYEjdJ+2OIyIibmjIV5NwGfEEOIrwaL02dse5OQFFoXh3awGr5dvZX61Zss/8Ys2aHX/g7wLc8a8v2dmAgCJWy7mA4tZt4MXbgGLWDNmGw45XJSIiItmMim0iWcDwr9/ENJIIdJTiyUYd7Y4jIiJuJj4piaX7ZgDwYMWBeDg8bE6UTrxDIH8Ta/lL0mmI+cNazv3x999JUX8X4Vhz5XMZHuCbH3wLWGPI/XXrHWrNiu0d8vcM2V7B4BkIDm9rfFKH999/X3UcTREREclJsl2x7e233+bVV18lMjKSKlWq8Oabb1K7dm27Y4nctFSni8OH7yAsyUnfBhXw8NBVcxERyVzPrphBMqfwJBcT2wyyO07G8slzcQKFRpevT4yC87sh7oC1xO+/+Pd+SDhqzYZ94bi13MqE2IanVbgzHBdbyjn+/ttwWI9duu5af192/+LzXXXymxth3uL+tyjeae/xRURE0km2KrYtWLCAoUOHMn36dOrUqcOUKVNo2bIlu3btIl++fHbHE7kpy/+I5Ni5ZCICmvJCi6Z2xxERETfjcrmYtXUqAK2L9SbY19/mRDbxzWsteRtc+ZgrxSrGJZ6AC5GQGGndXjgByWf/nh37ryU5Bpzx1n7/ZKZai1wpwe4AIiIi6SNbFdsmTZpEv3796N27NwDTp09n2bJlzJo1ixEjRticTuTGOV1O3v1+FwA96hXF1yuHdNsREZFsY8r/lnDetQfD9OGNtk/bHSdrcniBf7i13AjTtFrEuZKtwpsr2VpMF+Cybk3nxdtL193I45dsg4sba912ndtmVtfX8wlAp8w5loiISAbKNsW25ORkNm/ezMiRI9PWORwOmjdvzvr166+6T1JSEklJSWn3Y2NjMzynyI2Yuu4zvjk9kFDv++led4rdcURExA0t2bobDzOUmvlaUTy0gN1xchbDsLqNOrLNV2576bu6iIjkENlmcKjo6GicTif58+e/bH3+/PmJjIy86j4TJkwgJCQkbYmIiMiMqCLX7dWfXsdpnKFE/gTyBPrYHUdERNzM9mMxHDlWmSLJs5h172t2xxERERHJEbJNse1mjBw5kpiYmLTlyJEjdkcSSfPFH//jROIvYHrwWuuR/72DiIhIOpvx434A2lYuQoX8BW1OIyIiIpIzZJtiW1hYGB4eHpw8efKy9SdPnqRAgat3efDx8SE4OPiyRSSreGblBABKBjbn9hLlbE4jIv/m7bffplixYvj6+lKnTh02btxodySRW7b56D4+2f4pJk76NSxhdxwRERGRHCPbFNu8vb2pUaMGq1atSlvncrlYtWoV9erVszGZyI3bcnwvf55bDsDoJsNtTiMi/+avmbBHjx7Nr7/+SpUqVWjZsiWnTp2yO5rILRny1QROeb2MEfoWtxUKsTuOiIiISI6RbYptAEOHDmXGjBnMnTuXHTt28MgjjxAfH582O6lIdjH4q/FguAjzqs6D1RvbHUdE/sWlM2FXqFCB6dOn4+/vz6xZs+yOJnLTjp47w7rITwDoX7O7zWlEREREcpZsNTVS586diYqKYtSoUURGRlK1alWWL19+xaQJIlnZ6fjz/HhiAQCDag3BMAybE4nItWgmbMmphnz1Oi4jngBHEYY37mp3HBEREZEcJVu1bAMYNGgQhw4dIikpiQ0bNlCnTh27I4nckK+3nSZ/4ssU8ryfZ5p2sTuOiPwLzYQtOVF8UhJL980E4MGKA/FweNicSERERCRnyXbFNpHszOkyef9/B/A2S/BSk1fw8tAPHJGcRjNhS1b37Ir3SOYUXuRmYptBdscRERERyXGyVTdSkexu+R/HOXg6gRA/L+6rWdjuOCLyH252JmwfH5/MiCdyw1wuF7O2vglAq2K9Cfb1tzmRiIiISM6jlm0imcQ0TXosbUW01xu0q+6Lv7dq3SJZnWbClpxm2R97SU7xwDB9eKPtU3bHEREREcmR9GtfJJO8t2EpZ1K3Y3jsoVudknbHEZHrNHToUHr27EnNmjWpXbs2U6ZM0UzYkm0t2HCWAsmv0bGmD8VDr946U0RERERujYptIplk/A+vAlA1tAPl8hWyOY2IXC/NhC05xR/HY/jf3mg8HAZDm9W3O46IiIhIjqVim0gmWLn7Fw5fWAemwcRWI+yOIyI3aNCgQQwapIHkJXsb+fVsnBSgXaWyFM6tsdpEREREMoqKbSKZ4OkVEwAo4n8HzctUtTeMiIi4nV+O7OHLo8MwfD1pW/1Xu+OIiIiI5GiaIEEkg+04dZitp5cC8Gyjp21OIyIi7mjIsglgOAnzKc+dZSvYHUdEREQkR1OxTSSDDflqIqaRSm7P2+hXp5XdcURExM0cjTnNT5ELAHiizlCb04iIiIjkfOpGKpKBElOcHD96ByEpZxlUtxWGYdgdSURE3MyQL1/HZSTg7yjCiMZd7Y4jIiIikuOp2CaSgZb8dozYBH8q5urLqOaN7Y4jIiJuJj4piaX7ZgLwYMWBeDg8bE4kIiIikvOpG6lIBnE6Xcz4cT8AfW4vjqeH/ncTEZHM9eyK90gmCk9yM7HNQLvjiIiIiLgF/foXySBjV8/lp5jHwHcrnWtF2B1HRETcjGmaLPtzC5getC7WixDfALsjiYiIiLgFFdtEMshbmyaT5LGd4uGHCPRRj20REclcP+6JJuVcR0q5ZvNm25F2xxFxa2+//TbFihXD19eXOnXqsHHjxn/d/ty5cwwcOJCCBQvi4+NDmTJl+PrrrzMprYiI3CpVAEQywNzN33I65XcwPZly9wi744iIiBv6ayiDB2tVp2hoXpvTiLivBQsWMHToUKZPn06dOnWYMmUKLVu2ZNeuXeTLl++K7ZOTk7nzzjvJly8fCxcupFChQhw6dIhcuXJlfngREbkpKraJZIAX104EoGKuu6gSXtzmNCIi4m5W7NzKqr2b8XMUo08DnYdE7DRp0iT69etH7969AZg+fTrLli1j1qxZjBhx5UXZWbNmcebMGX766Se8vLwAKFasWGZGFhGRW6RupCLp7McD29l/fg0A4+9Utx0REcl8Q755jhO+A8lfaDkRof52xxFxW8nJyWzevJnmzZunrXM4HDRv3pz169dfdZ+lS5dSr149Bg4cSP78+bntttsYP348TqfzmsdJSkoiNjb2skVEROyjYptIOnvy6wlguAj3qUu7inXsjiMiIm7mlyN72BHzDQCD6newN4yIm4uOjsbpdJI/f/7L1ufPn5/IyMir7rN//34WLlyI0+nk66+/5vnnn+f1119n3Lhx1zzOhAkTCAkJSVsiIjQ5l4iInVRsE0lH+0+f4JeoRQAMa/CkzWlERMQdDf36ZTCc5PWuStdqTe2OIyI3yOVykS9fPt577z1q1KhB586defbZZ5k+ffo19xk5ciQxMTFpy5EjRzIxsYiI/JPGbBNJR19tjSFPyuN4B2zliQYd7Y4jIiJu5mjMadad+AQMeKLOULvjiLi9sLAwPDw8OHny5GXrT548SYECBa66T8GCBfHy8sLDwyNtXfny5YmMjCQ5ORlvb+8r9vHx8cHHxyd9w4uIyE1TyzaRdJKU6uTD9UcJcN7Bm63ex+HQ/14iIpK5Bn/5Gi4jAX9HEYbf0dXuOCJuz9vbmxo1arBq1aq0dS6Xi1WrVlGvXr2r7tOgQQP27t2Ly+VKW7d7924KFix41UKbiIhkPaoGiKSTz387RtT5JAoE+3J35XC744iIiJuJS0pk6b6ZAPS47TE8L2kVIyL2GTp0KDNmzGDu3Lns2LGDRx55hPj4+LTZSXv06MHIkX9PqvXII49w5swZnnjiCXbv3s2yZcsYP348AwcOtOsliIjIDVI3UpF0kOp08siKe8GzCsPqDcHbU3VsERHJXO+u+xGnmYqXEcrE1vpRLpJVdO7cmaioKEaNGkVkZCRVq1Zl+fLlaZMmHD58+LIeEREREaxYsYIhQ4ZQuXJlChUqxBNPPMHw4cPtegkiInKDVGwTSQfjV3/EWecvODx30LH6RLvjiIiImzFNkxVbvSmcOIvuDb0I8vWzO5KIXGLQoEEMGjToqo+tXbv2inX16tXj559/zuBUIiKSUVRsE0kHUzdNAqBheBfCQ0JtTiMiIu5m7a4odp+MI8jHn6ebaQZSERERETupr5vILZr7y7ecTtkGpidv3D3yv3cQERFJZ2NXLsTERZfaEQT7etkdR0RERMStqWWbyC0as+ZlAG7LfRdVwkvYnEZERNzNvF9Xs+bMQLx9itK93ja744iIiIi4PbVsE7kFq/Zs4UD8WgAmtnjW3jAiIuKWRq+ZAEDJ3JUoEhpscxoRERERUbFN5BY8tXw8GCYRfg1oXb6W3XFERMTN/Lh/O/vOrwbg5TufsTmNiIiIiIC6kYrctKjzSUSfaoA/kYxsOMzuOCIi4oaGfjMODBeFfOvRrmI9u+OIiIiICCq2idy0D9YfxJFSiuYRExhQt77dcURExM3sjjrG5qglYMDwBk/bHUdERERELlI3UpGbkJCcyoc/HwJgQKMSGIZhcyIREXE3j3/5MqaRTIhHOQbWb2d3HBERERG56IZbtkVHRzNr1izWr19PZGQkAAUKFKB+/fr06tWLvHnzpntIkazm4cXj2Zeyngq5H6RFxQJ2xxFxa0eOHGH06NHMmjXL7igimeZCspOfjvwMwMPVn8Dh0PVTERERkazihr6Zbdq0iTJlyjB16lRCQkJo1KgRjRo1IiQkhKlTp1KuXDl++eWXjMoqkiWcT7zAgl1TifNcTqWSR/FwqFWbiJ3OnDnD3Llz7Y4hkqk+3niY3BdGU8l7MmPu7GN3HBERERG5xA21bHvssce47777mD59+hXd5kzTZMCAATz22GOsX78+XUOKZCVPLptKCqfxIozX73rM7jgiOd7SpUv/9fH9+/dnUhKRrCE51cV7P+zHwGB403vw9fK2O5KIiIiIXOKGim1bt25lzpw5Vx2fyjAMhgwZQrVq1dItnEhWk5iSzId/TAWgY+kBhPj525xIJOfr0KEDhmFgmuY1t9G4ieJOJn+/guOxsRQIykOnGoXtjiMiIiIi/3BD3UgLFCjAxo0br/n4xo0byZ8//y2HEsmqnvv2fRLN43gQzNS2w+yOI+IWChYsyOLFi3G5XFddfv31V7sjimSaxJRkxqzrx1HfPjSpfAYfTw+7I4mIiIjIP9xQy7Zhw4bRv39/Nm/eTLNmzdIKaydPnmTVqlXMmDGD1157LUOCitjN6XTx7q/Wf98ti/QhX1CIzYlE3EONGjXYvHkz7du3v+rj/9XqTSQnee7bmVwwj+FhBDG0cQu744iIiIjIVdxQsW3gwIGEhYUxefJkpk2bhtPpBMDDw4MaNWowZ84c7r///gwJKmK38WvmEefaj8P0Z1r7kXbHEXEbTz31FPHx8dd8vFSpUqxZsyYTE4nYw+lyXnbRJ39QLnsDiYiIiMhV3VCxDaBz58507tyZlJQUoqOjAQgLC8PLyyvdw4lkFaZpsm5HboJTOlO3eAGKhuazO5KI22jYsOG/Ph4QEMAdd9yRSWlE7PPS6nnEuQ5cvOjzjN1xREREROQabmjMtkt5eXkRHx/Ptm3bSE1NBVA3Hsmxftp3mp3HDArQk4/uf8XuOCJube/evaxYsYILFy4AOveIe3C5XEze8DIADcO76qKPiIiISBZ2U8W206dP06xZM8qUKUObNm04ceIEAH379uXJJ59M14AiWcFbq/cC0KV2EfIG+dicRsQ9nT59mubNm+vcI27prZ8+51zqDgzTm7fbPW93HBERERH5FzdVbBsyZAheXl4cPnwYf3//tPWdO3dm+fLl6RZOJCuYtWk5S44+RIrHNvo1KmF3HBG3NWTIEDw9PXXuEbc0a+NqMB3UytuJigWK2B1HRERERP7FDY/ZBvDtt9+yYsUKChcufNn60qVLc+jQoXQJJpJVPLf6BZI8/iAszyYK5fKzO46I29K5R9zV+n2nOXeqNcU8avBuh8Z2xxERERGR/3BTLdvi4+Mva1XwlzNnzuDjoy52knPM2rScE4kbwPTg7XZj7Y4j4tZ07hF3NeW73QA8WKsWVQsVtzmNiIiIiPyXmyq2NWzYkA8++CDtvmEYuFwuJk6cSJMmTdItnIjdnlv9AgCVc7fj9uIV7Q0j4uZ07hF39MEv3/Pjwd/w9nDwaJOSdscRERERketwU91IJ06cSLNmzfjll19ITk7m6aef5o8//uDMmTOsW7cuvTOK2OLyVm3j7I4j4vZ07hF343K5ePLbwUT7bKVtkTEUDGltdyQRERERuQ431bLttttuY/fu3dx+++20b9+e+Ph4OnbsyG+//UbJkrrqKjnDc6teAKBy7vbcXryCvWFEROcecTtv//QF0SlbMPDghRZd7I4jIiIiItfpplq2AYSEhPDss8+mZxaRLGPuLys5kWS1apumsdpEsgyde8RduFwuxvzwAgA1895H9cKlbM0jIiIiItfvuott27Ztu+4nrVy58k2FEckqVvzmT57koZQrfIEGatUmYhude8RdvfG/xZxO2YZhejHjHg1lICIiIpKdXHexrWrVqhiGgWmaGIaRtt40TYDL1jmdznSMKJK5Nh08w0/7zpHL0YyPOze2O46IW9O5R9yRy+Vi3I9jAKiV736qhJewOZGIiIiI3IjrHrPtwIED7N+/nwMHDrBo0SKKFy/OtGnT2LJlC1u2bGHatGmULFmSRYsWZWRekQw3aeWfANxXszARof42pxFxbzr3iDua9ONnnEndjmF6M6ODhjIQERERyW6uu2Vb0aJF0/6+7777mDp1Km3atElbV7lyZSIiInj++efp0KFDuoYUySwzNnzDZ0d7EOrVhYFNXrY7jojb07lH3I3LZfLxpl04zGBq529P5fDidkcSERERkRt0UxMk/P777xQvfuWXv+LFi/Pnn3/ecigRO7hcLp5d/QxORzThYcconFut2kSyEp17xB18sz2S09E1KO09i3n33W53HBERERG5CdfdjfRS5cuXZ8KECSQnJ6etS05OZsKECZQvXz7dwolkpsk/fkZU8hZrMOoOatUmktXo3CM5XarTxevf7gLg4YaVKBGW3+ZEIiIiInIzbqpl2/Tp02nbti2FCxdOm/1t27ZtGIbBl19+ma4BRTKDy+Vi7I+jAKiTvwu1IkrbnEhE/knnHsnphi+byfYzhyjkfwcPNVT3UREREZHs6qaKbbVr12b//v3MmzePnTt3AtC5c2e6du1KQEBAugYUyQzPfzuLGOduHKYfs+99ye44InIVOvdITnY2IY63fnuOZJ8o7i6XmyDfFnZHEhEREZGbdFPFNoCAgAD69++fnllEbJGYksyUjdZsb80ielMuX2GbE4nItejcIzlV/8XjSSYKb/Iyqe0jdscRERERkVtw3cW2pUuXXveTtmvX7qbCiNhh3KqFJJiH8SCI9zuNsTuOiFxC5x5xB0diolmy7y0A+lQeTi4/tdQUERERyc6uu9jWoUOH69rOMAycTufN5hHJVEmpTtZsKUCBxNdpV8ObiJAwuyOJyCV07hF30Puz53FyHn+jKJPvfszuOCIiIiJyi6672OZyuTIyh4gt5v18mGPnLlA0uApvtG9sdxwR+QedeySn2x55iNVHZ4MBQ+uMwtfL2+5IIiIiInKLHHYHuB4HDx6kb9++FC9eHD8/P0qWLMno0aNJTk62O5pkYyfPxzB59U8APN6sNL5eHjYnEhERd9Nj4dOYRhK5PMsz5s5edscRERERkXRw3S3bpk6dSv/+/fH19WXq1Kn/uu3jjz9+y8EutXPnTlwuF++++y6lSpVi+/bt9OvXj/j4eF577bV0PZa4j76LxrDd9RYlgvtwX83WdscRkauw89wjktH2nDzPiROV8PLcyEtNJuBwZItroCIiIiLyHwzTNM3r2bB48eL88ssv5MmTh+LFi1/7CQ2D/fv3p1vAa3n11Vd55513buhYsbGxhISEEBMTQ3BwcAamk6xu16mjVJhWFpeRwNAab/H63QPtjiSSpWSVz8usdu65GVnlvZSsp/fsjazZFcWd5fMyo2dtu+OI2E6fl+lH76WIyPXJqM/L627ZduDAgav+bZeYmBhCQ0P/dZukpCSSkpLS7sfGxmZ0LMkmun/2NC4jgWCPsrzSeoDdcUTkGrLauUckvfy4O4o1u6LwdBiMbFPB7jgiIiIiko5uqr/Ciy++SEJCwhXrL1y4wIsvvnjLof7L3r17efPNN3n44Yf/dbsJEyYQEhKStkRERGR4Nsn6Vu3dwqaoTwEY1/hlPD00VptIdmD3uUckvSSnptL+0+bEeH5K59r5KZE30O5IIiIiIpKObqrYNmbMGOLi4q5Yn5CQwJgxY677eUaMGIFhGP+67Ny587J9jh07RqtWrbjvvvvo16/fvz7/yJEjiYmJSVuOHDly3dkk5+r3+VAwnBT2bcBjt3ewO46IXKf0OvdcL03OIxnliaVTOOvcRqznYvrcHm53HBERERFJZ9fdjfRSpmliGMYV67du3fqfXTsv9eSTT9KrV69/3aZEiRJpfx8/fpwmTZpQv3593nvvvf98fh8fH3x8fK47j+R872/8hgPxa8B0ML3dZLvjiMgNSK9zz/XS5DySEU6eP8f7v08AoGOpxygZVtDmRCIiIiKS3m6o2JY7d+60FmdlypS57EeP0+kkLi6OAQOuf/yrvHnzkjdv3uva9tixYzRp0oQaNWowe/ZszdglN8w0Td7+8QcM04fKoXdzV/ladkcSkeuQ3uee69WqVStatWqVdr9EiRLs2rWLd955R8U2uWk9Pn2OFM7gaxTk/U7P2R1HRERERDLADRXbpkyZgmma9OnThzFjxhASEpL2mLe3N8WKFaNevXrpHvLYsWM0btyYokWL8tprrxEVFZX2WIECBdL9eJIzff17JGeibqekd0Xm3d/I7jgicp3sOvdcjSbnkVux5fg+Vh6ZCQYMrjWGYF9/uyOJiIiISAa4oWJbz549AShevDgNGjTA0/Pfd3/55ZcZMGAAuXLluumAACtXrmTv3r3s3buXwoULX/aYaZq39NziHpJSnbyy3Br/b2Cj2lQsUMTmRCJyvew69/zTX5Pz/FertgkTJmTIGHKS/XVd8ASmkUSoZyVeatnX7jgiIiIikkFuqi/mHXfc8Z8/dgDGjx/PmTNnbuYQl+nVqxemaV51EbkeQ5a+y+5zG8kX5EP/RiX+ewcRyXLS69yjyXnEDsv++J0dMSsAmNpmsobDEBEREcnBbmqChOulYphkBQdPn+S930fg9DlPzyqz8ffO0P/sRcRm/3Xu0eQ8ktmcLpNpq84RnvQ2FYrvp1u1ZnZHEhEREZEMpKqD5HgPLHgSJ+cJdBTnxVbd7I4jIjbT5DyS2RZsOsIfx2MJ9S3Kx1172h1HRERERDKYim2So32zcxMbTn0MBrxwx0R8PL3sjiQi2YQm55H0cOjMKcYs/xIoxtA7yxAWqFaPIiIiIjmdim2SY7lcLvp+8RgYLor4NeLJRp3sjiQi2Ygm55H0cN/Hg9ltfkKpXH15sG5ru+OIiIiISCZQfxjJsSasnceJxA1gejK345t2xxGRbEaT88it+uKPn9gUtQAMk8dvb4OXh752iYiIiLiDm/rW17RpU8aMGXPF+rNnz9K0adO0+w0bNsTPz+/m04ncpLikRF763zMANArvSeNSlW1OJCK3SuceyU5cLhf9lg4Ew0WJgGY8dvs9dkcSERERkUxyU91I165dy++//85vv/3GvHnzCAgIACA5OZnvv/8+bbuvv/46fVKK3KB5Px/FP6kzhvdS5nd+xe44IpIOdO6R7GTE8neJSt6CYfow//637Y4jIiIiIpnopvszfPfdd0RGRlK3bl0OHjyYjpFEbk3U+STeXL2PQGcTZrX5jkIheeyOJCLpROceyQ6Ox5xhyqZRALQqOoA6RcranEhEREREMtNNF9sKFizI999/T6VKlahVqxZr165Nx1giN+/l5b8Tl5RK5cIh3Fcjwu44IpKOdO6R7ODe+YNJIRpfoyDzOo+zO46IiIiIZLKbKrYZhgGAj48P8+fP54knnqBVq1ZMmzYtXcOJ3KhPtqzljT9aEefxHaPbVsThMOyOJCLpROceyQ62H4th77FQHGYg4+6YTG7/QLsjiYiIiEgmu6kx2/45E9tzzz1H+fLl6dmzZ7qEErkZqU4njy57FKdxmjx5dlKjaG67I4lIOtK5R7I6p8vk2SW/E5B6J/eWu5cn72hodyQRERERscFNFdsOHDhA3rx5L1t37733Uq5cOX755Zd0CSZyowZ+/hpnU3fgMP349AG1dBHJaXTukaxu3s8H2Xo0hiAfT15sX8vuOCIiIiJik5sqthUtWvSq6ytWrEjFihVvKZDIzdgbdZz3t78EQKfST1IlvLjNiUQkvencI1nZ9siD9P+2KcGObrzY6iHyBfnaHUlEREREbHLTEySIZCWdPn4cJ+cJdJRgzv3P2x1HRETcTMf5A0gyDpLsv4gutTU5j4iIiIg7U7FNsr0PNq9k65nFALx+55v4eXnbnEhERNzJ6z98yp7zK8B08O7d0/Hy8LA7koiIiIjYSMU2ydacLpOXvlsIhkmFkLb0r9vG7kgiIuJGzibE8dzaIQDUydeVzlXvsDmRiIiIiNjtpsZsE8kqPvr5EEln21HCtwyfdbnP7jgiIuJm7vloCInmcbwIY3G3N+yOIyIiIiJZgFq2SbZ16nwir327C4AXWt5LhfxFbE4kIiLuZMGW7/n++CwAnmvwOuEhoTYnEhEREZGsQMU2ybY6z3uBM0lHqVQohK51rj5LoYiISEZIcbp4dvkcMFyUCmzBqOY97I4kIlnc22+/TbFixfD19aVOnTps3Ljxuvb75JNPMAyDDh06ZGxAERFJNyq2Sbb05rolrD35Cid8BjKkZT48HIbdkURExI2898N+Us91ojgvsrT7TLvjiEgWt2DBAoYOHcro0aP59ddfqVKlCi1btuTUqVP/ut/BgwcZNmwYDRs2zKSkIiKSHlRsk2znbEIcw1c9BkC1sA40LVPG5kQiIuJO9p6K441VewB4rW1vyueLsDmRiGR1kyZNol+/fvTu3ZsKFSowffp0/P39mTVr1jX3cTqddOvWjTFjxlCiRIlMTCsiIrdKxTbJdu6bP4wL5jG8yMOSB9+yO46IiLiRVKeTth8MIiE1mjvK5OWeaoXsjiQiWVxycjKbN2+mefPmaescDgfNmzdn/fr119zvxRdfJF++fPTt2/c/j5GUlERsbOxli4iI2EezkUq28uWfG1h1dCYYMLzORIrkCrM7koiIuJE+C8exM34unr5fM7rdbgxDwxiIyL+Ljo7G6XSSP3/+y9bnz5+fnTt3XnWf//3vf7z//vts2bLluo4xYcIExowZc6tRRUQknahlm2QbKU4nPZf0BcNJUf87eLFlb7sjiYiIG9lweBcf7XgZgC7lH6NEWC57A4lIjnT+/Hm6d+/OjBkzCAu7vgvLI0eOJCYmJm05cuRIBqcUEZF/o5Ztkm08smQyZ1P/wGH6sbjLTLUmEBGRTONyuej4cS9MI5E8XpWZ1ekZuyOJSDYRFhaGh4cHJ0+evGz9yZMnKVCgwBXb79u3j4MHD9K2bdu0dS6XCwBPT0927dpFyZIlL9vHx8cHHx+fDEgvIiI3Qy3bJFs4fu4C67aVISSlCz0qPEv1wqXsjiQiIm6k/+JXOZ74M4bpxfx7Z+Pp4WF3JBHJJry9valRowarVq1KW+dyuVi1ahX16tW7Yvty5crx+++/s2XLlrSlXbt2NGnShC1bthARoUlZRESyOrVskyzPNE1GfbGdC8keNC0ykPc71bc7koiIuJGfDu5g9vYxYECn0k/Romx1uyOJSDYzdOhQevbsSc2aNalduzZTpkwhPj6e3r2tYVF69OhBoUKFmDBhAr6+vtx2222X7Z8rVy6AK9aLiEjWpGKbZHnv/vQjK3ecw9vDk5fvrYzDoe6jIiKSOVwuk24LhuEyLhDmVYV5nTUAuYjcuM6dOxMVFcWoUaOIjIykatWqLF++PG3ShMOHD+NwqNORiEhOoWKbZGkHTkfy2Hftcfjk4emaMymTP8juSCIi4kbmrj+I82wfcvt4s7DzGLw89dVJRG7OoEGDGDRo0FUfW7t27b/uO2fOnPQPJCIiGUaXTyRLa/NBX1I5h6dHKk82r2V3HBERcSP7o+J4ZflOHPjyRqvJ3FGyst2RRERERCQbULFNsqwXv/uAnbFfg+lg2l0zyOUXYHckERFxE8mpqXT+8FUupKTSoFQeutUpanckEREREckm1BdCsqRDZ04xbt0QABoW7EXPGnfanEhERNzJAx8/yy/nJxLkW5eJnVZrvFARERERuW5q2SZZUpsPHiKFM/gZEXzR/Q2744iIiBv5ascGPt83CYBulTtRKJefzYlEREREJDtRsU2ynAmr5/NnzJdgGrzV+j1y+wfaHUlERNxEfFISDy7qgWmkUtj3dt7uMMTuSCIiIiKSzagbqWQpMQkpfLw+CR9nOWqE16ZPrVZ2RxIRETfS7sMniHHuxoMglnX/AIdD1yVFRERE5Mao2CZZythlfxJ7Ph/18rzF5z3r2R1HRETcyHs/f83qozPAgKdqv0bl8OJ2RxIRERGRbEiXayXL+Or3fSzcfBTDgNfur0aIn7/dkURExE2cTUjkiW8fBsNFxZC2TGjd3+5IIiIiIpJNqdgmWcLBMye5d3E9znq+T4964dQoGmp3JBERcSNjlu4g94WnCHXU5ds+c+yOIyIiIiLZmIptkiW0nNOTZKJI9f6FJ5qXsjuOiIi4kS+2HOPzLcfxpSTf9lhGeLAu+IiIiIjIzVOxTWz39NfvsPv8CjAdvHPXbEL9g+yOJCIibmLj4d08+fkSAAY1La2W1SIiIiJyy1RsE1ttOb6PSZueBuDOwo/Qo0YzmxOJiIi7SE5N5e6PHmAfQ8iTdyOPNVXLahERERG5dSq2iW1cLhd3ffggTuII8SjHku6v2x1JRETcSOePnyEq5TcMPHm9/b14eehrkYiIiIjcOn2rFNv0WTie44k/Y5jefNLpIwJ8fOyOJCIibuLTrd/z+b7JAPSv/CKNS1W2OZGIiIiI5BSedgcQ97Q/Ko4V22MwHH48UPYpWpWrYXckERFxE6fjz9P7i+5gpFLMvwnTOjxpdyQRERERyUFUbJNMl+p0MeTTrfgkN6Z98YZ8cP9ddkcSERE30uz93iSYR/AilJW95+FwqKG/iIiIiKQfFdsk001dvYutR84R5OvJ252b4unhYXckERFxE+NWfsrWs4vANJjY7D1KhRW0O5KIiIiI5DC6lCuZ6pPfvmf4uiZccPzGuA63EZ7Lz+5IIiLiJg5ExzP/x0Byp/SlRcSjDG54r92RRERERCQHUrFNMs3p+PP0/bIHqcZJgvKspV2VcLsjiYiIm0hKdTJo/q8kJJs0L9yXZb2m2h1JRERERHIoFdsk07SY3ZcE8zBe5GFFzw8wDMPuSCIi4ia6fjSJ34+fJLe/F290qYqnh74CiYiIiEjG0JhtkilGfzuLX09/BqbBy03fpWSYWrWJiEjmeGHlXBYfehpPn8K80/F7CoZoCAMRERERyTi6rCsZ7rdje3lp/RMA3F6gD0MbaYwcERHJHBsO72LcukEA1C7YlLtuK2FzIhERERHJ6VRskwyVkppK6w864ySOEI9yfN37TbsjiYiIm7iQkkybD+/DacSRy7McK3q/a3ckEREREXEDKrZJhpr+w07OJwRhmL4svP9jgnzUdUdERDJHm9mPcyb1dxymP192XUigj6/dkURERETEDWjMNskw246e443vDhPmGsaQZrloXqaq3ZFERMRNvPb9Z6w9/h4Y8HSdydxevKLdkURERETETajYJhniTHw8j3/8G6kukza3FeSJO6rbHUlERNzEiZgERq0dAYZJ9Tz3MaF1f7sjiYiIiIgbUbFNMkTDGZ05cD6aCsFPM6FjJQzDsDuSiIi4AafLZOiCbeS5MAYjZCHf9ZlldyQRERERcTMqtkm6G/rVm/wZswwcDh5u6kcuf2+7I4mIiJt4a/Ve1u8/TZB3GF8+9BG5/QPtjiQiIiIibkYTJEi6+vHAdt74ZQQALSIG0q9ua5sTiYiIu3hn/Ve8tOZ9AMZ1uI2SeVVoExEREZHMp5Ztkm4uJCfRfn5nXEYCeTwr80WP1+yOJCIibmL3qWM88W0vUrxP0zo8iI7V77I7koiIiIi4KbVsk3TT7oPBnE39E4cZyFcPfoqvl7qPiohIxkt1Omk2uzMpnMbfiGBOl4F2RxIRERERN6Zim6SLd9Yv5buj7wIwrPZr1C1a1uZEIiLiLh74+DmOJq7DML2Y1/ET8gXmsjuSiIiIiLixbFdsS0pKomrVqhiGwZYtW+yOI0BMQgrTVh/Cw8zLbSEdeKXNw3ZHEhERNzF380oW7X0VgF4VX6DDbfVtTiQiIiIi7i7bFduefvppwsPD7Y4hF5mmyTNLfuf8+RLUCZjJd33n2B1JRETcxKEzUTz8VQ8wnJQMbM7Me0fYHUlEREREJHsV27755hu+/fZbXntNA+9nFR/+vItlv5/A02EwrUtD8geF2B1JRETcgGma9PpkGklE4msUZM1DH+NwZKuvNSIiIiKSQ2Wb2UhPnjxJv379+Pzzz/H397+ufZKSkkhKSkq7Hxsbm1Hx3NLyXb/QZ0UzQjweZGzzIVSJyGV3JBERcRMf/nyIA4drUtBzFK/dewcRIWF2RxIRERERAbJJyzbTNOnVqxcDBgygZs2a173fhAkTCAkJSVsiIiIyMKV7iUmMp/NnXXAasXgHbaZ/o+J2RxIRyTAaLzRr2X4shnFf7QBgbKtedK3W1OZEIiIiIiJ/s7XYNmLECAzD+Ndl586dvPnmm5w/f56RI0fe0POPHDmSmJiYtOXIkSMZ9ErcT5s5jxDr3IsnIazo8QmeHh52RxIRyTAaLzTriDx/juZz7ifBdZLm5fPTp0ExuyOJiIiIiFzG1m6kTz75JL169frXbUqUKMHq1atZv349Pj4+lz1Ws2ZNunXrxty5c6+6r4+PzxX7yK2buPZjfjr5IQCjGrxF5fBi9gYSEclAf40XumjRIr755pv/3F5DGGQcl8tFk5ndOJn6Lf5++5h47x8YhmF3LBERERGRy9habMubNy958+b9z+2mTp3KuHHj0u4fP36cli1bsmDBAurUqZOREeUf/jh5iGe/fxSAWmHdeL75gzYnEhHJODczXuiECRMYM2ZMBidzT4O+mMLO2K/BdDCl1VRCA3VBTURERESynmwxQUKRIkUuux8YGAhAyZIlKVy4sB2R3JLT5aTFnM6kco5ARwm+7fOu3ZFERDLMP8cLPXjw4HXtN3LkSIYOHZp2PzY2VmOGpoNvdmxi+tZnwIC7iz9Bvzpt7I4kIiIiInJV2WKCBMka5v50gPjzJTFMPz7u9DG5/ALsjiQicsMyerxQHx8fgoODL1vk1pyJj+P+hZ0xjSQK+NRicbeJdkcSEREREbmmbNGy7Z+KFSuGaZp2x3ArO07E8vLyPeRK7cq45k9yd/nqdkcSEbkpGT1eqKS/ZrN6Eec6gCe5WdnrM7w8s+XXFxERERFxE/q2Kv/pTHwcg+ZvIDnVRbNy+Rh4RzW7I4mI3DSNF5q9fPLLbv6I3gyGwavNZnBbgaJ2RxIRERER+Vcqtsl/ajarN3/EbqZM4LNM7NRcM7+JiFvQeKH2Oxgdz7gvD1Ag6XWaVz3J4Ib32h1JREREROQ/qdgm/+r5b99ny5mFYBg8dEdu8mjmNxERyQRJqU4GffwrcUmp1C1WkPfu62B3JBERERGR66Jim1zTr0f3MmH9YAAaFezL4IYd7Q0kImIjjReauZrN6McfJ1Mp4teFN7pUxdNDczqJiIiISPagYptcVXJqKq0/fAAncYR4lGNZrzftjiQiIm5i3Hcfsu7UbPCC0U3upWCIn92RRERERESumy4Ty1XdP38kp5I3Y5i+LOr8MYE+vnZHEhERN7D56B5eWDcIgHr5ujO4UXubE4mIiIiI3BgV2+QKH/26ii/2TwZgQJWXaFa6qr2BRETELSSmJNPqg/txEkuIRxmW955udyQRERERkRumbqRymbikVKZ+ewofVxkKhxTmrfaD7Y4kIiJuot0HQ4lO2YLD9OfzBz4j2Nff7kgiIiIiIjdMxTa5zKjPt3PqXDDVQ97gs4dq4nCo8aOIiGS8N9d9zsoj08CAwTUn0rhUZbsjiYiIiIjcFBXbJM3cn7ex+LdjOAyY2qUGhUJy2x1JRETcwOm4JCavXg94UinXXbx+90C7I4mIiIiI3DQ1WxIA1h3YQZ/lDTjjNYNHmxSlZrFQuyOJiIgbcLlMnvxsK674RtQJeJdVfefYHUlERERE5JaoZZtwISWZdvM74zLi8PLdx6AmZeyOJCIibmLm//aydlcUPp4O5nS/l7yBwXZHEhERERG5JWrZJnT4cBhnUn/HYfrzZbcF+Hp52x1JRETcwEe/rmLQ6qYkGbsZ1bYC5Qqo0CYiIiIi2Z+KbW5u9qblfHv4bQCeqPkK9YtVsDmRiIi4gyMx0fT7qjspxlECw1bQtXYRuyOJiIiIiKQLFdvcWGTsWR79pg8YLsoGt2HS3YPsjiQiIm7A5XLRdGZXEs0T+BgF+K7PhxiGYXcsEREREZF0oWKbG2s5p6/1Q4f8rOz9gd1xRETETTz6+evsjVsJpgfv3vUBRXPntTuSiIiIiEi6UbHNTa388yTHTpbAYQYy6c73iMiVx+5IIiLiBlbt2cJ720YB0L7EEHrWuNPmRCIiIiIi6UuzkbqhqPNJjFi0jUBnEx6t05lH69eyO5KIiLiB+KQkOi3oimkkks+7Op91nWB3JBERERGRdKeWbW7G5XIx5LN1nI5PplyBIJ5tU93uSCIi4iZeW7mVpOQAPAhkWfdP8PLUNT8RERERyXlUbHMz/Re/yieHO5Hi+StTHqiKj6eH3ZFERMQNrN93mjnrosibPJp3W6ygZuHSdkcSEREREckQuqTsRtbs3cas7S9gGonUL3eBcgWC7Y4kIiJuIPp8AkM/3YJpwgM1i9C3XmW7I4mIiIiIZBgV29xEYkoy9y7oljZOzsddxtodSURE3IDL5aLuu+2ITDCpludJRrWtYHckEREREZEMpW6kbuLej4ZzNnU7DtOfL7vNx9ND3UdFRCTjDfpiMvviVxHv8T2PNvcnwEfX+UREREQkZ1OxzQ0s2Po9Xx96E4DHaoyndpGyNicSERF3sHbvNqZvfQ6AdsWH0KVaY1vziIjY6e2336ZYsWL4+vpSp04dNm7ceM1tZ8yYQcOGDcmdOze5c+emefPm/7q9iIhkLSq25XAxifH0XdoTDCclA5ox+e7H7Y4kIiJuICE5iXsWPIBpJJLXqxqfdZtgdyQREdssWLCAoUOHMnr0aH799VeqVKlCy5YtOXXq1FW3X7t2LV26dGHNmjWsX7+eiIgIWrRowbFjxzI5uYiI3AwV23K4N77bAckl8CSU5b0+xDAMuyOJiIgbaP/BUM6l7sBhBrKs+wK8PdV9VETc16RJk+jXrx+9e/emQoUKTJ8+HX9/f2bNmnXV7efNm8ejjz5K1apVKVeuHDNnzsTlcrFq1apMTi4iIjdDxbYcbMuRc8xZd5KwlCf58O7vKRVW0O5IIiLiBuZuXsl3R6cD8GStidSKKG1zIhER+yQnJ7N582aaN2+ets7hcNC8eXPWr19/Xc+RkJBASkoKoaGhV308KSmJ2NjYyxYREbGPim05VFxSEkMX/IbLhA5Vw3mgxm12RxIRETdwIdnJ5O+24SCYMkGtmHjXI3ZHEhGxVXR0NE6nk/z581+2Pn/+/ERGRl7XcwwfPpzw8PDLCnaXmjBhAiEhIWlLRETELecWEZGbp2JbDtVq9sP8HDuCkMA4XmhX0e44IiLiJl5ZvpNzZ8tRxWsm3/aaa3ccEZFs7+WXX+aTTz5hyZIl+Pr6XnWbkSNHEhMTk7YcOXIkk1OKiMilNIBKDvT+xm9YF/kBeJjcXy+FXP7edkcSERE38OOeU8z56SAAk+9rRNHQvPYGEhHJAsLCwvDw8ODkyZOXrT958iQFChT4131fe+01Xn75Zb777jsqV658ze18fHzw8fFJl7wiInLr1LIthzkdf57HlvcHw6RiSDuebfag3ZFERMQNHImJptXH9Yn3+J6utSO4o4wKbSIiAN7e3tSoUeOyyQ3+muygXr1619xv4sSJjB07luXLl1OzZs3MiCoiIulExbYc5u4PBnLBPIoXYSzrOdPuOCIi4iZaze5DgrmPOJ+PGNqiuN1xRESylKFDhzJjxgzmzp3Ljh07eOSRR4iPj6d3794A9OjRg5EjR6Zt/8orr/D8888za9YsihUrRmRkJJGRkcTFxdn1EkRE5AaoG2kO8u76r/j55EdgwLg73qRobrUqEBGRjPfCt7P5M+ZLMA3eav0+YYFBdkcSEclSOnfuTFRUFKNGjSIyMpKqVauyfPnytEkTDh8+jMPxdzuId955h+TkZDp16nTZ84wePZoXXnghM6OLiMhNMEzTNO0OkVliY2MJCQkhJiaG4OBgu+OkqzMJ5yn0WjkSzeNUytWBbU8ssTuSiGRjOfnzMrPl9Pdy56kjVHqnEqnE0KjgQ3zff4bdkUQkm8rpn5eZSe+liMj1yajPS3UjzSHGLv+eVKcTb/LydS/90BERkYzncrloM7cnqcQQ6CjBlz3esDuSiIiIiIjt1I00B9h+LIalvzgo6Hqb59vnoXBImN2RRETEDYxcPoMDCWvA9GBOhzkE+/rbHUlERERExHYqtmVzKU4XTy/chtNl0q5ycfrVq253JBERcQOn45KYu+kHAFoWeYR7KzW0OZGIiIiISNagYls21/XjUfx8KpoIvw680K6i3XFERMRNvPDln/he6ErtsAYs7NbH7jgiIiIiIlmGim3Z2Ko9v7Fo70RM7xQerlWHsEAfuyOJiIgbWPFHJF9uPY6Hw2DmA90I9PG1O5KIiIiISJahCRKyqVSnky6f9cU0UijoU4eXWvW0O5KIiLiBQ2dO0XVRF1KMSPo3KkGlwiF2RxIRERERyVLUsi2bGrDkVaJSfsMwffis8ywcDtVNRUQk4939YX/OmGsJ9D/G403/tDuOiIiIiEiWowpNNvTbsX3M3j4OgPvLDKNB8Qo2JxIREXfw6vcL2H7uCzANprR8Az9vXbMTEREREfknFduyoY7z++Ey4snlWZ4P7n/B7jgiIuIGjsWc5rm1jwFQJ183+tZubXMiEREREZGsSZeks5n3f/6eg/HfAx7M6TATb0/9E4qISMZr/+FAkonCxyjIlz3esjuOiIiIiEiWpUpNNnIh2cmstU4KJk2hbrmztK9Y3+5IIiLiBmZvWsHm6E/BgFebvk3eQE2KICIiIiJyLSq2ZSNTV+/h2LkLFM9VkY+6NLI7joiIuIEUp4uR304Aw6RiSDseu/0euyOJiIiIiGRpKrZlEyt2/crbP27AQRFeaFcRfw1KLSIimWDmjwfwOT+Ygn4lWNJtnN1xRERERESyPE2QkA24XC4eXNSHI16PUSziV+6skN/uSCIi4gYOn07gjVW7MfBi6t0vUjpvuN2RRERERESyPBXbsoHHlk4hOmUrBp680vZ+u+OIiIgbcLlcPPjxFC6kpFCvRB7urV7I7kgiIiIiItmC+iJmcfujI3lv64sAdCj5BHWKlLU5kYiIuIORy9/jx9PP4utTlhfbb8AwDLsjiYiIiIhkC2rZlsV1nD+IVGIIcBTjo84v2h1HRETcwKEzUUza9CwAjYu2oHR+zT4qIiIiInK9VGzLwub+8i1bzywGYFKLt/D39rE5kYiIuIN75g8ilTP4GxEs6Pqy3XFERERERLIVFduyqJTUVB5fPgiM/7d373FR1nn/x98DwoAH8ASIhiiW4ilPrSymmxXJmnfFlsqqPw+llaWl6VaaFdpBLY8dLDe3W2vb8rRl/ZLbdDW2A2zdKVTm+YB4E2CYiiJy/N5/eMtGUgrMzMXMvJ6PxzwecHFdzHs+zVyf+PiduYy6Bt+ie2KGWB0JAOAF3vhqs9Lz10mSFsS9pKCAhhYnAgAAANwLn9lWT63dfkQ+5/rLr8EprR2xzOo4AAAvUFJWpimbHpBsRl2Cb9H9/W6zOhIAAADgdljZVg+dKirV4s2HFFx2h168/hN1CYuwOhIAwAvc994CnSrfJx/TSGv/+LLVcQAAAAC3xMq2emjpln06XliiK0Mba3z/q6yOAwDwAicKS/TZruayl3fT7Z1vV9dWba2OBAAAALglVrbVM/88sEtztyeoyGe7km7pIj9f/hMBAJxv4ea9Ki66Qr9r+rJWDn3c6jgAAACA22KSU48YYzT23YdU4nNAvsHvq/+VLa2OBADwAhlZP+rtL7MkSU8ndJPdz8/iRAAAAID7YthWj7zw6X/pSNFmydi04tYXZbPZrI4EAPBwZeXlivvrjTreYIV+372JYqJaWB0JAAAAcGsM2+qJopIyPZnysCTpmtAEDel8rcWJAADeYMr/f1HHyzJ0xvcjTby+jdVxAAAAALfHsK2euP/dl3Xa7JKPArQ68QWr4wAAvEDWyXy99vXTkqQ/dHhQPVt3sDgRAAAA4P7cati2ceNGxcTEKDAwUM2aNVNCQoLVkRwi68eT+tueeZKkP0ZPVocWERYnAgB4gxHv/EllOqGGtgi9mTjH6jgAAACAR2hgdYDL9fe//11333235s6dqxtuuEFlZWXauXOn1bEc4v73lqnUdkwBPqF67Q+zrY4DAPAC2w58rdS8v0k2afbvFqiRf4DVkQAAAACP4BYr28rKyjRlyhQtWLBAEydOVMeOHdWlSxcNHz7c6mh1tjf3tL470EMhxbP07MDFauTfyOpIAICf8NRV1Xe9N1WylalNQKweHphodRwAAADAY7jFyrYdO3YoOztbPj4+6tWrl3Jzc9WzZ08tWLBA3bp1+8XjiouLVVxcXPl9QUGBK+LWyLPJu2WMTUO7/UHTBvSxOg4A4Cc8dVX1+9/uVFbhF5J8tOK2pVbHAQAAADyKWwzbDh06JEmaPXu2Fi9erHbt2mnRokUaOHCg9u3bp+bNm1d73Lx58zRnTv39DJo16Tv08b7DCvBtokd/H211HADAT/x0VfX48eMrt3fp0sXCVHVXXmG0fNsJtTn3mq6Jztbg6L5WRwIAAAA8iqVvI50xY4ZsNtuv3vbs2aOKigpJ0qxZs3THHXeoT58+WrlypWw2m9atW/eLv3/mzJk6depU5e3o0aOuemiXVFZeofs33qPvA+5WbJejimzB20cBoD75+arq8PBwDR48+JIr24qLi1VQUFDlVp+s335Uu3MK1DQgRK8Pe8jqOAAAAIDHsXRl2/Tp0zVu3Lhf3ScqKko5OTmSqq4msNvtioqKUlZW1i8ea7fbZbfbHZLV0R77r1X6sXy7bDY/Tb9+oNVxAAA/44mrqo+dKdATm9ZI6qIpN16l5o38rY4EAAAAeBxLV7aFhIQoOjr6V2/+/v7q06eP7Ha79u7dW3lsaWmpMjMzFRkZaeEjqJ2TZ4v04vYkSVJ827vUo3UnixMBgPfw5lXVY9cmaX/FIypp/KrGxLazOg4AAADgkdziM9uCgoI0ceJEJSUlKSIiQpGRkVqwYIEkadiwYRanq7k71z+rYv2P/NRMfx0+3+o4AOBVvHVVdXr2YX2U9WfJJo3pc7P8G7jFBckBAAAAt+MWwzZJWrBggRo0aKDRo0erqKhIMTEx2rZtm5o1a2Z1tBrZdyxHHxx6QbJJ9/aaqZaNmlodCQC8SkhIiEJCQi65309XVffv31+Se6+qHr1uuoytSM39OuvZ+HutjgMAAAB4LLcZtvn5+WnhwoVauHCh1VHqZMy6R1RhO6Mg3w5aMoQPpgaA+sqTVlW/922avjv5vmSTlsQvlq+Pr9WRAAAAAI/lNsM2T3Akv1C7836UfGx6auBzauBL+QGgPvOUVdWTNk6TbBXq0PhGjenze6vjAAAAAB6NaY8LLd26X81K7tcNUeM1pf/tVscBAFyCJ6yqfuGzd5VT/C/JNNDKPyy1Og4AAADg8Ri2ucjunAJtyMiWJD095EaL0wAAvEFFhdE7X2aqQUUr9Q67QQOiulkdCQAAAPB4XIrMRUavnaESHdV/XB2ubm2CrY4DAPACyTtzlHusk64yr2nNH1+wOg4AAADgFVjZ5gLL//WBtp98VTa7v8b/7oDVcQAAXqC0vEILPtorSbr3d9Fq17ylxYkAAAAA78DKNierqKjQ49uekCT1avkH9boiwuJEAABvMPWDV7Tz5Hq1aOSjCQPaWx0HAAAA8BqsbHOy5/+5VsdLv5HN+Os/b59rdRwAgBfIP3NaK76Zo1L/fN0W3UaN7IOtjgQAAAB4DVa2OVFZeYXmfTZbknRt+Ej1aB1lbSAAgFcYv/4ZlSpfdluoXrz1IavjAAAAAF6FYZsTzfrodRVU7JWPCdDK25+xOg4AwAsczM/Th5mvSJLu6zVTje2BFicCAAAAvAvDNic5fa5IL341W5I0KPJOXRnSxtpAAACvMG7946qwnVET3/Z6fvBkq+MAAAAAXodhm5Os/eqoAkriFaAIvTGUz2oDADjffx85qM9z/ypJmtX/Kfk14KNZAQAAAFdj2OYEhcVlejXliILL7tCfB6UotElTqyMBALzA2HcfkrEVK8S/ux65bpTVcQAAAACvxD95O8Hrnx5S/pkSRbZoqBF921kdBwDgBXZmn9LJYzfJ7ndEL/x+iWw2m9WRAAAAAK/EyjYH++TwV3rks3gV+WzX9EGd5OdLiQEAzvfcpj3yN1G6t8sqjeh1g9VxAAAAAK/FJMjB7t4wTcW2TPk2/qf+o3u41XEAAF5g657/0af78+Xna9P0mzpZHQcAAADwagzbHOj9XR9rX8GnkvHVgkFz5ePDW3gAAM51+twZ3bqur370W6Gh17RU2xYNrY4EAAAAeDU+s82BHtu8UJLUvuFgjezT1+I0AABv8MCH83S2Ikd+vmmaNLCj1XEAAAAAr8fKNgfZfjRLu09ukSTNvnEKH0wNAHC6syXFWr1rhSRp6FXTdEWzptYGAgAAAMCwzVEefH+JjK1Uzf2u0ujeN1odBwDgBR5N/ouKzQ9qoKZ6OWGy1XEAAAAAiGGbQ3x99IS++OEdSdLU2AdY1QYAcLqzJWVa+fUrkqSb249W80aNLE4EAAAAQGLY5hALN+9Ti9IH1Tqwp/7Uf4LVcQAAXuDx5PUq1C7Z5KeXbp1hdRwAAAAA/4dhWx2lHszXp/vz1UQ9lXrXZwr0C7Q6EgDAw50oLNF/ZrwmSYqLHKa2TVtbnAgAAADABVyNtA6OnTmmxz78UFKYRsa0VWRL3sIDAHC+V1IOKOjcRDUKsuvVW562Og4AAACAn2BlWy1VmArd/NZwfXLiPpX5/7cm33Cl1ZEAAF4g+2SR3kg7Ih810lt3vKEOLaKsjgQAAADgJxi21dK679Zre94/Jdk0vGdvhTYJsDoSAMDD/VD4g+5aO1/FZeWKad9cAzuGWB0JAAAAwM/wNtJa+uPfEyVJwbZrlTR4sMVpAADeIHRhqCSpsd/v9ejgt7n6NQAAAFAPsbKtFn48W1D5tc2+W8GBfhamAQB4g2OFxyq/9m94UL3bNrMwDQAAAIBfwrCtFp7Z8vfKr08U51iYBADgLW5f/f8qv45qwdtHAQAAgPqKYVsNFRaX6f1vDlkdAwDgRYwxOn4ivPL75g0bW5gGAFAby5YtU7t27RQQEKCYmBh9+eWXv7r/unXrFB0drYCAAHXv3l3JyckuSgoAqCuGbZfhx6IfteXgFr31zVta+flhlRf+tvJnn975qYXJAACerKC4QKlHU5Wy9wf9+GOHyu2TfzPZwlQAgJpas2aNpk2bpqSkJO3YsUM9evRQfHy8jh07Vu3+qampGjFihMaPH6/09HQlJCQoISFBO3fudHFyAEBt2IwxxuoQrlJQUKDg4GCtT92rwMZNJEkXHr3R+S++yt2m/Se+Vm7hEeWePaKcwiM6cS5PkhTYoLGiStfqzLkKPTe0o67tGKgrgq6w5LEAgDNdOF+eOnVKQUFBVsdxa5fTe/af+Frf5X+p/KLvlV/0vX4oylZ+0ff68f/6z3WN39XhH3zlHzZfXcJDtCFxAxdHAOBxPLn3xMTE6De/+Y1efvllSVJFRYUiIiL0wAMPaMaMGRftn5iYqMLCQn344YeV237729+qZ8+eWr58+SXvz5NrCQCO5KzzpVddjfTCXHHKX9PkY29Y7T4/+C/VOZ/tF233NWFSRZROluYpOixM8VeGykc2FRQUVPNbAMC9XTi3edG/xzjN5fSekw3+ptMN3q/2Zz6mhXaf2qcW9qu0acQHatrQX6dPn3ZaXgCwiqf2npKSEm3fvl0zZ86s3Obj46O4uDilpaVVe0xaWpqmTZtWZVt8fLw2bNhQ7f7FxcUqLi6u/P7UqVOSxN8qAHAJzuo9XjVsO378uCQp+9VxNT62XHkqUp6ylaZsSc1mXvIQAHB7x48fV3BwsNUx3Fpdeo8kVei4jmmGjkmKnO+4XABQX3la78nPz1d5ebnCwsKqbA8LC9OePXuqPSY3N7fa/XNzc6vdf968eZozZ85F2yMiImqZGgC8i6N7j1cN25o3by5JysrK8qgGboWCggJFRETo6NGjLE2vI2rpONTScU6dOqW2bdtWnjdRe/Qex+E17jjU0nGopePQe2pv5syZVVbCnTx5UpGRkfQe8Rq9gDr8G7U4jzqc56ze41XDNh+f89eDCA4O9uonkyMFBQVRSwehlo5DLR3nwnkTtUfvcTxe445DLR2HWjqOp/Weli1bytfXV3l5eVW25+XlqVWrVtUe06pVqxrtb7fbZbfbL9pO7/k3XqPnUYd/oxbnUYfzHN17PKuTAQAAAEA94u/vrz59+mjr1q2V2yoqKrR161bFxsZWe0xsbGyV/SVpy5Ytv7g/AKB+8aqVbQAAAADgatOmTdPYsWN1zTXXqG/fvlq6dKkKCwt15513SpLGjBmjNm3aaN68eZKkKVOm6LrrrtOiRYs0ZMgQrV69Wl999ZVee+01Kx8GAOAyedWwzW63Kykpqdol1qgZauk41NJxqKXjUEvHoZaOQy0dh1o6DrV0HE+uZWJion744Qc9+eSTys3NVc+ePbVp06bKiyBkZWVVeQtTv3799Pbbb+vxxx/XY489pquuukobNmxQt27dLuv+PLmWNUUtzqMO/0YtzqMO5zmrDjbjadfWBgAAAAAAACzCZ7YBAAAAAAAADsKwDQAAAAAAAHAQhm0AAAAAAACAgzBsAwAAAAAAABzEa4Ztzz77rPr166eGDRuqadOm1e6TlZWlIUOGqGHDhgoNDdXDDz+ssrIy1wZ1Q+3atZPNZqtymz9/vtWx3MKyZcvUrl07BQQEKCYmRl9++aXVkdzS7NmzL3oORkdHWx3LLXzyySe65ZZb1Lp1a9lsNm3YsKHKz40xevLJJxUeHq7AwEDFxcVp//791oR1Q/Qe56H31A39p+7oPbVH73GMmr6O161bp+joaAUEBKh79+5KTk52UVLnq0ktVqxYoQEDBqhZs2Zq1qyZ4uLiPOYcWNtz++rVq2Wz2ZSQkODcgC5S0zqcPHlSkyZNUnh4uOx2uzp27Ogxr4+a1mLp0qXq1KmTAgMDFRERoYceekjnzp1zUVrnuFTPqU5KSop69+4tu92uK6+8UqtWrarx/XrNsK2kpETDhg3TfffdV+3Py8vLNWTIEJWUlCg1NVVvvPGGVq1apSeffNLFSd3TU089pZycnMrbAw88YHWkem/NmjWaNm2akpKStGPHDvXo0UPx8fE6duyY1dHcUteuXas8Bz/77DOrI7mFwsJC9ejRQ8uWLav2588//7xefPFFLV++XF988YUaNWqk+Ph4t2+6rkLvcS56T+3QfxyH3lM79J66q+nrODU1VSNGjND48eOVnp6uhIQEJSQkaOfOnS5O7ng1rUVKSopGjBihjz/+WGlpaYqIiNCgQYOUnZ3t4uSOVdtze2Zmpv70pz9pwIABLkrqXDWtQ0lJiW666SZlZmZq/fr12rt3r1asWKE2bdq4OLnj1bQWb7/9tmbMmKGkpCTt3r1br7/+utasWaPHHnvMxckd61I95+cOHz6sIUOG6Prrr1dGRoamTp2qCRMm6KOPPqrZHRsvs3LlShMcHHzR9uTkZOPj42Nyc3Mrt7366qsmKCjIFBcXuzCh+4mMjDRLliyxOobb6du3r5k0aVLl9+Xl5aZ169Zm3rx5FqZyT0lJSaZHjx5Wx3B7ksx7771X+X1FRYVp1aqVWbBgQeW2kydPGrvdbt555x0LEroveo/j0Xtqj/7jGPQex6D31E5NX8fDhw83Q4YMqbItJibG3HvvvU7N6Qp1PaeVlZWZJk2amDfeeMNZEV2iNnUoKysz/fr1M3/5y1/M2LFjzW233eaCpM5V0zq8+uqrJioqypSUlLgqosvUtBaTJk0yN9xwQ5Vt06ZNM9dee61Tc7rSz3tOdR555BHTtWvXKtsSExNNfHx8je7La1a2XUpaWpq6d++usLCwym3x8fEqKCjQd999Z2Ey9zB//ny1aNFCvXr10oIFC3gL1CWUlJRo+/btiouLq9zm4+OjuLg4paWlWZjMfe3fv1+tW7dWVFSURo0apaysLKsjub3Dhw8rNze3yvM0ODhYMTExPE8dhN5TN/SemqP/OBa9x/HoPZdWm9dxWlpalf2l8/3G3WvqiHPa2bNnVVpaqubNmzsrptPVtg5PPfWUQkNDNX78eFfEdLra1OGDDz5QbGysJk2apLCwMHXr1k1z585VeXm5q2I7RW1q0a9fP23fvr3yraaHDh1ScnKybr75Zpdkri8cdb5s4MhQ7iw3N7fKHzuSKr/Pzc21IpLbePDBB9W7d281b95cqampmjlzpnJycrR48WKro9Vb+fn5Ki8vr/Y5t2fPHotSua+YmBitWrVKnTp1Uk5OjubMmaMBAwZo586datKkidXx3NaFc191z1POi45B76k9ek/t0H8ch97jHPSeS6vN6/iX+o2719QR57RHH31UrVu3vuiPa3dSmzp89tlnev3115WRkeGChK5RmzocOnRI27Zt06hRo5ScnKwDBw7o/vvvV2lpqZKSklwR2ylqU4uRI0cqPz9f/fv3lzFGZWVlmjhxotu/jbSmful8WVBQoKKiIgUGBl7W73HrlW0zZsy46INpf37jfxxrpya1nTZtmgYOHKirr75aEydO1KJFi/TSSy+puLjY4kcBbzF48GANGzZMV199teLj45WcnKyTJ09q7dq1VkeDB6L3OA+9B+6E3gO4v/nz52v16tV67733FBAQYHUclzl9+rRGjx6tFStWqGXLllbHsVRFRYVCQ0P12muvqU+fPkpMTNSsWbO0fPlyq6O5XEpKiubOnatXXnlFO3bs0LvvvquNGzfq6aeftjqaW3LrlW3Tp0/XuHHjfnWfqKioy/pdrVq1uujKHHl5eZU/8zZ1qW1MTIzKysqUmZmpTp06OSGd+2vZsqV8fX0rn2MX5OXleeXzzdGaNm2qjh076sCBA1ZHcWsXnot5eXkKDw+v3J6Xl6eePXtalMp69B7nofc4H/3Heeg9jkHvubTavI5btWrlka/7upzTFi5cqPnz5+sf//iHrr76amfGdLqa1uHgwYPKzMzULbfcUrmtoqJCktSgQQPt3btXHTp0cG5oJ6jN8yE8PFx+fn7y9fWt3Na5c2fl5uaqpKRE/v7+Ts3sLLWpxRNPPKHRo0drwoQJkqTu3bursLBQ99xzj2bNmiUfH7deq3XZful8GRQUdNmr2iQ3X9kWEhKi6OjoX71d7osjNjZW3377bZUrc2zZskVBQUHq0qWLsx5CvVWX2mZkZMjHx0ehoaEuTu0+/P391adPH23durVyW0VFhbZu3arY2FgLk3mGM2fO6ODBg1X+Jx011759e7Vq1arK87SgoEBffPGFVz9P6T3OQ+9xPvqP89B7HIPec2m1eR3HxsZW2V8632/cvaa1Pac9//zzevrpp7Vp0yZdc801rojqVDWtQ3R0tL799ltlZGRU3m699dbKqy9GRES4Mr7D1Ob5cO211+rAgQOVw0ZJ2rdvn8LDw9120CbVrhZnz569aKB2YQh5/toC3sFh58uaXbvBfR05csSkp6ebOXPmmMaNG5v09HSTnp5uTp8+bYw5fyWWbt26mUGDBpmMjAyzadMmExISYmbOnGlx8votNTXVLFmyxGRkZJiDBw+at956y4SEhJgxY8ZYHa3eW716tbHb7WbVqlVm165d5p577jFNmzatclVCXJ7p06eblJQUc/jwYfP555+buLg407JlS3Ps2DGro9V7p0+frjwfSjKLFy826enp5siRI8YYY+bPn2+aNm1q3n//ffPNN9+Y2267zbRv394UFRVZnNw90Hucg95TN/Qfx6D31B69p+4u9ToePXq0mTFjRuX+n3/+uWnQoIFZuHCh2b17t0lKSjJ+fn7m22+/teohOExNazF//nzj7+9v1q9fb3JycipvF3qzu6ppHX7OU65GWtM6ZGVlmSZNmpjJkyebvXv3mg8//NCEhoaaZ555xqqH4DA1rUVSUpJp0qSJeeedd8yhQ4fM5s2bTYcOHczw4cOteggOcameM2PGDDN69OjK/Q8dOmQaNmxoHn74YbN7926zbNky4+vrazZt2lSj+/WaYdvYsWONpItuH3/8ceU+mZmZZvDgwSYwMNC0bNnSTJ8+3ZSWlloX2g1s377dxMTEmODgYBMQEGA6d+5s5s6da86dO2d1NLfw0ksvmbZt2xp/f3/Tt29f869//cvqSG4pMTHRhIeHG39/f9OmTRuTmJhoDhw4YHUst/Dxxx9Xe24cO3asMcaYiooK88QTT5iwsDBjt9vNjTfeaPbu3WttaDdC73EOek/d0X/qjt5Te/Qex/i11/F1111XWc8L1q5dazp27Gj8/f1N165dzcaNG12c2HlqUovIyMhqn39JSUmuD+5gNX1O/JSnDNuMqXkdUlNTTUxMjLHb7SYqKso8++yzpqyszMWpnaMmtSgtLTWzZ882HTp0MAEBASYiIsLcf//95sSJE64P7kCX6jljx44111133UXH9OzZ0/j7+5uoqCizcuXKGt+vzRgvWg8IAAAAAAAAOJFbf2YbAAAAAAAAUJ8wbAMAAAAAAAAchGEbAAAAAAAA4CAM2wAAAAAAAAAHYdgGAAAAAAAAOAjDNgAAAAAAAMBBGLYBAAAAAAAADsKwDQAAAAAAAHAQhm0AAAAAAACAgzBsA+qhlJQU9e7dW3a7XVdeeaVWrVpldSQAgIfLycnRyJEj1bFjR/n4+Gjq1KlWRwIAAHBLDNuAeubw4cMaMmSIrr/+emVkZGjq1KmaMGGCPvroI6ujAQA8WHFxsUJCQvT444+rR48eVscBAABwWwzbACd488031aJFCxUXF1fZnpCQoNGjR//qscuXL1f79u21aNEide7cWZMnT9bQoUO1ZMkSZ0YGAHiAuvSfdu3a6YUXXtCYMWMUHBzszJgAAAAejWEb4ATDhg1TeXm5Pvjgg8ptx44d08aNG3XXXXf96rFpaWmKi4ursi0+Pl5paWlOyQoA8Bx16T8AAABwDIZtgBMEBgZq5MiRWrlyZeW2t956S23bttXAgQN/9djc3FyFhYVV2RYWFqaCggIVFRU5Iy4AwEPUpf8AAADAMRi2AU5y9913a/PmzcrOzpYkrVq1SuPGjZPNZrM4GQDAk9F/AAAArNXA6gCAp+rVq5d69OihN998U4MGDdJ3332njRs3XvK4Vq1aKS8vr8q2vLw8BQUFKTAw0FlxAQAeorb9BwAAAI7BsA1wogkTJmjp0qXKzs5WXFycIiIiLnlMbGyskpOTq2zbsmWLYmNjnRUTAOBhatN/AAAA4Bg2Y4yxOgTgqU6dOqXWrVurrKxMb775phITEy95zOHDh9WtWzdNmjRJd911l7Zt26YHH3xQGzduVHx8vAtSAwDcXW36jyRlZGRIOj+s69Spkx5++GH5+/urS5cuTkwLAADgWRi2AU42ZswYbdy4Ud9//73sdvtlHZOSkqKHHnpIu3bt0hVXXKEnnnhC48aNc25QAIBHqU3/qe5z3SIjI5WZmengdAAAAJ6Lt5ECTpadna1Ro0Zd9h86kjRw4EClp6c7MRUAwNPVpv/wb7AAAAB1x8o2wElOnDihlJQUDR06VLt27VKnTp2sjgQA8AL0HwAAAGuxsg1wkl69eunEiRN67rnnqvyh07VrVx05cqTaY/785z9r1KhRrooIAPBA9B8AAABrsbINcLEjR46otLS02p+FhYWpSZMmLk4EAPAG9B8AAADXYNgGAAAAAAAAOIiP1QEAAAAAAAAAT8GwDQAAAAAAAHAQhm0AAAAAAACAgzBsAwAAAAAAAByEYRsAAAAAAADgIAzbAAAAAAAAAAdh2AYAAAAAAAA4yP8CsC12GBu90l4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type=\"transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8649bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAINCAYAAAAQmVQ9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdxklEQVR4nO3deVyU1eIG8OedGYZhHUR2RBA3RNlEJTUzlVyuWZmZmqVRWdke1b15fzdtVUvzWmbapnkry7pdW10jzcwFRTHFFVxA9kV2YWDm/f0BTpGoLDOcWZ7v5zOfjw4vM89MyDy957znSLIsyyAiIiKyQArRAYiIiIiuhEWFiIiILBaLChEREVksFhUiIiKyWCwqREREZLFYVIiIiMhisagQERGRxWJRISIiIoulEh3AEhkMBuTk5MDNzQ2SJImOQ0REZDVkWUZFRQUCAgKgULT/fAiLSjNycnIQFBQkOgYREZHVysrKQpcuXdr9OCwqzXBzcwPQ8Ca7u7sLTkNkGc6XVOO+NfuQU1oDT2cH/HN8H4zp62c863i6qBIvfXsUKZkXoJCAhZMi8bcIf8GpiaijlZeXIygoyPhZ2l4S9/q5XHl5ObRaLcrKylhUiACUVdfh9hW/IaOwCiGdnfHJ/XEI8nS+7DhdvQH/t/4wvko5DwelhFX3DsSwnt4CEhORKKb+DOVkWiK6KoNBxmOfH0BGYRX8tRp88eDgZksKAKhVCrw+KRI3R/qjTi/jsbUHkV16sYMTE5EtYVEhoqta9dsZ/HqqCBoHBT6aORB+Ws1Vj1coJLx5ZxSiumhRdrEOj689gHq9oYPSEpGtYVEhois6nleONzadAAC8cHM4wgNadhrXUaXEsmn94aZR4UBmKT7eddaMKYnIlrGoEFGz9AYZz351CDq9AfF9fHDXoK6t+v6unZ3xr/F9AABLtp7kEBARtQmLChE1a21yJo5kl8NNo8KC2yPbtKbQ5NggDAzphGqdHvO+TTNDSiKydSwqRHSZ4spaLNp0HADw7Oje8HZzbNPjKBQSXpsYAZVCwk/H8rErvciUMYnIDrCoENFl3tx6EuU19Qj3d8f0uNYN+fxVL18342O8vvkEuCICEbUGiwoRNXG6sBLr9mUBAOZNCIdK2f5fE4+N7AlntRKHskqx6Uheux+PiOwHiwoRNfHm1pPQG2SMDPNBXGhnkzymt5sjHri+GwBg8ZYT0Bt4VoWIWoZFhYiMDp8vw4+/50KSgL+P7W3Sx551QyjcNSpkFFZhSxrPqhBRy7CoEJHRG5sbJtBOjA5EmJ9pt49w0zhg5pAQAMC72zM4V4WIWoRFhYgAAAcyL+DXU0VQKSQ8fVMvszzHvUNCoHFQ4HB2GXbyCiAiagEWFSICACz/OR0AcHv/wCvu5dNenV0dMa1x4biVv2SY5TmIyLawqBARjmSXIel4ARQSMPvGHmZ9rgeGhUIhAb+lF+NkfoVZn4uIrB+LChHh3e0NZ1MmRAWgm5eLWZ8r0MMJo8P9AABruAcQEV0DiwqRnUsvqMDGxrVNHh1h3rMpl9w7NAQA8L8D2SirruuQ5yQi68SiQmTnGq7AAcb09UUvX7cOec64bp4I83PDxTo9vkrJ6pDnJCLrxKJCZMfyymrwXWoOAOARM89N+TNJkoyXKq/ZfZYLwBHRFbGoENmxNbvPot4gY1A3T0QFeXToc98WHQitkwOySi7yUmUiuiIWFSI7VVVbj8/2nAMA4/L2HclJrcTEmEAAwLp9mR3+/ERkHVhUiOzU1wfOo7ymHiGdnTGqj6+QDFMGBgEAth7NR3FlrZAMRGTZWFSI7JDeIOOjnWcAAPdf3w1KhSQkRx9/d0R20aJOL2P9wWwhGYjIsrGoENmhn47l41xxNbRODpgU20VolktnVdbty+L+P0R0GRYVIjv00a8NZ1Puvq4rnNUqoVluiQqAk4MSpwoqcSCzVGgWIrI8LCpEdiYtpwzJZ0ugUkiYMThEdBy4aRwwPtIfACfVEtHlLKKoLF++HCEhIdBoNIiLi0NycvIVj01LS8OkSZMQEhICSZKwdOnSy47R6/V44YUX0K1bNzg5OaF79+545ZVXeFqZCMAnuxuu9BkX4Q9fd43gNA0uDf/88HsuqnX1gtMQkSURXlTWrVuHxMREzJs3DwcOHEBUVBTGjBmDgoKCZo+vrq5GaGgoFi5cCD8/v2aPef3117FixQq88847OHbsGF5//XW88cYbWLZsmTlfCpHFK6uuwzepDZNWZwwOFpzmDwOCOyG4szOqdXpsPZovOg4RWRDhRWXJkiWYNWsWEhISEB4ejpUrV8LZ2RmrVq1q9viBAwdi0aJFmDp1KhwdHZs9ZteuXbj11lsxfvx4hISE4I477sDo0aOveqaGyB58lZKFmjoDwvzcMCC4k+g4RpIk4bbohjVV/neAV/8Q0R+EFhWdToeUlBTEx8cb71MoFIiPj8fu3bvb/LhDhgxBUlISTp48CQA4dOgQdu7ciXHjxjV7fG1tLcrLy5vciGyNwSDjk8YF3mYMbhg6tSS3NS7+9uupQhRU1AhOQ0SWQmhRKSoqgl6vh69v08WmfH19kZeX1+bHff755zF16lSEhYXBwcEBMTExeOqppzB9+vRmj1+wYAG0Wq3xFhQU1ObnJrJUO04V4lxxNdw0KtwWEyA6zmW6ebkgpqsHDDKM+w8REQkf+jGHL7/8Ep999hnWrl2LAwcOYM2aNVi8eDHWrFnT7PFz5sxBWVmZ8ZaVxd1cyfZcmkQ7OTZI+CXJV3J741kVLv5GRJcI/W3l5eUFpVKJ/Pymk+fy8/OvOFG2JZ577jnjWRUAiIiIwLlz57BgwQLMnDnzsuMdHR2vON+FyBZklVTj5xMNE9TvsaBJtH91c2QAXv7hKNJyynEyvwK9fN1ERyIiwYSeUVGr1YiNjUVSUpLxPoPBgKSkJAwePLjNj1tdXQ2FoulLUyqVMBgMbX5MImv26Z5zkGVgWE8vdPNyER3nijq5qHFjbx8APKtCRA2ED/0kJibigw8+wJo1a3Ds2DHMnj0bVVVVSEhIAADMmDEDc+bMMR6v0+mQmpqK1NRU6HQ6ZGdnIzU1Fenp6cZjJkyYgNdeew0//vgjzp49i/Xr12PJkiWYOHFih78+ItFq6vRYt79hONMSFni7lkvDP98ezIbBwLWPiOyd8IHqKVOmoLCwEHPnzkVeXh6io6OxadMm4wTbzMzMJmdHcnJyEBMTY/z74sWLsXjxYgwfPhzbt28HACxbtgwvvPACHnnkERQUFCAgIAAPPfQQ5s6d26GvjcgSfH8oB6XVdQj0cMLIMB/Rca5pZB8fuGtUyCmrQfLZElwX2ll0JCISSJK5XOtlysvLodVqUVZWBnd3d9FxiNpMlmXc8s5vOJxdhn+MDcPsG7uLjtQif//vIXy5/zymx3XFaxMjRMcholYw9Weo8KEfIjKf38+X4XB2GdQqhXGZemtwS1TD8M/GI3mo03NuGZE9Y1EhsmFr9zZs8jc+wh+eLmrBaVruulBPeLmqUVKlw2/pRaLjEJFALCpENqrsYh2+O9SwcNr0uK6C07SOSqnA3yIadlT+/lCu4DREJBKLCpGN+uZgNi7W6dHL1xWxFrSvT0vdEtWweu6WtDzU1OkFpyEiUVhUiGyQLMvGYZ/pccEWt69PS/Tv2gkBWg0qauux/USh6DhEJAiLCpENSjl3ASfyK6BxUBg3+7M2CoWEmxvPqnz/O/f+IbJXLCpENujS2ZRbogKgdXIQnKbtLg3/JB3LR1VtveA0RCQCiwqRjblQpcMPhxsmoN4VZ7n7+rRE3wB3dPNyQU2dAT8dy7/2NxCRzWFRIbIxXx84D129AX0D3BHVRSs6TrtIkoQJkZeu/uHwD5E9YlEhsiGyLGNtsnVPov2rCY3DP7+cLERptU5wGiLqaCwqRDZkz+kSnC6sgotaiVuiA0THMYmevm4I83NDnV7G5rQ80XGIqIOxqBDZkM/2ngMA3BYTCFdH4XuOmsylsypc/I3I/rCoENmIospa4xmHu6xsJdprmRDZUFR2ZRShoKJGcBoi6kgsKkQ24qv951GnlxEd5IG+AdY9ifavunZ2RnSQBwwysPkIh3+I7AmLCpENMBhkfN44idbWzqZcMr5x758ffufwD5E9YVEhsgG7MoqRWVINN43KOExia8ZF+AEAks+WcPiHyI6wqBDZgHX7swAAt0UHwkmtFJzGPLp0ckZUkAdkDv8Q2RUWFSIrV1qtM06inTIwSHAa87q5cfjnx8Mc/iGyFywqRFbum4PZ0NUbEO7vjn6BtjWJ9q8uDf/sPcPhHyJ7waJCZMVkWca6/ecB2P7ZFIDDP0T2iEWFyIodyS7HsdxyqFUK3BYdKDpOhxjfeFaFwz9E9oFFhciKrdvfcEny2L5+0Do7CE7TMcb1a5inkszhHyK7wKJCZKUu6vT49mDDjsL2MOxzSZBnw/APF38jsg8sKkRWauORXFTU1iPI0wmDQzuLjtOhOPxDZD9YVIis1Lp9DWunTI4NgkIhCU7Tsf48/FNYUSs4DRGZE4sKkRU6W1SFvWdKIEnAHbFdRMfpcEGezojqooVBBjalcfiHyJaxqBBZoS8bV6K9oac3AjycBKcR42+Ni79t4N4/RDaNRYXIyhgMMtYfzAZgX5No/+pSUdl7ppjDP0Q2jEWFyMokny1BblkN3DQqjAzzER1HGA7/ENkHFhUiK/NtasMlyeP6+UHjYJsbELYUh3+IbB+LCpEV0dUbsKHxklx7WYn2ajj8Q2T7WFSIrMgvJwtRdrEOPm6OiLOztVOaE+TpjMjG4Z/NHP4hskksKkRW5NvUhkm0E6ICoLSztVOu5NKaKiwqRLaJRYXISlTW1uOnY/kAgFujAwSnsRxj+zWsUrs7oxhl1XWC0xCRqbGoEFmJrUfzUFNnQKiXCyICtaLjWIxuXi4I83NDvUE2Fjkish0sKkRW4pvGDQhviQ6AJHHY58/G9G04q7KRmxQS2RwWFSIrUFRZi53pRQCAW3m1z2UuDf/sOFWIqtp6wWmIyJRYVIiswIbDudAbZER10aKbl4voOBYnzM8NIZ2doas3YPuJQtFxiMiEWFSIrMA3jUvm38KzKc2SJAlj+l0a/uHib0S2hEWFyMJlFlfjQGYpJAmYEOkvOo7FGts4T2Xb8QLU1OkFpyEiU2FRIbJw3//eMIl2SPfO8HHXCE5juaK6eMBfq0GVTo/fGufzEJH1Y1EhsmCyLBuHfTiJ9uoUColX/xDZIBYVIgt2LLcCpwoqoVYpjFe20JVdeo9+OpaPOr1BcBoiMgUWFSIL9u2hhrMpI3v7wF3jIDiN5RsY4onOLmqUVtch+UyJ6DhEZAIsKkQWymCQ8X1qw/wULpnfMkqFhJvCfQHw6h8iW8GiQmSh9p0tQU5ZDdwcVRgR5iM6jtW4NPyzOS0fBoMsOA0RtReLCpGF+vZQw9mUsf38oHFQCk5jPYZ094KbRoXCiloczLogOg4RtROLCpEF0tUbsOFww9AFr/ZpHbVKgfg+jcM/h3n1D5G1Y1EhskA7ThaitLoO3m6OGNy9s+g4VufSZcqb0vIgyxz+IbJmLCpEFujSsM+EyAAoFdwpubWG9/KGk4MS5y9cRFpOueg4RNQOLCpEFqaqth5bjzYMWfBqn7ZxUitxY29vAMAmLv5GZNVYVIgszNaj+aipMyCkszMiu2hFx7Fal67+2ZTGokJkzVhUiCzMN6l/LJkvSRz2aasRYT5wUEpIL6jE6cJK0XGIqI1YVIgsSHFlLX491bCh3i0c9mkXd40DrgttmIi89Wi+4DRE1FYsKkQWZMPhXOgNMiICteju7So6jtUb3bhK7RYWFSKrxaJCZEG+4ZL5JhXfWFQOZF5AYUWt4DRE1BYsKkQWIqukGinnLkCSgAlRLCqm4K91QmQXLWQZSDrGsypE1ohFhchCfNe4dsrg0M7wddcITmM7Lg3/cJ4KkXViUSGyALIs41vj1T48m2JKN4U3XKb8a3oRqmrrBachotZiUSGyAMfzKnAyvxJqpQJj+/mLjmNTevm6IrizM3T1Bvx6qlB0HCJqJRYVIgvwbeMk2hFh3tA6OQhOY1skScJNjZsUbknj8A+RtWFRIRLMYJDx/aFLV/twp2RzGN24SWHS8QLU6w2C0xBRa7CoEAm2/9wFZJdehKujCiPDfETHsUmxwZ3g6aJG2cU6JJ8tER2HiFqBRYVIsEuTaMf284PGQSk4jW1SKiSMaiyBvPqHyLqwqBAJpKs34MfDuQB4tY+53RT+xzwVWZYFpyGilmJRIRLo11OFKK2ug5erIwY37ktD5jGspzc0Dgpkl17EsdwK0XGIqIVYVIgEWn+wYdhnQpQ/VEr+czQnJ7USw3p6AwC2HM0TnIaIWoq/GYkEqaipM86XmBjDq306AlepJbI+FlFUli9fjpCQEGg0GsTFxSE5OfmKx6alpWHSpEkICQmBJElYunTpZcdc+tpfb48++qgZXwVR62w6kofaegNCvV0QEagVHccujOrjC4UEpOWU4/yFatFxiKgFhBeVdevWITExEfPmzcOBAwcQFRWFMWPGoKCgoNnjq6urERoaioULF8LPz6/ZY/bt24fc3FzjbevWrQCAyZMnm+11ELXWN41X+0yMDoQkSYLT2AdPFzUGhHgC4FkVImshvKgsWbIEs2bNQkJCAsLDw7Fy5Uo4Oztj1apVzR4/cOBALFq0CFOnToWjo2Ozx3h7e8PPz894++GHH9C9e3cMHz7cnC+FqMXyy2uwK6MYABd562gc/iGyLkKLik6nQ0pKCuLj4433KRQKxMfHY/fu3SZ7jk8//RT33XffFf+vtba2FuXl5U1uROb0XWoOZBkYENwJXTs7i45jVy5dprz3TAlKq3WC0xDRtQgtKkVFRdDr9fD19W1yv6+vL/LyTDMr/5tvvkFpaSnuvffeKx6zYMECaLVa4y0oKMgkz010JZeu9rmNk2g7XHBnF/T2dYPeIGPbieaHmInIcggf+jG3jz76COPGjUNAwJUX05ozZw7KysqMt6ysrA5MSPbmRF4FjuaWw0EpYXwEd0oWIT68YZXan46xqBBZOqFFxcvLC0qlEvn5TceK8/PzrzhRtjXOnTuHn376CQ888MBVj3N0dIS7u3uTG5G5XJpEe2NvH3RyUQtOY59GNe6mvONEIXT13KSQyJIJLSpqtRqxsbFISkoy3mcwGJCUlITBgwe3+/FXr14NHx8fjB8/vt2PRWQKBoOMbxuHfbh2ijjRXTzg5apGRW099nGTQiKLJnzoJzExER988AHWrFmDY8eOYfbs2aiqqkJCQgIAYMaMGZgzZ47xeJ1Oh9TUVKSmpkKn0yE7OxupqalIT09v8rgGgwGrV6/GzJkzoVKpOvQ1EV1J8tkS5JTVwI07JQulUEgY0fvS8A+v/iGyZMKLypQpU7B48WLMnTsX0dHRSE1NxaZNm4wTbDMzM5Gbm2s8PicnBzExMYiJiUFubi4WL16MmJiYy4Z3fvrpJ2RmZuK+++7r0NdDdDXfNJ5NGRfBnZJFuzT8k3SsgJsUElkwSea/0MuUl5dDq9WirKyM81XIZGrq9Bj42k+oqKnH2gfiMKSHl+hIdq2qth4xL2+FTm/AT4k3oIePm+hIRDbB1J+hws+oENmLzWl5qKipR6CHE67jTsnCuTiqMLh7w38HXv1DZLlYVIg6yH9TzgMAJsV2gULBJfMtQXyfhnkqSZynQmSxWFSIOkB26UXsTC8CAEyO7SI4DV0ysnGeSsq5C7hQxVVqiSwRiwpRB/hfynnIMnBdqCeCPLlkvqUI9HBCmJ8bDDK4Si2RhWJRITIzWZbx3wMNwz6TY7k9g6WJ/9PVP0RkeVhUiMws+UwJzhVXw9VRhXER7V9xmUxrVOM8lV9OcpVaIkvEokJkZl81TqIdH+EPZzUXH7Q0UV084OXqiMraeiSf4Sq1RJaGRYXIjKpq67HhcMOChZMHcBKtJVIoJIwM8wbAVWqJLBGLCpEZ/Xg4F9U6PUK9XBAb3El0HLoC4yq1x/O5Si2RhWFRITKjdfuyADSsnSJJXDvFUg3r6QW1SoGskos4VVApOg4R/QmLCpGZnMirQMq5C1ApJK6dYuGc1SoMMa5Sy+EfIkvCokJkJmv3ngPQcPmrj7tGcBq6llG8TJnIIrGoEJlBta4e/zvQsFPy9Ou6Ck5DLTEqrOEy5QOZF1DCVWqJLAaLCpEZ/HAoFxW19ejq6Yyh3blLsjUI8HBCuL87ZBnYdpxnVYgsBYsKkRl8lpwJAJg2qCs3ILQixk0Kj3OeCpGlYFEhMrG0nDIcyiqFg1Li2ilW5tI8lR0ni7hKLZGFYFEhMrG1exvOpozp6wcvV0fBaag1IgK18HZrWKV275li0XGICCwqRCZVXlOHbw42TKK9K46TaK2NQiFhZO/G4R9e/UNkEVhUiEzoq/3nUaXTo6ePKwaHdhYdh9rg0iaFPx3jKrVEloBFhchE9AYZa3adBQDcOzSEK9FaqesbV6k9f+EiTuZzlVoi0VhUiExk2/ECZJZUw12jwsSYQNFxqI2c1SoM5Sq1RBaDRYXIRFbvOgOg4ZJkZ7VKcBpqj0tX/7CoEInHokJkAifzK/BbejEUEnDP4GDRcaid4huLSmpWKQoragWnIbJvLCpEJrD6t7MAgNHhfujSyVlsGGo3P60GkV20kGUgiWdViIRiUSFqp9JqHdYfPA8ASBgaIjYMmcxNjWdVth5lUSESiUWFqJ3+s/scauoMCPd3x6BunqLjkInc1LehqOxML0K1rl5wGiL7xaJC1A4XdXp83HhJ8kPDQ3lJsg3p7euGIE8n1NYb8OupItFxiOwWiwpRO3yVkoWSKh2CPJ0wPsJfdBwyIUmScFMfPwAc/iESiUWFqI3q9Qa8v+M0AGDWsFColPznZGviwxtWqf35eAH0Bq5SSyQCf7MStdGPh3Nx/sJFeLqoMTk2SHQcMoNBIZ7QOjmgpEqHlHMXRMchskssKkRtIMsyVv7ScDYlYUgInNRKwYnIHFRKBUaG/bH3DxF1PBYVojb45WQhjuWWw1mt5AJvNu6m8D8uU+YmhUQdj0WFqJVkWcbbSacAAHcN6goPZ7XgRGRON/TyhlqpwJmiKmQUcpNCoo7GokLUSr+eKsKBzFI4qhR4cHio6DhkZq6OKgxu3KRwC6/+IepwLCpErSDLMpb+dBIAcPd1wfBx0whORB3hz8M/RNSxWFSIWmHHn86mPMSzKXbjUlFJzSpFQUWN4DRE9oVFhaiFeDbFfvm6axDVuEnhz8cKRMchsissKkQttONUEQ7ybIrd4vAPkRgsKkQtwLMpFB/OTQqJRGBRIWqBn48X8GyKnfvzJoU7ThaKjkNkN1hUiK5Bb5DxxqYTAIB7h4bwbIqdkiQJY/s2bFK48Uie4DRE9oNFhega1h/Mxon8CrhrVHhkeA/RcUigsf0adshOOlaA2nq94DRE9oFFhegqaur0+PfWhrkpj4zoAa2zg+BEJFJMkAf83DWorK3HzlNFouMQ2QUWFaKr+HTPOWSXXoSfuwb3DgkRHYcEUygkjO3H4R+ijsSiQnQF5TV1eGdbOgDg6Zt6QuPAHZIJGNdYVLYezUed3iA4DZHtY1EhuoL3fslAaXUdunu7YFL/LqLjkIUYEOIJL1dHlF2sw+6MYtFxiGweiwpRM7JLL+LDX88AAJ4bEwaVkv9UqIFSIWFM34Y1VTYeyRWchsj28bcvUTNe33gctfUGDArxNH4oEV3yt4iGq3+2pOWjnsM/RGbFokL0FynnSvDdoRxIEjB3QjgkSRIdiSxMXDdPdHJ2QHGVDslnS0THIbJpLCpEf2IwyHj5+6MAgDtjg9AvUCs4EVkilVKB0eENk2o38eofIrNiUSH6k/UHs3HofBlcHVV4Zkwv0XHIgo2N+OMyZYNBFpyGyHaxqBA1qqqtxxubjwMAHh3Rg0vl01UN7e4FN40KhRW1SMm8IDoOkc1iUSFq9O72dOSX1yLI0wkJQ0NExyELp1YpcFOfxqt/DnP4h8hcWFSIAGQUVuL9HacBAP/3t3Au7kYtMq7x6p+NR3I5/ENkJiwqZPdkWcYL3xxBnV7GiN7evByZWmxYTy+4OqqQW1aDg1kc/iEyBxYVsnvfHcrBroxiOKoUeOmWfrwcmVpM46DE6MZi+/0hLv5GZA4sKmTXymvq8OqPxwAAj43oga6dnQUnImszISoAAPDD77nQc/iHyORYVMiuLdlyEoUVtQj1csGDw0NFxyErdH0PL3g4O6CoshZ7T3PvHyJTY1Ehu3Ukuwz/2X0WAPDyrf3gqOIEWmo9B6XCuKPy97/nCE5DZHtYVMgu1esN+Of6wzDIDafur+/pJToSWbEJkQ3DPxuP5EFXz71/iEyJRYXs0qrfzuD382Vw06jwwvg+ouOQlYsL7QwvV0eUVtfht/Qi0XGIbAqLCtmdM0VVeHPLSQDAC+PD4ePOFWipfZQKCTdHNqyp8v0hDv8QmRKLCtkVg0HGP77+HbX1BlzfwwuTB3QRHYlsxISohqKy5Wg+aur0gtMQ2Q4WFbIrnyVnIvlMCZwclFhwewTXTCGTiQnqhEAPJ1TW1mP7iULRcYhsBosK2Y3s0otYuKFhzZS/j+2NIE+umUKmo/jz8A+v/iEyGRYVsguyLOP/1h9GlU6P2OBOmDE4RHQkskGXFn9LOpaPqtp6wWmIbAOLCtmFrw9kY/uJQqiVCrw+KQJKBYd8yPT6Brijm5cLauoM+OlYvug4RDaBRYVs3vkL1XjxuzQAwJPxPdHDx01wIrJVkiRhgvHqH+79Q2QKFlFUli9fjpCQEGg0GsTFxSE5OfmKx6alpWHSpEkICQmBJElYunRps8dlZ2fj7rvvRufOneHk5ISIiAjs37/fTK+ALJXBIOPZrw6hsrYe/bt64KEbuEw+mdel4Z9fThagrLpOcBoi6ye8qKxbtw6JiYmYN28eDhw4gKioKIwZMwYFBQXNHl9dXY3Q0FAsXLgQfn5+zR5z4cIFDB06FA4ODti4cSOOHj2KN998E506dTLnSyELtOq3M9hzugTOaiWW3BkNlVL4jzzZuJ6+bgjzc0OdXsaGIzyrQtRewn9rL1myBLNmzUJCQgLCw8OxcuVKODs7Y9WqVc0eP3DgQCxatAhTp06Fo6Njs8e8/vrrCAoKwurVqzFo0CB069YNo0ePRvfu3c35UsjCnMirwBubTgAA/m98H4R4uQhORPZiYkwgAGD9wWzBSYisn9CiotPpkJKSgvj4eON9CoUC8fHx2L17d5sf97vvvsOAAQMwefJk+Pj4ICYmBh988MEVj6+trUV5eXmTG1k3Xb0BT61LhU5vwIje3rhrUFfRkciO3BIdAEkCks+U4PyFatFxiKya0KJSVFQEvV4PX1/fJvf7+voiLy+vzY97+vRprFixAj179sTmzZsxe/ZsPPHEE1izZk2zxy9YsABardZ4CwoKavNzk2VY+tNJHMstRydnB7x+RyQXdqMO5a91wnXdOgMAvk3lmipE7SF86MccDAYD+vfvj/nz5yMmJgYPPvggZs2ahZUrVzZ7/Jw5c1BWVma8ZWVldXBiMqX9Z0uw8pcMAMD8iRHwceNePtTxLg3/fHMwG7IsC05DZL2EFhUvLy8olUrk5zddbyA/P/+KE2Vbwt/fH+Hh4U3u69OnDzIzM5s93tHREe7u7k1uZJ3Kquvw5BepMMjA7TGBGBfhLzoS2amxEX5QqxQ4VVCJo7kcTiZqK6FFRa1WIzY2FklJScb7DAYDkpKSMHjw4DY/7tChQ3HixIkm9508eRLBwcFtfkyyfLLcsOFgdulFdPV0xku39hUdieyYu8YBN/VpGNb+hpNqidpM+NBPYmIiPvjgA6xZswbHjh3D7NmzUVVVhYSEBADAjBkzMGfOHOPxOp0OqampSE1NhU6nQ3Z2NlJTU5Genm485umnn8aePXswf/58pKenY+3atXj//ffx6KOPdvjro47z6Z5z2JSWBwelhHfuioGbxkF0JLJztzUO/3ybmgO9gcM/RG2hEh1gypQpKCwsxNy5c5GXl4fo6Ghs2rTJOME2MzMTCsUffSonJwcxMTHGvy9evBiLFy/G8OHDsX37dgANlzCvX78ec+bMwcsvv4xu3bph6dKlmD59eoe+Nuo4R3PK8cqPDRsO/mNsGCK7eIgNRARgeC9veDg7oKCiFrszinF9Ty/RkYisjiRzltdlysvLodVqUVZWxvkqVqBaV4+bl+3E6cIqjAzzwUczB/AqH7IY/7f+MD7bm4lJ/bvgzTujRMchMjtTf4YKH/ohaq+536bhdGEVfN0dsXhyFEsKWZRLV/9sOpKLizq94DRE1odFhaza+oPn8d+U81BIwFtTY+DpohYdiaiJ2OBO6NLJCVU6PXdUJmoDFhWyWmeKqvCv9UcAAI+P7InrQjsLTkR0OUmSmqypQkSt0+aiUlZWhhMnTuDEiRMoKyszZSaia6qt1+Pxzw+gSqdHXDdPPDGqp+hIRFd0a3RDUfnlZCGKK2sFpyGyLq0uKh9++CHCw8Ph6emJ8PDwJn/+6KOPzJGR6DILNx7HkeyGJfKXTo2GUsF5KWS5evi4IiJQi3qDjB8Pc0dlotZoVVFZtGgRnnzySdx6661ISkrCkSNHcOTIESQlJeG2227Dk08+icWLF5srKxEAYOvRfKz+7SwAYPHkKPhrncQGImqBS2uqfJ1yXnASIuvSqsuTg4ODsWjRItx5553Nfn3dunV47rnnrrhUvbXg5cmWK7fsIsa99StKq+tw//Xd8MLN4df+JiILUFxZi7j5Sag3yNj81A3o7ecmOhKRWQi9PLmgoAARERFX/HpERASKioraHYqoOfV6A578PBWl1XWICNTi72N7i45E1GKdXR0xqo8PAOCr/dz4lKilWlVUBg4ciIULF6K+vv6yr+n1erz++usYOHCgycIR/dnbP6cj+WwJXB1VWDYtBo4qpehIRK0yOTYIALD+YDbq9AbBaYisQ6uW0H/nnXcwZswY+Pn54YYbbjAuc5+fn48dO3ZArVZjy5YtZglK9m1XRhGW/XwKAPDaxH4I8XIRnIio9W7s7Q1vN0cUVtTi5+MFGNO37bvEE9mLVp1RiYyMxMmTJ/HKK6/Azc0Np0+fxunTp+Hm5oZXX30Vx48fR79+/cyVlexUcWUtnvoiFbIM3Dmgi/FSTyJro1IqcHvjpNqv9nNSLVFLmHWvn4ULF+Lhhx+Gh4eHuZ7CLDiZ1nIYDDLuX7MP204UooePK757bCic1cL30iRqs/SCCsQv2QGlQsLuOSPh46YRHYnIpKxqr5/58+ejpKTEnE9BNu7jXWex7UQh1CoF3rkrhiWFrF4PHzfEdPWA3iBzpVqiFjBrUeHGzNQeR3PKsXDjcQDAC+P7IMyPZ7fINtw5oGFS7Zf7z/P3JNE1cK8fskgXdQ1L5Ov0BsT38cXd1wWLjkRkMjdH+kPjoEB6QSVSs0pFxyGyaCwqZJFe+fEoMgqr4OPmiDfuiIQkcYl8sh1uGgf8rZ8/gIazKkR0ZSwqZHE2HcnD2r2ZkCTg31Oi4emiFh2JyOQmNw7/fH8oB5W1l69NRUQNWFTIouSWXcTz//sdAPDgDaEY2sNLcCIi87gu1BOhXi6orK3Ht6mcVEt0JWYtKsOGDYOTEzeMo5bRG2Q8va5hifzILlo8cxOXyCfbJUkS7orrCgD4dE8mJ9USXUG7i0pNTQ3Ky8ub3C7ZsGED/P392/sUZCdW/pKBPadL4KxW4q2pMVCreMKPbNsdsV3gqFLgWG45DnJSLVGz2vRJUF1djcceeww+Pj5wcXFBp06dmtyIWutg5gUs2XoSAPDSLX3RjUvkkx3wcFbj5sgAAMCne84JTkNkmdpUVJ577jn8/PPPWLFiBRwdHfHhhx/ipZdeQkBAAP7zn/+YOiPZuMraejz5RSr0Bhk3R/rjjtguoiMRdZi7r2sY/vnh91xcqNIJTkNkedpUVL7//nu8++67mDRpElQqFYYNG4Z//etfmD9/Pj777DNTZyQbN/fbI8gsqUaghxNemxjBS5HJrkQHeaBvgDt09QZ8fYCXKhP9VZuKSklJCUJDQwEA7u7uxmXyr7/+euzYscN06cjmfZuajf8dyIZCAt6aGg2tk4PoSEQdSpIk44KGn+3NhMHASbVEf9amohIaGoozZ84AAMLCwvDll18CaDjTYm0bEJI4mcXV+L/1RwAAT4zqiQEhnoITEYlxa3QA3BxVOFNUhR2nCkXHIbIobSoqCQkJOHToEADg+eefx/Lly6HRaPD000/jueeeM2lAsk31egOeXHcQlbX1GBDcCY+N6CE6EpEwzmoVpgxsWADuo51nBKchsiySbIKL98+dO4eUlBT06NEDkZGRpsgllKm3qKbLLdlyAm//nA43jQobnxyGLp2cRUciEur8hWrc8MY2GGRg01PDuAknWS1Tf4aaZKGK4OBg3H777TZRUsj89p4uxjvb0gEAr02MYEkhAtClkzPGNe7/s4pnVYiMVC098O23327xgz7xxBNtCkO2r6y6Dk+tS4VBbljs6paoANGRiCzG/cO64cfDufjmYA6eGxMGbzdH0ZGIhGtxUfn3v//d5O+FhYWorq42Tp4tLS2Fs7MzfHx8WFSoWbIsY87635FbVoNuXi546Za+oiMRWZT+XTshpqsHDmaW4tM95/D0Tb1ERyISrsVDP2fOnDHeXnvtNURHR+PYsWMoKSlBSUkJjh07hv79++OVV14xZ16yYl/uz8KGw3lQKSS8NTUaLo4t7slEduOB6xuWfvh0zznU1OkFpyESr01zVF544QUsW7YMvXv/sWlc79698e9//xv/+te/TBaObEd6QSVe/O4oAODZMb0R2cVDbCAiCzWmry8CPZxQXKXD/w5wV2WiNhWV3Nxc1NfXX3a/Xq9Hfn5+u0ORbamt1+PJLw7iYp0eQ3t0xoPDQkVHIrJYKqUC91/fDQDw3o4M1OsNghMRidWmojJq1Cg89NBDOHDggPG+lJQUzJ49G/Hx8SYLR7bhjU0nkJZTjk7ODlhyZzQUCi6RT3Q1UwcFoZOzA84VV2PDkTzRcYiEalNRWbVqFfz8/DBgwAA4OjrC0dERgwYNgq+vLz788ENTZyQrtu14gXEBq0V3RMHXXSM4EZHlc1arcN/QhrMq725LhwmWuyKyWm2azejt7Y0NGzbg5MmTOHbsGCRJQlhYGHr14gx1+kNBeQ2e/aphBeN7h4QgPtxXcCIi6zFjcAhW/pKB43kV2HaiACPD+O+H7FO7Lrvo1asXevbsCQDc8ZaaMBhkJH55CMVVOvTxd8fz48JERyKyKlpnB9x9XTDe23Eay7dlYERvH/6eJbvU5pVpP/roI/Tr1w8ajQYajQb9+vXjsA8ZvbfjNHamF8HJQYll02KgcVCKjkRkde6/vhvUKgVSzl1A8pkS0XGIhGhTUZk7dy6efPJJTJgwAV999RW++uorTJgwAU8//TTmzp1r6oxkZQ5mXsCbW04AAF68JRw9fFwFJyKyTj7uGkyO7QIAeHd7huA0RGK0aVNCb29vvP3225g2bVqT+z///HM8/vjjKCoqMllAEbgpYduV19Rh/Nu/IqvkIsZH+uOdaTE8XU3UDpnF1Rjx5nboDTJ+ePx69AvUio5EdFUWsSlhXV0dBgwYcNn9sbGxza6vQvZBlmX8a/0RZJVcRKCHE+ZPjGBJIWqnrp2dMSGyYbPCd7enC05D1PHaVFTuuecerFix4rL733//fUyfPr3docg6fZ6che8O5UCpkPD2tGhonRxERyKyCbNv7AEA2HgkDxmFlYLTEHWsFl/1k5iYaPyzJEn48MMPsWXLFlx33XUAgL179yIzMxMzZswwfUqyeEeyy/Di92kAgGdH90ZssKfgRES2o7efG24K98XWo/lYuT0DiyZHiY5E1GFaXFQOHjzY5O+xsbEAgIyMhgleXl5e8PLyQlpamgnjkTUou1iHRz47AF29AaPCfPDQDVwin8jUHrmxO7Yezcf6g9l46qZeCPRwEh2JqEO0uKhs27bNnDnISsmyjOe+OoTMkmoEejjhzTujuEQ+kRnEdO2EId07Y1dGMT7YcRov3tJXdCSiDtHmdVSIAOCjnWew5Wg+1EoF3p3eHx7OatGRiGzWoyMa5qp8npyJospawWmIOkabVqatqanBsmXLsG3bNhQUFMBgaLq75583KyTblXKuBAs3HgcAvHBzH0QFeYgNRGTjhnTvjKggDxzKKsWqnWfw97Fc8ZlsX5uKyv33348tW7bgjjvuwKBBg3gJqh0qqqzFo58dRL1BxoSoANx9XbDoSEQ2T5IkPHpjdzz4SQo+2X0OD9/YHe4aXl1Htq1NReWHH37Ahg0bMHToUFPnISugqzfgkU8PIK+8BqHeLlhwO9dLIeoo8X180cvXFSfzK/HJ7nPG4SAiW9WmOSqBgYFwc3MzdRayEi//kIbksyVwc1Th/XsGwNWxXXtbElErKBQSZt/YHQCwaucZXNTpBSciMq82FZU333wT//jHP3Du3DlT5yEL93lyJj7dkwlJApZOjeY+PkQCTIgMQJdOTiiu0mHdvkzRcYjMqk1FZcCAAaipqUFoaCjc3Nzg6enZ5Ea2af/ZEsz99ggA4JmbemFUH1/BiYjsk0qpwMPDG86qvL/jNHT1hmt8B5H1atM5+2nTpiE7Oxvz58+Hr68v5yfYgdyyi3j40wOo08v4W4Qfx8WJBLsjtgveSjqFnLIafJOajTsHBImORGQWbSoqu3btwu7duxEVxWWc7UG1rh4PfZKCospahPm5YdEdUSynRIJpHJSYNawb5m84jpXbMzCpfxcoudgi2aA2Df2EhYXh4sWLps5CFkhvkPHkF6n4/XwZOjk74P17BsCFk2eJLMJdccHQOjngdFEVNh3JEx2HyCzaVFQWLlyIZ555Btu3b0dxcTHKy8ub3Mh2LNhwDFsbV579YMYAdO3sLDoSETVydVRh5pAQAMCKX9Ihy7LYQERm0Kb/NR47diwAYNSoUU3ul2UZkiRBr+flcrbgk91n8eHOMwCARZMjMSCEE6WJLM29Q0Lw/o4MHMkux66MYgzt4SU6EpFJtamocINC27fteAHmfdewE/azo3vh1uhAwYmIqDmeLmpMGRCENbvPYeUvGSwqZHPaVFSGDx9u6hxkQY7mlOOxtQdgkBuuLOAVPkSW7YFhofh0byZ+PVWEI9ll6BeoFR2JyGTaNSuyuroamZmZ0Ol0Te6PjIxsVygSJ7+8Bvev2YcqnR6DQztj/kQuj09k6YI8nXFzpD++Tc3Byl8y8M5d/UVHIjKZNhWVwsJCJCQkYOPGjc1+nXNUrFNFTR3u+3gfcstq0N3bBSvvjoVa1ab51kTUwR68IRTfpuZgw+FcZBZXc+I72Yw2fQo99dRTKC0txd69e+Hk5IRNmzZhzZo16NmzJ7777jtTZ6QOoKs34OFPU5CWU47OLmqsvncQtM7clZXIWvQN0OKGXt4wyMAHv54WHYfIZNpUVH7++WcsWbIEAwYMgEKhQHBwMO6++2688cYbWLBggakzkpkZDDKe++8h/JZeDGe1EqsTBvL/xois0MPDQwEAX+7PQlFlreA0RKbRpqJSVVUFHx8fAECnTp1QWFgIAIiIiMCBAwdMl446xIKNx/Btag5UCgkr7o5FZBcP0ZGIqA0Gh3ZGVBctausNWLPrrOg4RCbRpqLSu3dvnDhxAgAQFRWF9957D9nZ2Vi5ciX8/f1NGpDM64Mdp/HBrw1rpbxxRySG9/IWnIiI2kqSJDzUuFnhf3afQ1VtveBERO3XpqLy5JNPIjc3FwAwb948bNy4EUFBQXjrrbcwf/58kwYk8/k2NRuvbTgGAJgzLgy39+8iOBERtdeYvn7o5uWCsot1+GJflug4RO0mySZYc7m6uhrHjx9H165d4eVl/YsNlZeXQ6vVoqysDO7u7qLjmMXOU0VI+DgZdXoZ9w3thhdu7sPLkIlsxNq9mfjn+sMI0Grwy99HwEHJq/eo45j6M7TFlycnJia2+EGXLFnSpjDUMY5kl+GhT/ajTi/j5kh//Gs8SwqRLbm9fyCWbD2JnLIafH8oh2dLyaq1uGYfPHiwRbfU1NRWh1i+fDlCQkKg0WgQFxeH5OTkKx6blpaGSZMmISQkBJIkYenSpZcd8+KLL0KSpCa3sLCwVueyRZnF1bh39R8Lur15ZxQU3BqeyKZoHJRIGBoCAHjvl9PcrJCsWovPqJhrf59169YhMTERK1euRFxcHJYuXYoxY8bgxIkTxiuL/qy6uhqhoaGYPHkynn766Ss+bt++ffHTTz8Z/65StWsRXptQUFGDGav2oqiyFn383fHejFg4qpSiYxGRGdx9XTBWbM/AifwKbDtRgJFhvqIjEbWJ8IHLJUuWYNasWUhISEB4eDhWrlwJZ2dnrFq1qtnjBw4ciEWLFmHq1KlwdHS84uOqVCr4+fkZb7Ywd6Y9Sqt1uOfDZJwtrkaQpxPWJAyEu4YLuhHZKq2TA+6K6woAWLmdC8CR9RJaVHQ6HVJSUhAfH2+8T6FQID4+Hrt3727XY586dQoBAQEIDQ3F9OnTkZmZecVja2trUV5e3uRmSypr63Hv6n04kV8BHzdHfHb/dfBx14iORURmdt/QbnBQSkg+W4KUcxdExyFqE6FFpaioCHq9Hr6+TU9J+vr6Ii8vr82PGxcXh48//hibNm3CihUrcObMGQwbNgwVFRXNHr9gwQJotVrjLSgoqM3PbWlq6vR48D/7kZpVCg9nB3xyfxxXnSWyE35aDW6LDgQAvPdLhuA0RG0jfOjHHMaNG4fJkycjMjISY8aMwYYNG1BaWoovv/yy2ePnzJmDsrIy4y0ryzbWHqjTG/D45wexK6MYLmol1iQMQm8/N9GxiKgDPdS4rP7WY/lIL6gUnIao9YQWFS8vLyiVSuTn5ze5Pz8/H35+fiZ7Hg8PD/Tq1Qvp6enNft3R0RHu7u5NbtbOYJDx9//+jq1H86FWKfDhzIGICvIQHYuIOlgPHzfcFO4LWQbe38GzKmR9hBYVtVqN2NhYJCUlGe8zGAxISkrC4MGDTfY8lZWVyMjIsJvl/Q0GGf9cfxjrD2Y37N8zvT8Gd+8sOhYRCfJw47L66w9mI7+8RnAaotYRPvSTmJiIDz74AGvWrMGxY8cwe/ZsVFVVISEhAQAwY8YMzJkzx3i8TqdDamoqUlNTodPpkJ2djdTU1CZnS5599ln88ssvOHv2LHbt2oWJEydCqVRi2rRpHf76OtqlkvLFviwoJODNO6Mwqg8vSySyZ7HBnTAwpBPq9DJW7TwjOg5RqwhfXGTKlCkoLCzE3LlzkZeXh+joaGzatMk4wTYzMxMKxR99KicnBzExMca/L168GIsXL8bw4cOxfft2AMD58+cxbdo0FBcXw9vbG9dffz327NkDb2/b3nDPYJDxf9/8UVKW3BmNWxsn0hGRfXt4eHfsO7sfn+3NxCMjekDrxOUJyDqYZK8fW2ONe/00lJQj+Dw503gmZWIMl80mogYGg4yxb+3AyfxK/H1sbzxyYw/RkchGmfozVPjQD7Vfvd6A5//3O0sKEV2RQiHhoRsa5qqs/u0saur0ghMRtQyLipWrrdfjsbUH8eX+81BIwOLJLClE1LwJUQHw12pQWFGL9QezRcchahEWFStWVVuP+z/ej01peVArFXh3eix3SSWiK1KrFLj/+m4AgOXb0lGnNwhORHRtLCpWqqRKh7s/2oud6UVwViuxOmEgxvYz3dozRGSbpscFw8vVEecvXMR/U86LjkN0TSwqVii9oBIT3/0NBzNLoXVywGcPxGFoD/vedJGIWsZJrcQjNzbMVXnn53TU1nOuClk2FhUr81t6EW5/9zeca9wF+b8PD0ZM106iYxGRFbkrrit83R2RXXoRX+7nWRWybCwqVkKWZazZdRYzVyWjvKYescGd8M0jQ9HTl3v3EFHraByUeHREw+XJy39O5xVAZNFYVKxAZW09Hvv8IOZ9l4Z6g4xbowPw2QNx6OzqKDoaEVmpKQOD4K/VIK+8Bl8kZ4qOQ3RFLCoW7lBWKW5ZthM//p4LlULCCzeHY+mUaGgclKKjEZEVc1Qp8djIxrMq2zN4VoUsFouKhaqt12Px5hO4fcUunC6qgr9Wg3UPDcb913eDJEmi4xGRDZgcG4RADycUVtTi0z3nRMchahaLigXae7oYtyz7De9sS4feIGNCVAA2PDEMscGcNEtEpqNWKfDEqIazKiu2Z6Cytl5wIqLLsahYkLyyGjzx+UFMeX8PTuRXwNNFjXen98eyaTHo5KIWHY+IbNDt/bugm5cLiqt0+GDHadFxiC7DomIBCitq8coPRzF80TZ8dygHktRw+eBPicPxtwh/0fGIyIY5KBV4dnRvAMCHv55GUWWt4ERETalEB7Bn2aUX8fFvZ/DJnnOoqWtYynpgSCfMm9AX/QK1gtMRkb34W4QfIrto8fv5MrzzczpevKWv6EhERiwqV3EqvwKu1ZdPXJUhX/X75Kt/GYUVtVi7NxNbjubB0HhsdJAHEm/qhWE9vThZlog6lCRJ+MfYMEz/cC8+23sO9w3thq6dnUXHIgLAonJVE9/dBYWjef+xDuneGbOGheLG3t4sKEQkzNAeXhjW0wu/nirCkq0nsHRqjOhIRABYVK6qs4sDlJqWTmJteclwUEoYEeaDmYND0NuPK8sSkWX4x9gw/HpqJ749lIMHb+iO8AB30ZGIIMnytQYq7E95eTm0Wi3Kysrg7s5/qERkPx5bewA//J6LG3t74+OEQaLjkBUy9Wcor/ohIiKjZ0f3hkohYfuJQuw5XSw6DhGLChER/SHEywVTBwUBABZuPA6edCfRWFSIiKiJJ0b1hLNaidSsUmw4nCc6Dtk5FhUiImrCx02Dh27oDgBYuOkYauu5YSGJw6JCRESXmXVDN/i4OSKr5CI+2c0NC0kcFhUiIrqMs1plXFr/7aRTuFClE5yI7BWLChERNWtSbBeE+bmhvKYey35OFx2H7BSLChERNUupkPB/4/sAAD7ZcxZni6oEJyJ7xKJCRERXNKynN27s7Y06vYzXNx0XHYfsEIsKERFd1T//1gcKCdh4JA/7zpaIjkN2hkWFiIiuqpevG6YM7AoAePXHY1wEjjoUiwoREV3T0zc1LAJ3KKsUP/yeKzoO2REWFSIiuiYfNw0eHt6wCNzrm46jpo6LwFHHYFEhIqIWmTUsFL7ujjh/4SL+s/us6DhkJ1hUiIioRZzUSuMicMt+TkcJF4GjDsCiQkRELXZ7/y4I93dHRU093k46JToO2QEWFSIiarE/LwL36Z5zOF1YKTgR2ToWFSIiapWhPbwwMswH9QYuAkfmx6JCREStNmdcGBQSsDktH8lnuAgcmQ+LChERtVrPPy0Ct2AjF4Ej82FRISKiNnk6viecHJQ4mFmKzWn5ouOQjWJRISKiNvFx1+CBYd0AAG9sPo56vUFwIrJFLCpERNRmD94QCk8XNU4XVmHd/izRccgGsagQEVGbuWkc8PjIHgCApT+dQrWuXnAisjUsKkRE1C7T44LR1dMZhRW1+OjXM6LjkI1hUSEionZRqxR4dkzD0vrv7TiN4spawYnIlrCoEBFRu90c4Y+IQC0qa+ux7Od00XHIhrCoEBFRuykUEp4fFwYA+GzvOZwrrhKciGwFiwoREZnE0B5euKGXN+r0MhZvOSk6DtkIFhUiIjKZf4ztDUkCvj+Ug8Pny0THIRvAokJERCbTN0CLW6MCAACLtpwQnIZsAYsKERGZ1NM39YJKIWHHyUJuWEjtxqJCREQmFdzZBXcODAIALN58ghsWUruwqBARkck9PrIH1CoFks+WYMepItFxyIqxqBARkcn5a50w47pgADyrQu3DokJERGYx+8bucFErcTi7DJvT8kTHISvFokJERGbR2dUR91/fDQDw5paT0Bt4VoVaj0WFiIjM5oEbQqF1csCpgkp8m5otOg5ZIRYVIiIyG3eNAx4aHgoAWPrTKdTpDYITkbVhUSEiIrO6d0gIvFwdkVlSjS/3Z4mOQ1aGRYWIiMzKWa3CYyO6AwCWJaWjpk4vOBFZExYVIiIyu2lxXRHo4YS88hp8uuec6DhkRVhUiIjI7BxVSjw5qicA4N3tGaisrReciKwFiwoREXWI2/sHItTLBSVVOqzeeUZ0HLISLCpERNQhVEoFnr6pFwDg/R2nUVqtE5yIrAGLChERdZjxEf7o4++Oitp6vLfjtOg4ZAVYVIiIqMMoFBKeHd1wVmX1b2dQUFEjOBFZOhYVIiLqUCPDfBDT1QM1dQa8uy1DdByycCwqRETUoSRJwnNjegMAPtt7DucvVAtORJaMRYWIiDrckO5euL6HF+r0Mt766ZToOGTBWFSIiEiIZxvPqnx94DwyCisFpyFLZRFFZfny5QgJCYFGo0FcXBySk5OveGxaWhomTZqEkJAQSJKEpUuXXvWxFy5cCEmS8NRTT5k2NBERtUt0kAduCveFQQaWbD0pOg5ZKOFFZd26dUhMTMS8efNw4MABREVFYcyYMSgoKGj2+OrqaoSGhmLhwoXw8/O76mPv27cP7733HiIjI80RnYiI2umZ0b0gScCPv+ciLadMdByyQMKLypIlSzBr1iwkJCQgPDwcK1euhLOzM1atWtXs8QMHDsSiRYswdepUODo6XvFxKysrMX36dHzwwQfo1KmTueITEVE7hPm545aoAADAm1t4VoUuJ7So6HQ6pKSkID4+3nifQqFAfHw8du/e3a7HfvTRRzF+/Pgmj30ltbW1KC8vb3IjIqKO8XR8LygVEn4+XoCUcyWi45CFEVpUioqKoNfr4evr2+R+X19f5OXltflxv/jiCxw4cAALFixo0fELFiyAVqs13oKCgtr83ERE1DohXi64c0AXAMAbm05AlmXBiciSCB/6MbWsrCw8+eST+Oyzz6DRaFr0PXPmzEFZWZnxlpWVZeaURET0Z4+P7Am1SoG9Z0qwM71IdByyIEKLipeXF5RKJfLz85vcn5+ff82JsleSkpKCgoIC9O/fHyqVCiqVCr/88gvefvttqFQq6PX6y77H0dER7u7uTW5ERNRxAjyccM91wQCARZt5VoX+ILSoqNVqxMbGIikpyXifwWBAUlISBg8e3KbHHDVqFA4fPozU1FTjbcCAAZg+fTpSU1OhVCpNFZ+IiExo9o3d4axW4vfzZdhyNP/a30B2QSU6QGJiImbOnIkBAwZg0KBBWLp0KaqqqpCQkAAAmDFjBgIDA43zTXQ6HY4ePWr8c3Z2NlJTU+Hq6ooePXrAzc0N/fr1a/IcLi4u6Ny582X3ExGR5fBydcT913fDsp/T8eaWE4jv4wulQhIdiwQTXlSmTJmCwsJCzJ07F3l5eYiOjsamTZuME2wzMzOhUPxx4icnJwcxMTHGvy9evBiLFy/G8OHDsX379o6OT0REJvTAsFCs2XUWJ/Mr8d2hbEyM6SI6EgkmyRwIvEx5eTm0Wi3Kyso4X4WIqIO9uz0db2w6ga6ezkh6ZjgclDZ33YdNM/VnKP/rExGRRbl3SAi8XB2RWVKNL/fzKkx7x6JCREQWxVmtwmMjugMAliWlo6bu8qs1yX6wqBARkcWZFtcVgR5OyCuvwad7zomOQwKxqBARkcVxVCnx5KieAIB3t2egsrZecCIShUWFiIgs0u39AxHq5YKSKh1W7TwjOg4JwqJCREQWSaVUIHF0LwDA+ztOo7iyVnAiEoFFhYiILNbf+vkjIlCLytp6LPs5XXQcEoBFhYiILJZCIeH5cWEAgM/2nkNmcbXgRNTRWFSIiMiiDe3hhRt6eaNOL2PRlhOi41AHY1EhIiKL9/zYMEgS8P2hHPx+vlR0HOpALCpERGTxwgPcMTE6EACwYMNxcPcX+8GiQkREViFxdC+olQrsPl2M7ScLRcehDsKiQkREVqFLJ2fMHBIMAHh943HoDTyrYg9YVIiIyGo8OqIH3DUqHM+rwPqD2aLjUAdgUSEiIqvh4azGoyN6AACWbDnBDQvtAIsKERFZlZlDQhCg1SCnrAZrdp0VHYfMjEWFiIisisZBicTRvQEA72xLR2m1TnAiMicWFSIisjoTYwIR5ueGipp6vJ3EpfVtGYsKERFZHaVCwv+N7wMA+M/us8gorBSciMyFRYWIiKzSsJ7eGBXmg3qDjPk/HhMdh8yERYWIiKzWP8f3gUohIel4AXZwETibxKJCRERWq7u3K2YMDgEAvPrjUdTrDWIDkcmxqBARkVV7clRPeDg74GR+JT7flyU6DpkYiwoREVk1rbMDEm/qBaBhEbiyi3WCE5EpsagQEZHVu2tQV/T0ccWF6josSzolOg6ZEIsKERFZPZVSgX/dHA4A+HjXWZzm5co2g0WFiIhswvBe3hjR2xv1Bhkv/3AUsszdlW0BiwoREdmMF24Oh4NSwvYThdh6NF90HDIBFhUiIrIZod6umDUsFADw0vdHcVHH3ZWtHYsKERHZlMdG9kCAVoPs0ot4dzv3AbJ2LCpERGRTnNUqzJ3QMLH2vV9O40xRleBE1B4sKkREZHPG9PXDDb28odMb8NL3aZxYa8VYVIiIyOZIkoSXbukLtVKB7ScKsYUTa60WiwoREdmkbl4uePCGhom1L39/FNW6esGJqC1YVIiIyGY9OqIHAj2ckF16Ef/eelJ0HGoDFhUiIrJZTmolXp3YDwDw0c4z+P18qdhA1GosKkREZNNG9PbBLVEBMMjA818fRp3eIDoStQKLChER2by5E8Lh4eyAo7nl+PDXM6LjUCuwqBARkc3zcnXEv8Y3rK2y9KeTOMu1VawGiwoREdmFSf0DcX0PL9TWG/DP9Ye5toqVYFEhIiK7IEkSXpvYDxoHBXZlFOOrlPOiI1ELsKgQEZHdCO7sgqfjewEAXvnhKHLLLgpORNfCokJERHbl/uu7IaqLFhU19fjH1xwCsnQsKkREZFdUSgXevDMKapUCO04W4ot9WaIj0VWwqBARkd3p4eOG50b3BgC8+sNRZJVUC05EV8KiQkREdum+67thYEgnVOn0eO6/h2AwcAjIErGoEBGRXVIqJCyeHAUnByX2nC7Bf3afFR2JmsGiQkREdiu4swv++bcwAMCCjcdxKr9CcCL6KxYVIiKya9PjgjGsZ8NCcI9/fhA1dXrRkehPWFSIiMiuKRQS3rwzCp1d1DieV4HXNx0XHYn+hEWFiIjsno+bBosnRwEAVv92FtuOFwhORJewqBAREQEYEeaDe4eEAACe/eoQCipqxAYiACwqRERERs+PC0OYnxuKq3R45ktesmwJWFSIiIgaaRyUWDYtBo4qBX49VYQVv2SIjmT3WFSIiIj+pKevG16+tS8A4M0tJ/BbepHgRPaNRYWIiOgvpgzsismxXWCQgSc+P4i8Ms5XEYVFhYiIqBmv3NYPffzdUVylw2NrD6BObxAdyS6xqBARETVD46DEiun94eaowv5zF7BwI9dXEYFFhYiI6ApCvFyw+M6G9VU+2nkG3x/KEZzI/rCoEBERXcWYvn54eHh3AA3rq/x+vlRsIDvDokJERHQNz43pjRG9vVFbb8CD/0lBQTkn13YUFhUiIqJrUCokvDUtBj18XJFXXoNZn6Rw88IOwqJCRETUAu4aB3w4YwC0Tg44lFWKOf87DFnmyrXmxqJCRETUQiFeLlgxvT+UCgnrD2Zj+bZ00ZFsHosKERFRKwzp4YUXJ4QDABZvOYn/HTgvOJFtY1EhIiJqpXsGh+DBG0IBAH//7+/49VSh4ES2i0WFiIioDZ4fG4YJUQGoN8iY/ekBpOWUiY5kk1hUiIiI2kChkLB4ciSuC/VEZW09ElbvQ3bpRdGxbI5FFJXly5cjJCQEGo0GcXFxSE5OvuKxaWlpmDRpEkJCQiBJEpYuXXrZMStWrEBkZCTc3d3h7u6OwYMHY+PGjWZ8BUREZI8cVUq8d88A9PZ1Q0FFLe75aC+KK2tFx7IpwovKunXrkJiYiHnz5uHAgQOIiorCmDFjUFBQ0Ozx1dXVCA0NxcKFC+Hn59fsMV26dMHChQuRkpKC/fv3Y+TIkbj11luRlpZmzpdCRER2SOvkgNUJAxGg1eB0YRVmrEpG2cU60bFshiQLvgg8Li4OAwcOxDvvvAMAMBgMCAoKwuOPP47nn3/+qt8bEhKCp556Ck899dQ1n8fT0xOLFi3C/ffff81jy8vLodVqUVZWBnd39xa9DiIism+nCytx53u7UVSpw4DgTvjP/YPgrFaJjtXhTP0ZKvSMik6nQ0pKCuLj4433KRQKxMfHY/fu3SZ5Dr1ejy+++AJVVVUYPHhws8fU1taivLy8yY2IiKg1Qr1d8Z/74uCuadht+aFPUlBbz9Vr20toUSkqKoJer4evr2+T+319fZGXl9euxz58+DBcXV3h6OiIhx9+GOvXr0d4eHizxy5YsABardZ4CwoKatdzExGRfQoPcMfqhEFwVivx66kiPPl5Kur1BtGxrJrwOSrm0rt3b6SmpmLv3r2YPXs2Zs6ciaNHjzZ77Jw5c1BWVma8ZWVldXBaIiKyFbHBnfD+PQOgViqwKS0Pf//v79AbuNR+WwktKl5eXlAqlcjPz29yf35+/hUnyraUWq1Gjx49EBsbiwULFiAqKgpvvfVWs8c6OjoarxC6dCMiImqr63t64Z27YqBUSPjfwWw8//XvMLCstInQoqJWqxEbG4ukpCTjfQaDAUlJSVecT9JWBoMBtbW8ZIyIiDrG6L5+WDolGgoJ+CrlPP65/jDLShsIn46cmJiImTNnYsCAARg0aBCWLl2KqqoqJCQkAABmzJiBwMBALFiwAEDDBNxLQzg6nQ7Z2dlITU2Fq6srevToAaBhKGfcuHHo2rUrKioqsHbtWmzfvh2bN28W8yKJiMguTYgKgEGW8fS6VHyxLwsKhYTXbusHSZJER7MawovKlClTUFhYiLlz5yIvLw/R0dHYtGmTcYJtZmYmFIo/Tvzk5OQgJibG+PfFixdj8eLFGD58OLZv3w4AKCgowIwZM5CbmwutVovIyEhs3rwZN910U4e+NiIiolujA2GQZSR+eQhr92ZCKUl4+da+LCstJHwdFUvEdVSIiMjU/ptyHs/99xBkGbh3SAjmTQi3ybJiU+uoEBER2Ys7Yrvg9dsjAQAf7zqLV344Bp4ruDYWFSIiog5y58AgLLw9AgCw6rczeO1HlpVrYVEhIiLqQFMHdcVrE/sBAD7ceQZzv03j1UBXwaJCRETUwabHBWPB7RGQJOCTPefw/P+4KNyVsKgQEREJMG1QVyy5MwoKCfhy/3k8vS4VdVxu/zIsKkRERIJMjOmCd+7qD5VCwneHcvDY2gPQ1bOs/BmLChERkUB/i/DHe/fEQq1SYHNaPh76ZD9q6rjr8iUsKkRERIKN6uOLVTMHQuOgwLYThUhYvQ8VNXWiY1kEFhUiIiILcH1PL/znvji4Oqqw+3Qxpry3BwUVNaJjCceiQkREZCEGdfPEFw9eBy9XNY7mlmPSil04W1QlOpZQLCpEREQWpF+gFl/PHoKuns7IKrmISSt24fD5MtGxhGFRISIisjDBnV3w9ewh6BvgjuIqHaa+vxs7TxWJjiUEiwoREZEF8nZzxBcPXoehPTqjSqfHvauT8UVypuhYHY5FhYiIyEK5aRyw6t6BuCUqAPUGGc//7zBe+eGoXa1iy6JCRERkwRxVSrw1NRqJN/UCAHy08wweWGM/ly+zqBAREVk4SZLwxKieWH5Xf+NaK7e/uwunCytFRzM7FhUiIiIrMT7SH18+NBi+7o44VVCJCct24offc0THMisWFSIiIisS2cUD3z92PQZ180SVTo/H1h7Ei9+l2eweQSwqREREVsbHXYO1D8Rh9o3dAQAf7zqLO1buQnpBheBkpseiQkREZIVUSgX+MTYMq+4dAK2TA34/X4bxb+/Eh7+ehsGGrgpiUSEiIrJiI8N8sfmpGzC8lzdq6w149cdjmPbBHmQWV4uOZhIsKkRERFbOT6vBxwkD8drEfnBWK7H3TAlu+vcvWL4t3ernrrCoEBER2QBJkjA9LhgbnxyGId07o7begEWbT+Bvb/+KPaeLRcdrMxYVIiIiGxLc2QWfPRCHpVOi4eWqRnpBJaa+vwdPr0tFXlmN6HitxqJCRERkYyRJwm0xgUhKvBHT47pCkoD1B7MxYvF2LP3pJC7q9KIjtpgky7LtTA02kfLycmi1WpSVlcHd3V10HCIionY5lFWKV344iv3nLgAA/Nw1mDIwCGqVApIESJAAAJLU/ue6WFWBxPExJvsMZVFpRllZGTw8PJCVlcWiQkRENkGWZWxOy8ObW04i14xDQIbaamSvuBelpaXQarXtfjyVCTLZnOLihklHQUFBgpMQERFZp+LiYhYVc/H09AQAZGZmmuRNthfl5eUICgrimahW4HvWNnzfWo/vWdvwfWu9srIydO3a1fhZ2l4sKs1QKBrmGGu1Wv5gtoG7uzvft1bie9Y2fN9aj+9Z2/B9a71Ln6XtfhyTPAoRERGRGbCoEBERkcViUWmGo6Mj5s2bB0dHR9FRrArft9bje9Y2fN9aj+9Z2/B9az1Tv2e8PJmIiIgsFs+oEBERkcViUSEiIiKLxaJCREREFotFhYiIiCwWi8pfvPbaaxgyZAicnZ3h4eHR7DGSJF12++KLLzo2qIVpyfuWmZmJ8ePHw9nZGT4+PnjuuedQX1/fsUEtXEhIyGU/WwsXLhQdy6IsX74cISEh0Gg0iIuLQ3JysuhIFu3FF1+87GcqLCxMdCyLs2PHDkyYMAEBAQGQJAnffPNNk6/Lsoy5c+fC398fTk5OiI+Px6lTp8SEtRDXes/uvffey372xo4d2+rnYVH5C51Oh8mTJ2P27NlXPW716tXIzc013m677baOCWihrvW+6fV6jB8/HjqdDrt27cKaNWvw8ccfY+7cuR2c1PK9/PLLTX62Hn/8cdGRLMa6deuQmJiIefPm4cCBA4iKisKYMWNQUFAgOppF69u3b5OfqZ07d4qOZHGqqqoQFRWF5cuXN/v1N954A2+//TZWrlyJvXv3wsXFBWPGjEFNjfk297N013rPAGDs2LFNfvY+//zz1j+RTM1avXq1rNVqm/0aAHn9+vUdmsdaXOl927Bhg6xQKOS8vDzjfStWrJDd3d3l2traDkxo2YKDg+V///vfomNYrEGDBsmPPvqo8e96vV4OCAiQFyxYIDCVZZs3b54cFRUlOoZV+evveIPBIPv5+cmLFi0y3ldaWio7OjrKn3/+uYCElqe5z8WZM2fKt956a7sfm2dU2ujRRx+Fl5cXBg0ahFWrVkHmcjRXtXv3bkRERMDX19d435gxY1BeXo60tDSBySzPwoUL0blzZ8TExGDRokUcHmuk0+mQkpKC+Ph4430KhQLx8fHYvXu3wGSW79SpUwgICEBoaCimT5+OzMxM0ZGsypkzZ5CXl9fkZ0+r1SIuLo4/e9ewfft2+Pj4oHfv3pg9ezaKi4tb/RjclLANXn75ZYwcORLOzs7YsmULHnnkEVRWVuKJJ54QHc1i5eXlNSkpAIx/z8vLExHJIj3xxBPo378/PD09sWvXLsyZMwe5ublYsmSJ6GjCFRUVQa/XN/tzdPz4cUGpLF9cXBw+/vhj9O7dG7m5uXjppZcwbNgwHDlyBG5ubqLjWYVLv6Oa+9nj768rGzt2LG6//XZ069YNGRkZ+Oc//4lx48Zh9+7dUCqVLX4cuygqzz//PF5//fWrHnPs2LEWTzB74YUXjH+OiYlBVVUVFi1aZHNFxdTvm71qzfuYmJhovC8yMhJqtRoPPfQQFixYwCW8qU3GjRtn/HNkZCTi4uIQHByML7/8Evfff7/AZGTrpk6davxzREQEIiMj0b17d2zfvh2jRo1q8ePYRVF55plncO+99171mNDQ0DY/flxcHF555RXU1tba1IeJKd83Pz+/y67OyM/PN37NlrXnfYyLi0N9fT3Onj2L3r17myGd9fDy8oJSqTT+3FySn59v8z9DpuTh4YFevXohPT1ddBSrcennKz8/H/7+/sb78/PzER0dLSiV9QkNDYWXlxfS09NZVP7K29sb3t7eZnv81NRUdOrUyaZKCmDa923w4MF47bXXUFBQAB8fHwDA1q1b4e7ujvDwcJM8h6Vqz/uYmpoKhUJhfM/smVqtRmxsLJKSkoxX2RkMBiQlJeGxxx4TG86KVFZWIiMjA/fcc4/oKFajW7du8PPzQ1JSkrGYlJeXY+/evde8QpT+cP78eRQXFzcpey1hF0WlNTIzM1FSUoLMzEzo9XqkpqYCAHr06AFXV1d8//33yM/Px3XXXQeNRoOtW7di/vz5ePbZZ8UGF+xa79vo0aMRHh6Oe+65B2+88Qby8vLwr3/9C48++qjNFby22r17N/bu3YsRI0bAzc0Nu3fvxtNPP427774bnTp1Eh3PIiQmJmLmzJkYMGAABg0ahKVLl6KqqgoJCQmio1msZ599FhMmTEBwcDBycnIwb948KJVKTJs2TXQ0i1JZWdnkLNOZM2eQmpoKT09PdO3aFU899RReffVV9OzZE926dcMLL7yAgIAAu16a4mrvmaenJ1566SVMmjQJfn5+yMjIwN///nf06NEDY8aMad0Ttfu6IRszc+ZMGcBlt23btsmyLMsbN26Uo6OjZVdXV9nFxUWOioqSV65cKev1erHBBbvW+ybLsnz27Fl53LhxspOTk+zl5SU/88wzcl1dnbjQFiYlJUWOi4uTtVqtrNFo5D59+sjz58+Xa2pqREezKMuWLZO7du0qq9VqedCgQfKePXtER7JoU6ZMkf39/WW1Wi0HBgbKU6ZMkdPT00XHsjjbtm1r9nfYzJkzZVluuET5hRdekH19fWVHR0d51KhR8okTJ8SGFuxq71l1dbU8evRo2dvbW3ZwcJCDg4PlWbNmNVmioqUkWeZ1tURERGSZuI4KERERWSwWFSIiIrJYLCpERERksVhUiIiIyGKxqBAREZHFYlEhIiIii8WiQkRERBaLRYWIrEpISAiWLl1q/LskSfjmm2+uePzZs2chSZJxtWQisi4sKkRkkT7++GN4eHhcdv++ffvw4IMPdnwgIhKCe/0QkVUx5wajRGR5eEaFiMzq0tDLX2833njjFb9n+/btSEhIQFlZmfH4F198EcDlQz9/lZycjJiYGGg0GgwYMAAHDx687JgjR45g3LhxcHV1ha+vL+655x4UFRW185USkTmwqBCRWQUFBSE3N9d4O3jwIDp37owbbrjhit8zZMgQLF26FO7u7sbva8kO5ZWVlbj55psRHh6OlJQUvPjii5d9X2lpKUaOHImYmBjs378fmzZtQn5+Pu688852v1YiMj0O/RCRWSmVSvj5+QEAampqcNttt2Hw4MHGMyTNUavV0Gq1kCTJ+L0tsXbtWhgMBnz00UfQaDTo27cvzp8/j9mzZxuPeeeddxATE4P58+cb71u1ahWCgoJw8uRJ9OrVq/UvkojMhkWFiDrMfffdh4qKCmzduhUKhelP6B47dgyRkZHQaDTG+wYPHtzkmEOHDmHbtm1wdXW97PszMjJYVIgsDIsKEXWIV199FZs3b0ZycjLc3NyE5aisrMSECRPw+uuvX/Y1f39/AYmI6GpYVIjI7L7++mu8/PLL2LhxI7p3796i71Gr1dDr9a16nj59+uCTTz5BTU2N8azKnj17mhzTv39/fP311wgJCYFKxV+BRJaOk2mJyKyOHDmCGTNm4B//+Af69u2LvLw85OXloaSk5KrfFxISgsrKSiQlJaGoqAjV1dXXfK677roLkiRh1qxZOHr0KDZs2IDFixc3OebRRx9FSUkJpk2bhn379iEjIwObN29GQkJCq4sREZkfiwoRmdX+/ftRXV2NV199Ff7+/sbb7bffftXvGzJkCB5++GFMmTIF3t7eeOONN675XK6urvj+++9x+PBhxMTE4P/+7/8uG+IJCAjAb7/9Br1ej9GjRyMiIgJPPfUUPDw8zDJvhojaR5JlWRYdgoiIiKg5/N8HIiIislgsKkQkxKWVYZu7/XmNEyKybxz6ISIhsrOzcfHixWa/5unpCU9Pzw5ORESWiEWFiIiILBaHfoiIiMhisagQERGRxWJRISIiIovFokJEREQWi0WFiIiILBaLChEREVksFhUiIiKyWCwqREREZLH+H90bNGR0T/NaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5aa64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86eb78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vast-standard/home/f.capunaycaceres/u22491/gtm/gtm/gtm_plots_analysis/plot_splines.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_splines(layer_type = \"decorrelation\", decorrelation_layer_number=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
