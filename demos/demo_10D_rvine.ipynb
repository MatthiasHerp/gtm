{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70b4550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTM Package including GTM and the plot functions\n",
    "from gtm import *\n",
    "# Helper functions to create simulation data and analyze it\n",
    "from demos.pyvinecopulib_simulation_helpers import *\n",
    "# Sample Copulas Package\n",
    "import pyvinecopulib as pv\n",
    "import numpy as np\n",
    "# Other Stuff\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc123abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed17c60",
   "metadata": {},
   "source": [
    "### 1. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc86d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvine_structure = pv.RVineStructure.simulate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d90e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10  # dimension\n",
    "pair_copulas = sample_random_pair_copulas(D,Independence_tree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcaf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vine_model = pv.Vinecop.from_structure(structure=rvine_structure, pair_copulas=pair_copulas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb304e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>edge</th>\n",
       "      <th>conditioned variables</th>\n",
       "      <th>conditioning variables</th>\n",
       "      <th>var_types</th>\n",
       "      <th>family</th>\n",
       "      <th>rotation</th>\n",
       "      <th>parameters</th>\n",
       "      <th>df</th>\n",
       "      <th>tau</th>\n",
       "      <th>conditioned variable 1</th>\n",
       "      <th>conditioned variable 2</th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7  1</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4  3</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9  10</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7  10</td>\n",
       "      <td>1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2  9</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6  8</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5  3</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8  9</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4  10</td>\n",
       "      <td>3</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1  9</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3  9</td>\n",
       "      <td>10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7  9</td>\n",
       "      <td>10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.55, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2  1</td>\n",
       "      <td>9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6  9</td>\n",
       "      <td>8  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5  9</td>\n",
       "      <td>3  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gumbel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8  1</td>\n",
       "      <td>9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4  9</td>\n",
       "      <td>10  3</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gumbel</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1  3</td>\n",
       "      <td>9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7  8</td>\n",
       "      <td>9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2  8</td>\n",
       "      <td>1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6  1</td>\n",
       "      <td>9  8  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5  1</td>\n",
       "      <td>9  3  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8  3</td>\n",
       "      <td>1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4  1</td>\n",
       "      <td>9  10  3</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7  3</td>\n",
       "      <td>8  9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2  3</td>\n",
       "      <td>8  1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6  3</td>\n",
       "      <td>1  9  8  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5  4</td>\n",
       "      <td>1  9  3  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8  4</td>\n",
       "      <td>3  1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7  4</td>\n",
       "      <td>3  8  9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2  4</td>\n",
       "      <td>3  8  1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6  4</td>\n",
       "      <td>3  1  9  8  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5  8</td>\n",
       "      <td>4  1  9  3  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7  6</td>\n",
       "      <td>4  3  8  9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2  5</td>\n",
       "      <td>4  3  8  1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6  5</td>\n",
       "      <td>4  3  1  9  8  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7  5</td>\n",
       "      <td>6  4  3  8  9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2  6</td>\n",
       "      <td>5  4  3  8  1  9  10</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7  2</td>\n",
       "      <td>5  6  4  3  8  9  10  1</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tree  edge conditioned variables      conditioning variables  \\\n",
       "0      1     1                  7  1                               \n",
       "1      1     2                 2  10                               \n",
       "2      1     3                 6  10                               \n",
       "3      1     4                 5  10                               \n",
       "4      1     5                 8  10                               \n",
       "5      1     6                  4  3                               \n",
       "6      1     7                 1  10                               \n",
       "7      1     8                 3  10                               \n",
       "8      1     9                 9  10                               \n",
       "9      2     1                 7  10                        1      \n",
       "10     2     2                  2  9                       10      \n",
       "11     2     3                  6  8                       10      \n",
       "12     2     4                  5  3                       10      \n",
       "13     2     5                  8  9                       10      \n",
       "14     2     6                 4  10                        3      \n",
       "15     2     7                  1  9                       10      \n",
       "16     2     8                  3  9                       10      \n",
       "17     3     1                  7  9                    10  1      \n",
       "18     3     2                  2  1                    9  10      \n",
       "19     3     3                  6  9                    8  10      \n",
       "20     3     4                  5  9                    3  10      \n",
       "21     3     5                  8  1                    9  10      \n",
       "22     3     6                  4  9                    10  3      \n",
       "23     3     7                  1  3                    9  10      \n",
       "24     4     1                  7  8                 9  10  1      \n",
       "25     4     2                  2  8                 1  9  10      \n",
       "26     4     3                  6  1                 9  8  10      \n",
       "27     4     4                  5  1                 9  3  10      \n",
       "28     4     5                  8  3                 1  9  10      \n",
       "29     4     6                  4  1                 9  10  3      \n",
       "30     5     1                  7  3              8  9  10  1      \n",
       "31     5     2                  2  3              8  1  9  10      \n",
       "32     5     3                  6  3              1  9  8  10      \n",
       "33     5     4                  5  4              1  9  3  10      \n",
       "34     5     5                  8  4              3  1  9  10      \n",
       "35     6     1                  7  4           3  8  9  10  1      \n",
       "36     6     2                  2  4           3  8  1  9  10      \n",
       "37     6     3                  6  4           3  1  9  8  10      \n",
       "38     6     4                  5  8           4  1  9  3  10      \n",
       "39     7     1                  7  6        4  3  8  9  10  1      \n",
       "40     7     2                  2  5        4  3  8  1  9  10      \n",
       "41     7     3                  6  5        4  3  1  9  8  10      \n",
       "42     8     1                  7  5     6  4  3  8  9  10  1      \n",
       "43     8     2                  2  6     5  4  3  8  1  9  10      \n",
       "44     9     1                  7  2  5  6  4  3  8  9  10  1      \n",
       "\n",
       "        var_types        family  rotation   parameters   df   tau  \\\n",
       "0   c, c                    Joe     270.0         5.44  1.0 -0.70   \n",
       "1       c, c            Student       0.0   0.42, 2.00  2.0  0.28   \n",
       "2        c, c          Gaussian       0.0        -0.34  1.0 -0.22   \n",
       "3   c, c                    Joe     180.0         3.46  1.0  0.57   \n",
       "4     c, c                Frank       0.0        -5.18  1.0 -0.47   \n",
       "5     c, c                Frank       0.0        -3.92  1.0 -0.38   \n",
       "6     c, c                Frank       0.0        -3.04  1.0 -0.31   \n",
       "7     c, c                Frank       0.0         5.17  1.0  0.47   \n",
       "8       c, c            Student       0.0  -0.36, 2.00  2.0 -0.23   \n",
       "9   c, c                    Joe     270.0         3.67  1.0 -0.59   \n",
       "10  c, c                    Joe       0.0         3.56  1.0  0.58   \n",
       "11    c, c                Frank       0.0        -8.84  1.0 -0.63   \n",
       "12  c, c                    Joe      90.0         2.27  1.0 -0.41   \n",
       "13       c, c          Gaussian       0.0         0.34  1.0  0.22   \n",
       "14  c, c                    Joe       0.0         2.60  1.0  0.46   \n",
       "15       c, c          Gaussian       0.0        -0.43  1.0 -0.28   \n",
       "16      c, c            Clayton     270.0         3.46  1.0 -0.63   \n",
       "17      c, c            Student       0.0  -0.55, 2.00  2.0 -0.37   \n",
       "18    c, c                Frank       0.0        -4.43  1.0 -0.42   \n",
       "19      c, c            Clayton      90.0         0.98  1.0 -0.33   \n",
       "20     c, c              Gumbel      90.0         1.72  1.0 -0.42   \n",
       "21    c, c                Frank       0.0         5.92  1.0  0.51   \n",
       "22     c, c              Gumbel     180.0         3.00  1.0  0.67   \n",
       "23      c, c            Clayton     270.0         1.97  1.0 -0.50   \n",
       "24           c, c  Independence       NaN               0.0   NaN   \n",
       "25           c, c  Independence       NaN               0.0   NaN   \n",
       "26           c, c  Independence       NaN               0.0   NaN   \n",
       "27           c, c  Independence       NaN               0.0   NaN   \n",
       "28           c, c  Independence       NaN               0.0   NaN   \n",
       "29           c, c  Independence       NaN               0.0   NaN   \n",
       "30           c, c  Independence       NaN               0.0   NaN   \n",
       "31           c, c  Independence       NaN               0.0   NaN   \n",
       "32           c, c  Independence       NaN               0.0   NaN   \n",
       "33           c, c  Independence       NaN               0.0   NaN   \n",
       "34           c, c  Independence       NaN               0.0   NaN   \n",
       "35           c, c  Independence       NaN               0.0   NaN   \n",
       "36           c, c  Independence       NaN               0.0   NaN   \n",
       "37           c, c  Independence       NaN               0.0   NaN   \n",
       "38           c, c  Independence       NaN               0.0   NaN   \n",
       "39           c, c  Independence       NaN               0.0   NaN   \n",
       "40           c, c  Independence       NaN               0.0   NaN   \n",
       "41           c, c  Independence       NaN               0.0   NaN   \n",
       "42           c, c  Independence       NaN               0.0   NaN   \n",
       "43           c, c  Independence       NaN               0.0   NaN   \n",
       "44           c, c  Independence       NaN               NaN  0.00   \n",
       "\n",
       "    conditioned variable 1  conditioned variable 2  var_row  var_col  \\\n",
       "0                        7                       1        7        1   \n",
       "1                        2                      10       10        2   \n",
       "2                        6                      10       10        6   \n",
       "3                        5                      10       10        5   \n",
       "4                        8                      10       10        8   \n",
       "5                        4                       3        4        3   \n",
       "6                        1                      10       10        1   \n",
       "7                        3                      10       10        3   \n",
       "8                        9                      10       10        9   \n",
       "9                        7                      10       10        7   \n",
       "10                       2                       9        9        2   \n",
       "11                       6                       8        8        6   \n",
       "12                       5                       3        5        3   \n",
       "13                       8                       9        9        8   \n",
       "14                       4                      10       10        4   \n",
       "15                       1                       9        9        1   \n",
       "16                       3                       9        9        3   \n",
       "17                       7                       9        9        7   \n",
       "18                       2                       1        2        1   \n",
       "19                       6                       9        9        6   \n",
       "20                       5                       9        9        5   \n",
       "21                       8                       1        8        1   \n",
       "22                       4                       9        9        4   \n",
       "23                       1                       3        3        1   \n",
       "24                       7                       8        8        7   \n",
       "25                       2                       8        8        2   \n",
       "26                       6                       1        6        1   \n",
       "27                       5                       1        5        1   \n",
       "28                       8                       3        8        3   \n",
       "29                       4                       1        4        1   \n",
       "30                       7                       3        7        3   \n",
       "31                       2                       3        3        2   \n",
       "32                       6                       3        6        3   \n",
       "33                       5                       4        5        4   \n",
       "34                       8                       4        8        4   \n",
       "35                       7                       4        7        4   \n",
       "36                       2                       4        4        2   \n",
       "37                       6                       4        6        4   \n",
       "38                       5                       8        8        5   \n",
       "39                       7                       6        7        6   \n",
       "40                       2                       5        5        2   \n",
       "41                       6                       5        6        5   \n",
       "42                       7                       5        7        5   \n",
       "43                       2                       6        6        2   \n",
       "44                       7                       2        7        2   \n",
       "\n",
       "    dependence  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  \n",
       "10           1  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           1  \n",
       "16           1  \n",
       "17           0  \n",
       "18           0  \n",
       "19           0  \n",
       "20           0  \n",
       "21           0  \n",
       "22           0  \n",
       "23           0  \n",
       "24           0  \n",
       "25           0  \n",
       "26           0  \n",
       "27           0  \n",
       "28           0  \n",
       "29           0  \n",
       "30           0  \n",
       "31           0  \n",
       "32           0  \n",
       "33           0  \n",
       "34           0  \n",
       "35           0  \n",
       "36           0  \n",
       "37           0  \n",
       "38           0  \n",
       "39           0  \n",
       "40           0  \n",
       "41           0  \n",
       "42           0  \n",
       "43           0  \n",
       "44           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = compute_conditional_dependence_table(vine_model)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639cb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/3150062370.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_true_structure_sub[\"var_row\"] = df_true_structure_sub[\"var_row\"] - 1\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/3150062370.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_true_structure_sub[\"var_col\"] = df_true_structure_sub[\"var_col\"] - 1\n"
     ]
    }
   ],
   "source": [
    "#creating a table to copare the true dependence structure later on to what the gtm learned\n",
    "df_true_structure = df[[\"tree\",\"edge\",\"conditioned variables\", \"conditioned variable 1\", \"conditioned variable 2\", \"dependence\", \"var_row\", \"var_col\"]]\n",
    "df_true_structure_sub = df_true_structure[[\"var_row\", \"var_col\", \"dependence\"]]\n",
    "df_true_structure_sub[\"var_row\"] = df_true_structure_sub[\"var_row\"] - 1\n",
    "df_true_structure_sub[\"var_col\"] = df_true_structure_sub[\"var_col\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13083e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vine_model.plot(tree=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91426a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "N_train = 2000\n",
    "simulated_data_uniform_train = vine_model.simulate(n=N_train)\n",
    "simulated_data_train = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_train)).float()\n",
    "\n",
    "# Validate\n",
    "N_validate = 2000\n",
    "simulated_data_uniform_validate = vine_model.simulate(n=N_validate)\n",
    "simulated_data_validate = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_validate)).float()\n",
    "\n",
    "# Test\n",
    "N_test = 20000\n",
    "simulated_data_uniform_test = vine_model.simulate(n=N_test)\n",
    "simulated_data_test = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a347f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/1520218578.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/1520218578.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/1520218578.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_train = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_validate = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_test = torch.tensor(loglik_copula) + log_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab3f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_pv_est = vine_model\n",
    "copula_pv_est.fit(simulated_data_uniform_train)\n",
    "means = simulated_data_train.mean(0)\n",
    "vars = simulated_data_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357cb0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/2452348847.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/2452348847.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_66388/2452348847.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_est_train = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_est_validate = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_est_test = torch.tensor(loglik_copula) + log_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2036680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_densities(simulated_data_train, x_lim=[-4,4], y_lim=[-4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133db9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_marginals(simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83659cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Copula_2D_Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # First Dimension (N) needs to be the samples\n",
    "        # Second Dimension (D) is the dimensionality of the data\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "# Create dataset and DataLoader\n",
    "dataset_train = Copula_2D_Dataset(simulated_data_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=N_train)\n",
    "\n",
    "dataset_validate = Copula_2D_Dataset(simulated_data_validate)\n",
    "dataloader_validate = DataLoader(dataset_validate, batch_size=N_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d69048b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can see that we load the full data, so not batches\n",
    "# Model is just implemented with dataloaders because that is eeded for huge datasets in bioinformatics\n",
    "data_iter = iter(dataloader_train)\n",
    "sample = next(data_iter)\n",
    "sample.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c111eb",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef92cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GTM(\n",
    "    transformation_spline_range=list([[-10], [10]]), \n",
    "    degree_decorrelation=40,\n",
    "    degree_transformations=15,\n",
    "    num_decorr_layers=3,\n",
    "    num_trans_layers=1,\n",
    "    number_variables=10,\n",
    "    calc_method_bspline=\"deBoor\",\n",
    "    affine_decorr_layer=False,\n",
    "    span_restriction=\"reluler\",\n",
    "    device=\"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41ca3e",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tune and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "807c8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/anaconda3/envs/mctm_pytorch/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-05-22 16:50:06,150] A new study created in RDB with name: no-name-4d81e84a-1b21-4824-a3dc-01ea12a658c3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 25.104129248666837   pensecondridge_opt: 23.994565434781308   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      " 11%|        | 114/1000 [00:23<03:05,  4.79it/s]\n",
      "[I 2025-05-22 16:50:30,599] Trial 0 finished with value: -6.8281779289245605 and parameters: {'penfirstridge': 25.104129248666837, 'pensecondridge': 23.994565434781308}. Best is trial 0 with value: -6.8281779289245605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 16.23786016337484   pensecondridge_opt: 28.26384183374429   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 62/1000 [00:14<03:33,  4.40it/s]\n",
      "[I 2025-05-22 16:50:44,894] Trial 1 finished with value: -7.281529426574707 and parameters: {'penfirstridge': 16.23786016337484, 'pensecondridge': 28.26384183374429}. Best is trial 0 with value: -6.8281779289245605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 0.19910622875556377   pensecondridge_opt: 12.864957235244843   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 202/1000 [00:45<03:00,  4.43it/s]\n",
      "[I 2025-05-22 16:51:30,621] Trial 2 finished with value: -6.721148490905762 and parameters: {'penfirstridge': 0.19910622875556377, 'pensecondridge': 12.864957235244843}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 21.38591220150713   pensecondridge_opt: 27.917858845787332   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 48/1000 [00:10<03:32,  4.48it/s]\n",
      "[I 2025-05-22 16:51:41,463] Trial 3 finished with value: -7.269013404846191 and parameters: {'penfirstridge': 21.38591220150713, 'pensecondridge': 27.917858845787332}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 26.48550564358533   pensecondridge_opt: 15.995686859555507   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 54/1000 [00:12<03:31,  4.46it/s]\n",
      "[I 2025-05-22 16:51:53,727] Trial 4 finished with value: -7.196055889129639 and parameters: {'penfirstridge': 26.48550564358533, 'pensecondridge': 15.995686859555507}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 2.408399294593017   pensecondridge_opt: 13.025308685220324   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 84/1000 [00:23<04:16,  3.57it/s]\n",
      "[I 2025-05-22 16:52:17,424] Trial 5 finished with value: -6.983153343200684 and parameters: {'penfirstridge': 2.408399294593017, 'pensecondridge': 13.025308685220324}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 0.2946439172376414   pensecondridge_opt: 28.962359966849522   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 60/1000 [00:16<04:18,  3.64it/s]\n",
      "[I 2025-05-22 16:52:34,095] Trial 6 finished with value: -7.1110334396362305 and parameters: {'penfirstridge': 0.2946439172376414, 'pensecondridge': 28.962359966849522}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 16.466002517155633   pensecondridge_opt: 14.70571929813131   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 79/1000 [00:21<04:10,  3.68it/s]\n",
      "[I 2025-05-22 16:52:55,724] Trial 7 finished with value: -6.964749336242676 and parameters: {'penfirstridge': 16.466002517155633, 'pensecondridge': 14.70571929813131}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 27.491488312561568   pensecondridge_opt: 20.877984294595887   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 51/1000 [00:12<03:45,  4.21it/s]\n",
      "[I 2025-05-22 16:53:07,991] Trial 8 finished with value: -7.25343132019043 and parameters: {'penfirstridge': 27.491488312561568, 'pensecondridge': 20.877984294595887}. Best is trial 2 with value: -6.721148490905762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 8.010196243020976   pensecondridge_opt: 5.813901439704735   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 211/1000 [00:48<02:59,  4.39it/s]\n",
      "[I 2025-05-22 16:53:56,223] Trial 9 finished with value: -6.705333709716797 and parameters: {'penfirstridge': 8.010196243020976, 'pensecondridge': 5.813901439704735}. Best is trial 9 with value: -6.705333709716797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 9.718994502031027   pensecondridge_opt: 0.2681760998490086   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 79/1000 [00:19<03:47,  4.05it/s]\n",
      "[I 2025-05-22 16:54:15,879] Trial 10 finished with value: -7.084171772003174 and parameters: {'penfirstridge': 9.718994502031027, 'pensecondridge': 0.2681760998490086}. Best is trial 9 with value: -6.705333709716797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 17.608510288295157   pensecondridge_opt: 6.473275906270323   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 211/1000 [00:49<03:04,  4.27it/s]\n",
      "[I 2025-05-22 16:55:05,468] Trial 11 finished with value: -6.648456573486328 and parameters: {'penfirstridge': 17.608510288295157, 'pensecondridge': 6.473275906270323}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 25.56816469075453   pensecondridge_opt: 2.325322691144164   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 115/1000 [00:26<03:26,  4.28it/s]\n",
      "[I 2025-05-22 16:55:32,479] Trial 12 finished with value: -6.835743427276611 and parameters: {'penfirstridge': 25.56816469075453, 'pensecondridge': 2.325322691144164}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 1.4835258787668844   pensecondridge_opt: 3.5586162865578626   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 150/1000 [00:33<03:10,  4.46it/s]\n",
      "[I 2025-05-22 16:56:06,281] Trial 13 finished with value: -6.849526405334473 and parameters: {'penfirstridge': 1.4835258787668844, 'pensecondridge': 3.5586162865578626}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 16.00872451079815   pensecondridge_opt: 7.449043141800514   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 164/1000 [00:40<03:28,  4.01it/s]\n",
      "[I 2025-05-22 16:56:47,401] Trial 14 finished with value: -6.720091819763184 and parameters: {'penfirstridge': 16.00872451079815, 'pensecondridge': 7.449043141800514}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 8.697862383787184   pensecondridge_opt: 22.536015577150703   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 110/1000 [00:26<03:38,  4.08it/s]\n",
      "[I 2025-05-22 16:57:14,530] Trial 15 finished with value: -6.840102672576904 and parameters: {'penfirstridge': 8.697862383787184, 'pensecondridge': 22.536015577150703}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 16.831212566499453   pensecondridge_opt: 0.1661790403425334   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 184/1000 [00:42<03:07,  4.36it/s]\n",
      "[I 2025-05-22 16:57:56,877] Trial 16 finished with value: -6.712996959686279 and parameters: {'penfirstridge': 16.831212566499453, 'pensecondridge': 0.1661790403425334}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 12.962691916642484   pensecondridge_opt: 7.746832033955146   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 197/1000 [00:47<03:13,  4.15it/s]\n",
      "[I 2025-05-22 16:58:44,465] Trial 17 finished with value: -6.672553539276123 and parameters: {'penfirstridge': 12.962691916642484, 'pensecondridge': 7.746832033955146}. Best is trial 11 with value: -6.648456573486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 24.980936519024027   pensecondridge_opt: 9.478651662035217   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 223/1000 [00:52<03:03,  4.24it/s]\n",
      "[I 2025-05-22 16:59:37,282] Trial 18 finished with value: -6.635349750518799 and parameters: {'penfirstridge': 24.980936519024027, 'pensecondridge': 9.478651662035217}. Best is trial 18 with value: -6.635349750518799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 27.02327427860537   pensecondridge_opt: 9.593425714651843   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 139/1000 [00:32<03:20,  4.28it/s]\n",
      "[I 2025-05-22 17:00:09,898] Trial 19 finished with value: -6.7256999015808105 and parameters: {'penfirstridge': 27.02327427860537, 'pensecondridge': 9.593425714651843}. Best is trial 18 with value: -6.635349750518799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter_tuning done\n"
     ]
    }
   ],
   "source": [
    "study = model.hyperparameter_tune_penalties( \n",
    "                                train_dataloader=dataloader_train, \n",
    "                                validate_dataloader=dataloader_validate, \n",
    "                                penvalueridge = [0], #[\"sample\"],\n",
    "                                penfirstridge = [\"sample\"],\n",
    "                                pensecondridge = [\"sample\"],\n",
    "                                ctm_pensecondridge = [0], #[\"sample\"],\n",
    "                                lambda_penalty_params = [0], #[\"sample\"], #[0],\n",
    "                                train_covariates=False, \n",
    "                                validate_covariates=False, \n",
    "                                adaptive_lasso_weights_matrix = False,\n",
    "                                learning_rate=1, \n",
    "                                iterations=1000, \n",
    "                                patience=5, \n",
    "                                min_delta=1e-7, \n",
    "                                optimizer='LBFGS', \n",
    "                                lambda_penalty_mode=\"square\", \n",
    "                                objective_type=\"negloglik\", \n",
    "                                seperate_copula_training=False,\n",
    "                                max_batches_per_iter=False,\n",
    "                                tuning_mode=\"optuna\",\n",
    "                                cross_validation_folds=False,\n",
    "                                random_state_KFold=42,\n",
    "                                device=None,\n",
    "                                pretrained_transformation_layer=False,\n",
    "                                n_trials=20,\n",
    "                                temp_folder=\".\", \n",
    "                                study_name=None)\n",
    "    \n",
    "penalty_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penvalueridge\"],\n",
    "                            study.best_params[\"penfirstridge\"],\n",
    "                            study.best_params[\"pensecondridge\"],\n",
    "                            0 #study.best_params[\"ctm_pensecondridge\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "lambda_penalty_params= False #study.best_params[\"lambda_penalty_params\"] #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fa875cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penvalueridge\"],\n",
    "                            15,\n",
    "                            2,\n",
    "                            0 #study.best_params[\"ctm_pensecondridge\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "lambda_penalty_params= False #study.best_params[\"lambda_penalty_params\"] #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f19f1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_model/gtm.py:296: UserWarning: Optimiser for pretrain_tranformation_layer is always LBFGS. If this is an issue change the code.\n",
      "  warnings.warn(\"Optimiser for pretrain_tranformation_layer is always LBFGS. If this is an issue change the code.\")\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      " 13%|        | 130/1000 [00:03<00:26, 32.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# pretrain the marginal transformations\n",
    "_ = model.pretrain_tranformation_layer(dataloader_train, iterations=1000, max_batches_per_iter=False, penalty_params=penalty_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7429a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 193/1000 [00:33<02:18,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the joint model\n",
    "_ = model.__train__(train_dataloader=dataloader_train, validate_dataloader=dataloader_validate, iterations=1000, optimizer=\"LBFGS\", learning_rate=1,\n",
    "                penalty_params=penalty_params, adaptive_lasso_weights_matrix=adaptive_lasso_weights_matrix, lambda_penalty_params=lambda_penalty_params, \n",
    "                max_batches_per_iter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5eebff",
   "metadata": {},
   "source": [
    "### 4. Compare Fit to Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b910002",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_train_gtm = model.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_gtm = model.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_gtm = model.log_likelihood(simulated_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad6c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the Multivariate Normal Distribution as Model\n",
    "mean_mvn_model = simulated_data_train.mean(0)  # 0 to do mean across dim 0 not globally\n",
    "cov_mvn_model = simulated_data_train.T.cov()\n",
    "mvn_model = torch.distributions.MultivariateNormal(loc=mean_mvn_model, covariance_matrix=cov_mvn_model)\n",
    "log_likelihood_train_gaussian = mvn_model.log_prob(simulated_data_train)\n",
    "log_likelihood_validate_gaussian = mvn_model.log_prob(simulated_data_validate)\n",
    "log_likelihood_test_gaussian = mvn_model.log_prob(simulated_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c2f1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD GTM      Train Data:  0.6142\n",
      "KLD Gaussian Train Data:  3.2696\n",
      "KLD Copula   Train Data:  0.0084\n",
      "KLD GTM      Test  Data:  1.0833\n",
      "KLD Gaussian Test  Data:  3.3092\n",
      "KLD Copula   Test  Data:  0.0438\n"
     ]
    }
   ],
   "source": [
    "print(\"KLD GTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Train Data: \",np.round(torch.mean(loglik_true_train - loglik_true_est_train).item(),4) )\n",
    "\n",
    "print(\"KLD GTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Test  Data: \",np.round(torch.mean(loglik_true_test - loglik_true_est_test).item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941037db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#torch.save(model, \"10D_rvine_model_state_dict.pth\")\n",
    "#model = torch.load(\"./10D_rvine_model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee4e5d",
   "metadata": {},
   "source": [
    "### 5. Evaluate and Plot GTM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0990e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.approximate_transformation_inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6637a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_samples = model.sample(2000)\n",
    "conditional_correlation_matrix_train = model.compute_correlation_matrix(synthetic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a30faa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_metric_scatter(data=synthetic_samples,metric=conditional_correlation_matrix_train,metric_type=\"precision_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b2203",
   "metadata": {},
   "source": [
    "#### does the GTM identify the conditional independence structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d82487b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 with var_row_num 1 and var_col_num 0.\n",
      "Processing row 9 with var_row_num 4 and var_col_num 3.\n",
      "Processing row 3 with var_row_num 3 and var_col_num 0.\n",
      "Processing row 6 with var_row_num 4 and var_col_num 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1 with var_row_num 2 and var_col_num 0.\n",
      "Processing row 10 with var_row_num 5 and var_col_num 0.\n",
      "Processing row 4 with var_row_num 3 and var_col_num 1.\n",
      "Processing row 7 with var_row_num 4 and var_col_num 1.\n",
      "Processing row 2 with var_row_num 2 and var_col_num 1.\n",
      "Processing row 5 with var_row_num 3 and var_col_num 2.\n",
      "Processing row 11 with var_row_num 5 and var_col_num 1.\n",
      "Processing row 8 with var_row_num 4 and var_col_num 2.\n",
      "Processing row 12 with var_row_num 5 and var_col_num 2.\n",
      "Processing row 15 with var_row_num 6 and var_col_num 0.\n",
      "Processing row 18 with var_row_num 6 and var_col_num 3.\n",
      "Processing row 21 with var_row_num 7 and var_col_num 0.\n",
      "Processing row 13 with var_row_num 5 and var_col_num 3.\n",
      "Processing row 16 with var_row_num 6 and var_col_num 1.\n",
      "Processing row 19 with var_row_num 6 and var_col_num 4.\n",
      "Processing row 22 with var_row_num 7 and var_col_num 1.\n",
      "Processing row 14 with var_row_num 5 and var_col_num 4.\n",
      "Processing row 17 with var_row_num 6 and var_col_num 2.\n",
      "Processing row 20 with var_row_num 6 and var_col_num 5.\n",
      "Processing row 23 with var_row_num 7 and var_col_num 2.\n",
      "Processing row 24 with var_row_num 7 and var_col_num 3.\n",
      "Processing row 27 with var_row_num 7 and var_col_num 6.\n",
      "Processing row 30 with var_row_num 8 and var_col_num 2.\n",
      "Processing row 33 with var_row_num 8 and var_col_num 5.\n",
      "Processing row 25 with var_row_num 7 and var_col_num 4.\n",
      "Processing row 28 with var_row_num 8 and var_col_num 0.\n",
      "Processing row 31 with var_row_num 8 and var_col_num 3.\n",
      "Processing row 34 with var_row_num 8 and var_col_num 6.\n",
      "Processing row 29 with var_row_num 8 and var_col_num 1.\n",
      "Processing row 26 with var_row_num 7 and var_col_num 5.\n",
      "Processing row 32 with var_row_num 8 and var_col_num 4.\n",
      "Processing row 35 with var_row_num 8 and var_col_num 7.\n",
      "Processing row 36 with var_row_num 9 and var_col_num 0.\n",
      "Processing row 39 with var_row_num 9 and var_col_num 3.\n",
      "Processing row 42 with var_row_num 9 and var_col_num 6.\n",
      "Processing row 37 with var_row_num 9 and var_col_num 1.\n",
      "Processing row 40 with var_row_num 9 and var_col_num 4.\n",
      "Processing row 43 with var_row_num 9 and var_col_num 7.\n",
      "Processing row 41 with var_row_num 9 and var_col_num 5.\n",
      "Processing row 38 with var_row_num 9 and var_col_num 2.\n",
      "Processing row 44 with var_row_num 9 and var_col_num 8.\n",
      "Time taken: 1111.7047219276428\n",
      "All rows processed.\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_table = model.compute_conditional_independence_table(\n",
    "                                        y = None,\n",
    "                                        x = False,\n",
    "                                        evaluation_data_type = \"samples_from_model\",\n",
    "                                        num_processes=4,\n",
    "                                        sample_size = 5000,\n",
    "                                        num_points_quad=20,\n",
    "                                        optimized=True,\n",
    "                                        copula_only=False,\n",
    "                                        min_val=-8,\n",
    "                                        max_val=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b773375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging together computed metrics for conditional independence table and actual structure of the simulation data for comparison\n",
    "merged = pd.merge(\n",
    "    conditional_independence_table,\n",
    "    df_true_structure_sub,\n",
    "    on=[\"var_row\", \"var_col\"] # or \"inner\", \"left\", depending on your needs\n",
    ")\n",
    "merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e083eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.624477</td>\n",
       "      <td>13.794410</td>\n",
       "      <td>0.658751</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>0.866287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.200791</td>\n",
       "      <td>5.540302</td>\n",
       "      <td>0.362587</td>\n",
       "      <td>0.136574</td>\n",
       "      <td>0.378671</td>\n",
       "      <td>0.860712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.038741</td>\n",
       "      <td>56.124306</td>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.885794</td>\n",
       "      <td>3.356807</td>\n",
       "      <td>0.790776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.862352</td>\n",
       "      <td>9.597827</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.111041</td>\n",
       "      <td>0.370006</td>\n",
       "      <td>0.780183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.441384</td>\n",
       "      <td>6.784243</td>\n",
       "      <td>0.554259</td>\n",
       "      <td>0.320982</td>\n",
       "      <td>0.793396</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3.675336</td>\n",
       "      <td>15.468559</td>\n",
       "      <td>0.727214</td>\n",
       "      <td>0.537641</td>\n",
       "      <td>1.185591</td>\n",
       "      <td>0.678889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.605496</td>\n",
       "      <td>7.334979</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.473425</td>\n",
       "      <td>0.513496</td>\n",
       "      <td>0.581441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.149970</td>\n",
       "      <td>1.730498</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.442774</td>\n",
       "      <td>0.566283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.570043</td>\n",
       "      <td>2.533107</td>\n",
       "      <td>0.520888</td>\n",
       "      <td>0.276734</td>\n",
       "      <td>0.580847</td>\n",
       "      <td>0.559309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1.448094</td>\n",
       "      <td>2.141280</td>\n",
       "      <td>0.717184</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.350275</td>\n",
       "      <td>0.447577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.527595</td>\n",
       "      <td>2.465228</td>\n",
       "      <td>0.401093</td>\n",
       "      <td>0.166864</td>\n",
       "      <td>0.304046</td>\n",
       "      <td>0.431301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1.296808</td>\n",
       "      <td>1.785274</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.126731</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.391962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.664687</td>\n",
       "      <td>0.697188</td>\n",
       "      <td>0.169173</td>\n",
       "      <td>0.044371</td>\n",
       "      <td>0.215582</td>\n",
       "      <td>0.364071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.275137</td>\n",
       "      <td>1.916600</td>\n",
       "      <td>0.333961</td>\n",
       "      <td>0.122050</td>\n",
       "      <td>0.204682</td>\n",
       "      <td>0.363889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.423551</td>\n",
       "      <td>0.260779</td>\n",
       "      <td>0.099594</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.108091</td>\n",
       "      <td>0.359251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958085</td>\n",
       "      <td>1.130218</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>0.142651</td>\n",
       "      <td>0.354504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580308</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.181646</td>\n",
       "      <td>0.345735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762147</td>\n",
       "      <td>0.715114</td>\n",
       "      <td>0.273285</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.175144</td>\n",
       "      <td>0.339254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.654823</td>\n",
       "      <td>0.241799</td>\n",
       "      <td>0.070906</td>\n",
       "      <td>0.126337</td>\n",
       "      <td>0.331938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.372047</td>\n",
       "      <td>0.287334</td>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.300133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468847</td>\n",
       "      <td>0.345030</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.057541</td>\n",
       "      <td>0.266897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410631</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.049224</td>\n",
       "      <td>0.217803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.291270</td>\n",
       "      <td>0.118399</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.208670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.291913</td>\n",
       "      <td>0.176009</td>\n",
       "      <td>0.066549</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.195308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366853</td>\n",
       "      <td>0.172150</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.044894</td>\n",
       "      <td>0.187978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.303836</td>\n",
       "      <td>0.123956</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.045911</td>\n",
       "      <td>0.173181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249149</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.092881</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.172362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234949</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.030153</td>\n",
       "      <td>0.159027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>0.069670</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165723</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.144605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270548</td>\n",
       "      <td>0.105974</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.142207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.156699</td>\n",
       "      <td>0.042341</td>\n",
       "      <td>0.047557</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.136974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.192239</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>0.132341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193721</td>\n",
       "      <td>0.053943</td>\n",
       "      <td>0.101209</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.130798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.126410</td>\n",
       "      <td>0.027676</td>\n",
       "      <td>0.044192</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181631</td>\n",
       "      <td>0.050607</td>\n",
       "      <td>0.040092</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.117401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.141718</td>\n",
       "      <td>0.032314</td>\n",
       "      <td>0.044685</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.109013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.167995</td>\n",
       "      <td>0.044532</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.102594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.101048</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.091074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.148425</td>\n",
       "      <td>0.039178</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.088709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113497</td>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.039354</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.088559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.127651</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.082139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.043166</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.071971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080658</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.066055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081566</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.057180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  precision_abs_mean  precision_square_mean  \\\n",
       "38        9        2            3.624477              13.794410   \n",
       "42        9        6            2.200791               5.540302   \n",
       "15        6        0            7.038741              56.124306   \n",
       "36        9        0            2.862352               9.597827   \n",
       "30        8        2            2.441384               6.784243   \n",
       "40        9        4            3.675336              15.468559   \n",
       "8         4        2            2.605496               7.334979   \n",
       "44        9        8            1.149970               1.730498   \n",
       "31        8        3            1.570043               2.533107   \n",
       "26        7        5            1.448094               2.141280   \n",
       "41        9        5            1.527595               2.465228   \n",
       "43        9        7            1.296808               1.785274   \n",
       "39        9        3            0.664687               0.697188   \n",
       "32        8        4            1.275137               1.916600   \n",
       "34        8        6            0.423551               0.260779   \n",
       "28        8        0            0.958085               1.130218   \n",
       "37        9        1            0.580308               0.515957   \n",
       "29        8        1            0.762147               0.715114   \n",
       "5         3        2            0.731875               0.654823   \n",
       "17        6        2            0.372047               0.287334   \n",
       "1         2        0            0.468847               0.345030   \n",
       "6         4        0            0.410631               0.395932   \n",
       "21        7        0            0.495820               0.291270   \n",
       "19        6        4            0.291913               0.176009   \n",
       "0         1        0            0.366853               0.172150   \n",
       "33        8        5            0.303836               0.123956   \n",
       "2         2        1            0.249149               0.090226   \n",
       "3         3        0            0.234949               0.088875   \n",
       "9         4        3            0.194421               0.071259   \n",
       "16        6        1            0.165723               0.045892   \n",
       "7         4        1            0.270548               0.105974   \n",
       "18        6        3            0.156699               0.042341   \n",
       "35        8        7            0.192239               0.052350   \n",
       "4         3        1            0.193721               0.053943   \n",
       "23        7        2            0.126410               0.027676   \n",
       "10        5        0            0.181631               0.050607   \n",
       "27        7        6            0.141718               0.032314   \n",
       "20        6        5            0.167995               0.044532   \n",
       "25        7        4            0.101048               0.016574   \n",
       "14        5        4            0.148425               0.039178   \n",
       "12        5        2            0.113497               0.022102   \n",
       "13        5        3            0.127651               0.025149   \n",
       "24        7        3            0.089624               0.012618   \n",
       "22        7        1            0.080658               0.010527   \n",
       "11        5        1            0.081566               0.014537   \n",
       "\n",
       "    cond_correlation_abs_mean  cond_correlation_square_mean       kld  \\\n",
       "38                   0.658751                      0.441811  0.878687   \n",
       "42                   0.362587                      0.136574  0.378671   \n",
       "15                   0.940714                      0.885794  3.356807   \n",
       "36                   0.323245                      0.111041  0.370006   \n",
       "30                   0.554259                      0.320982  0.793396   \n",
       "40                   0.727214                      0.537641  1.185591   \n",
       "8                    0.684766                      0.473425  0.513496   \n",
       "44                   0.207519                      0.055558  0.442774   \n",
       "31                   0.520888                      0.276734  0.580847   \n",
       "26                   0.717184                      0.516534  0.350275   \n",
       "41                   0.401093                      0.166864  0.304046   \n",
       "43                   0.348225                      0.126731  0.176308   \n",
       "39                   0.169173                      0.044371  0.215582   \n",
       "32                   0.333961                      0.122050  0.204682   \n",
       "34                   0.099594                      0.015615  0.108091   \n",
       "28                   0.156158                      0.031947  0.142651   \n",
       "37                   0.162705                      0.037133  0.181646   \n",
       "29                   0.273285                      0.083337  0.175144   \n",
       "5                    0.241799                      0.070906  0.126337   \n",
       "17                   0.073918                      0.009675  0.045037   \n",
       "1                    0.071147                      0.007371  0.057541   \n",
       "6                    0.063530                      0.007068  0.049224   \n",
       "21                   0.118399                      0.018076  0.030335   \n",
       "19                   0.066549                      0.006936  0.011205   \n",
       "0                    0.096500                      0.013228  0.044894   \n",
       "33                   0.106749                      0.016137  0.045911   \n",
       "2                    0.092881                      0.012328  0.029024   \n",
       "3                    0.049453                      0.003737  0.030153   \n",
       "9                    0.069670                      0.008032  0.028622   \n",
       "16                   0.055791                      0.004684  0.024624   \n",
       "7                    0.117658                      0.018877  0.026720   \n",
       "18                   0.047557                      0.003678  0.013133   \n",
       "35                   0.065791                      0.005958  0.019434   \n",
       "4                    0.101209                      0.014105  0.013764   \n",
       "23                   0.044192                      0.003449  0.009584   \n",
       "10                   0.040092                      0.002469  0.015609   \n",
       "27                   0.044685                      0.003026  0.006643   \n",
       "20                   0.053486                      0.004503  0.014748   \n",
       "25                   0.041227                      0.002845  0.007974   \n",
       "14                   0.055254                      0.004966  0.008063   \n",
       "12                   0.039354                      0.002750  0.006691   \n",
       "13                   0.060780                      0.005707  0.007792   \n",
       "24                   0.043166                      0.002871  0.007570   \n",
       "22                   0.043887                      0.002952  0.002304   \n",
       "11                   0.042022                      0.003253  0.006100   \n",
       "\n",
       "         iae  dependence  \n",
       "38  0.866287           1  \n",
       "42  0.860712           1  \n",
       "15  0.790776           1  \n",
       "36  0.780183           1  \n",
       "30  0.737579           1  \n",
       "40  0.678889           1  \n",
       "8   0.581441           1  \n",
       "44  0.566283           1  \n",
       "31  0.559309           0  \n",
       "26  0.447577           1  \n",
       "41  0.431301           1  \n",
       "43  0.391962           1  \n",
       "39  0.364071           1  \n",
       "32  0.363889           0  \n",
       "34  0.359251           0  \n",
       "28  0.354504           1  \n",
       "37  0.345735           1  \n",
       "29  0.339254           1  \n",
       "5   0.331938           1  \n",
       "17  0.300133           0  \n",
       "1   0.266897           0  \n",
       "6   0.217803           0  \n",
       "21  0.208670           0  \n",
       "19  0.195308           0  \n",
       "0   0.187978           0  \n",
       "33  0.173181           0  \n",
       "2   0.172362           0  \n",
       "3   0.159027           0  \n",
       "9   0.146367           0  \n",
       "16  0.144605           0  \n",
       "7   0.142207           0  \n",
       "18  0.136974           0  \n",
       "35  0.132341           1  \n",
       "4   0.130798           0  \n",
       "23  0.130284           0  \n",
       "10  0.117401           0  \n",
       "27  0.109013           0  \n",
       "20  0.102594           0  \n",
       "25  0.091074           0  \n",
       "14  0.088709           0  \n",
       "12  0.088559           0  \n",
       "13  0.082139           0  \n",
       "24  0.071971           0  \n",
       "22  0.066055           0  \n",
       "11  0.057180           0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.sort_values(\"iae\",ascending=False) #.sort_values(\"abs_mean\",ascending=False) #.sort_values(\"iae\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72fc7423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.038741</td>\n",
       "      <td>56.124306</td>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.885794</td>\n",
       "      <td>3.356807</td>\n",
       "      <td>0.790776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3.675336</td>\n",
       "      <td>15.468559</td>\n",
       "      <td>0.727214</td>\n",
       "      <td>0.537641</td>\n",
       "      <td>1.185591</td>\n",
       "      <td>0.678889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1.448094</td>\n",
       "      <td>2.141280</td>\n",
       "      <td>0.717184</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.350275</td>\n",
       "      <td>0.447577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.605496</td>\n",
       "      <td>7.334979</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.473425</td>\n",
       "      <td>0.513496</td>\n",
       "      <td>0.581441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.624477</td>\n",
       "      <td>13.794410</td>\n",
       "      <td>0.658751</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>0.866287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.441384</td>\n",
       "      <td>6.784243</td>\n",
       "      <td>0.554259</td>\n",
       "      <td>0.320982</td>\n",
       "      <td>0.793396</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.570043</td>\n",
       "      <td>2.533107</td>\n",
       "      <td>0.520888</td>\n",
       "      <td>0.276734</td>\n",
       "      <td>0.580847</td>\n",
       "      <td>0.559309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.527595</td>\n",
       "      <td>2.465228</td>\n",
       "      <td>0.401093</td>\n",
       "      <td>0.166864</td>\n",
       "      <td>0.304046</td>\n",
       "      <td>0.431301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.200791</td>\n",
       "      <td>5.540302</td>\n",
       "      <td>0.362587</td>\n",
       "      <td>0.136574</td>\n",
       "      <td>0.378671</td>\n",
       "      <td>0.860712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1.296808</td>\n",
       "      <td>1.785274</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.126731</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.391962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.275137</td>\n",
       "      <td>1.916600</td>\n",
       "      <td>0.333961</td>\n",
       "      <td>0.122050</td>\n",
       "      <td>0.204682</td>\n",
       "      <td>0.363889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.862352</td>\n",
       "      <td>9.597827</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.111041</td>\n",
       "      <td>0.370006</td>\n",
       "      <td>0.780183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762147</td>\n",
       "      <td>0.715114</td>\n",
       "      <td>0.273285</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.175144</td>\n",
       "      <td>0.339254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.654823</td>\n",
       "      <td>0.241799</td>\n",
       "      <td>0.070906</td>\n",
       "      <td>0.126337</td>\n",
       "      <td>0.331938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.149970</td>\n",
       "      <td>1.730498</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.442774</td>\n",
       "      <td>0.566283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.664687</td>\n",
       "      <td>0.697188</td>\n",
       "      <td>0.169173</td>\n",
       "      <td>0.044371</td>\n",
       "      <td>0.215582</td>\n",
       "      <td>0.364071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580308</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.037133</td>\n",
       "      <td>0.181646</td>\n",
       "      <td>0.345735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958085</td>\n",
       "      <td>1.130218</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>0.142651</td>\n",
       "      <td>0.354504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.291270</td>\n",
       "      <td>0.118399</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.208670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270548</td>\n",
       "      <td>0.105974</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.142207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.303836</td>\n",
       "      <td>0.123956</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.045911</td>\n",
       "      <td>0.173181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193721</td>\n",
       "      <td>0.053943</td>\n",
       "      <td>0.101209</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.130798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.423551</td>\n",
       "      <td>0.260779</td>\n",
       "      <td>0.099594</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.108091</td>\n",
       "      <td>0.359251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366853</td>\n",
       "      <td>0.172150</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.044894</td>\n",
       "      <td>0.187978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249149</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.092881</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.172362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.372047</td>\n",
       "      <td>0.287334</td>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.300133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468847</td>\n",
       "      <td>0.345030</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.057541</td>\n",
       "      <td>0.266897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>0.069670</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.291913</td>\n",
       "      <td>0.176009</td>\n",
       "      <td>0.066549</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.195308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.192239</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>0.132341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410631</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.049224</td>\n",
       "      <td>0.217803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.127651</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.082139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165723</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.144605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.148425</td>\n",
       "      <td>0.039178</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.088709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.167995</td>\n",
       "      <td>0.044532</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.102594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234949</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.030153</td>\n",
       "      <td>0.159027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.156699</td>\n",
       "      <td>0.042341</td>\n",
       "      <td>0.047557</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.136974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.141718</td>\n",
       "      <td>0.032314</td>\n",
       "      <td>0.044685</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.109013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.126410</td>\n",
       "      <td>0.027676</td>\n",
       "      <td>0.044192</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080658</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.066055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.043166</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.071971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081566</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.057180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.101048</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.091074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181631</td>\n",
       "      <td>0.050607</td>\n",
       "      <td>0.040092</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.117401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113497</td>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.039354</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.088559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  precision_abs_mean  precision_square_mean  \\\n",
       "15        6        0            7.038741              56.124306   \n",
       "40        9        4            3.675336              15.468559   \n",
       "26        7        5            1.448094               2.141280   \n",
       "8         4        2            2.605496               7.334979   \n",
       "38        9        2            3.624477              13.794410   \n",
       "30        8        2            2.441384               6.784243   \n",
       "31        8        3            1.570043               2.533107   \n",
       "41        9        5            1.527595               2.465228   \n",
       "42        9        6            2.200791               5.540302   \n",
       "43        9        7            1.296808               1.785274   \n",
       "32        8        4            1.275137               1.916600   \n",
       "36        9        0            2.862352               9.597827   \n",
       "29        8        1            0.762147               0.715114   \n",
       "5         3        2            0.731875               0.654823   \n",
       "44        9        8            1.149970               1.730498   \n",
       "39        9        3            0.664687               0.697188   \n",
       "37        9        1            0.580308               0.515957   \n",
       "28        8        0            0.958085               1.130218   \n",
       "21        7        0            0.495820               0.291270   \n",
       "7         4        1            0.270548               0.105974   \n",
       "33        8        5            0.303836               0.123956   \n",
       "4         3        1            0.193721               0.053943   \n",
       "34        8        6            0.423551               0.260779   \n",
       "0         1        0            0.366853               0.172150   \n",
       "2         2        1            0.249149               0.090226   \n",
       "17        6        2            0.372047               0.287334   \n",
       "1         2        0            0.468847               0.345030   \n",
       "9         4        3            0.194421               0.071259   \n",
       "19        6        4            0.291913               0.176009   \n",
       "35        8        7            0.192239               0.052350   \n",
       "6         4        0            0.410631               0.395932   \n",
       "13        5        3            0.127651               0.025149   \n",
       "16        6        1            0.165723               0.045892   \n",
       "14        5        4            0.148425               0.039178   \n",
       "20        6        5            0.167995               0.044532   \n",
       "3         3        0            0.234949               0.088875   \n",
       "18        6        3            0.156699               0.042341   \n",
       "27        7        6            0.141718               0.032314   \n",
       "23        7        2            0.126410               0.027676   \n",
       "22        7        1            0.080658               0.010527   \n",
       "24        7        3            0.089624               0.012618   \n",
       "11        5        1            0.081566               0.014537   \n",
       "25        7        4            0.101048               0.016574   \n",
       "10        5        0            0.181631               0.050607   \n",
       "12        5        2            0.113497               0.022102   \n",
       "\n",
       "    cond_correlation_abs_mean  cond_correlation_square_mean       kld  \\\n",
       "15                   0.940714                      0.885794  3.356807   \n",
       "40                   0.727214                      0.537641  1.185591   \n",
       "26                   0.717184                      0.516534  0.350275   \n",
       "8                    0.684766                      0.473425  0.513496   \n",
       "38                   0.658751                      0.441811  0.878687   \n",
       "30                   0.554259                      0.320982  0.793396   \n",
       "31                   0.520888                      0.276734  0.580847   \n",
       "41                   0.401093                      0.166864  0.304046   \n",
       "42                   0.362587                      0.136574  0.378671   \n",
       "43                   0.348225                      0.126731  0.176308   \n",
       "32                   0.333961                      0.122050  0.204682   \n",
       "36                   0.323245                      0.111041  0.370006   \n",
       "29                   0.273285                      0.083337  0.175144   \n",
       "5                    0.241799                      0.070906  0.126337   \n",
       "44                   0.207519                      0.055558  0.442774   \n",
       "39                   0.169173                      0.044371  0.215582   \n",
       "37                   0.162705                      0.037133  0.181646   \n",
       "28                   0.156158                      0.031947  0.142651   \n",
       "21                   0.118399                      0.018076  0.030335   \n",
       "7                    0.117658                      0.018877  0.026720   \n",
       "33                   0.106749                      0.016137  0.045911   \n",
       "4                    0.101209                      0.014105  0.013764   \n",
       "34                   0.099594                      0.015615  0.108091   \n",
       "0                    0.096500                      0.013228  0.044894   \n",
       "2                    0.092881                      0.012328  0.029024   \n",
       "17                   0.073918                      0.009675  0.045037   \n",
       "1                    0.071147                      0.007371  0.057541   \n",
       "9                    0.069670                      0.008032  0.028622   \n",
       "19                   0.066549                      0.006936  0.011205   \n",
       "35                   0.065791                      0.005958  0.019434   \n",
       "6                    0.063530                      0.007068  0.049224   \n",
       "13                   0.060780                      0.005707  0.007792   \n",
       "16                   0.055791                      0.004684  0.024624   \n",
       "14                   0.055254                      0.004966  0.008063   \n",
       "20                   0.053486                      0.004503  0.014748   \n",
       "3                    0.049453                      0.003737  0.030153   \n",
       "18                   0.047557                      0.003678  0.013133   \n",
       "27                   0.044685                      0.003026  0.006643   \n",
       "23                   0.044192                      0.003449  0.009584   \n",
       "22                   0.043887                      0.002952  0.002304   \n",
       "24                   0.043166                      0.002871  0.007570   \n",
       "11                   0.042022                      0.003253  0.006100   \n",
       "25                   0.041227                      0.002845  0.007974   \n",
       "10                   0.040092                      0.002469  0.015609   \n",
       "12                   0.039354                      0.002750  0.006691   \n",
       "\n",
       "         iae  dependence  \n",
       "15  0.790776           1  \n",
       "40  0.678889           1  \n",
       "26  0.447577           1  \n",
       "8   0.581441           1  \n",
       "38  0.866287           1  \n",
       "30  0.737579           1  \n",
       "31  0.559309           0  \n",
       "41  0.431301           1  \n",
       "42  0.860712           1  \n",
       "43  0.391962           1  \n",
       "32  0.363889           0  \n",
       "36  0.780183           1  \n",
       "29  0.339254           1  \n",
       "5   0.331938           1  \n",
       "44  0.566283           1  \n",
       "39  0.364071           1  \n",
       "37  0.345735           1  \n",
       "28  0.354504           1  \n",
       "21  0.208670           0  \n",
       "7   0.142207           0  \n",
       "33  0.173181           0  \n",
       "4   0.130798           0  \n",
       "34  0.359251           0  \n",
       "0   0.187978           0  \n",
       "2   0.172362           0  \n",
       "17  0.300133           0  \n",
       "1   0.266897           0  \n",
       "9   0.146367           0  \n",
       "19  0.195308           0  \n",
       "35  0.132341           1  \n",
       "6   0.217803           0  \n",
       "13  0.082139           0  \n",
       "16  0.144605           0  \n",
       "14  0.088709           0  \n",
       "20  0.102594           0  \n",
       "3   0.159027           0  \n",
       "18  0.136974           0  \n",
       "27  0.109013           0  \n",
       "23  0.130284           0  \n",
       "22  0.066055           0  \n",
       "24  0.071971           0  \n",
       "11  0.057180           0  \n",
       "25  0.091074           0  \n",
       "10  0.117401           0  \n",
       "12  0.088559           0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.sort_values(\"cond_correlation_abs_mean\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91dfe4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_row</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>0.464364</td>\n",
       "      <td>0.459035</td>\n",
       "      <td>0.456171</td>\n",
       "      <td>0.448379</td>\n",
       "      <td>0.484878</td>\n",
       "      <td>0.519245</td>\n",
       "      <td>0.588760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_col</th>\n",
       "      <td>0.468889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.108165</td>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.029705</td>\n",
       "      <td>0.067670</td>\n",
       "      <td>0.155219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <td>0.464364</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>0.950198</td>\n",
       "      <td>0.948617</td>\n",
       "      <td>0.973123</td>\n",
       "      <td>0.977207</td>\n",
       "      <td>0.734083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_square_mean</th>\n",
       "      <td>0.459035</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.942161</td>\n",
       "      <td>0.971410</td>\n",
       "      <td>0.978524</td>\n",
       "      <td>0.730554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <td>0.456171</td>\n",
       "      <td>0.108165</td>\n",
       "      <td>0.950198</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>0.924769</td>\n",
       "      <td>0.914756</td>\n",
       "      <td>0.734083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <td>0.448379</td>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.948617</td>\n",
       "      <td>0.942161</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926482</td>\n",
       "      <td>0.913702</td>\n",
       "      <td>0.730554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kld</th>\n",
       "      <td>0.484878</td>\n",
       "      <td>0.029705</td>\n",
       "      <td>0.973123</td>\n",
       "      <td>0.971410</td>\n",
       "      <td>0.924769</td>\n",
       "      <td>0.926482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.730554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iae</th>\n",
       "      <td>0.519245</td>\n",
       "      <td>0.067670</td>\n",
       "      <td>0.977207</td>\n",
       "      <td>0.978524</td>\n",
       "      <td>0.914756</td>\n",
       "      <td>0.913702</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependence</th>\n",
       "      <td>0.588760</td>\n",
       "      <td>0.155219</td>\n",
       "      <td>0.734083</td>\n",
       "      <td>0.730554</td>\n",
       "      <td>0.734083</td>\n",
       "      <td>0.730554</td>\n",
       "      <td>0.730554</td>\n",
       "      <td>0.727025</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               var_row   var_col  precision_abs_mean  \\\n",
       "var_row                       1.000000  0.468889            0.464364   \n",
       "var_col                       0.468889  1.000000            0.014586   \n",
       "precision_abs_mean            0.464364  0.014586            1.000000   \n",
       "precision_square_mean         0.459035  0.003796            0.997760   \n",
       "cond_correlation_abs_mean     0.456171  0.108165            0.950198   \n",
       "cond_correlation_square_mean  0.448379  0.103636            0.948617   \n",
       "kld                           0.484878  0.029705            0.973123   \n",
       "iae                           0.519245  0.067670            0.977207   \n",
       "dependence                    0.588760  0.155219            0.734083   \n",
       "\n",
       "                              precision_square_mean  \\\n",
       "var_row                                    0.459035   \n",
       "var_col                                    0.003796   \n",
       "precision_abs_mean                         0.997760   \n",
       "precision_square_mean                      1.000000   \n",
       "cond_correlation_abs_mean                  0.942688   \n",
       "cond_correlation_square_mean               0.942161   \n",
       "kld                                        0.971410   \n",
       "iae                                        0.978524   \n",
       "dependence                                 0.730554   \n",
       "\n",
       "                              cond_correlation_abs_mean  \\\n",
       "var_row                                        0.456171   \n",
       "var_col                                        0.108165   \n",
       "precision_abs_mean                             0.950198   \n",
       "precision_square_mean                          0.942688   \n",
       "cond_correlation_abs_mean                      1.000000   \n",
       "cond_correlation_square_mean                   0.997892   \n",
       "kld                                            0.924769   \n",
       "iae                                            0.914756   \n",
       "dependence                                     0.734083   \n",
       "\n",
       "                              cond_correlation_square_mean       kld  \\\n",
       "var_row                                           0.448379  0.484878   \n",
       "var_col                                           0.103636  0.029705   \n",
       "precision_abs_mean                                0.948617  0.973123   \n",
       "precision_square_mean                             0.942161  0.971410   \n",
       "cond_correlation_abs_mean                         0.997892  0.924769   \n",
       "cond_correlation_square_mean                      1.000000  0.926482   \n",
       "kld                                               0.926482  1.000000   \n",
       "iae                                               0.913702  0.971014   \n",
       "dependence                                        0.730554  0.730554   \n",
       "\n",
       "                                   iae  dependence  \n",
       "var_row                       0.519245    0.588760  \n",
       "var_col                       0.067670    0.155219  \n",
       "precision_abs_mean            0.977207    0.734083  \n",
       "precision_square_mean         0.978524    0.730554  \n",
       "cond_correlation_abs_mean     0.914756    0.734083  \n",
       "cond_correlation_square_mean  0.913702    0.730554  \n",
       "kld                           0.971014    0.730554  \n",
       "iae                           1.000000    0.727025  \n",
       "dependence                    0.727025    1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.corr(\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "531c7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_row</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.313990</td>\n",
       "      <td>0.136642</td>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.229923</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>0.483034</td>\n",
       "      <td>0.525150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_col</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055454</td>\n",
       "      <td>-0.151068</td>\n",
       "      <td>0.067078</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.085888</td>\n",
       "      <td>0.093986</td>\n",
       "      <td>0.200386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <td>0.313990</td>\n",
       "      <td>-0.055454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912995</td>\n",
       "      <td>0.899513</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>0.933595</td>\n",
       "      <td>0.850070</td>\n",
       "      <td>0.616119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_square_mean</th>\n",
       "      <td>0.136642</td>\n",
       "      <td>-0.151068</td>\n",
       "      <td>0.912995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716868</td>\n",
       "      <td>0.827302</td>\n",
       "      <td>0.978361</td>\n",
       "      <td>0.597232</td>\n",
       "      <td>0.398593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.067078</td>\n",
       "      <td>0.899513</td>\n",
       "      <td>0.716868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963376</td>\n",
       "      <td>0.794271</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.670810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <td>0.229923</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>0.827302</td>\n",
       "      <td>0.963376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880437</td>\n",
       "      <td>0.735732</td>\n",
       "      <td>0.562201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kld</th>\n",
       "      <td>0.204762</td>\n",
       "      <td>-0.085888</td>\n",
       "      <td>0.933595</td>\n",
       "      <td>0.978361</td>\n",
       "      <td>0.794271</td>\n",
       "      <td>0.880437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667003</td>\n",
       "      <td>0.465372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iae</th>\n",
       "      <td>0.483034</td>\n",
       "      <td>0.093986</td>\n",
       "      <td>0.850070</td>\n",
       "      <td>0.597232</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.735732</td>\n",
       "      <td>0.667003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependence</th>\n",
       "      <td>0.525150</td>\n",
       "      <td>0.200386</td>\n",
       "      <td>0.616119</td>\n",
       "      <td>0.398593</td>\n",
       "      <td>0.670810</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.465372</td>\n",
       "      <td>0.738113</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               var_row   var_col  precision_abs_mean  \\\n",
       "var_row                       1.000000  0.500000            0.313990   \n",
       "var_col                       0.500000  1.000000           -0.055454   \n",
       "precision_abs_mean            0.313990 -0.055454            1.000000   \n",
       "precision_square_mean         0.136642 -0.151068            0.912995   \n",
       "cond_correlation_abs_mean     0.337374  0.067078            0.899513   \n",
       "cond_correlation_square_mean  0.229923 -0.000748            0.915940   \n",
       "kld                           0.204762 -0.085888            0.933595   \n",
       "iae                           0.483034  0.093986            0.850070   \n",
       "dependence                    0.525150  0.200386            0.616119   \n",
       "\n",
       "                              precision_square_mean  \\\n",
       "var_row                                    0.136642   \n",
       "var_col                                   -0.151068   \n",
       "precision_abs_mean                         0.912995   \n",
       "precision_square_mean                      1.000000   \n",
       "cond_correlation_abs_mean                  0.716868   \n",
       "cond_correlation_square_mean               0.827302   \n",
       "kld                                        0.978361   \n",
       "iae                                        0.597232   \n",
       "dependence                                 0.398593   \n",
       "\n",
       "                              cond_correlation_abs_mean  \\\n",
       "var_row                                        0.337374   \n",
       "var_col                                        0.067078   \n",
       "precision_abs_mean                             0.899513   \n",
       "precision_square_mean                          0.716868   \n",
       "cond_correlation_abs_mean                      1.000000   \n",
       "cond_correlation_square_mean                   0.963376   \n",
       "kld                                            0.794271   \n",
       "iae                                            0.838288   \n",
       "dependence                                     0.670810   \n",
       "\n",
       "                              cond_correlation_square_mean       kld  \\\n",
       "var_row                                           0.229923  0.204762   \n",
       "var_col                                          -0.000748 -0.085888   \n",
       "precision_abs_mean                                0.915940  0.933595   \n",
       "precision_square_mean                             0.827302  0.978361   \n",
       "cond_correlation_abs_mean                         0.963376  0.794271   \n",
       "cond_correlation_square_mean                      1.000000  0.880437   \n",
       "kld                                               0.880437  1.000000   \n",
       "iae                                               0.735732  0.667003   \n",
       "dependence                                        0.562201  0.465372   \n",
       "\n",
       "                                   iae  dependence  \n",
       "var_row                       0.483034    0.525150  \n",
       "var_col                       0.093986    0.200386  \n",
       "precision_abs_mean            0.850070    0.616119  \n",
       "precision_square_mean         0.597232    0.398593  \n",
       "cond_correlation_abs_mean     0.838288    0.670810  \n",
       "cond_correlation_square_mean  0.735732    0.562201  \n",
       "kld                           0.667003    0.465372  \n",
       "iae                           1.000000    0.738113  \n",
       "dependence                    0.738113    1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.corr(\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "798e7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC IAE                    : 0.9327731092436975\n",
      "AUC KLD                    : 0.9348739495798319\n",
      "AUC Conditional Correlation: 0.9369747899159664\n",
      "AUC Precision Matrix       : 0.9369747899159664\n"
     ]
    }
   ],
   "source": [
    "auc_iae = roc_auc_score(merged[\"dependence\"], merged[\"iae\"])\n",
    "auc_kld = roc_auc_score(merged[\"dependence\"], merged[\"kld\"])\n",
    "auc_corr = roc_auc_score(merged[\"dependence\"], merged[\"cond_correlation_abs_mean\"])\n",
    "auc_pmat = roc_auc_score(merged[\"dependence\"], merged[\"precision_abs_mean\"])\n",
    "print(\"AUC IAE                    :\",auc_iae)\n",
    "print(\"AUC KLD                    :\",auc_kld)\n",
    "print(\"AUC Conditional Correlation:\",auc_corr)\n",
    "print(\"AUC Precision Matrix       :\",auc_pmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45b9b4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(merged[\"dependence\"], merged[\"iae\"])\n",
    "plt.plot(fpr, tpr, label=\"iae\")\n",
    "fpr, tpr, thresholds = roc_curve(merged[\"dependence\"], merged[\"kld\"])\n",
    "plt.plot(fpr, tpr, label=\"kld\")\n",
    "fpr, tpr, thresholds = roc_curve(merged[\"dependence\"], merged[\"cond_correlation_abs_mean\"])\n",
    "plt.plot(fpr, tpr, label=\"cond_correlation_abs_mean\")\n",
    "fpr, tpr, thresholds = roc_curve(merged[\"dependence\"], merged[\"precision_abs_mean\"])\n",
    "plt.plot(fpr, tpr, label=\"precision_abs_mean\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6cda5",
   "metadata": {},
   "source": [
    "#### Looking at the model splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "149a1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.transformation,simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8649bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[0],simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5aa64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[1],simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86eb78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[2],simulated_data_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mctm_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
