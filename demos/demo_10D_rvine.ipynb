{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923c2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/anaconda3/envs/mctm_pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gtm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b4550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTM Package including GTM and the plot functions\n",
    "from gtm import *\n",
    "# Sample Copulas Package\n",
    "import pyvinecopulib as pv\n",
    "import numpy as np\n",
    "# Other Stuff\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc123abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed_int):\n",
    "    # Reproducibility\n",
    "    # Infos from here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    # Set Seeds for Torch, Numpy and Python\n",
    "    torch.manual_seed(seed_int)\n",
    "    np.random.seed(seed_int)\n",
    "    random.seed(seed_int)\n",
    "\n",
    "set_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed17c60",
   "metadata": {},
   "source": [
    "### 1. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc86d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvine_structure = pv.RVineStructure.simulate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc8ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvinecopulib as pv\n",
    "import numpy as np\n",
    "\n",
    "def sample_random_pair_copulas(D,Independence_tree=2):\n",
    "    pair_copulas = []\n",
    "\n",
    "    # List of families to sample from (can add/remove)\n",
    "    families = [\n",
    "        #pv.BicopFamily.indep,\n",
    "        pv.BicopFamily.gaussian,\n",
    "        pv.BicopFamily.student,\n",
    "        pv.BicopFamily.clayton,\n",
    "        pv.BicopFamily.gumbel,\n",
    "        pv.BicopFamily.frank,\n",
    "        pv.BicopFamily.joe,\n",
    "    ]\n",
    "\n",
    "    # For each tree in the vine\n",
    "    for tree in range(D - 1):\n",
    "        bicop_list = []\n",
    "        num_edges = D - tree - 1\n",
    "        if tree >= Independence_tree:\n",
    "            for _ in range(num_edges):\n",
    "                bicop = pv.Bicop(family=pv.BicopFamily.indep, rotation=0)\n",
    "                bicop_list.append(bicop)\n",
    "            pair_copulas.append(bicop_list)\n",
    "        else:\n",
    "            for _ in range(num_edges):\n",
    "                fam = np.random.choice(families)\n",
    "                \n",
    "                tau = (0.3 + 0.4 * np.random.random())\n",
    "                neg = np.random.choice([-1, 1])\n",
    "                \n",
    "                # Sample rotation 0-3 for asymmetric families (e.g., Clayton, Gumbel, Frank)\n",
    "                if fam in [pv.BicopFamily.clayton, pv.BicopFamily.gumbel,pv.BicopFamily.joe]:\n",
    "                    rotation = np.random.choice([0,90,180,270])\n",
    "                else:\n",
    "                    rotation = 0\n",
    "                if fam == pv.BicopFamily.student:\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation, parameters=np.stack([np.array([neg*tau]),\n",
    "                                                                                         np.array([2])])) \n",
    "                elif fam == pv.BicopFamily.gaussian:\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation, parameters=np.stack([\n",
    "                                                                                         np.array([neg*tau])])) \n",
    "                elif fam == pv.BicopFamily.frank:\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation)\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation, parameters=bicop.tau_to_parameters(np.stack([np.array([neg*tau]),])))\n",
    "                else:\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation)\n",
    "                    bicop = pv.Bicop(family=fam, rotation=rotation, parameters=bicop.tau_to_parameters(np.array([tau]),))\n",
    "\n",
    "                bicop_list.append(bicop)\n",
    "            pair_copulas.append(bicop_list)\n",
    "\n",
    "    return pair_copulas\n",
    "\n",
    "# Usage example:\n",
    "# rvine_structure should be created or loaded beforehand\n",
    "# pair_copulas = sample_random_pair_copulas(rvine_structure)\n",
    "# vine = pv.Vinecop(structure=rvine_structure, pair_copulas=pair_copulas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d90e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/455988265.py:50: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  bicop = pv.Bicop(family=fam, rotation=rotation, parameters=bicop.tau_to_parameters(np.array([tau]),))\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/455988265.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  bicop = pv.Bicop(family=fam, rotation=rotation, parameters=bicop.tau_to_parameters(np.stack([np.array([neg*tau]),])))\n"
     ]
    }
   ],
   "source": [
    "D = 10  # dimension\n",
    "pair_copulas = sample_random_pair_copulas(D,Independence_tree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcaf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vine_model = pv.Vinecop.from_structure(structure=rvine_structure, pair_copulas=pair_copulas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb304e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = vine_model.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7156c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>edge</th>\n",
       "      <th>conditioned variables</th>\n",
       "      <th>conditioning variables</th>\n",
       "      <th>var_types</th>\n",
       "      <th>family</th>\n",
       "      <th>rotation</th>\n",
       "      <th>parameters</th>\n",
       "      <th>df</th>\n",
       "      <th>tau</th>\n",
       "      <th>conditioned variable 1</th>\n",
       "      <th>conditioned variable 2</th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3  9</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10  7</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4  5</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1  9</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2  9</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7  8</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5  6</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8  9</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6  9</td>\n",
       "      <td></td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3  8</td>\n",
       "      <td>9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10  8</td>\n",
       "      <td>7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4  6</td>\n",
       "      <td>5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1  8</td>\n",
       "      <td>9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2  6</td>\n",
       "      <td>9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7  9</td>\n",
       "      <td>8</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Joe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5  9</td>\n",
       "      <td>6</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8  6</td>\n",
       "      <td>9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3  6</td>\n",
       "      <td>8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.55, 2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10  9</td>\n",
       "      <td>8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4  9</td>\n",
       "      <td>6  5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1  7</td>\n",
       "      <td>8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gumbel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2  8</td>\n",
       "      <td>6  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7  6</td>\n",
       "      <td>9  8</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Gumbel</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5  8</td>\n",
       "      <td>9  6</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3  5</td>\n",
       "      <td>6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10  6</td>\n",
       "      <td>9  8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4  8</td>\n",
       "      <td>9  6  5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1  6</td>\n",
       "      <td>7  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2  5</td>\n",
       "      <td>8  6  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7  5</td>\n",
       "      <td>6  9  8</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3  7</td>\n",
       "      <td>5  6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10  5</td>\n",
       "      <td>6  9  8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4  7</td>\n",
       "      <td>8  9  6  5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1  5</td>\n",
       "      <td>6  7  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2  7</td>\n",
       "      <td>5  8  6  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3  1</td>\n",
       "      <td>7  5  6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10  2</td>\n",
       "      <td>5  6  9  8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4  2</td>\n",
       "      <td>7  8  9  6  5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1  2</td>\n",
       "      <td>5  6  7  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3  2</td>\n",
       "      <td>1  7  5  6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10  1</td>\n",
       "      <td>2  5  6  9  8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4  1</td>\n",
       "      <td>2  7  8  9  6  5</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3  4</td>\n",
       "      <td>2  1  7  5  6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10  4</td>\n",
       "      <td>1  2  5  6  9  8  7</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3  10</td>\n",
       "      <td>4  2  1  7  5  6  8  9</td>\n",
       "      <td>c, c</td>\n",
       "      <td>Independence</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tree  edge conditioned variables     conditioning variables  \\\n",
       "0      1     1                  3  9                              \n",
       "1      1     2                 10  7                              \n",
       "2      1     3                  4  5                              \n",
       "3      1     4                  1  9                              \n",
       "4      1     5                  2  9                              \n",
       "5      1     6                  7  8                              \n",
       "6      1     7                  5  6                              \n",
       "7      1     8                  8  9                              \n",
       "8      1     9                  6  9                              \n",
       "9      2     1                  3  8                       9      \n",
       "10     2     2                 10  8                       7      \n",
       "11     2     3                  4  6                       5      \n",
       "12     2     4                  1  8                       9      \n",
       "13     2     5                  2  6                       9      \n",
       "14     2     6                  7  9                       8      \n",
       "15     2     7                  5  9                       6      \n",
       "16     2     8                  8  6                       9      \n",
       "17     3     1                  3  6                    8  9      \n",
       "18     3     2                 10  9                    8  7      \n",
       "19     3     3                  4  9                    6  5      \n",
       "20     3     4                  1  7                    8  9      \n",
       "21     3     5                  2  8                    6  9      \n",
       "22     3     6                  7  6                    9  8      \n",
       "23     3     7                  5  8                    9  6      \n",
       "24     4     1                  3  5                 6  8  9      \n",
       "25     4     2                 10  6                 9  8  7      \n",
       "26     4     3                  4  8                 9  6  5      \n",
       "27     4     4                  1  6                 7  8  9      \n",
       "28     4     5                  2  5                 8  6  9      \n",
       "29     4     6                  7  5                 6  9  8      \n",
       "30     5     1                  3  7              5  6  8  9      \n",
       "31     5     2                 10  5              6  9  8  7      \n",
       "32     5     3                  4  7              8  9  6  5      \n",
       "33     5     4                  1  5              6  7  8  9      \n",
       "34     5     5                  2  7              5  8  6  9      \n",
       "35     6     1                  3  1           7  5  6  8  9      \n",
       "36     6     2                 10  2           5  6  9  8  7      \n",
       "37     6     3                  4  2           7  8  9  6  5      \n",
       "38     6     4                  1  2           5  6  7  8  9      \n",
       "39     7     1                  3  2        1  7  5  6  8  9      \n",
       "40     7     2                 10  1        2  5  6  9  8  7      \n",
       "41     7     3                  4  1        2  7  8  9  6  5      \n",
       "42     8     1                  3  4     2  1  7  5  6  8  9      \n",
       "43     8     2                 10  4     1  2  5  6  9  8  7      \n",
       "44     9     1                 3  10  4  2  1  7  5  6  8  9      \n",
       "\n",
       "        var_types        family  rotation   parameters   df   tau  \\\n",
       "0   c, c                    Joe     270.0         5.44  1.0 -0.70   \n",
       "1       c, c            Student       0.0   0.42, 2.00  2.0  0.28   \n",
       "2        c, c          Gaussian       0.0        -0.34  1.0 -0.22   \n",
       "3   c, c                    Joe     180.0         3.46  1.0  0.57   \n",
       "4     c, c                Frank       0.0        -5.18  1.0 -0.47   \n",
       "5     c, c                Frank       0.0        -3.92  1.0 -0.38   \n",
       "6     c, c                Frank       0.0        -3.04  1.0 -0.31   \n",
       "7     c, c                Frank       0.0         5.17  1.0  0.47   \n",
       "8       c, c            Student       0.0  -0.36, 2.00  2.0 -0.23   \n",
       "9   c, c                    Joe     270.0         3.67  1.0 -0.59   \n",
       "10  c, c                    Joe       0.0         3.56  1.0  0.58   \n",
       "11    c, c                Frank       0.0        -8.84  1.0 -0.63   \n",
       "12  c, c                    Joe      90.0         2.27  1.0 -0.41   \n",
       "13       c, c          Gaussian       0.0         0.34  1.0  0.22   \n",
       "14  c, c                    Joe       0.0         2.60  1.0  0.46   \n",
       "15       c, c          Gaussian       0.0        -0.43  1.0 -0.28   \n",
       "16      c, c            Clayton     270.0         3.46  1.0 -0.63   \n",
       "17      c, c            Student       0.0  -0.55, 2.00  2.0 -0.37   \n",
       "18    c, c                Frank       0.0        -4.43  1.0 -0.42   \n",
       "19      c, c            Clayton      90.0         0.98  1.0 -0.33   \n",
       "20     c, c              Gumbel      90.0         1.72  1.0 -0.42   \n",
       "21    c, c                Frank       0.0         5.92  1.0  0.51   \n",
       "22     c, c              Gumbel     180.0         3.00  1.0  0.67   \n",
       "23      c, c            Clayton     270.0         1.97  1.0 -0.50   \n",
       "24           c, c  Independence       NaN               0.0   NaN   \n",
       "25           c, c  Independence       NaN               0.0   NaN   \n",
       "26           c, c  Independence       NaN               0.0   NaN   \n",
       "27           c, c  Independence       NaN               0.0   NaN   \n",
       "28           c, c  Independence       NaN               0.0   NaN   \n",
       "29           c, c  Independence       NaN               0.0   NaN   \n",
       "30           c, c  Independence       NaN               0.0   NaN   \n",
       "31           c, c  Independence       NaN               0.0   NaN   \n",
       "32           c, c  Independence       NaN               0.0   NaN   \n",
       "33           c, c  Independence       NaN               0.0   NaN   \n",
       "34           c, c  Independence       NaN               0.0   NaN   \n",
       "35           c, c  Independence       NaN               0.0   NaN   \n",
       "36           c, c  Independence       NaN               0.0   NaN   \n",
       "37           c, c  Independence       NaN               0.0   NaN   \n",
       "38           c, c  Independence       NaN               0.0   NaN   \n",
       "39           c, c  Independence       NaN               0.0   NaN   \n",
       "40           c, c  Independence       NaN               0.0   NaN   \n",
       "41           c, c  Independence       NaN               0.0   NaN   \n",
       "42           c, c  Independence       NaN               0.0   NaN   \n",
       "43           c, c  Independence       NaN               0.0   NaN   \n",
       "44           c, c  Independence       NaN               NaN  0.00   \n",
       "\n",
       "    conditioned variable 1  conditioned variable 2  var_row  var_col  \\\n",
       "0                        3                       9        9        3   \n",
       "1                       10                       7       10        7   \n",
       "2                        4                       5        5        4   \n",
       "3                        1                       9        9        1   \n",
       "4                        2                       9        9        2   \n",
       "5                        7                       8        8        7   \n",
       "6                        5                       6        6        5   \n",
       "7                        8                       9        9        8   \n",
       "8                        6                       9        9        6   \n",
       "9                        3                       8        8        3   \n",
       "10                      10                       8       10        8   \n",
       "11                       4                       6        6        4   \n",
       "12                       1                       8        8        1   \n",
       "13                       2                       6        6        2   \n",
       "14                       7                       9        9        7   \n",
       "15                       5                       9        9        5   \n",
       "16                       8                       6        8        6   \n",
       "17                       3                       6        6        3   \n",
       "18                      10                       9       10        9   \n",
       "19                       4                       9        9        4   \n",
       "20                       1                       7        7        1   \n",
       "21                       2                       8        8        2   \n",
       "22                       7                       6        7        6   \n",
       "23                       5                       8        8        5   \n",
       "24                       3                       5        5        3   \n",
       "25                      10                       6       10        6   \n",
       "26                       4                       8        8        4   \n",
       "27                       1                       6        6        1   \n",
       "28                       2                       5        5        2   \n",
       "29                       7                       5        7        5   \n",
       "30                       3                       7        7        3   \n",
       "31                      10                       5       10        5   \n",
       "32                       4                       7        7        4   \n",
       "33                       1                       5        5        1   \n",
       "34                       2                       7        7        2   \n",
       "35                       3                       1        3        1   \n",
       "36                      10                       2       10        2   \n",
       "37                       4                       2        4        2   \n",
       "38                       1                       2        2        1   \n",
       "39                       3                       2        3        2   \n",
       "40                      10                       1       10        1   \n",
       "41                       4                       1        4        1   \n",
       "42                       3                       4        4        3   \n",
       "43                      10                       4       10        4   \n",
       "44                       3                      10       10        3   \n",
       "\n",
       "    dependence  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  \n",
       "10           1  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           1  \n",
       "16           1  \n",
       "17           0  \n",
       "18           0  \n",
       "19           0  \n",
       "20           0  \n",
       "21           0  \n",
       "22           0  \n",
       "23           0  \n",
       "24           0  \n",
       "25           0  \n",
       "26           0  \n",
       "27           0  \n",
       "28           0  \n",
       "29           0  \n",
       "30           0  \n",
       "31           0  \n",
       "32           0  \n",
       "33           0  \n",
       "34           0  \n",
       "35           0  \n",
       "36           0  \n",
       "37           0  \n",
       "38           0  \n",
       "39           0  \n",
       "40           0  \n",
       "41           0  \n",
       "42           0  \n",
       "43           0  \n",
       "44           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "text = vine_model.format()\n",
    "\n",
    "# Strip first line (title) and get all data lines\n",
    "lines = text.strip().split('\\n')[2:]\n",
    "\n",
    "pattern = re.compile(\n",
    "    r\"^\\s*(\\d+)\\s+(\\d+)\\s+([\\d, ]+)\\s+([\\d, ]+)\\s+([cI, ]+)\\s+(\\w+)\\s+(-?\\d+)?\\s+(.+?)\\s+([-\\d.]+)?\\s+([-\\d.]+)?\\s*$\"\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        rows.append(match.groups())\n",
    "    else:\n",
    "        print(f\"Failed to parse line: {line}\")\n",
    "\n",
    "columns = ['tree', 'edge', 'conditioned variables', 'conditioning variables',\n",
    "           'var_types', 'family', 'rotation', 'parameters', 'df', 'tau']\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Optional: convert numeric columns\n",
    "for col in ['tree', 'edge', 'rotation', 'df', 'tau']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "def split_variables(row):\n",
    "    # Split by comma and strip spaces\n",
    "    row['conditioned variables'] = row['conditioned variables'].replace(',', ' ')\n",
    "    nums = [x.strip() for x in row['conditioned variables'].split(' ')]\n",
    "    if len(nums) >= 2:\n",
    "        conditioned = ' '.join(nums[:3])\n",
    "        conditioning = ' '.join(nums[3:]) if len(nums) > 2 else ''\n",
    "    else:\n",
    "        conditioned = row['conditioned variables']\n",
    "        conditioning = ''\n",
    "    return pd.Series([conditioned, conditioning])\n",
    "\n",
    "# Apply the function to split the variable columns\n",
    "df[['conditioned variables', 'conditioning variables']] = df.apply(split_variables, axis=1)\n",
    "\n",
    "\n",
    "df[\"conditioned variable 1\"] = [df[\"conditioned variables\"][i].split(\" \")[0] for i in range(df.shape[0])]\n",
    "df[\"conditioned variable 1\"] = df[\"conditioned variable 1\"].astype(int)\n",
    "df[\"conditioned variable 2\"] = [df[\"conditioned variables\"][i].split(\" \")[2] for i in range(df.shape[0])]\n",
    "df[\"conditioned variable 2\"] = df[\"conditioned variable 2\"].astype(int)\n",
    "df[\"var_row\"] = [df[\"conditioned variable 1\"][i] if df[\"conditioned variable 1\"][i] > df[\"conditioned variable 2\"][i] else df[\"conditioned variable 2\"][i] for i in range(df.shape[0])]\n",
    "df[\"var_col\"] = [df[\"conditioned variable 2\"][i] if df[\"conditioned variable 1\"][i] > df[\"conditioned variable 2\"][i] else df[\"conditioned variable 1\"][i] for i in range(df.shape[0])]\n",
    "df[\"dependence\"] = [1 if df[\"tree\"][i] < 3 else 0 for i in range(df.shape[0])]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639cb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_structure = df[[\"tree\",\"edge\",\"conditioned variables\", \"conditioned variable 1\", \"conditioned variable 2\", \"dependence\", \"var_row\", \"var_col\"]]\n",
    "#df_true_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13083e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vine_model.plot(tree=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91426a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "N_train = 2000\n",
    "simulated_data_uniform_train = vine_model.simulate(n=N_train)\n",
    "simulated_data_train = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_train)).float()\n",
    "\n",
    "# Validate\n",
    "N_validate = 2000\n",
    "simulated_data_uniform_validate = vine_model.simulate(n=N_validate)\n",
    "simulated_data_validate = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_validate)).float()\n",
    "\n",
    "# Test\n",
    "N_test = 20000\n",
    "simulated_data_uniform_test = vine_model.simulate(n=N_test)\n",
    "simulated_data_test = torch.distributions.Normal(0,1).icdf(torch.tensor(simulated_data_uniform_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a347f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/1520218578.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/1520218578.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/1520218578.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_train = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_validate = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(vine_model.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(0,1).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_test = torch.tensor(loglik_copula) + log_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab3f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_pv_est = vine_model\n",
    "copula_pv_est.fit(simulated_data_uniform_train)\n",
    "means = simulated_data_train.mean(0)\n",
    "vars = simulated_data_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357cb0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/2452348847.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/2452348847.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/2452348847.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_test)).sum(1)\n"
     ]
    }
   ],
   "source": [
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_train))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_train)).sum(1)\n",
    "loglik_true_est_train = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_validate))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_validate)).sum(1)\n",
    "loglik_true_est_validate = torch.tensor(loglik_copula) + log_marginals\n",
    "\n",
    "loglik_copula = np.log(copula_pv_est.pdf(simulated_data_uniform_test))\n",
    "log_marginals = torch.distributions.Normal(means,vars).log_prob(torch.tensor(simulated_data_test)).sum(1)\n",
    "loglik_true_est_test = torch.tensor(loglik_copula) + log_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2036680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_densities(simulated_data_train, x_lim=[-4,4], y_lim=[-4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "133db9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_marginals(simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83659cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Copula_2D_Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # First Dimension (N) needs to be the samples\n",
    "        # Second Dimension (D) is the dimensionality of the data\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "# Create dataset and DataLoader\n",
    "dataset_train = Copula_2D_Dataset(simulated_data_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=N_train)\n",
    "\n",
    "dataset_validate = Copula_2D_Dataset(simulated_data_validate)\n",
    "dataloader_validate = DataLoader(dataset_validate, batch_size=N_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69048b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can see that we load the full data, so not batches\n",
    "# Model is just implemented with dataloaders because that is eeded for huge datasets in bioinformatics\n",
    "data_iter = iter(dataloader_train)\n",
    "sample = next(data_iter)\n",
    "sample.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c111eb",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef92cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GTM(\n",
    "    transformation_spline_range=list([[-15], [15]]), \n",
    "    degree_decorrelation=40,\n",
    "    degree_transformations=15,\n",
    "    num_decorr_layers=3,\n",
    "    num_trans_layers=1,\n",
    "    number_variables=10,\n",
    "    calc_method_bspline=\"deBoor\",\n",
    "    affine_decorr_layer=False,\n",
    "    device=\"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41ca3e",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tune and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "807c8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/anaconda3/envs/mctm_pytorch/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-05-21 15:40:50,257] A new study created in RDB with name: no-name-ff939b09-cd0f-4763-bf07-4d3a02d6f1f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 7.257230827695732   pensecondridge_opt: 18.988425261665334   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      " 18%|█▊        | 184/1000 [00:47<03:28,  3.91it/s]\n",
      "[I 2025-05-21 15:41:38,186] Trial 0 finished with value: -6.916006565093994 and parameters: {'penfirstridge': 7.257230827695732, 'pensecondridge': 18.988425261665334}. Best is trial 0 with value: -6.916006565093994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 8.844731920596114   pensecondridge_opt: 13.509777367297914   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 213/1000 [00:56<03:27,  3.79it/s]\n",
      "[I 2025-05-21 15:42:34,513] Trial 1 finished with value: -6.861380577087402 and parameters: {'penfirstridge': 8.844731920596114, 'pensecondridge': 13.509777367297914}. Best is trial 1 with value: -6.861380577087402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 0.04260109974997851   pensecondridge_opt: 14.308962398370383   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 109/1000 [00:29<04:01,  3.68it/s]\n",
      "[I 2025-05-21 15:43:04,287] Trial 2 finished with value: -7.281329154968262 and parameters: {'penfirstridge': 0.04260109974997851, 'pensecondridge': 14.308962398370383}. Best is trial 1 with value: -6.861380577087402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 0.2529575358025462   pensecondridge_opt: 10.933548972535224   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 87/1000 [00:23<04:04,  3.73it/s]\n",
      "[I 2025-05-21 15:43:27,810] Trial 3 finished with value: -7.406711101531982 and parameters: {'penfirstridge': 0.2529575358025462, 'pensecondridge': 10.933548972535224}. Best is trial 1 with value: -6.861380577087402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 23.226947660359478   pensecondridge_opt: 0.6862765962442597   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [00:53<03:32,  3.77it/s]\n",
      "[I 2025-05-21 15:44:20,999] Trial 4 finished with value: -6.856955051422119 and parameters: {'penfirstridge': 23.226947660359478, 'pensecondridge': 0.6862765962442597}. Best is trial 4 with value: -6.856955051422119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 18.74808327517621   pensecondridge_opt: 29.35168063705491   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:32<03:46,  3.86it/s]\n",
      "[I 2025-05-21 15:44:53,269] Trial 5 finished with value: -7.003628730773926 and parameters: {'penfirstridge': 18.74808327517621, 'pensecondridge': 29.35168063705491}. Best is trial 4 with value: -6.856955051422119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 4.453071899541935   pensecondridge_opt: 4.34915035906042   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 219/1000 [00:56<03:21,  3.88it/s]\n",
      "[I 2025-05-21 15:45:49,859] Trial 6 finished with value: -7.072941303253174 and parameters: {'penfirstridge': 4.453071899541935, 'pensecondridge': 4.34915035906042}. Best is trial 4 with value: -6.856955051422119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 29.1471160530973   pensecondridge_opt: 20.312213688355417   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [00:42<03:41,  3.79it/s]\n",
      "[I 2025-05-21 15:46:32,563] Trial 7 finished with value: -6.928414821624756 and parameters: {'penfirstridge': 29.1471160530973, 'pensecondridge': 20.312213688355417}. Best is trial 4 with value: -6.856955051422119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 18.94050373737133   pensecondridge_opt: 8.396861802788   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 223/1000 [00:58<03:22,  3.84it/s]\n",
      "[I 2025-05-21 15:47:30,857] Trial 8 finished with value: -6.834580898284912 and parameters: {'penfirstridge': 18.94050373737133, 'pensecondridge': 8.396861802788}. Best is trial 8 with value: -6.834580898284912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 5.575509592664974   pensecondridge_opt: 7.49908296970035   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 165/1000 [00:43<03:37,  3.83it/s]\n",
      "[I 2025-05-21 15:48:14,121] Trial 9 finished with value: -7.060526371002197 and parameters: {'penfirstridge': 5.575509592664974, 'pensecondridge': 7.49908296970035}. Best is trial 8 with value: -6.834580898284912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 18.725178293251332   pensecondridge_opt: 13.348723434021151   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:26<03:56,  3.80it/s]\n",
      "[I 2025-05-21 15:48:41,141] Trial 10 finished with value: -7.136041641235352 and parameters: {'penfirstridge': 18.725178293251332, 'pensecondridge': 13.348723434021151}. Best is trial 8 with value: -6.834580898284912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 23.764098669894135   pensecondridge_opt: 0.42077949923157093   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 166/1000 [00:43<03:36,  3.85it/s]\n",
      "[I 2025-05-21 15:49:24,468] Trial 11 finished with value: -6.989620208740234 and parameters: {'penfirstridge': 23.764098669894135, 'pensecondridge': 0.42077949923157093}. Best is trial 8 with value: -6.834580898284912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 23.626559542512666   pensecondridge_opt: 8.55670756983607   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 106/1000 [00:27<03:55,  3.79it/s]\n",
      "[I 2025-05-21 15:49:52,635] Trial 12 finished with value: -7.108657360076904 and parameters: {'penfirstridge': 23.626559542512666, 'pensecondridge': 8.55670756983607}. Best is trial 8 with value: -6.834580898284912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 16.494614228120156   pensecondridge_opt: 6.563050348747511   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 266/1000 [01:09<03:10,  3.85it/s]\n",
      "[I 2025-05-21 15:51:01,995] Trial 13 finished with value: -6.8133864402771 and parameters: {'penfirstridge': 16.494614228120156, 'pensecondridge': 6.563050348747511}. Best is trial 13 with value: -6.8133864402771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 17.107880481858302   pensecondridge_opt: 6.846455858077931   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 235/1000 [01:02<03:22,  3.77it/s]\n",
      "[I 2025-05-21 15:52:04,450] Trial 14 finished with value: -6.787020683288574 and parameters: {'penfirstridge': 17.107880481858302, 'pensecondridge': 6.846455858077931}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 12.334762972140965   pensecondridge_opt: 1.1300738018195071   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 109/1000 [00:28<03:56,  3.77it/s]\n",
      "[I 2025-05-21 15:52:33,573] Trial 15 finished with value: -7.2775444984436035 and parameters: {'penfirstridge': 12.334762972140965, 'pensecondridge': 1.1300738018195071}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 17.001499326187094   pensecondridge_opt: 21.164587710221475   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 195/1000 [00:50<03:28,  3.86it/s]\n",
      "[I 2025-05-21 15:53:24,309] Trial 16 finished with value: -6.920670986175537 and parameters: {'penfirstridge': 17.001499326187094, 'pensecondridge': 21.164587710221475}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 13.374251278561498   pensecondridge_opt: 9.322095544494328   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [00:58<03:25,  3.79it/s]\n",
      "[I 2025-05-21 15:54:22,774] Trial 17 finished with value: -6.8537139892578125 and parameters: {'penfirstridge': 13.374251278561498, 'pensecondridge': 9.322095544494328}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 29.00952138099087   pensecondridge_opt: 6.390737692462563   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 186/1000 [00:49<03:35,  3.77it/s]\n",
      "[I 2025-05-21 15:55:12,236] Trial 18 finished with value: -6.8293561935424805 and parameters: {'penfirstridge': 29.00952138099087, 'pensecondridge': 6.390737692462563}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Trial has the Hyperparameters: penvalueridge_opt: 0   penfirstridge_opt: 25.298498699752802   pensecondridge_opt: 14.608697139809959   ctm_pensecondridge_opt: 0   lambda_penalty_params_opt: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [00:33<03:49,  3.81it/s]\n",
      "[I 2025-05-21 15:55:46,047] Trial 19 finished with value: -7.090094089508057 and parameters: {'penfirstridge': 25.298498699752802, 'pensecondridge': 14.608697139809959}. Best is trial 14 with value: -6.787020683288574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter_tuning done\n"
     ]
    }
   ],
   "source": [
    "study = model.hyperparameter_tune_penalties( \n",
    "                                train_dataloader=dataloader_train, \n",
    "                                validate_dataloader=dataloader_validate, \n",
    "                                penvalueridge = [0], #[\"sample\"],\n",
    "                                penfirstridge = [\"sample\"],\n",
    "                                pensecondridge = [\"sample\"],\n",
    "                                ctm_pensecondridge = [0], #[\"sample\"],\n",
    "                                lambda_penalty_params = [0], #[\"sample\"], #[0],\n",
    "                                train_covariates=False, \n",
    "                                validate_covariates=False, \n",
    "                                adaptive_lasso_weights_matrix = False,\n",
    "                                learning_rate=1, \n",
    "                                iterations=1000, \n",
    "                                patience=5, \n",
    "                                min_delta=1e-7, \n",
    "                                optimizer='LBFGS', \n",
    "                                lambda_penalty_mode=\"square\", \n",
    "                                objective_type=\"negloglik\", \n",
    "                                seperate_copula_training=False,\n",
    "                                max_batches_per_iter=False,\n",
    "                                tuning_mode=\"optuna\",\n",
    "                                cross_validation_folds=False,\n",
    "                                random_state_KFold=42,\n",
    "                                device=None,\n",
    "                                pretrained_transformation_layer=False,\n",
    "                                n_trials=20,\n",
    "                                temp_folder=\".\", \n",
    "                                study_name=None)\n",
    "    \n",
    "penalty_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penvalueridge\"],\n",
    "                            study.best_params[\"penfirstridge\"],\n",
    "                            study.best_params[\"pensecondridge\"],\n",
    "                            0 #study.best_params[\"ctm_pensecondridge\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "lambda_penalty_params= False #study.best_params[\"lambda_penalty_params\"] #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3294e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, 17.1079,  6.8465,  0.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3c82d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_params=torch.FloatTensor([\n",
    "                            0, #study.best_params[\"penvalueridge\"],\n",
    "                            1, #study.best_params[\"penfirstridge\"],\n",
    "                            5, #study.best_params[\"pensecondridge\"],\n",
    "                            0, #study.best_params[\"ctm_pensecondridge\"]\n",
    "                              ])\n",
    "adaptive_lasso_weights_matrix = False\n",
    "lambda_penalty_params=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f19f1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_model/gtm.py:296: UserWarning: Optimiser for pretrain_tranformation_layer is always LBFGS. If this is an issue change the code.\n",
      "  warnings.warn(\"Optimiser for pretrain_tranformation_layer is always LBFGS. If this is an issue change the code.\")\n",
      "  8%|▊         | 84/1000 [00:06<01:14, 12.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# pretrain the marginal transformations\n",
    "_ = model.pretrain_tranformation_layer(dataloader_train, iterations=1000, max_batches_per_iter=False, penalty_params=penalty_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7429a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 179/1000 [00:51<03:57,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the joint model\n",
    "_ = model.__train__(train_dataloader=dataloader_train, validate_dataloader=dataloader_validate, iterations=1000, optimizer=\"LBFGS\", learning_rate=1,\n",
    "                penalty_params=penalty_params, adaptive_lasso_weights_matrix=adaptive_lasso_weights_matrix, lambda_penalty_params=lambda_penalty_params, \n",
    "                max_batches_per_iter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5eebff",
   "metadata": {},
   "source": [
    "### 4. Compare Fit to Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b910002",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_train_gtm = model.log_likelihood(simulated_data_train)\n",
    "log_likelihood_validate_gtm = model.log_likelihood(simulated_data_validate)\n",
    "log_likelihood_test_gtm = model.log_likelihood(simulated_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ad6c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the Multivariate Normal Distribution as Model\n",
    "mean_mvn_model = simulated_data_train.mean(0)  # 0 to do mean across dim 0 not globally\n",
    "cov_mvn_model = simulated_data_train.T.cov()\n",
    "mvn_model = torch.distributions.MultivariateNormal(loc=mean_mvn_model, covariance_matrix=cov_mvn_model)\n",
    "log_likelihood_train_gaussian = mvn_model.log_prob(simulated_data_train)\n",
    "log_likelihood_validate_gaussian = mvn_model.log_prob(simulated_data_validate)\n",
    "log_likelihood_test_gaussian = mvn_model.log_prob(simulated_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c2f1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD GTM      Train Data:  0.733\n",
      "KLD Gaussian Train Data:  3.3577\n",
      "KLD Copula   Train Data:  0.0093\n",
      "KLD GTM      Test  Data:  1.1632\n",
      "KLD Gaussian Test  Data:  3.4445\n",
      "KLD Copula   Test  Data:  0.0322\n"
     ]
    }
   ],
   "source": [
    "print(\"KLD GTM      Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Train Data: \",np.round(torch.mean(loglik_true_train - log_likelihood_train_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Train Data: \",np.round(torch.mean(loglik_true_train - loglik_true_est_train).item(),4) )\n",
    "\n",
    "print(\"KLD GTM      Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gtm).item(),4) )\n",
    "print(\"KLD Gaussian Test  Data: \",np.round(torch.mean(loglik_true_test - log_likelihood_test_gaussian).item(),4) )\n",
    "print(\"KLD Copula   Test  Data: \",np.round(torch.mean(loglik_true_test - loglik_true_est_test).item(),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd1fb0",
   "metadata": {},
   "source": [
    "KLD GTM      Train Data:  0.7392\n",
    "KLD Gaussian Train Data:  3.2368\n",
    "KLD Copula   Train Data:  0.0207\n",
    "KLD GTM      Test  Data:  1.169\n",
    "KLD Gaussian Test  Data:  3.3249\n",
    "KLD Copula   Test  Data:  0.0394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "941037db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, \"10D_rvine_model_state_dict.pth\")\n",
    "#model = torch.load(\"./10D_rvine_model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee4e5d",
   "metadata": {},
   "source": [
    "### 5. Evaluate and Plot GTM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6690f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.approximate_transformation_inverse()\n",
    "synthetic_samples = model.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22df00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_densities(synthetic_samples, x_lim=[-4,4], y_lim=[-4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6637a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_samples = model.sample(2000)\n",
    "conditional_correlation_matrix_train = model.compute_correlation_matrix(synthetic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a30faa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_metric_scatter(data=synthetic_samples,metric=conditional_correlation_matrix_train,metric_type=\"precision_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b2203",
   "metadata": {},
   "source": [
    "did it identify the cis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d82487b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 with var_row_num 1 and var_col_num 0.\n",
      "Processing row 3 with var_row_num 3 and var_col_num 0.\n",
      "Processing row 6 with var_row_num 4 and var_col_num 0.\n",
      "Processing row 9 with var_row_num 4 and var_col_num 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n",
      "/Users/matthiasherp/Desktop/phd_github_repositories/gtm/gtm/gtm_splines/bspline_prediction_vectorized.py:404: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  t=knots.T,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 4 with var_row_num 3 and var_col_num 1.\n",
      "Processing row 10 with var_row_num 5 and var_col_num 0.\n",
      "Processing row 1 with var_row_num 2 and var_col_num 0.\n",
      "Processing row 7 with var_row_num 4 and var_col_num 1.\n",
      "Processing row 5 with var_row_num 3 and var_col_num 2.\n",
      "Processing row 11 with var_row_num 5 and var_col_num 1.\n",
      "Processing row 2 with var_row_num 2 and var_col_num 1.\n",
      "Processing row 8 with var_row_num 4 and var_col_num 2.\n",
      "Processing row 12 with var_row_num 5 and var_col_num 2.\n",
      "Processing row 15 with var_row_num 6 and var_col_num 0.\n",
      "Processing row 18 with var_row_num 6 and var_col_num 3.\n",
      "Processing row 21 with var_row_num 7 and var_col_num 0.\n",
      "Processing row 13 with var_row_num 5 and var_col_num 3.\n",
      "Processing row 16 with var_row_num 6 and var_col_num 1.\n",
      "Processing row 19 with var_row_num 6 and var_col_num 4.\n",
      "Processing row 22 with var_row_num 7 and var_col_num 1.\n",
      "Processing row 14 with var_row_num 5 and var_col_num 4.\n",
      "Processing row 17 with var_row_num 6 and var_col_num 2.\n",
      "Processing row 20 with var_row_num 6 and var_col_num 5.\n",
      "Processing row 23 with var_row_num 7 and var_col_num 2.\n",
      "Processing row 24 with var_row_num 7 and var_col_num 3.\n",
      "Processing row 27 with var_row_num 7 and var_col_num 6.\n",
      "Processing row 30 with var_row_num 8 and var_col_num 2.\n",
      "Processing row 33 with var_row_num 8 and var_col_num 5.\n",
      "Processing row 25 with var_row_num 7 and var_col_num 4.\n",
      "Processing row 28 with var_row_num 8 and var_col_num 0.\n",
      "Processing row 31 with var_row_num 8 and var_col_num 3.\n",
      "Processing row 34 with var_row_num 8 and var_col_num 6.\n",
      "Processing row 26 with var_row_num 7 and var_col_num 5.\n",
      "Processing row 29 with var_row_num 8 and var_col_num 1.\n",
      "Processing row 32 with var_row_num 8 and var_col_num 4.\n",
      "Processing row 35 with var_row_num 8 and var_col_num 7.\n",
      "Processing row 36 with var_row_num 9 and var_col_num 0.\n",
      "Processing row 39 with var_row_num 9 and var_col_num 3.\n",
      "Processing row 42 with var_row_num 9 and var_col_num 6.\n",
      "Processing row 37 with var_row_num 9 and var_col_num 1.\n",
      "Processing row 40 with var_row_num 9 and var_col_num 4.\n",
      "Processing row 43 with var_row_num 9 and var_col_num 7.\n",
      "Processing row 38 with var_row_num 9 and var_col_num 2.\n",
      "Processing row 41 with var_row_num 9 and var_col_num 5.\n",
      "Processing row 44 with var_row_num 9 and var_col_num 8.\n",
      "Time taken: 198.34175777435303\n",
      "All rows processed.\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_table2 = model.compute_conditional_independence_table(\n",
    "                                        y = None,\n",
    "                                        x = False,\n",
    "                                        evaluation_data_type = \"samples_from_model\",\n",
    "                                        num_processes=4,\n",
    "                                        sample_size = 5000,\n",
    "                                        num_points_quad=10,\n",
    "                                        optimized=True,\n",
    "                                        copula_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2945eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130672</td>\n",
       "      <td>0.030188</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.048348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298501</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.095325</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.097532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.066311</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.070178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128217</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.051077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060777</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.042285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112575</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.058142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.034702</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.043271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121463</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.065356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307460</td>\n",
       "      <td>0.112218</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.069585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.814102</td>\n",
       "      <td>3.350703</td>\n",
       "      <td>0.794375</td>\n",
       "      <td>0.633263</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.449599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265968</td>\n",
       "      <td>0.118856</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.072198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870805</td>\n",
       "      <td>0.804824</td>\n",
       "      <td>0.299808</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.163981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667903</td>\n",
       "      <td>0.632914</td>\n",
       "      <td>0.133204</td>\n",
       "      <td>0.023673</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.114581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.331463</td>\n",
       "      <td>1.821984</td>\n",
       "      <td>0.405705</td>\n",
       "      <td>0.170207</td>\n",
       "      <td>0.133357</td>\n",
       "      <td>0.260150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.226012</td>\n",
       "      <td>5.043569</td>\n",
       "      <td>0.579539</td>\n",
       "      <td>0.340130</td>\n",
       "      <td>0.231575</td>\n",
       "      <td>0.357167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634740</td>\n",
       "      <td>0.500329</td>\n",
       "      <td>0.213002</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.146056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177380</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.080594</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.061143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272326</td>\n",
       "      <td>0.132726</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.102082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133664</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.042346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.047291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.455548</td>\n",
       "      <td>2.347937</td>\n",
       "      <td>0.326312</td>\n",
       "      <td>0.110318</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>0.258485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.592268</td>\n",
       "      <td>2.946120</td>\n",
       "      <td>0.424231</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.114535</td>\n",
       "      <td>0.252404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929049</td>\n",
       "      <td>0.905065</td>\n",
       "      <td>0.327086</td>\n",
       "      <td>0.110487</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>0.177771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.990554</td>\n",
       "      <td>4.338652</td>\n",
       "      <td>0.418610</td>\n",
       "      <td>0.181113</td>\n",
       "      <td>0.121703</td>\n",
       "      <td>0.259857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.182125</td>\n",
       "      <td>0.048985</td>\n",
       "      <td>0.056376</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.058222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351352</td>\n",
       "      <td>0.157713</td>\n",
       "      <td>0.093795</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.104419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.378639</td>\n",
       "      <td>6.571157</td>\n",
       "      <td>0.416982</td>\n",
       "      <td>0.189040</td>\n",
       "      <td>0.159221</td>\n",
       "      <td>0.280657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.046760</td>\n",
       "      <td>4.622615</td>\n",
       "      <td>0.474131</td>\n",
       "      <td>0.244841</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.285882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.733715</td>\n",
       "      <td>8.125902</td>\n",
       "      <td>0.694233</td>\n",
       "      <td>0.484976</td>\n",
       "      <td>0.274952</td>\n",
       "      <td>0.431728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.339578</td>\n",
       "      <td>1.884171</td>\n",
       "      <td>0.450458</td>\n",
       "      <td>0.212141</td>\n",
       "      <td>0.099663</td>\n",
       "      <td>0.253474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.454144</td>\n",
       "      <td>7.617582</td>\n",
       "      <td>0.450815</td>\n",
       "      <td>0.223649</td>\n",
       "      <td>0.171828</td>\n",
       "      <td>0.308868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.417945</td>\n",
       "      <td>0.237958</td>\n",
       "      <td>0.116779</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.081983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.243525</td>\n",
       "      <td>0.092967</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.073792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.762545</td>\n",
       "      <td>0.879161</td>\n",
       "      <td>0.130099</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>0.175546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.703585</td>\n",
       "      <td>3.150872</td>\n",
       "      <td>0.375385</td>\n",
       "      <td>0.149876</td>\n",
       "      <td>0.153716</td>\n",
       "      <td>0.296173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2.493917</td>\n",
       "      <td>6.742613</td>\n",
       "      <td>0.441144</td>\n",
       "      <td>0.213793</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.305461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256071</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.114557</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.066165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106324</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.062101</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.054536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148958</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>0.052395</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.075511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.094525</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.049491</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.042165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.039528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.042177</td>\n",
       "      <td>0.051610</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.069375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.749803</td>\n",
       "      <td>3.249647</td>\n",
       "      <td>0.663920</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.224758</td>\n",
       "      <td>0.393844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1.350220</td>\n",
       "      <td>1.914697</td>\n",
       "      <td>0.410921</td>\n",
       "      <td>0.174237</td>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.262809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.263703</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.084429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  precision_abs_mean  precision_square_mean  \\\n",
       "10        1        0            0.130672               0.030188   \n",
       "20        2        0            0.298501               0.136463   \n",
       "21        2        1            0.156284               0.038252   \n",
       "30        3        0            0.128217               0.024678   \n",
       "31        3        1            0.060777               0.005742   \n",
       "32        3        2            0.112575               0.021200   \n",
       "40        4        0            0.085129               0.010212   \n",
       "41        4        1            0.121463               0.021952   \n",
       "42        4        2            0.307460               0.112218   \n",
       "43        4        3            1.814102               3.350703   \n",
       "50        5        0            0.265968               0.118856   \n",
       "51        5        1            0.870805               0.804824   \n",
       "52        5        2            0.667903               0.632914   \n",
       "53        5        3            1.331463               1.821984   \n",
       "54        5        4            2.226012               5.043569   \n",
       "60        6        0            0.634740               0.500329   \n",
       "61        6        1            0.177380               0.043597   \n",
       "62        6        2            0.272326               0.132726   \n",
       "63        6        3            0.133664               0.025127   \n",
       "64        6        4            0.140205               0.025692   \n",
       "65        6        5            1.455548               2.347937   \n",
       "70        7        0            1.592268               2.946120   \n",
       "71        7        1            0.929049               0.905065   \n",
       "72        7        2            1.990554               4.338652   \n",
       "73        7        3            0.182125               0.048985   \n",
       "74        7        4            0.351352               0.157713   \n",
       "75        7        5            2.378639               6.571157   \n",
       "76        7        6            2.046760               4.622615   \n",
       "80        8        0            2.733715               8.125902   \n",
       "81        8        1            1.339578               1.884171   \n",
       "82        8        2            2.454144               7.617582   \n",
       "83        8        3            0.417945               0.237958   \n",
       "84        8        4            0.243525               0.092967   \n",
       "85        8        5            0.762545               0.879161   \n",
       "86        8        6            1.703585               3.150872   \n",
       "87        8        7            2.493917               6.742613   \n",
       "90        9        0            0.256071               0.093085   \n",
       "91        9        1            0.106324               0.016455   \n",
       "92        9        2            0.148958               0.039126   \n",
       "93        9        3            0.094525               0.010686   \n",
       "94        9        4            0.061587               0.006029   \n",
       "95        9        5            0.169441               0.042177   \n",
       "96        9        6            1.749803               3.249647   \n",
       "97        9        7            1.350220               1.914697   \n",
       "98        9        8            0.263703               0.101935   \n",
       "\n",
       "    cond_correlation_abs_mean  cond_correlation_square_mean       kld  \\\n",
       "10                   0.065359                      0.006809  0.003458   \n",
       "20                   0.095325                      0.013157  0.016557   \n",
       "21                   0.066311                      0.007179  0.010960   \n",
       "30                   0.059504                      0.005329  0.004229   \n",
       "31                   0.036282                      0.002079  0.002563   \n",
       "32                   0.039262                      0.002392  0.009081   \n",
       "40                   0.034702                      0.001738  0.003806   \n",
       "41                   0.062389                      0.005912  0.007381   \n",
       "42                   0.096491                      0.011204  0.008307   \n",
       "43                   0.794375                      0.633263  0.387458   \n",
       "50                   0.069849                      0.007567  0.008582   \n",
       "51                   0.299808                      0.092732  0.039535   \n",
       "52                   0.133204                      0.023673  0.021040   \n",
       "53                   0.405705                      0.170207  0.133357   \n",
       "54                   0.579539                      0.340130  0.231575   \n",
       "60                   0.213002                      0.049767  0.038061   \n",
       "61                   0.080594                      0.009255  0.005145   \n",
       "62                   0.072125                      0.008302  0.017230   \n",
       "63                   0.051253                      0.003623  0.002191   \n",
       "64                   0.047487                      0.002999  0.003516   \n",
       "65                   0.326312                      0.110318  0.116387   \n",
       "70                   0.424231                      0.190895  0.114535   \n",
       "71                   0.327086                      0.110487  0.042398   \n",
       "72                   0.418610                      0.181113  0.121703   \n",
       "73                   0.056376                      0.004755  0.006350   \n",
       "74                   0.093795                      0.011432  0.019406   \n",
       "75                   0.416982                      0.189040  0.159221   \n",
       "76                   0.474131                      0.244841  0.150999   \n",
       "80                   0.694233                      0.484976  0.274952   \n",
       "81                   0.450458                      0.212141  0.099663   \n",
       "82                   0.450815                      0.223649  0.171828   \n",
       "83                   0.116779                      0.017567  0.011421   \n",
       "84                   0.059315                      0.005291  0.007123   \n",
       "85                   0.130099                      0.026249  0.078807   \n",
       "86                   0.375385                      0.149876  0.153716   \n",
       "87                   0.441144                      0.213793  0.158864   \n",
       "90                   0.114557                      0.017474  0.004728   \n",
       "91                   0.062101                      0.005512  0.007417   \n",
       "92                   0.052395                      0.004555  0.011910   \n",
       "93                   0.049491                      0.003040  0.004473   \n",
       "94                   0.028389                      0.001390  0.003793   \n",
       "95                   0.051610                      0.003867  0.009920   \n",
       "96                   0.663920                      0.444391  0.224758   \n",
       "97                   0.410921                      0.174237  0.120154   \n",
       "98                   0.080126                      0.009919  0.011623   \n",
       "\n",
       "         iae  \n",
       "10  0.048348  \n",
       "20  0.097532  \n",
       "21  0.070178  \n",
       "30  0.051077  \n",
       "31  0.042285  \n",
       "32  0.058142  \n",
       "40  0.043271  \n",
       "41  0.065356  \n",
       "42  0.069585  \n",
       "43  0.449599  \n",
       "50  0.072198  \n",
       "51  0.163981  \n",
       "52  0.114581  \n",
       "53  0.260150  \n",
       "54  0.357167  \n",
       "60  0.146056  \n",
       "61  0.061143  \n",
       "62  0.102082  \n",
       "63  0.042346  \n",
       "64  0.047291  \n",
       "65  0.258485  \n",
       "70  0.252404  \n",
       "71  0.177771  \n",
       "72  0.259857  \n",
       "73  0.058222  \n",
       "74  0.104419  \n",
       "75  0.280657  \n",
       "76  0.285882  \n",
       "80  0.431728  \n",
       "81  0.253474  \n",
       "82  0.308868  \n",
       "83  0.081983  \n",
       "84  0.073792  \n",
       "85  0.175546  \n",
       "86  0.296173  \n",
       "87  0.305461  \n",
       "90  0.066165  \n",
       "91  0.054536  \n",
       "92  0.075511  \n",
       "93  0.042165  \n",
       "94  0.039528  \n",
       "95  0.069375  \n",
       "96  0.393844  \n",
       "97  0.262809  \n",
       "98  0.084429  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_independence_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4f8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 with var_row_num 1 and var_col_num 0.\n",
      "Processing row 1 with var_row_num 2 and var_col_num 0.\n",
      "Processing row 2 with var_row_num 2 and var_col_num 1.\n",
      "Processing row 3 with var_row_num 3 and var_col_num 0.\n",
      "Processing row 4 with var_row_num 3 and var_col_num 1.\n",
      "Processing row 5 with var_row_num 3 and var_col_num 2.\n",
      "Processing row 6 with var_row_num 4 and var_col_num 0.\n",
      "Processing row 7 with var_row_num 4 and var_col_num 1.\n",
      "Processing row 8 with var_row_num 4 and var_col_num 2.\n",
      "Processing row 9 with var_row_num 4 and var_col_num 3.\n",
      "Processing row 10 with var_row_num 5 and var_col_num 0.\n",
      "Processing row 11 with var_row_num 5 and var_col_num 1.\n",
      "Processing row 12 with var_row_num 5 and var_col_num 2.\n",
      "Processing row 13 with var_row_num 5 and var_col_num 3.\n",
      "Processing row 14 with var_row_num 5 and var_col_num 4.\n",
      "Processing row 15 with var_row_num 6 and var_col_num 0.\n",
      "Processing row 16 with var_row_num 6 and var_col_num 1.\n",
      "Processing row 17 with var_row_num 6 and var_col_num 2.\n",
      "Processing row 18 with var_row_num 6 and var_col_num 3.\n",
      "Processing row 19 with var_row_num 6 and var_col_num 4.\n",
      "Processing row 20 with var_row_num 6 and var_col_num 5.\n",
      "Processing row 21 with var_row_num 7 and var_col_num 0.\n",
      "Processing row 22 with var_row_num 7 and var_col_num 1.\n",
      "Processing row 23 with var_row_num 7 and var_col_num 2.\n",
      "Processing row 24 with var_row_num 7 and var_col_num 3.\n",
      "Processing row 25 with var_row_num 7 and var_col_num 4.\n",
      "Processing row 26 with var_row_num 7 and var_col_num 5.\n",
      "Processing row 27 with var_row_num 7 and var_col_num 6.\n",
      "Processing row 28 with var_row_num 8 and var_col_num 0.\n",
      "Processing row 29 with var_row_num 8 and var_col_num 1.\n",
      "Processing row 30 with var_row_num 8 and var_col_num 2.\n",
      "Processing row 31 with var_row_num 8 and var_col_num 3.\n",
      "Processing row 32 with var_row_num 8 and var_col_num 4.\n",
      "Processing row 33 with var_row_num 8 and var_col_num 5.\n",
      "Processing row 34 with var_row_num 8 and var_col_num 6.\n",
      "Processing row 35 with var_row_num 8 and var_col_num 7.\n",
      "Processing row 36 with var_row_num 9 and var_col_num 0.\n",
      "Processing row 37 with var_row_num 9 and var_col_num 1.\n",
      "Processing row 38 with var_row_num 9 and var_col_num 2.\n",
      "Processing row 39 with var_row_num 9 and var_col_num 3.\n",
      "Processing row 40 with var_row_num 9 and var_col_num 4.\n",
      "Processing row 41 with var_row_num 9 and var_col_num 5.\n",
      "Processing row 42 with var_row_num 9 and var_col_num 6.\n",
      "Processing row 43 with var_row_num 9 and var_col_num 7.\n",
      "Processing row 44 with var_row_num 9 and var_col_num 8.\n",
      "Time taken: 108.2450499534607\n",
      "All rows processed.\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_table = model.compute_conditional_independence_table(\n",
    "                                        y = simulated_data_train, #None,\n",
    "                                        x = False,\n",
    "                                        evaluation_data_type = \"data\", #samples_from_model\",\n",
    "                                        num_processes=1,\n",
    "                                        sample_size = 5000,\n",
    "                                        num_points_quad=10,\n",
    "                                        optimized=True,\n",
    "                                        copula_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cd94c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130883</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.065635</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.045704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.126183</td>\n",
       "      <td>0.093822</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.090118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154703</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.066089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121454</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.056185</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.046658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059098</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.035526</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.042299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109407</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.038088</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>0.055389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083891</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.034360</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.041348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121690</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.064561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300572</td>\n",
       "      <td>0.107579</td>\n",
       "      <td>0.094119</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.063105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.803154</td>\n",
       "      <td>3.320621</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.631256</td>\n",
       "      <td>0.374569</td>\n",
       "      <td>0.456228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271312</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.066497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871165</td>\n",
       "      <td>0.809126</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>0.091761</td>\n",
       "      <td>0.042722</td>\n",
       "      <td>0.143298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699772</td>\n",
       "      <td>0.674762</td>\n",
       "      <td>0.138871</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>0.108926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.324696</td>\n",
       "      <td>1.807055</td>\n",
       "      <td>0.401211</td>\n",
       "      <td>0.166524</td>\n",
       "      <td>0.125075</td>\n",
       "      <td>0.234993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.212220</td>\n",
       "      <td>4.992951</td>\n",
       "      <td>0.573882</td>\n",
       "      <td>0.333818</td>\n",
       "      <td>0.235327</td>\n",
       "      <td>0.329620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636202</td>\n",
       "      <td>0.494142</td>\n",
       "      <td>0.213475</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>0.039412</td>\n",
       "      <td>0.135328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179016</td>\n",
       "      <td>0.043520</td>\n",
       "      <td>0.081476</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.060652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.270995</td>\n",
       "      <td>0.134857</td>\n",
       "      <td>0.071316</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.090254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.135066</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.051679</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.040063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.135575</td>\n",
       "      <td>0.024373</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.043931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.493156</td>\n",
       "      <td>2.462621</td>\n",
       "      <td>0.331029</td>\n",
       "      <td>0.113258</td>\n",
       "      <td>0.122213</td>\n",
       "      <td>0.237978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.585137</td>\n",
       "      <td>2.909626</td>\n",
       "      <td>0.420796</td>\n",
       "      <td>0.187807</td>\n",
       "      <td>0.111669</td>\n",
       "      <td>0.233961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929033</td>\n",
       "      <td>0.905675</td>\n",
       "      <td>0.326949</td>\n",
       "      <td>0.110551</td>\n",
       "      <td>0.053986</td>\n",
       "      <td>0.153329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.012151</td>\n",
       "      <td>4.428928</td>\n",
       "      <td>0.420957</td>\n",
       "      <td>0.182688</td>\n",
       "      <td>0.138765</td>\n",
       "      <td>0.232847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.177121</td>\n",
       "      <td>0.046451</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.054697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353667</td>\n",
       "      <td>0.161573</td>\n",
       "      <td>0.094863</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.449362</td>\n",
       "      <td>6.926278</td>\n",
       "      <td>0.426353</td>\n",
       "      <td>0.197246</td>\n",
       "      <td>0.196883</td>\n",
       "      <td>0.253898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.027940</td>\n",
       "      <td>4.590477</td>\n",
       "      <td>0.465191</td>\n",
       "      <td>0.237737</td>\n",
       "      <td>0.158038</td>\n",
       "      <td>0.258003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.733966</td>\n",
       "      <td>8.125795</td>\n",
       "      <td>0.692983</td>\n",
       "      <td>0.483415</td>\n",
       "      <td>0.321877</td>\n",
       "      <td>0.396985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.330511</td>\n",
       "      <td>1.860675</td>\n",
       "      <td>0.448233</td>\n",
       "      <td>0.210215</td>\n",
       "      <td>0.103111</td>\n",
       "      <td>0.242604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.460646</td>\n",
       "      <td>7.689456</td>\n",
       "      <td>0.451004</td>\n",
       "      <td>0.223868</td>\n",
       "      <td>0.207589</td>\n",
       "      <td>0.278345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.408852</td>\n",
       "      <td>0.228785</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.075030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250529</td>\n",
       "      <td>0.098347</td>\n",
       "      <td>0.061468</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.069816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.770557</td>\n",
       "      <td>0.899149</td>\n",
       "      <td>0.131213</td>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.111890</td>\n",
       "      <td>0.166114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.723895</td>\n",
       "      <td>3.226063</td>\n",
       "      <td>0.378689</td>\n",
       "      <td>0.152789</td>\n",
       "      <td>0.180071</td>\n",
       "      <td>0.264361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2.467786</td>\n",
       "      <td>6.626958</td>\n",
       "      <td>0.436246</td>\n",
       "      <td>0.209831</td>\n",
       "      <td>0.204958</td>\n",
       "      <td>0.276520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258883</td>\n",
       "      <td>0.097420</td>\n",
       "      <td>0.114550</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.059315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105594</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.047186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140740</td>\n",
       "      <td>0.034376</td>\n",
       "      <td>0.049715</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.064309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.048749</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.036908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.035772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.163418</td>\n",
       "      <td>0.040114</td>\n",
       "      <td>0.049601</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.059498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.765759</td>\n",
       "      <td>3.321558</td>\n",
       "      <td>0.664278</td>\n",
       "      <td>0.445570</td>\n",
       "      <td>0.245383</td>\n",
       "      <td>0.342817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1.353139</td>\n",
       "      <td>1.935446</td>\n",
       "      <td>0.408550</td>\n",
       "      <td>0.172865</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.228964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273999</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.073158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  precision_abs_mean  precision_square_mean  \\\n",
       "10        1        0            0.130883               0.029357   \n",
       "20        2        0            0.289226               0.126183   \n",
       "21        2        1            0.154703               0.037360   \n",
       "30        3        0            0.121454               0.022630   \n",
       "31        3        1            0.059098               0.005539   \n",
       "32        3        2            0.109407               0.020070   \n",
       "40        4        0            0.083891               0.010055   \n",
       "41        4        1            0.121690               0.022152   \n",
       "42        4        2            0.300572               0.107579   \n",
       "43        4        3            1.803154               3.320621   \n",
       "50        5        0            0.271312               0.123800   \n",
       "51        5        1            0.871165               0.809126   \n",
       "52        5        2            0.699772               0.674762   \n",
       "53        5        3            1.324696               1.807055   \n",
       "54        5        4            2.212220               4.992951   \n",
       "60        6        0            0.636202               0.494142   \n",
       "61        6        1            0.179016               0.043520   \n",
       "62        6        2            0.270995               0.134857   \n",
       "63        6        3            0.135066               0.025495   \n",
       "64        6        4            0.135575               0.024373   \n",
       "65        6        5            1.493156               2.462621   \n",
       "70        7        0            1.585137               2.909626   \n",
       "71        7        1            0.929033               0.905675   \n",
       "72        7        2            2.012151               4.428928   \n",
       "73        7        3            0.177121               0.046451   \n",
       "74        7        4            0.353667               0.161573   \n",
       "75        7        5            2.449362               6.926278   \n",
       "76        7        6            2.027940               4.590477   \n",
       "80        8        0            2.733966               8.125795   \n",
       "81        8        1            1.330511               1.860675   \n",
       "82        8        2            2.460646               7.689456   \n",
       "83        8        3            0.408852               0.228785   \n",
       "84        8        4            0.250529               0.098347   \n",
       "85        8        5            0.770557               0.899149   \n",
       "86        8        6            1.723895               3.226063   \n",
       "87        8        7            2.467786               6.626958   \n",
       "90        9        0            0.258883               0.097420   \n",
       "91        9        1            0.105594               0.015928   \n",
       "92        9        2            0.140740               0.034376   \n",
       "93        9        3            0.093359               0.010501   \n",
       "94        9        4            0.060640               0.006035   \n",
       "95        9        5            0.163418               0.040114   \n",
       "96        9        6            1.765759               3.321558   \n",
       "97        9        7            1.353139               1.935446   \n",
       "98        9        8            0.273999               0.105979   \n",
       "\n",
       "    cond_correlation_abs_mean  cond_correlation_square_mean       kld  \\\n",
       "10                   0.065635                      0.006726  0.004159   \n",
       "20                   0.093822                      0.012843  0.004649   \n",
       "21                   0.065037                      0.006779  0.008797   \n",
       "30                   0.056185                      0.004868  0.006280   \n",
       "31                   0.035526                      0.002047  0.002151   \n",
       "32                   0.038088                      0.002253  0.007348   \n",
       "40                   0.034360                      0.001742  0.002974   \n",
       "41                   0.063110                      0.006121  0.006403   \n",
       "42                   0.094119                      0.010641  0.004856   \n",
       "43                   0.792900                      0.631256  0.374569   \n",
       "50                   0.070350                      0.007681  0.007179   \n",
       "51                   0.297910                      0.091761  0.042722   \n",
       "52                   0.138871                      0.024967  0.026382   \n",
       "53                   0.401211                      0.166524  0.125075   \n",
       "54                   0.573882                      0.333818  0.235327   \n",
       "60                   0.213475                      0.049929  0.039412   \n",
       "61                   0.081476                      0.009262  0.007507   \n",
       "62                   0.071316                      0.008363  0.011308   \n",
       "63                   0.051679                      0.003658  0.003782   \n",
       "64                   0.046076                      0.002877  0.004684   \n",
       "65                   0.331029                      0.113258  0.122213   \n",
       "70                   0.420796                      0.187807  0.111669   \n",
       "71                   0.326949                      0.110551  0.053986   \n",
       "72                   0.420957                      0.182688  0.138765   \n",
       "73                   0.054651                      0.004462  0.003411   \n",
       "74                   0.094863                      0.011867  0.020519   \n",
       "75                   0.426353                      0.197246  0.196883   \n",
       "76                   0.465191                      0.237737  0.158038   \n",
       "80                   0.692983                      0.483415  0.321877   \n",
       "81                   0.448233                      0.210215  0.103111   \n",
       "82                   0.451004                      0.223868  0.207589   \n",
       "83                   0.114285                      0.016851  0.009999   \n",
       "84                   0.061468                      0.005708  0.007918   \n",
       "85                   0.131213                      0.026925  0.111890   \n",
       "86                   0.378689                      0.152789  0.180071   \n",
       "87                   0.436246                      0.209831  0.204958   \n",
       "90                   0.114550                      0.017829  0.003969   \n",
       "91                   0.061833                      0.005404  0.005568   \n",
       "92                   0.049715                      0.004120  0.006579   \n",
       "93                   0.048749                      0.002967  0.002674   \n",
       "94                   0.027925                      0.001392  0.003404   \n",
       "95                   0.049601                      0.003752  0.005605   \n",
       "96                   0.664278                      0.445570  0.245383   \n",
       "97                   0.408550                      0.172865  0.139400   \n",
       "98                   0.083090                      0.010302  0.017018   \n",
       "\n",
       "         iae  \n",
       "10  0.045704  \n",
       "20  0.090118  \n",
       "21  0.066089  \n",
       "30  0.046658  \n",
       "31  0.042299  \n",
       "32  0.055389  \n",
       "40  0.041348  \n",
       "41  0.064561  \n",
       "42  0.063105  \n",
       "43  0.456228  \n",
       "50  0.066497  \n",
       "51  0.143298  \n",
       "52  0.108926  \n",
       "53  0.234993  \n",
       "54  0.329620  \n",
       "60  0.135328  \n",
       "61  0.060652  \n",
       "62  0.090254  \n",
       "63  0.040063  \n",
       "64  0.043931  \n",
       "65  0.237978  \n",
       "70  0.233961  \n",
       "71  0.153329  \n",
       "72  0.232847  \n",
       "73  0.054697  \n",
       "74  0.091981  \n",
       "75  0.253898  \n",
       "76  0.258003  \n",
       "80  0.396985  \n",
       "81  0.242604  \n",
       "82  0.278345  \n",
       "83  0.075030  \n",
       "84  0.069816  \n",
       "85  0.166114  \n",
       "86  0.264361  \n",
       "87  0.276520  \n",
       "90  0.059315  \n",
       "91  0.047186  \n",
       "92  0.064309  \n",
       "93  0.036908  \n",
       "94  0.035772  \n",
       "95  0.059498  \n",
       "96  0.342817  \n",
       "97  0.228964  \n",
       "98  0.073158  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_independence_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "226f5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtm.gtm_plots_analysis.compute_precision_matrix_summary_statistics import compute_precision_matrix_summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "566f17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_samples = model.sample(10000)\n",
    "cond_corr_matrix = model.compute_correlation_matrix(synthetic_samples)\n",
    "#cond_corr_matrix = model.compute_precision_matrix(simulated_data_train)\n",
    "cond_corr_matrix_summary_statistics = compute_precision_matrix_summary_statistics(cond_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf43009",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_independence_table = cond_corr_matrix_summary_statistics[[\"var_row\",\t\"var_col\",\t\"abs_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca8f57e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/800703291.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_true_structure_sub[\"var_row\"] = df_true_structure_sub[\"var_row\"] - 1\n",
      "/var/folders/57/_f_fv4s97k300zslnyj86dxc0000gn/T/ipykernel_84295/800703291.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_true_structure_sub[\"var_col\"] = df_true_structure_sub[\"var_col\"] - 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  dependence\n",
       "0         8        2           1\n",
       "1         9        6           1\n",
       "2         4        3           1\n",
       "3         8        0           1\n",
       "4         8        1           1\n",
       "5         7        6           1\n",
       "6         5        4           1\n",
       "7         8        7           1\n",
       "8         8        5           1\n",
       "9         7        2           1\n",
       "10        9        7           1\n",
       "11        5        3           1\n",
       "12        7        0           1\n",
       "13        5        1           1\n",
       "14        8        6           1\n",
       "15        8        4           1\n",
       "16        7        5           1\n",
       "17        5        2           0\n",
       "18        9        8           0\n",
       "19        8        3           0\n",
       "20        6        0           0\n",
       "21        7        1           0\n",
       "22        6        5           0\n",
       "23        7        4           0\n",
       "24        4        2           0\n",
       "25        9        5           0\n",
       "26        7        3           0\n",
       "27        5        0           0\n",
       "28        4        1           0\n",
       "29        6        4           0\n",
       "30        6        2           0\n",
       "31        9        4           0\n",
       "32        6        3           0\n",
       "33        4        0           0\n",
       "34        6        1           0\n",
       "35        2        0           0\n",
       "36        9        1           0\n",
       "37        3        1           0\n",
       "38        1        0           0\n",
       "39        2        1           0\n",
       "40        9        0           0\n",
       "41        3        0           0\n",
       "42        3        2           0\n",
       "43        9        3           0\n",
       "44        9        2           0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_structure_sub = df_true_structure[[\"var_row\", \"var_col\", \"dependence\"]]\n",
    "df_true_structure_sub[\"var_row\"] = df_true_structure_sub[\"var_row\"] - 1\n",
    "df_true_structure_sub[\"var_col\"] = df_true_structure_sub[\"var_col\"] - 1\n",
    "df_true_structure_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc9f66",
   "metadata": {},
   "source": [
    "I had an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b773375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(\n",
    "    conditional_independence_table2,\n",
    "    df_true_structure_sub,\n",
    "    on=[\"var_row\", \"var_col\"] # or \"inner\", \"left\", depending on your needs\n",
    ")\n",
    "merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e083eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.814102</td>\n",
       "      <td>3.350703</td>\n",
       "      <td>0.794375</td>\n",
       "      <td>0.633263</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.449599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.733715</td>\n",
       "      <td>8.125902</td>\n",
       "      <td>0.694233</td>\n",
       "      <td>0.484976</td>\n",
       "      <td>0.274952</td>\n",
       "      <td>0.431728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.749803</td>\n",
       "      <td>3.249647</td>\n",
       "      <td>0.663920</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.224758</td>\n",
       "      <td>0.393844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.226012</td>\n",
       "      <td>5.043569</td>\n",
       "      <td>0.579539</td>\n",
       "      <td>0.340130</td>\n",
       "      <td>0.231575</td>\n",
       "      <td>0.357167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.454144</td>\n",
       "      <td>7.617582</td>\n",
       "      <td>0.450815</td>\n",
       "      <td>0.223649</td>\n",
       "      <td>0.171828</td>\n",
       "      <td>0.308868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2.493917</td>\n",
       "      <td>6.742613</td>\n",
       "      <td>0.441144</td>\n",
       "      <td>0.213793</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.305461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.703585</td>\n",
       "      <td>3.150872</td>\n",
       "      <td>0.375385</td>\n",
       "      <td>0.149876</td>\n",
       "      <td>0.153716</td>\n",
       "      <td>0.296173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.046760</td>\n",
       "      <td>4.622615</td>\n",
       "      <td>0.474131</td>\n",
       "      <td>0.244841</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.285882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.378639</td>\n",
       "      <td>6.571157</td>\n",
       "      <td>0.416982</td>\n",
       "      <td>0.189040</td>\n",
       "      <td>0.159221</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1.350220</td>\n",
       "      <td>1.914697</td>\n",
       "      <td>0.410921</td>\n",
       "      <td>0.174237</td>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.262809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.331463</td>\n",
       "      <td>1.821984</td>\n",
       "      <td>0.405705</td>\n",
       "      <td>0.170207</td>\n",
       "      <td>0.133357</td>\n",
       "      <td>0.260150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.990554</td>\n",
       "      <td>4.338652</td>\n",
       "      <td>0.418610</td>\n",
       "      <td>0.181113</td>\n",
       "      <td>0.121703</td>\n",
       "      <td>0.259857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.455548</td>\n",
       "      <td>2.347937</td>\n",
       "      <td>0.326312</td>\n",
       "      <td>0.110318</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>0.258485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.339578</td>\n",
       "      <td>1.884171</td>\n",
       "      <td>0.450458</td>\n",
       "      <td>0.212141</td>\n",
       "      <td>0.099663</td>\n",
       "      <td>0.253474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.592268</td>\n",
       "      <td>2.946120</td>\n",
       "      <td>0.424231</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.114535</td>\n",
       "      <td>0.252404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929049</td>\n",
       "      <td>0.905065</td>\n",
       "      <td>0.327086</td>\n",
       "      <td>0.110487</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>0.177771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.762545</td>\n",
       "      <td>0.879161</td>\n",
       "      <td>0.130099</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>0.175546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870805</td>\n",
       "      <td>0.804824</td>\n",
       "      <td>0.299808</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.163981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634740</td>\n",
       "      <td>0.500329</td>\n",
       "      <td>0.213002</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.146056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667903</td>\n",
       "      <td>0.632914</td>\n",
       "      <td>0.133204</td>\n",
       "      <td>0.023673</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.114581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351352</td>\n",
       "      <td>0.157713</td>\n",
       "      <td>0.093795</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.104419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272326</td>\n",
       "      <td>0.132726</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.102082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298501</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.095325</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.097532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.263703</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.417945</td>\n",
       "      <td>0.237958</td>\n",
       "      <td>0.116779</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.081983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148958</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>0.052395</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.075511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.243525</td>\n",
       "      <td>0.092967</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.073792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265968</td>\n",
       "      <td>0.118856</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.066311</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.070178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307460</td>\n",
       "      <td>0.112218</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.042177</td>\n",
       "      <td>0.051610</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.069375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256071</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.114557</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.066165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121463</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.065356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177380</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.080594</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.061143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.182125</td>\n",
       "      <td>0.048985</td>\n",
       "      <td>0.056376</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.058222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112575</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.058142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106324</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.062101</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.054536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128217</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130672</td>\n",
       "      <td>0.030188</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.048348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.047291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.034702</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.043271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133664</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.042346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060777</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.094525</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.049491</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.039528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_row  var_col  precision_abs_mean  precision_square_mean  \\\n",
       "9         4        3            1.814102               3.350703   \n",
       "28        8        0            2.733715               8.125902   \n",
       "42        9        6            1.749803               3.249647   \n",
       "14        5        4            2.226012               5.043569   \n",
       "30        8        2            2.454144               7.617582   \n",
       "35        8        7            2.493917               6.742613   \n",
       "34        8        6            1.703585               3.150872   \n",
       "27        7        6            2.046760               4.622615   \n",
       "26        7        5            2.378639               6.571157   \n",
       "43        9        7            1.350220               1.914697   \n",
       "13        5        3            1.331463               1.821984   \n",
       "23        7        2            1.990554               4.338652   \n",
       "20        6        5            1.455548               2.347937   \n",
       "29        8        1            1.339578               1.884171   \n",
       "21        7        0            1.592268               2.946120   \n",
       "22        7        1            0.929049               0.905065   \n",
       "33        8        5            0.762545               0.879161   \n",
       "11        5        1            0.870805               0.804824   \n",
       "15        6        0            0.634740               0.500329   \n",
       "12        5        2            0.667903               0.632914   \n",
       "25        7        4            0.351352               0.157713   \n",
       "17        6        2            0.272326               0.132726   \n",
       "1         2        0            0.298501               0.136463   \n",
       "44        9        8            0.263703               0.101935   \n",
       "31        8        3            0.417945               0.237958   \n",
       "38        9        2            0.148958               0.039126   \n",
       "32        8        4            0.243525               0.092967   \n",
       "10        5        0            0.265968               0.118856   \n",
       "2         2        1            0.156284               0.038252   \n",
       "8         4        2            0.307460               0.112218   \n",
       "41        9        5            0.169441               0.042177   \n",
       "36        9        0            0.256071               0.093085   \n",
       "7         4        1            0.121463               0.021952   \n",
       "16        6        1            0.177380               0.043597   \n",
       "24        7        3            0.182125               0.048985   \n",
       "5         3        2            0.112575               0.021200   \n",
       "37        9        1            0.106324               0.016455   \n",
       "3         3        0            0.128217               0.024678   \n",
       "0         1        0            0.130672               0.030188   \n",
       "19        6        4            0.140205               0.025692   \n",
       "6         4        0            0.085129               0.010212   \n",
       "18        6        3            0.133664               0.025127   \n",
       "4         3        1            0.060777               0.005742   \n",
       "39        9        3            0.094525               0.010686   \n",
       "40        9        4            0.061587               0.006029   \n",
       "\n",
       "    cond_correlation_abs_mean  cond_correlation_square_mean       kld  \\\n",
       "9                    0.794375                      0.633263  0.387458   \n",
       "28                   0.694233                      0.484976  0.274952   \n",
       "42                   0.663920                      0.444391  0.224758   \n",
       "14                   0.579539                      0.340130  0.231575   \n",
       "30                   0.450815                      0.223649  0.171828   \n",
       "35                   0.441144                      0.213793  0.158864   \n",
       "34                   0.375385                      0.149876  0.153716   \n",
       "27                   0.474131                      0.244841  0.150999   \n",
       "26                   0.416982                      0.189040  0.159221   \n",
       "43                   0.410921                      0.174237  0.120154   \n",
       "13                   0.405705                      0.170207  0.133357   \n",
       "23                   0.418610                      0.181113  0.121703   \n",
       "20                   0.326312                      0.110318  0.116387   \n",
       "29                   0.450458                      0.212141  0.099663   \n",
       "21                   0.424231                      0.190895  0.114535   \n",
       "22                   0.327086                      0.110487  0.042398   \n",
       "33                   0.130099                      0.026249  0.078807   \n",
       "11                   0.299808                      0.092732  0.039535   \n",
       "15                   0.213002                      0.049767  0.038061   \n",
       "12                   0.133204                      0.023673  0.021040   \n",
       "25                   0.093795                      0.011432  0.019406   \n",
       "17                   0.072125                      0.008302  0.017230   \n",
       "1                    0.095325                      0.013157  0.016557   \n",
       "44                   0.080126                      0.009919  0.011623   \n",
       "31                   0.116779                      0.017567  0.011421   \n",
       "38                   0.052395                      0.004555  0.011910   \n",
       "32                   0.059315                      0.005291  0.007123   \n",
       "10                   0.069849                      0.007567  0.008582   \n",
       "2                    0.066311                      0.007179  0.010960   \n",
       "8                    0.096491                      0.011204  0.008307   \n",
       "41                   0.051610                      0.003867  0.009920   \n",
       "36                   0.114557                      0.017474  0.004728   \n",
       "7                    0.062389                      0.005912  0.007381   \n",
       "16                   0.080594                      0.009255  0.005145   \n",
       "24                   0.056376                      0.004755  0.006350   \n",
       "5                    0.039262                      0.002392  0.009081   \n",
       "37                   0.062101                      0.005512  0.007417   \n",
       "3                    0.059504                      0.005329  0.004229   \n",
       "0                    0.065359                      0.006809  0.003458   \n",
       "19                   0.047487                      0.002999  0.003516   \n",
       "6                    0.034702                      0.001738  0.003806   \n",
       "18                   0.051253                      0.003623  0.002191   \n",
       "4                    0.036282                      0.002079  0.002563   \n",
       "39                   0.049491                      0.003040  0.004473   \n",
       "40                   0.028389                      0.001390  0.003793   \n",
       "\n",
       "         iae  dependence  \n",
       "9   0.449599           1  \n",
       "28  0.431728           1  \n",
       "42  0.393844           1  \n",
       "14  0.357167           1  \n",
       "30  0.308868           1  \n",
       "35  0.305461           1  \n",
       "34  0.296173           1  \n",
       "27  0.285882           1  \n",
       "26  0.280657           1  \n",
       "43  0.262809           1  \n",
       "13  0.260150           1  \n",
       "23  0.259857           1  \n",
       "20  0.258485           0  \n",
       "29  0.253474           1  \n",
       "21  0.252404           1  \n",
       "22  0.177771           0  \n",
       "33  0.175546           1  \n",
       "11  0.163981           1  \n",
       "15  0.146056           0  \n",
       "12  0.114581           0  \n",
       "25  0.104419           0  \n",
       "17  0.102082           0  \n",
       "1   0.097532           0  \n",
       "44  0.084429           0  \n",
       "31  0.081983           0  \n",
       "38  0.075511           0  \n",
       "32  0.073792           1  \n",
       "10  0.072198           0  \n",
       "2   0.070178           0  \n",
       "8   0.069585           0  \n",
       "41  0.069375           0  \n",
       "36  0.066165           0  \n",
       "7   0.065356           0  \n",
       "16  0.061143           0  \n",
       "24  0.058222           0  \n",
       "5   0.058142           0  \n",
       "37  0.054536           0  \n",
       "3   0.051077           0  \n",
       "0   0.048348           0  \n",
       "19  0.047291           0  \n",
       "6   0.043271           0  \n",
       "18  0.042346           0  \n",
       "4   0.042285           0  \n",
       "39  0.042165           0  \n",
       "40  0.039528           0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.sort_values(\"iae\",ascending=False) #.sort_values(\"abs_mean\",ascending=False) #.sort_values(\"iae\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91dfe4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_row</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.189022</td>\n",
       "      <td>0.137937</td>\n",
       "      <td>0.144930</td>\n",
       "      <td>0.196948</td>\n",
       "      <td>0.183960</td>\n",
       "      <td>0.235504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_col</th>\n",
       "      <td>0.468889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307111</td>\n",
       "      <td>0.297321</td>\n",
       "      <td>0.171173</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>0.333087</td>\n",
       "      <td>0.322364</td>\n",
       "      <td>0.335415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.307111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>0.952042</td>\n",
       "      <td>0.954677</td>\n",
       "      <td>0.930567</td>\n",
       "      <td>0.961397</td>\n",
       "      <td>0.772905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_square_mean</th>\n",
       "      <td>0.189022</td>\n",
       "      <td>0.297321</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951779</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.933992</td>\n",
       "      <td>0.964822</td>\n",
       "      <td>0.772905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <td>0.137937</td>\n",
       "      <td>0.171173</td>\n",
       "      <td>0.952042</td>\n",
       "      <td>0.951779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.909223</td>\n",
       "      <td>0.941897</td>\n",
       "      <td>0.755259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <td>0.144930</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>0.954677</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915283</td>\n",
       "      <td>0.947167</td>\n",
       "      <td>0.758788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kld</th>\n",
       "      <td>0.196948</td>\n",
       "      <td>0.333087</td>\n",
       "      <td>0.930567</td>\n",
       "      <td>0.933992</td>\n",
       "      <td>0.909223</td>\n",
       "      <td>0.915283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981291</td>\n",
       "      <td>0.762317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iae</th>\n",
       "      <td>0.183960</td>\n",
       "      <td>0.322364</td>\n",
       "      <td>0.961397</td>\n",
       "      <td>0.964822</td>\n",
       "      <td>0.941897</td>\n",
       "      <td>0.947167</td>\n",
       "      <td>0.981291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependence</th>\n",
       "      <td>0.235504</td>\n",
       "      <td>0.335415</td>\n",
       "      <td>0.772905</td>\n",
       "      <td>0.772905</td>\n",
       "      <td>0.755259</td>\n",
       "      <td>0.758788</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0.783493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               var_row   var_col  precision_abs_mean  \\\n",
       "var_row                       1.000000  0.468889            0.184826   \n",
       "var_col                       0.468889  1.000000            0.307111   \n",
       "precision_abs_mean            0.184826  0.307111            1.000000   \n",
       "precision_square_mean         0.189022  0.297321            0.998419   \n",
       "cond_correlation_abs_mean     0.137937  0.171173            0.952042   \n",
       "cond_correlation_square_mean  0.144930  0.183228            0.954677   \n",
       "kld                           0.196948  0.333087            0.930567   \n",
       "iae                           0.183960  0.322364            0.961397   \n",
       "dependence                    0.235504  0.335415            0.772905   \n",
       "\n",
       "                              precision_square_mean  \\\n",
       "var_row                                    0.189022   \n",
       "var_col                                    0.297321   \n",
       "precision_abs_mean                         0.998419   \n",
       "precision_square_mean                      1.000000   \n",
       "cond_correlation_abs_mean                  0.951779   \n",
       "cond_correlation_square_mean               0.955336   \n",
       "kld                                        0.933992   \n",
       "iae                                        0.964822   \n",
       "dependence                                 0.772905   \n",
       "\n",
       "                              cond_correlation_abs_mean  \\\n",
       "var_row                                        0.137937   \n",
       "var_col                                        0.171173   \n",
       "precision_abs_mean                             0.952042   \n",
       "precision_square_mean                          0.951779   \n",
       "cond_correlation_abs_mean                      1.000000   \n",
       "cond_correlation_square_mean                   0.999078   \n",
       "kld                                            0.909223   \n",
       "iae                                            0.941897   \n",
       "dependence                                     0.755259   \n",
       "\n",
       "                              cond_correlation_square_mean       kld  \\\n",
       "var_row                                           0.144930  0.196948   \n",
       "var_col                                           0.183228  0.333087   \n",
       "precision_abs_mean                                0.954677  0.930567   \n",
       "precision_square_mean                             0.955336  0.933992   \n",
       "cond_correlation_abs_mean                         0.999078  0.909223   \n",
       "cond_correlation_square_mean                      1.000000  0.915283   \n",
       "kld                                               0.915283  1.000000   \n",
       "iae                                               0.947167  0.981291   \n",
       "dependence                                        0.758788  0.762317   \n",
       "\n",
       "                                   iae  dependence  \n",
       "var_row                       0.183960    0.235504  \n",
       "var_col                       0.322364    0.335415  \n",
       "precision_abs_mean            0.961397    0.772905  \n",
       "precision_square_mean         0.964822    0.772905  \n",
       "cond_correlation_abs_mean     0.941897    0.755259  \n",
       "cond_correlation_square_mean  0.947167    0.758788  \n",
       "kld                           0.981291    0.762317  \n",
       "iae                           1.000000    0.783493  \n",
       "dependence                    0.783493    1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.corr(\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "531c7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_row</th>\n",
       "      <th>var_col</th>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <th>precision_square_mean</th>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <th>kld</th>\n",
       "      <th>iae</th>\n",
       "      <th>dependence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_row</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.248475</td>\n",
       "      <td>0.239255</td>\n",
       "      <td>0.191632</td>\n",
       "      <td>0.141357</td>\n",
       "      <td>0.147071</td>\n",
       "      <td>0.219018</td>\n",
       "      <td>0.276395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_col</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317690</td>\n",
       "      <td>0.265355</td>\n",
       "      <td>0.241185</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.293854</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.345494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_abs_mean</th>\n",
       "      <td>0.248475</td>\n",
       "      <td>0.317690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961674</td>\n",
       "      <td>0.918673</td>\n",
       "      <td>0.830883</td>\n",
       "      <td>0.880786</td>\n",
       "      <td>0.943771</td>\n",
       "      <td>0.827607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_square_mean</th>\n",
       "      <td>0.239255</td>\n",
       "      <td>0.265355</td>\n",
       "      <td>0.961674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825247</td>\n",
       "      <td>0.766942</td>\n",
       "      <td>0.819368</td>\n",
       "      <td>0.857331</td>\n",
       "      <td>0.748524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_abs_mean</th>\n",
       "      <td>0.191632</td>\n",
       "      <td>0.241185</td>\n",
       "      <td>0.918673</td>\n",
       "      <td>0.825247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963329</td>\n",
       "      <td>0.956603</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>0.807402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond_correlation_square_mean</th>\n",
       "      <td>0.141357</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.830883</td>\n",
       "      <td>0.766942</td>\n",
       "      <td>0.963329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>0.938532</td>\n",
       "      <td>0.730431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kld</th>\n",
       "      <td>0.147071</td>\n",
       "      <td>0.293854</td>\n",
       "      <td>0.880786</td>\n",
       "      <td>0.819368</td>\n",
       "      <td>0.956603</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965960</td>\n",
       "      <td>0.770968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iae</th>\n",
       "      <td>0.219018</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.943771</td>\n",
       "      <td>0.857331</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>0.938532</td>\n",
       "      <td>0.965960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependence</th>\n",
       "      <td>0.276395</td>\n",
       "      <td>0.345494</td>\n",
       "      <td>0.827607</td>\n",
       "      <td>0.748524</td>\n",
       "      <td>0.807402</td>\n",
       "      <td>0.730431</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>0.825776</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               var_row   var_col  precision_abs_mean  \\\n",
       "var_row                       1.000000  0.500000            0.248475   \n",
       "var_col                       0.500000  1.000000            0.317690   \n",
       "precision_abs_mean            0.248475  0.317690            1.000000   \n",
       "precision_square_mean         0.239255  0.265355            0.961674   \n",
       "cond_correlation_abs_mean     0.191632  0.241185            0.918673   \n",
       "cond_correlation_square_mean  0.141357  0.204713            0.830883   \n",
       "kld                           0.147071  0.293854            0.880786   \n",
       "iae                           0.219018  0.318321            0.943771   \n",
       "dependence                    0.276395  0.345494            0.827607   \n",
       "\n",
       "                              precision_square_mean  \\\n",
       "var_row                                    0.239255   \n",
       "var_col                                    0.265355   \n",
       "precision_abs_mean                         0.961674   \n",
       "precision_square_mean                      1.000000   \n",
       "cond_correlation_abs_mean                  0.825247   \n",
       "cond_correlation_square_mean               0.766942   \n",
       "kld                                        0.819368   \n",
       "iae                                        0.857331   \n",
       "dependence                                 0.748524   \n",
       "\n",
       "                              cond_correlation_abs_mean  \\\n",
       "var_row                                        0.191632   \n",
       "var_col                                        0.241185   \n",
       "precision_abs_mean                             0.918673   \n",
       "precision_square_mean                          0.825247   \n",
       "cond_correlation_abs_mean                      1.000000   \n",
       "cond_correlation_square_mean                   0.963329   \n",
       "kld                                            0.956603   \n",
       "iae                                            0.982771   \n",
       "dependence                                     0.807402   \n",
       "\n",
       "                              cond_correlation_square_mean       kld  \\\n",
       "var_row                                           0.141357  0.147071   \n",
       "var_col                                           0.204713  0.293854   \n",
       "precision_abs_mean                                0.830883  0.880786   \n",
       "precision_square_mean                             0.766942  0.819368   \n",
       "cond_correlation_abs_mean                         0.963329  0.956603   \n",
       "cond_correlation_square_mean                      1.000000  0.973013   \n",
       "kld                                               0.973013  1.000000   \n",
       "iae                                               0.938532  0.965960   \n",
       "dependence                                        0.730431  0.770968   \n",
       "\n",
       "                                   iae  dependence  \n",
       "var_row                       0.219018    0.276395  \n",
       "var_col                       0.318321    0.345494  \n",
       "precision_abs_mean            0.943771    0.827607  \n",
       "precision_square_mean         0.857331    0.748524  \n",
       "cond_correlation_abs_mean     0.982771    0.807402  \n",
       "cond_correlation_square_mean  0.938532    0.730431  \n",
       "kld                           0.965960    0.770968  \n",
       "iae                           1.000000    0.825776  \n",
       "dependence                    0.825776    1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.corr(\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ff53e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x3562c9f10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(merged[\"dependence\"],merged[\"iae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.transformation,simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[0],simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[1],simulated_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plot_splines(model.decorrelation_layers[2],simulated_data_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mctm_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
